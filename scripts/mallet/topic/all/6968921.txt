>I think that's a broad mischaraterization of functional programmingYes, but it's a common one, because its a correct characterization of Haskell and Haskell-derived languages.Functional programming is very popular and used all the time. Consider jQuery, SQL or LINQ. Consider things like Facebook's react library. Functional programming is a very usefull tool, in a much larger toolset.But it has a bad reputation by being associated with the language design mess that is Haskell. And here we have a derived language, making it even worse.The problem is not the functional nature of the language. It's the syntax rooted in ancient (paper) math combined with lazy evalution, and the illusions perpetuated by their followers.To illustrate just how far anti-human this Haskell dialect is: _it uses greek symbols_. This alone excludes 99.99% of the world population.Yet, the language designer's intent is for this to 'cure programming'. To improve things. Yes, what computer science needs is more symbols, that aren't even on our keyboards. Symbols a majority of the world doesn't even know how to pronounce.To ask the question "what does that lambda symbol mean?" one would have to make a screenshot and mark it. A new student having to learn the language, lacks both the ability to verbalize, as well as type, the symbol. How out of reach with reality can one be to suggest this would ever become mainstream?It was mainstream. 2500 years ago. We don't calculate the speed of a space rocket using horse power, and we shouldn't encourage anyone introducing greek symbols into a programming language that is intented to me more than esoteric.I'm often baffled why this is not more appearant to everyone. Haskell and haskell derived languages are failing to become mainstream, because:- they were not designed with that goal in mind (actual statements of the language designers)- the syntax is only friendly to those humans that wasted their life, studying the variant of math syntax, that stopped having an economic value the moment computers were invented. The syntax isn't optimized to limit the cognitive load of actual real world use-cases. Instead, it's optimized to make a fibonacci function look as much like ancient math as possible. Has anyone ever beed paid to code that function? No. Is this function particularly difficult to implement in other languages? No.- They pretend computers don't exist. Haskell implementations have operational semantics: they are just under-specified, unpredictable and implementation-specific.  Pretending computers don't exist, doesn't solve any problem in computer science. Performance and scalablility don't need to be good; they need to be predictable by a human. The algorithmic complexitiy of any operation, should not became a secret hidden behind a curtain of mystery.- The core problem we have with large code-bases is coordination of state. This requires standardisation and normalisation.. By making all state explicit arguments, and being all religious about it, you end with a zillion competing ways to structure and reflect on the state. Knee-deep in monad transformers that convert one type of state to some other type of state, one has to wonder: is it so bad that most programming languages just wrap every computation is one standarized state-monad? No! That's actually a good thing.- The cult surrounding it keeps propagating misconceptions about the nature of computation itself. Take your comment for example:>Ultimately, functional programming lets you talk about what where imperative languages force you to talk about how.This not true. Functional programming does not let you talk about the what. Haskell definately doesn't let you just talk about the what. If i put "e = m * c" into haskell, i won't suddenly get m, given an e. Just because the operational semantics of Haskell are under-specified and incomprehensible by anyone without an academic background and years of experience wasting time with Haskell, doesn't mean there is no operational semantics. At it's core, it's just a term rewriter with a lot of fine print, that nobody bothered to properly document, and which is far from intuitive.>even concepts like mutable variables and loops are not particularity intuitive.Correct. But combined with term rewriting, dataflow and logic programming, and a bunch of other paradigms the best tools we've got to deal with a wide scenario of use-cases.Functional programming is doing fine. Static type analysis is a great tool and we all use it often, but not exclusively, because it is the enemy of exploration. (A run-time type error, is one that carries real example data!)It's just that a lazy evaluated language drenched in a syntax that had its peak a millenium ago, pushed by fanatic supporters combined with completely unrealistic notions of computation and real-world use-cases, isn't contributing.And this Haskell derivate, is even worse. It has an actual lambda symbol. Everything about it screams to the uninitiated: i don't want to be understand. I am exclusive.The notion we need more ancient math syntax in a modern programming language, is similar to the notion we need more Shakesperian acting in Breaking Bad. People have been using math to produce economic value. They are just using languages that are optimized for their cultural background (using the dictionary and alphabet of our times), their cognitive skills, modern technology (auto-complete, refactoring) and their actual use-cases. These languages are commonly referred to as "mainstream programming languages".