{
  "hits": [
    {
      "created_at": "2012-10-03T07:42:23.000Z",
      "title": "",
      "url": "",
      "author": "ot",
      "points": 35,
      "story_text": null,
      "comment_text": "This is great news! When I was at MSR I heard the rumor that they wanted to <i>sell</i> Z3, not open-source it!<p>Some context, as not everybody may have heard about it.<p>Z3 is an SMT [1] solver. Since SMT generalizes SAT, it is clearly NP-hard, so a number of heuristics are needed. In particular, Z3 won several SMT speed competitions, so it has been for long the fastest SMT solver.<p>You can play with it online using its Lisp-like native language [2] or using the Python bindings [3]<p>The reason SMT is important is that several static analysis tools work by encoding the program constraints (such as pre/post conditions, invariants, ...) into a big formula. The satisfiability of this formula determines the correctness of the program, and sometimes assignments can be translated back to counterexamples to program correctness.<p>[1] <a href=\"http://en.wikipedia.org/wiki/Satisfiability_Modulo_Theories\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Satisfiability_Modulo_Theories</a><p>[2] <a href=\"http://rise4fun.com/Z3/bit-count\" rel=\"nofollow\">http://rise4fun.com/Z3/bit-count</a><p>[3] <a href=\"http://rise4fun.com/Z3Py/nonlinear\" rel=\"nofollow\">http://rise4fun.com/Z3Py/nonlinear</a>",
      "num_comments": null,
      "story_id": 4606231,
      "story_title": "The Z3 theorem prover is now open source",
      "story_url": "http://research.microsoft.com/en-us/um/people/leonardo/blog/2012/10/02/open-z3.html",
      "parent_id": 4606231,
      "created_at_i": 1349250143,
      "_tags": [
        "comment",
        "author_ot",
        "story_4606231"
      ],
      "objectID": "4606306",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "ot",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is great news! When I was at MSR I heard the rumor that they wanted to <i>sell</i> Z3, not open-source it!<p>Some context, as not everybody may have heard about it.<p>Z3 is an SMT [1] solver. Since SMT generalizes SAT, it is clearly NP-hard, so a number of heuristics are needed. In particular, Z3 won several SMT speed competitions, so it has been for long the fastest SMT solver.<p>You can play with it online using its Lisp-like native language [2] or using the Python bindings [3]<p>The reason SMT is important is that several <em>static</em> <em>analysis</em> <em>tools</em> work by encoding the program constraints (such as pre/post conditions, invariants, ...) into a big formula. The satisfiability of this formula determines the correctness of the program, and sometimes assignments can be translated back to counterexamples to program correctness.<p>[1] <a href=\"http://en.wikipedia.org/wiki/Satisfiability_Modulo_Theories\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Satisfiability_Modulo_Theories</a><p>[2] <a href=\"http://rise4fun.com/Z3/bit-count\" rel=\"nofollow\">http://rise4fun.com/Z3/bit-count</a><p>[3] <a href=\"http://rise4fun.com/Z3Py/nonlinear\" rel=\"nofollow\">http://rise4fun.com/Z3Py/nonlinear</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Z3 theorem prover is now open source",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://research.microsoft.com/en-us/um/people/leonardo/blog/2012/10/02/open-z3.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-28T02:02:45.000Z",
      "title": null,
      "url": null,
      "author": "rdtsc",
      "points": 24,
      "story_text": null,
      "comment_text": "Very good comparison, stuff that most other blogs don&#x27;t talk much about -- scheduling, fault isolation, garbage collection strategies. I guess they don&#x27;t because other frameworks&#x2F;languages don&#x27;t provide that. It usually stays at syntax level with obligatory mention of generics.<p>Fault isolation and pauseless garbage collection is something that is very important in some contexts. Often the need for it becomes apparent the second time around, after one version of the system has been plagued by large mutable shared state bugs, or strange, un-predictable response times in a highly concurrent system.<p>Do you pay in terms of raw CPU performance by copying messages and keeping private heaps per lightweight process? Yes you do. There are no magic unicorns behind the scene.  That is the trade-off you get for getting fault isolation and soft realtime properties.  But keep this in mind, one of the biggest slowdowns a system incurs is when it goes from working to crashing and not working.<p>Also, no matter how strong the static compile checking is, your system will still crash in production. It is usually a hard bug that has been lurking around not a simple &quot;I thought it was an int but got a string&quot;, those are caught early on. It will probably be something subtle and hard to reproduce. Can your system tolerate that kind of a crash in a graceful way? Sometimes you need that.<p>In the end, it is good for both systems to be around. If you need fault tolerance, optimization for low latency responses, supervision strategies, built-in inter-node clustering(node = OS process or instance of running Erlang BEAM VM) you cannot get that in any other way easily.<p>Now, one could think of trying to replicate some of the things Erlang provides. Like say build tools static analysis tools to check if go-routines end up accessing shared state. Or say, devise a strategy to use channels-based supervision tree. Heck, if you don&#x27;t have too many concurrency contexts (processes, go-routines) you can always fall back on OS process-based isolation and use IPC (+ ZMQ for example), as a mailbox. But then again Erlang provides that in one package.",
      "num_comments": null,
      "story_id": 7657394,
      "story_title": "Some thoughts on Go and Erlang",
      "story_url": "http://blog.erlware.org/2014/04/27/some-thoughts-on-go-and-erlang/",
      "parent_id": 7657394,
      "created_at_i": 1398650565,
      "_tags": [
        "comment",
        "author_rdtsc",
        "story_7657394"
      ],
      "objectID": "7657873",
      "_highlightResult": {
        "author": {
          "value": "rdtsc",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Very good comparison, stuff that most other blogs don't talk much about -- scheduling, fault isolation, garbage collection strategies. I guess they don't because other frameworks/languages don't provide that. It usually stays at syntax level with obligatory mention of generics.<p>Fault isolation and pauseless garbage collection is something that is very important in some contexts. Often the need for it becomes apparent the second time around, after one version of the system has been plagued by large mutable shared state bugs, or strange, un-predictable response times in a highly concurrent system.<p>Do you pay in terms of raw CPU performance by copying messages and keeping private heaps per lightweight process? Yes you do. There are no magic unicorns behind the scene.  That is the trade-off you get for getting fault isolation and soft realtime properties.  But keep this in mind, one of the biggest slowdowns a system incurs is when it goes from working to crashing and not working.<p>Also, no matter how strong the <em>static</em> compile checking is, your system will still crash in production. It is usually a hard bug that has been lurking around not a simple &quot;I thought it was an int but got a string&quot;, those are caught early on. It will probably be something subtle and hard to reproduce. Can your system tolerate that kind of a crash in a graceful way? Sometimes you need that.<p>In the end, it is good for both systems to be around. If you need fault tolerance, optimization for low latency responses, supervision strategies, built-in inter-node clustering(node = OS process or instance of running Erlang BEAM VM) you cannot get that in any other way easily.<p>Now, one could think of trying to replicate some of the things Erlang provides. Like say build <em>tools</em> <em>static</em> <em>analysis</em> <em>tools</em> to check if go-routines end up accessing shared state. Or say, devise a strategy to use channels-based supervision tree. Heck, if you don't have too many concurrency contexts (processes, go-routines) you can always fall back on OS process-based isolation and use IPC (+ ZMQ for example), as a mailbox. But then again Erlang provides that in one package.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Some thoughts on Go and Erlang",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.erlware.org/2014/04/27/some-thoughts-on-go-and-erlang/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-02T19:51:24.000Z",
      "title": null,
      "url": null,
      "author": "xenadu02",
      "points": 22,
      "story_text": null,
      "comment_text": "Heartbleed. Majority of all SSL keys on the internet compromised. All ~2 billion of humans on the internet required to change their passwords due to a single mistake by a single programmer using C. That&#x27;s billions of human beings wasting hours either changing all their passwords or having their money, identities, medical records, and more stolen because they didn&#x27;t. Having their accounts hijacked. For all we know totalitarian governments have already exploited this to monitor citizens and torture or kill them.<p>If that isn&#x27;t enough, how about goto fail? All the IIS exploits in v4&#x2F;5? Various Windows RPC overflows, WMF overflows, SQL Slammer, et al? How many billions in damages have been caused by stack smashing and buffer overflows? How many millions of hours of manpower wasted cleaning up after these errors? Toyota killed some people because their dumb code overwrote memory, blasting the OS task tables causing the watchdog task to stop getting CPU time, meaning nothing provided a stopgap against unintended acceleration. People are <i></i>literally<i></i> dying because we can&#x27;t fucking let go of C.<p>C is like saying &quot;forget seat belts, child seats, anti-lock breaks, and adaptive steering! How can I power-slide? I want full control; I need to pump the breaks. People should just drive better, then we&#x27;d have fewer accidents&quot;.<p>We&#x27;ve been trying to &quot;drive better&quot; for decades (Valgrind, lint, code reviews, static analysis tools, education, ASLR, NX protection, et al). We still regularly see massive security-smashing epic failures.<p>It hasn&#x27;t worked. Furthermore the C standard library has been proven turing-complete for ROP gadgets in the presence of a buffer overflow. So no matter what you do, the presence of a single stack smash is enough to allow code execution, subject to payload size limits and execution time.<p>At some point we have to admit C is no longer acceptable. Not for libraries, not for drivers, not for operating systems. It has to go.<p>All the performance benefits ever derived from writing everything in C has been more than erased, by orders of magnitude, by the damage caused from even simple innocent mistakes.<p>Software allows us as programmers to greatly magnify our impact on the world; we like to think of that in positive ways. But the inverse is also true: thanks to the continued use of non-memory-safe languages we have the power to negatively affect the world on a massive scale.<p>It is unethical to continue writing code in non-memory-safe C or C-based languages, for any purpose. Period.",
      "num_comments": null,
      "story_id": 7835099,
      "story_title": "Introducing Swift",
      "story_url": "https://developer.apple.com/swift/",
      "parent_id": 7835275,
      "created_at_i": 1401738684,
      "_tags": [
        "comment",
        "author_xenadu02",
        "story_7835099"
      ],
      "objectID": "7835802",
      "_highlightResult": {
        "author": {
          "value": "xenadu02",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Heartbleed. Majority of all SSL keys on the internet compromised. All ~2 billion of humans on the internet required to change their passwords due to a single mistake by a single programmer using C. That's billions of human beings wasting hours either changing all their passwords or having their money, identities, medical records, and more stolen because they didn't. Having their accounts hijacked. For all we know totalitarian governments have already exploited this to monitor citizens and torture or kill them.<p>If that isn't enough, how about goto fail? All the IIS exploits in v4/5? Various Windows RPC overflows, WMF overflows, SQL Slammer, et al? How many billions in damages have been caused by stack smashing and buffer overflows? How many millions of hours of manpower wasted cleaning up after these errors? Toyota killed some people because their dumb code overwrote memory, blasting the OS task tables causing the watchdog task to stop getting CPU time, meaning nothing provided a stopgap against unintended acceleration. People are <i></i>literally<i></i> dying because we can't fucking let go of C.<p>C is like saying &quot;forget seat belts, child seats, anti-lock breaks, and adaptive steering! How can I power-slide? I want full control; I need to pump the breaks. People should just drive better, then we'd have fewer accidents&quot;.<p>We've been trying to &quot;drive better&quot; for decades (Valgrind, lint, code reviews, <em>static</em> <em>analysis</em> <em>tools</em>, education, ASLR, NX protection, et al). We still regularly see massive security-smashing epic failures.<p>It hasn't worked. Furthermore the C standard library has been proven turing-complete for ROP gadgets in the presence of a buffer overflow. So no matter what you do, the presence of a single stack smash is enough to allow code execution, subject to payload size limits and execution time.<p>At some point we have to admit C is no longer acceptable. Not for libraries, not for drivers, not for operating systems. It has to go.<p>All the performance benefits ever derived from writing everything in C has been more than erased, by orders of magnitude, by the damage caused from even simple innocent mistakes.<p>Software allows us as programmers to greatly magnify our impact on the world; we like to think of that in positive ways. But the inverse is also true: thanks to the continued use of non-memory-safe languages we have the power to negatively affect the world on a massive scale.<p>It is unethical to continue writing code in non-memory-safe C or C-based languages, for any purpose. Period.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Introducing Swift",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://developer.apple.com/swift/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-27T17:58:41.000Z",
      "title": null,
      "url": null,
      "author": "JoshTriplett",
      "points": 20,
      "story_text": null,
      "comment_text": "Personally, I find it painful that the compiler detects this kind of undefined behavior, and silently uses it for optimization, rather then stopping and emitting an error.  In the printf example, the compiler could trivially emit an error saying &quot;NULL check on p after dereference of p&quot;, and that would catch a large class of bugs.  (Some static analysis tools check for exactly that.)  Similarly, a loop access statically determined to fall outside the bounds of the array should produce an error.",
      "num_comments": null,
      "story_id": 7954944,
      "story_title": "Undefined behavior can result in time travel",
      "story_url": "http://blogs.msdn.com/b/oldnewthing/archive/2014/06/27/10537746.aspx",
      "parent_id": 7954944,
      "created_at_i": 1403891921,
      "_tags": [
        "comment",
        "author_JoshTriplett",
        "story_7954944"
      ],
      "objectID": "7955334",
      "_highlightResult": {
        "author": {
          "value": "JoshTriplett",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Personally, I find it painful that the compiler detects this kind of undefined behavior, and silently uses it for optimization, rather then stopping and emitting an error.  In the printf example, the compiler could trivially emit an error saying &quot;NULL check on p after dereference of p&quot;, and that would catch a large class of bugs.  (Some <em>static</em> <em>analysis</em> <em>tools</em> check for exactly that.)  Similarly, a loop access statically determined to fall outside the bounds of the array should produce an error.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Undefined behavior can result in time travel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.msdn.com/b/oldnewthing/archive/2014/06/27/10537746.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T06:39:52.000Z",
      "title": null,
      "url": null,
      "author": "tikhonj",
      "points": 18,
      "story_text": null,
      "comment_text": "This is exactly the sort of thing Haskell is great at. First, the type system catches all sorts of errors at compile time (both null-pointer and printf issues cannot come up in Haskell).<p>However, more fundamentally, Haskell code just naturally provides <i>much</i> more information to static analysis tools than any other language I've worked with. Even if the level of tooling is not there yet (I haven't worked on any large projects, so I am not entirely familiar with it) the <i>potential</i> for these tools is much greater in Haskell. I think programs like HLint are already very thorough. I've just been using Haskell as more of a hacker language than a \"bondage and discipline\" language and haven't bothered with these tools :)",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388290,
      "created_at_i": 1324708792,
      "_tags": [
        "comment",
        "author_tikhonj",
        "story_3388290"
      ],
      "objectID": "3388386",
      "_highlightResult": {
        "author": {
          "value": "tikhonj",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is exactly the sort of thing Haskell is great at. First, the type system catches all sorts of errors at compile time (both null-pointer and printf issues cannot come up in Haskell).<p>However, more fundamentally, Haskell code just naturally provides <i>much</i> more information to <em>static</em> <em>analysis</em> <em>tools</em> than any other language I've worked with. Even if the level of tooling is not there yet (I haven't worked on any large projects, so I am not entirely familiar with it) the <i>potential</i> for these <em>tools</em> is much greater in Haskell. I think programs like HLint are already very thorough. I've just been using Haskell as more of a hacker language than a \"bondage and discipline\" language and haven't bothered with these <em>tools</em> :)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2014-02-23T05:46:55.000Z",
      "title": null,
      "url": null,
      "author": "blazespin",
      "points": 17,
      "story_text": null,
      "comment_text": "It is absolutely abnormal for companies like Apple to release core security bugs this shallow that could have been easily discovered by straightforward unit tests and static analysis tools.<p>This is why it&#x27;s a big deal.",
      "num_comments": null,
      "story_id": 7284099,
      "story_title": "On the Timing of iOS’s SSL Vulnerability and Apple’s ‘Addition’ to NSA’s PRISM",
      "story_url": "http://daringfireball.net/2014/02/apple_prism",
      "parent_id": 7284751,
      "created_at_i": 1393134415,
      "_tags": [
        "comment",
        "author_blazespin",
        "story_7284099"
      ],
      "objectID": "7285064",
      "_highlightResult": {
        "author": {
          "value": "blazespin",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It is absolutely abnormal for companies like Apple to release core security bugs this shallow that could have been easily discovered by straightforward unit tests and <em>static</em> <em>analysis</em> <em>tools</em>.<p>This is why it's a big deal.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "On the Timing of iOS’s SSL Vulnerability and Apple’s ‘Addition’ to NSA’s PRISM",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://daringfireball.net/2014/02/apple_prism",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-27T01:59:33.000Z",
      "title": null,
      "url": null,
      "author": "pcwalton",
      "points": 16,
      "story_text": null,
      "comment_text": "&gt; lack of module system<p>ES6 fixes this with, well, a module system.<p>&gt; weak-typing,<p>Yup, this is a problem.<p>&gt; verbose function syntax,<p>ES6 fixes this with arrow functions.<p>&gt; late binding<p>Does this just mean dynamic typing? Well, yes, JavaScript is dynamically typed, but I wouldn&#x27;t call that a language flaw. Static vs. dynamic typing is a tradeoff.<p>&gt; which has led to the creation of various static analysis tools to alleviate this language flaw<p>The footnote talks about JSLint and friends, but none of those impose a type system, which means that they do nothing about dynamic typing.<p>&gt; but with limited success (there is even a static type checker)<p>Well, yeah. It&#x27;s very hard (read: &quot;research problem&quot;) to impose a good static typechecker on a dynamically typed system, though.<p>&gt; finicky equality&#x2F;automatic conversion<p>Yeah, this is bad. I really wish tools like restrict mode [1] had caught on: together with ES6 they eliminate a lot of what people dislike about JavaScript.<p>&gt; this behaviour,<p>Fixed in ES6 if you use arrow functions (finally!)<p>&gt; and lack of static types.<p>Again, I wouldn&#x27;t say it &quot;sucks&quot; for this reason, just that it&#x27;s dynamically typed. That&#x27;s a tradeoff.<p>[1]: <a href=\"http://restrictmode.org/\" rel=\"nofollow\">http:&#x2F;&#x2F;restrictmode.org&#x2F;</a>",
      "num_comments": null,
      "story_id": 7653013,
      "story_title": "The JavaScript Problem",
      "story_url": "http://www.haskell.org/haskellwiki/The_JavaScript_Problem",
      "parent_id": 7653013,
      "created_at_i": 1398563973,
      "_tags": [
        "comment",
        "author_pcwalton",
        "story_7653013"
      ],
      "objectID": "7653594",
      "_highlightResult": {
        "author": {
          "value": "pcwalton",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; lack of module system<p>ES6 fixes this with, well, a module system.<p>&gt; weak-typing,<p>Yup, this is a problem.<p>&gt; verbose function syntax,<p>ES6 fixes this with arrow functions.<p>&gt; late binding<p>Does this just mean dynamic typing? Well, yes, JavaScript is dynamically typed, but I wouldn't call that a language flaw. <em>Static</em> vs. dynamic typing is a tradeoff.<p>&gt; which has led to the creation of various <em>static</em> <em>analysis</em> <em>tools</em> to alleviate this language flaw<p>The footnote talks about JSLint and friends, but none of those impose a type system, which means that they do nothing about dynamic typing.<p>&gt; but with limited success (there is even a <em>static</em> type checker)<p>Well, yeah. It's very hard (read: &quot;research problem&quot;) to impose a good <em>static</em> typechecker on a dynamically typed system, though.<p>&gt; finicky equality/automatic conversion<p>Yeah, this is bad. I really wish <em>tools</em> like restrict mode [1] had caught on: together with ES6 they eliminate a lot of what people dislike about JavaScript.<p>&gt; this behaviour,<p>Fixed in ES6 if you use arrow functions (finally!)<p>&gt; and lack of <em>static</em> types.<p>Again, I wouldn't say it &quot;sucks&quot; for this reason, just that it's dynamically typed. That's a tradeoff.<p>[1]: <a href=\"http://restrictmode.org/\" rel=\"nofollow\">http://restrictmode.org/</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The JavaScript Problem",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.haskell.org/haskellwiki/The_JavaScript_Problem",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-01T15:09:15.000Z",
      "title": null,
      "url": null,
      "author": "walterbell",
      "points": 15,
      "story_text": null,
      "comment_text": "Thanks to Jan Beulich, the SUSE Xen maintainer in Germany who is credited with finding this x86 HVM vulnerability.<p>It would be helpful if errata announcements included documentation of the static analysis tools, code review process or automated testing techniques which identified the weakness, along with a postmortem of previous audits of relevant code paths.<p>What made it possible for this issue to be identified now, when the issue escaped previous analysis, audits and tests? Such process improvement knowledge is possibly more valuable to the worldwide technical community than any point fix.<p>Heartbleed was discovered by an external party, but this issue which affects the data of millions of users was found by the originating open-source project. Kudos to Jan for finding this cross-domain escalation.",
      "num_comments": null,
      "story_id": 8393863,
      "story_title": "XSA-108 Advisory",
      "story_url": "http://xenbits.xen.org/xsa/advisory-108.html",
      "parent_id": 8393863,
      "created_at_i": 1412176155,
      "_tags": [
        "comment",
        "author_walterbell",
        "story_8393863"
      ],
      "objectID": "8395009",
      "_highlightResult": {
        "author": {
          "value": "walterbell",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Thanks to Jan Beulich, the SUSE Xen maintainer in Germany who is credited with finding this x86 HVM vulnerability.<p>It would be helpful if errata announcements included documentation of the <em>static</em> <em>analysis</em> <em>tools</em>, code review process or automated testing techniques which identified the weakness, along with a postmortem of previous audits of relevant code paths.<p>What made it possible for this issue to be identified now, when the issue escaped previous <em>analysis</em>, audits and tests? Such process improvement knowledge is possibly more valuable to the worldwide technical community than any point fix.<p>Heartbleed was discovered by an external party, but this issue which affects the data of millions of users was found by the originating open-source project. Kudos to Jan for finding this cross-domain escalation.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "XSA-108 Advisory",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://xenbits.xen.org/xsa/advisory-108.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-22T03:43:31.000Z",
      "title": "",
      "url": "",
      "author": "timothya",
      "points": 13,
      "story_text": null,
      "comment_text": "<i>IDE like Eclipse</i><p>You don't need to write Dart in the Dart Editor if you don't want the IDE experience. I happily write Dart in Sublime, and Dart has command-line tools that I can use to validate the code that I write.<p><i>But web developers, who are the primary producers of JavaScript, will happily stick with Node.js, CoffeeScript, or plain JavaScript.</i><p>If web developers are happy with the tools they have, then that's just fine. The Dart team isn't trying to replace JavaScript, but instead provide another option for web development. What I think the Dart team is finding is that there are a lot of people that are having trouble with putting together all the pieces just to build a web app. This is especially true if you are new to the web platform, and you're familiar with the development from other places. Dart provides a very consistent platform that you can build web applications with, and you don't need to worry about jumping through all the hoops that normal web development requires.<p><i>By way of contrast, consider Go. Go is (in my opinion) an extremely successful successor to C, in terms of its design. It fixes a handful of problems with C (strings, and I would argue pointer arithmetic), and modernizes and streamlines it. The interface system is fantastic. In terms of its design, I have nothing but good things to say about Go.</i><p>In a way, this is how I see Dart too (though Dart is a much newer platform, not yet out of beta). Dart aims to fix a handful of problems with JavaScript (like better scoping semantics, a built-in module system, better toolability and static analysis tools, etc.), and then also takes the existing browser APIs and modernizes and streamlines them (for example, all of the core browser APIs use a consistent Future-based API for asynchronous values, which cleans up a lot of messy code that you'd ordinarily see in JavaScript web application code).<p><i>Is it any surprise that Dart has failed to take off?</i><p>It's not at 1.0 yet. I still think there is plenty of room for improvement, and plenty of time for adoption.",
      "num_comments": null,
      "story_id": 5747961,
      "story_title": "Dart Is Not the Language You Think It Is",
      "story_url": "http://programming.oreilly.com/2013/05/dart-is-not-the-language-you-think-it-is.html",
      "parent_id": 5748539,
      "created_at_i": 1369194211,
      "_tags": [
        "comment",
        "author_timothya",
        "story_5747961"
      ],
      "objectID": "5748744",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "timothya",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>IDE like Eclipse</i><p>You don't need to write Dart in the Dart Editor if you don't want the IDE experience. I happily write Dart in Sublime, and Dart has command-line <em>tools</em> that I can use to validate the code that I write.<p><i>But web developers, who are the primary producers of JavaScript, will happily stick with Node.js, CoffeeScript, or plain JavaScript.</i><p>If web developers are happy with the <em>tools</em> they have, then that's just fine. The Dart team isn't trying to replace JavaScript, but instead provide another option for web development. What I think the Dart team is finding is that there are a lot of people that are having trouble with putting together all the pieces just to build a web app. This is especially true if you are new to the web platform, and you're familiar with the development from other places. Dart provides a very consistent platform that you can build web applications with, and you don't need to worry about jumping through all the hoops that normal web development requires.<p><i>By way of contrast, consider Go. Go is (in my opinion) an extremely successful successor to C, in terms of its design. It fixes a handful of problems with C (strings, and I would argue pointer arithmetic), and modernizes and streamlines it. The interface system is fantastic. In terms of its design, I have nothing but good things to say about Go.</i><p>In a way, this is how I see Dart too (though Dart is a much newer platform, not yet out of beta). Dart aims to fix a handful of problems with JavaScript (like better scoping semantics, a built-in module system, better toolability and <em>static</em> <em>analysis</em> <em>tools</em>, etc.), and then also takes the existing browser APIs and modernizes and streamlines them (for example, all of the core browser APIs use a consistent Future-based API for asynchronous values, which cleans up a lot of messy code that you'd ordinarily see in JavaScript web application code).<p><i>Is it any surprise that Dart has failed to take off?</i><p>It's not at 1.0 yet. I still think there is plenty of room for improvement, and plenty of time for adoption.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dart Is Not the Language You Think It Is",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://programming.oreilly.com/2013/05/dart-is-not-the-language-you-think-it-is.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-19T15:51:39.000Z",
      "title": "",
      "url": "",
      "author": "santaragolabs",
      "points": 13,
      "story_text": null,
      "comment_text": "So I've dealt with dozens of Fortune-100 companies implementing and using static code analysis tools. They can and will help but in general I feel that these tools are not much more than the code-equivalent of the syntax- and grammar- checker in your word processing software.<p>I've been doing manual code reviews for a living now (mostly security related) for roughly  3 years now and while I get assisted from time to time by code analysis tools I still find heaps of bugs not caught by any of the tools mentioned by Carmack. The biggest issue for a development shop is to properly integrate these tools and to not overwhelm developers with too much false positives.<p>I've had cases where a developer got a 1500 page PDF spit out by one of these static analysis tools. After spending two weeks going through everything the developer ended up with 50 pages of actual bugs; the rest were describing false positives. Then I got on-site and I still logged dozens and dozens of security-related bugs that the static analysis tools failed to find.<p>Edit: also consider that one even needs a SAT solver to even do proper C-style preprocessor dependency checking. A lot of these code analysis tools are being run on debug builds only and then there when the release build is being made these tools are not being run meaning they fail to catch a lot of issues. It's insanely hard to write proper code analysis tools and static source code analysis tools which do not integrate with the compilation process I wouldn't trust at all.<p>Nowadays with clang there are very nice possibilities for someone to write your own simple checks and integrate them into the build process. But even clang doesn't expose everything about the preprocessor that you might want to have from a static code analysis perspective.",
      "num_comments": null,
      "story_id": 4543553,
      "story_title": "John Carmack on Static Code Analysis",
      "story_url": "http://www.altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 4543553,
      "created_at_i": 1348069899,
      "_tags": [
        "comment",
        "author_santaragolabs",
        "story_4543553"
      ],
      "objectID": "4544075",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "santaragolabs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "So I've dealt with dozens of Fortune-100 companies implementing and using <em>static</em> code <em>analysis</em> <em>tools</em>. They can and will help but in general I feel that these <em>tools</em> are not much more than the code-equivalent of the syntax- and grammar- checker in your word processing software.<p>I've been doing manual code reviews for a living now (mostly security related) for roughly  3 years now and while I get assisted from time to time by code <em>analysis</em> <em>tools</em> I still find heaps of bugs not caught by any of the <em>tools</em> mentioned by Carmack. The biggest issue for a development shop is to properly integrate these <em>tools</em> and to not overwhelm developers with too much false positives.<p>I've had cases where a developer got a 1500 page PDF spit out by one of these <em>static</em> <em>analysis</em> <em>tools</em>. After spending two weeks going through everything the developer ended up with 50 pages of actual bugs; the rest were describing false positives. Then I got on-site and I still logged dozens and dozens of security-related bugs that the <em>static</em> <em>analysis</em> <em>tools</em> failed to find.<p>Edit: also consider that one even needs a SAT solver to even do proper C-style preprocessor dependency checking. A lot of these code <em>analysis</em> <em>tools</em> are being run on debug builds only and then there when the release build is being made these <em>tools</em> are not being run meaning they fail to catch a lot of issues. It's insanely hard to write proper code <em>analysis</em> <em>tools</em> and <em>static</em> source code <em>analysis</em> <em>tools</em> which do not integrate with the compilation process I wouldn't trust at all.<p>Nowadays with clang there are very nice possibilities for someone to write your own simple checks and integrate them into the build process. But even clang doesn't expose everything about the preprocessor that you might want to have from a <em>static</em> code <em>analysis</em> perspective.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://www.altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2012-08-12T04:18:41.000Z",
      "title": "",
      "url": "",
      "author": "mynegation",
      "points": 13,
      "story_text": null,
      "comment_text": "This is quite an undertaking and even if they do not achieve all the lofty goals, the experience and the code (if they open-source it) will be extremely valuable.<p>For many years I made a living working on static analysis tools and that included a lot of compiler construction stuff. Unfortunately not all languages are equally amenable to static analysis.<p>Take C++ for example. On one hand C++ is statically typed and that helps in static analysis and refactoring. On the other hand, its semantic is so horribly complicated that it makes almost impossible to write static analyzers for it and useful refactoring tools for C++ are almost non-existent. Pointer aliasing and macroprocessor just add insult to injury.<p>Python on the other hand is very clean language, no macroprocessor, but it is dynamically typed which makes reasoning about code very difficult.<p>Java (and after it, C#) managed to strike very nice balance, that is why tooling ecosystems for these languages are very good. The road to good tools starts with carefully designed language.",
      "num_comments": null,
      "story_id": 4371267,
      "story_title": "Steve Yegge and Grok",
      "story_url": "http://bsumm.net/2012/08/11/steve-yegge-and-grok.html",
      "parent_id": 4371267,
      "created_at_i": 1344745121,
      "_tags": [
        "comment",
        "author_mynegation",
        "story_4371267"
      ],
      "objectID": "4371821",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "mynegation",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is quite an undertaking and even if they do not achieve all the lofty goals, the experience and the code (if they open-source it) will be extremely valuable.<p>For many years I made a living working on <em>static</em> <em>analysis</em> <em>tools</em> and that included a lot of compiler construction stuff. Unfortunately not all languages are equally amenable to <em>static</em> <em>analysis.</em><p>Take C++ for example. On one hand C++ is statically typed and that helps in <em>static</em> <em>analysis</em> and refactoring. On the other hand, its semantic is so horribly complicated that it makes almost impossible to write <em>static</em> analyzers for it and useful refactoring <em>tools</em> for C++ are almost non-existent. Pointer aliasing and macroprocessor just add insult to injury.<p>Python on the other hand is very clean language, no macroprocessor, but it is dynamically typed which makes reasoning about code very difficult.<p>Java (and after it, C#) managed to strike very nice balance, that is why tooling ecosystems for these languages are very good. The road to good <em>tools</em> starts with carefully designed language.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Steve Yegge and Grok",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://bsumm.net/2012/08/11/steve-yegge-and-grok.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T06:27:06.000Z",
      "title": null,
      "url": null,
      "author": "erichocean",
      "points": 13,
      "story_text": null,
      "comment_text": "Not mentioned in the article are two nice static analysis tools: the Clang Static Analyzer (<a href=\"http://clang-analyzer.llvm.org/\" rel=\"nofollow\">http://clang-analyzer.llvm.org/</a>) and Klee (<a href=\"http://klee.llvm.org/\" rel=\"nofollow\">http://klee.llvm.org/</a>).<p>Both are LLVM-related projects (and there's a few others as well, but these are the two \"big\" ones).",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388290,
      "created_at_i": 1324708026,
      "_tags": [
        "comment",
        "author_erichocean",
        "story_3388290"
      ],
      "objectID": "3388367",
      "_highlightResult": {
        "author": {
          "value": "erichocean",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Not mentioned in the article are two nice <em>static</em> <em>analysis</em> <em>tools</em>: the Clang <em>Static</em> Analyzer (<a href=\"http://clang-analyzer.llvm.org/\" rel=\"nofollow\">http://clang-analyzer.llvm.org/</a>) and Klee (<a href=\"http://klee.llvm.org/\" rel=\"nofollow\">http://klee.llvm.org/</a>).<p>Both are LLVM-related projects (and there's a few others as well, but these are the two \"big\" ones).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2012-11-29T18:26:47.000Z",
      "title": "",
      "url": "",
      "author": "dkhenry",
      "points": 12,
      "story_text": null,
      "comment_text": "Nice to see a move to Coverity. I use their product and it is one of the best static analysis tools I have used. Maybe we will see support for more languages rolled into the tool.<p>Hey Eric while your there how about you make the CLI tool suck less. I want a simple invocation to test for the presence of failures.",
      "num_comments": null,
      "story_id": 4848456,
      "story_title": "Eric Lippert is leaving Microsoft",
      "story_url": "http://ericlippert.com/",
      "parent_id": 4848456,
      "created_at_i": 1354213607,
      "_tags": [
        "comment",
        "author_dkhenry",
        "story_4848456"
      ],
      "objectID": "4849395",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dkhenry",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Nice to see a move to Coverity. I use their product and it is one of the best <em>static</em> <em>analysis</em> <em>tools</em> I have used. Maybe we will see support for more languages rolled into the tool.<p>Hey Eric while your there how about you make the CLI tool suck less. I want a simple invocation to test for the presence of failures.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Eric Lippert is leaving Microsoft",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ericlippert.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-10T14:40:21.000Z",
      "title": "",
      "url": "",
      "author": "dap",
      "points": 10,
      "story_text": null,
      "comment_text": "Just because C++ is a superset of C doesn't make it strictly better.  The presence of additional features can be a liability.  The obvious problem is that if you want to use the C subset in a multi-person project (whose team evolves over time), you have to create a way to enforce that.  Another example is that it's more difficult to produce static analysis tools like lint.  (As an example, lint in C detects unused stack variables.  This is trivial for C.  This is extremely difficult for C++ because the mere construction of the object on the stack often has important side effects.)",
      "num_comments": null,
      "story_id": 3953434,
      "story_title": "Why should I have written ZeroMQ in C, not C++",
      "story_url": "http://www.250bpm.com/blog:4",
      "parent_id": 3953531,
      "created_at_i": 1336660821,
      "_tags": [
        "comment",
        "author_dap",
        "story_3953434"
      ],
      "objectID": "3953726",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dap",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Just because C++ is a superset of C doesn't make it strictly better.  The presence of additional features can be a liability.  The obvious problem is that if you want to use the C subset in a multi-person project (whose team evolves over time), you have to create a way to enforce that.  Another example is that it's more difficult to produce <em>static</em> <em>analysis</em> <em>tools</em> like lint.  (As an example, lint in C detects unused stack variables.  This is trivial for C.  This is extremely difficult for C++ because the mere construction of the object on the stack often has important side effects.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why should I have written ZeroMQ in C, not C++",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.250bpm.com/blog:4",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-04-07T17:26:36.000Z",
      "title": "",
      "url": "",
      "author": "jof",
      "points": 9,
      "story_text": null,
      "comment_text": "In my favorite static analysis toolset (Radare, <a href=\"http://radare.org/\" rel=\"nofollow\">http://radare.org/</a>), there's a nice feature similar to this. It \"zooms\" out on a big file by summarizing portions of it into chunks and displaying colored ascii characters in a chart to represent the block.<p>With the entropy and ASCII printable filters setup, it makes repeating patterns and TEXT sections pretty clear.",
      "num_comments": null,
      "story_id": 3811136,
      "story_title": "Static analysis of an unknown compression format",
      "story_url": "http://blog.lse.epita.fr/articles/8-static-analysis-of-an-unknown-compression-format.html",
      "parent_id": 3811244,
      "created_at_i": 1333819596,
      "_tags": [
        "comment",
        "author_jof",
        "story_3811136"
      ],
      "objectID": "3811435",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jof",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In my favorite <em>static</em> <em>analysis</em> <em>tools</em>et (Radare, <a href=\"http://radare.org/\" rel=\"nofollow\">http://radare.org/</a>), there's a nice feature similar to this. It \"zooms\" out on a big file by summarizing portions of it into chunks and displaying colored ascii characters in a chart to represent the block.<p>With the entropy and ASCII printable filters setup, it makes repeating patterns and TEXT sections pretty clear.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "<em>Static</em> <em>analysis</em> of an unknown compression format",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://blog.lse.epita.fr/articles/8-<em>static</em>-<em>analysis</em>-of-an-unknown-compression-format.html",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2014-04-11T23:50:32.000Z",
      "title": null,
      "url": null,
      "author": "TorKlingberg",
      "points": 8,
      "story_text": null,
      "comment_text": "It would be good to hear other HN:ers experience with various static analysis tools for C.<p>I have had good experiences with Flexelint (PC-Lint). It does not attempt to deeply analyze control flow, more like compiler additional warnings. It flags a lot of common mistakes and can basically turn C into a more strictly typed language. I feel a lot more confident in C code if I know that it passes lint, since it warns if you try to mix unsigned and signed ints, cast away const, call functions with wrong types etc.<p>Like many static analyzers it takes some work to set it up, and tune which warnings you actually car about. It is definitely business-priced and feel a bit old (although command line tools age well.<p>The is a clear lack of good open source tools. I tried all i could find, but Splint was the only one that would flag switch-cases without break. It was last updated in 2010.",
      "num_comments": null,
      "story_id": 7575191,
      "story_title": "Frama-C is a suite of tools dedicated to the analysis of software written in C",
      "story_url": "http://frama-c.com/what_is.html",
      "parent_id": 7575191,
      "created_at_i": 1397260232,
      "_tags": [
        "comment",
        "author_TorKlingberg",
        "story_7575191"
      ],
      "objectID": "7576247",
      "_highlightResult": {
        "author": {
          "value": "TorKlingberg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It would be good to hear other HN:ers experience with various <em>static</em> <em>analysis</em> <em>tools</em> for C.<p>I have had good experiences with Flexelint (PC-Lint). It does not attempt to deeply analyze control flow, more like compiler additional warnings. It flags a lot of common mistakes and can basically turn C into a more strictly typed language. I feel a lot more confident in C code if I know that it passes lint, since it warns if you try to mix unsigned and signed ints, cast away const, call functions with wrong types etc.<p>Like many <em>static</em> analyzers it takes some work to set it up, and tune which warnings you actually car about. It is definitely business-priced and feel a bit old (although command line <em>tools</em> age well.<p>The is a clear lack of good open source <em>tools</em>. I tried all i could find, but Splint was the only one that would flag switch-cases without break. It was last updated in 2010.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Frama-C is a suite of <em>tools</em> dedicated to the <em>analysis</em> of software written in C",
          "matchLevel": "partial",
          "matchedWords": [
            "analysis",
            "tools"
          ]
        },
        "story_url": {
          "value": "http://frama-c.com/what_is.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T19:04:38.000Z",
      "title": null,
      "url": null,
      "author": "hackinthebochs",
      "points": 8,
      "story_text": null,
      "comment_text": "Even easier, I would bet a lot of money that they have at least some rudimentary static analysis tools to detect potential targets, and this sort of memory error is pretty low hanging fruit for such a tool. To me it seems almost certain that they knew about it and they certainly exploited it if they knew.<p>The bigger question to me is how many of these bugs have they rooted out that have not been made public yet?",
      "num_comments": null,
      "story_id": 7565577,
      "story_title": "Were Intelligence Agencies Using Heartbleed in November 2013?",
      "story_url": "https://www.eff.org/deeplinks/2014/04/wild-heart-were-intelligence-agencies-using-heartbleed-november-2013",
      "parent_id": 7568079,
      "created_at_i": 1397156678,
      "_tags": [
        "comment",
        "author_hackinthebochs",
        "story_7565577"
      ],
      "objectID": "7568900",
      "_highlightResult": {
        "author": {
          "value": "hackinthebochs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Even easier, I would bet a lot of money that they have at least some rudimentary <em>static</em> <em>analysis</em> <em>tools</em> to detect potential targets, and this sort of memory error is pretty low hanging fruit for such a tool. To me it seems almost certain that they knew about it and they certainly exploited it if they knew.<p>The bigger question to me is how many of these bugs have they rooted out that have not been made public yet?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Were Intelligence Agencies Using Heartbleed in November 2013?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.eff.org/deeplinks/2014/04/wild-heart-were-intelligence-agencies-using-heartbleed-november-2013",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-22T19:22:43.000Z",
      "title": null,
      "url": null,
      "author": "eliteraspberrie",
      "points": 8,
      "story_text": null,
      "comment_text": "Unfortunately the decision to use static analysis tools would have to come from developers who are comfortable admitting they make mistakes sometimes.<p>It takes a special kind of ego to write an SSL library with no unit tests, not turn on compiler warnings, and not use static analysis tools.",
      "num_comments": null,
      "story_id": 7282005,
      "story_title": "Apple's SSL/TLS bug",
      "story_url": "https://www.imperialviolet.org/2014/02/22/applebug.html",
      "parent_id": 7282208,
      "created_at_i": 1393096963,
      "_tags": [
        "comment",
        "author_eliteraspberrie",
        "story_7282005"
      ],
      "objectID": "7283205",
      "_highlightResult": {
        "author": {
          "value": "eliteraspberrie",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Unfortunately the decision to use <em>static</em> <em>analysis</em> <em>tools</em> would have to come from developers who are comfortable admitting they make mistakes sometimes.<p>It takes a special kind of ego to write an SSL library with no unit tests, not turn on compiler warnings, and not use <em>static</em> <em>analysis</em> <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Apple's SSL/TLS bug",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.imperialviolet.org/2014/02/22/applebug.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-03T16:19:14.000Z",
      "title": null,
      "url": null,
      "author": "BruceM",
      "points": 8,
      "story_text": null,
      "comment_text": "Over with Open Dylan (<a href=\\\"http://opendylan.org/\\\" rel=\\\"nofollow\\\">http:&#x2F;&#x2F;opendylan.org&#x2F;</a>), we&#x27;ve been building a new IDE using IntelliJ CE and it has been a joy.  Even though we&#x27;ve gone the route of writing a whole new parser and doing new static analysis tools, it has been a pretty good experience so far. Can&#x27;t say enough positive things about this.",
      "num_comments": null,
      "story_id": 6840262,
      "story_title": "IntelliJ IDEA 13 is Released",
      "story_url": "http://blog.jetbrains.com/idea/2013/12/intellij-idea-13-is-released-work-miracles-in-java-and-beyond/",
      "parent_id": 6840262,
      "created_at_i": 1386087554,
      "_tags": [
        "comment",
        "author_BruceM",
        "story_6840262"
      ],
      "objectID": "6841161",
      "_highlightResult": {
        "author": {
          "value": "BruceM",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Over with Open Dylan (<a href=\\\"http://opendylan.org/\\\" rel=\\\"nofollow\\\">http://opendylan.org/</a>), we've been building a new IDE using IntelliJ CE and it has been a joy.  Even though we've gone the route of writing a whole new parser and doing new <em>static</em> <em>analysis</em> <em>tools</em>, it has been a pretty good experience so far. Can't say enough positive things about this.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "IntelliJ IDEA 13 is Released",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.jetbrains.com/idea/2013/12/intellij-idea-13-is-released-work-miracles-in-java-and-beyond/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-19T17:17:39.000Z",
      "title": "",
      "url": "",
      "author": "pnathan",
      "points": 8,
      "story_text": null,
      "comment_text": "The bugs that static analysis tools tend to turn up are ones that Haskell catches out of the gate in general.<p>What Haskell brings to the table in terms of unique flavors of bug, I don't know. I would love to read articles about 1MLoC+ codebases in Haskell and how they play out.",
      "num_comments": null,
      "story_id": 4543553,
      "story_title": "John Carmack on Static Code Analysis",
      "story_url": "http://www.altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 4544445,
      "created_at_i": 1348075059,
      "_tags": [
        "comment",
        "author_pnathan",
        "story_4543553"
      ],
      "objectID": "4544468",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pnathan",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The bugs that <em>static</em> <em>analysis</em> <em>tools</em> tend to turn up are ones that Haskell catches out of the gate in general.<p>What Haskell brings to the table in terms of unique flavors of bug, I don't know. I would love to read articles about 1MLoC+ codebases in Haskell and how they play out.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://www.altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2014-08-11T09:04:21.000Z",
      "title": null,
      "url": null,
      "author": "lmm",
      "points": 7,
      "story_text": null,
      "comment_text": "Using a language with a more powerful type system (e.g. Haskell) you can derive the same benefits as you would from static analysis tools, but integrated with the rest of your development tools, extensible, and supported by other users of the same language (e.g. library writers). So I think most people who appreciate the benefits tend to move on from C (particularly given how large the library ecosystem in safer languages is these days).",
      "num_comments": null,
      "story_id": 8162259,
      "story_title": "Can We Trust the Libraries We Use?",
      "story_url": "http://www.viva64.com/en/b/0271/",
      "parent_id": 8162389,
      "created_at_i": 1407747861,
      "_tags": [
        "comment",
        "author_lmm",
        "story_8162259"
      ],
      "objectID": "8162526",
      "_highlightResult": {
        "author": {
          "value": "lmm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Using a language with a more powerful type system (e.g. Haskell) you can derive the same benefits as you would from <em>static</em> <em>analysis</em> <em>tools</em>, but integrated with the rest of your development <em>tools</em>, extensible, and supported by other users of the same language (e.g. library writers). So I think most people who appreciate the benefits tend to move on from C (particularly given how large the library ecosystem in safer languages is these days).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Can We Trust the Libraries We Use?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0271/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-13T20:17:01.000Z",
      "title": null,
      "url": null,
      "author": "adamnemecek",
      "points": 7,
      "story_text": null,
      "comment_text": "Generally, statically typed languages are less bug prone  than dynamically typed languages. Dynamically typed languages are OK for smaller projects but as projects grow in size, you have to write a lot of tests to be sure that everything works.<p>Also, projects written in statically typed languages are easier to read and navigate for humans and it&#x27;s also easier to write static analysis tools for them.",
      "num_comments": null,
      "story_id": 7890449,
      "story_title": "Typed Lua: An Optional Type System for Lua [pdf]",
      "story_url": "http://www.lifl.fr/dyla14/papers/dyla14-4-typed-lua-an-optional-type-system.pdf",
      "parent_id": 7890603,
      "created_at_i": 1402690621,
      "_tags": [
        "comment",
        "author_adamnemecek",
        "story_7890449"
      ],
      "objectID": "7890633",
      "_highlightResult": {
        "author": {
          "value": "adamnemecek",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Generally, statically typed languages are less bug prone  than dynamically typed languages. Dynamically typed languages are OK for smaller projects but as projects grow in size, you have to write a lot of tests to be sure that everything works.<p>Also, projects written in statically typed languages are easier to read and navigate for humans and it's also easier to write <em>static</em> <em>analysis</em> <em>tools</em> for them.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Typed Lua: An Optional Type System for Lua [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.lifl.fr/dyla14/papers/dyla14-4-typed-lua-an-optional-type-system.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-09T13:41:38.000Z",
      "title": null,
      "url": null,
      "author": "jerf",
      "points": 7,
      "story_text": null,
      "comment_text": "I don&#x27;t think the NSA had to create this bug. I do think that static analysis could find this bug, and if they did not have the static analysis tools to do so, they probably will soon enough. It is far better for them to find existing bugs than introduce new ones, because the former is untraceable. The latter, inevitably, leaves a paper trail. I&#x27;d need a lot of convincing to believe that OpenSSL is so darned secure that it has no bugs in it until the NSA adds them, just based on the software engineering practices of the product (using C, little test code, etc).",
      "num_comments": null,
      "story_id": 7558563,
      "story_title": "Heartbleed",
      "story_url": "https://www.schneier.com/blog/archives/2014/04/heartbleed.html",
      "parent_id": 7559015,
      "created_at_i": 1397050898,
      "_tags": [
        "comment",
        "author_jerf",
        "story_7558563"
      ],
      "objectID": "7559171",
      "_highlightResult": {
        "author": {
          "value": "jerf",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't think the NSA had to create this bug. I do think that <em>static</em> <em>analysis</em> could find this bug, and if they did not have the <em>static</em> <em>analysis</em> <em>tools</em> to do so, they probably will soon enough. It is far better for them to find existing bugs than introduce new ones, because the former is untraceable. The latter, inevitably, leaves a paper trail. I'd need a lot of convincing to believe that OpenSSL is so darned secure that it has no bugs in it until the NSA adds them, just based on the software engineering practices of the product (using C, little test code, etc).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Heartbleed",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.schneier.com/blog/archives/2014/04/heartbleed.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-09T06:49:03.000Z",
      "title": "",
      "url": "",
      "author": "DanWaterworth",
      "points": 7,
      "story_text": null,
      "comment_text": "<i>If you want to pitch Rust to the engine guys, you&#x27;re going to be battling against their toolchains that have been developed for decades and have some of the best static analysis tools under the sun.</i><p>I&#x27;ve never used static analysis tools for C++, but from what I&#x27;ve heard, the reason they need to be so advanced is because C++ is so difficult to analyse. Rust, on the other hand, with it&#x27;s strong, static type system, may not even require extra static analysis tools to be used effectively.",
      "num_comments": null,
      "story_id": 6181897,
      "story_title": "New Rust runtime turned on. What next?",
      "story_url": "https://mail.mozilla.org/pipermail/rust-dev/2013-August/005158.html",
      "parent_id": 6184017,
      "created_at_i": 1376030943,
      "_tags": [
        "comment",
        "author_DanWaterworth",
        "story_6181897"
      ],
      "objectID": "6184102",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "DanWaterworth",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>If you want to pitch Rust to the engine guys, you're going to be battling against their toolchains that have been developed for decades and have some of the best <em>static</em> <em>analysis</em> <em>tools</em> under the sun.</i><p>I've never used <em>static</em> <em>analysis</em> <em>tools</em> for C++, but from what I've heard, the reason they need to be so advanced is because C++ is so difficult to analyse. Rust, on the other hand, with it's strong, <em>static</em> type system, may not even require extra <em>static</em> <em>analysis</em> <em>tools</em> to be used effectively.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "New Rust runtime turned on. What next?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://mail.mozilla.org/pipermail/rust-dev/2013-August/005158.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-03T21:44:36.000Z",
      "title": "",
      "url": "",
      "author": "pcwalton",
      "points": 7,
      "story_text": null,
      "comment_text": "\"The traditional response to these kind of language imperfections is \"better tests, better practices\". Otherwise as, Unit Tests solve all problems.\"<p>The security vulnerabilities found in all browser engines stemming from things like use-after-free suggest otherwise.<p>\"For C++, someone would say to use some set of abstractions or static analysis tools that confers additional safety that isn't available in the out-of-the-box language.\"<p>It's really, really hard. The language works against you at all levels. Type systems are much easier ways to achieve the same result.",
      "num_comments": null,
      "story_id": 5486495,
      "story_title": "Mozilla and Samsung Collaborate on Next Generation Web Browser Engine",
      "story_url": "https://blog.mozilla.org/blog/2013/04/03/mozilla-and-samsung-collaborate-on-next-generation-web-browser-engine/",
      "parent_id": 5488361,
      "created_at_i": 1365025476,
      "_tags": [
        "comment",
        "author_pcwalton",
        "story_5486495"
      ],
      "objectID": "5489372",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pcwalton",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "\"The traditional response to these kind of language imperfections is \"better tests, better practices\". Otherwise as, Unit Tests solve all problems.\"<p>The security vulnerabilities found in all browser engines stemming from things like use-after-free suggest otherwise.<p>\"For C++, someone would say to use some set of abstractions or <em>static</em> <em>analysis</em> <em>tools</em> that confers additional safety that isn't available in the out-of-the-box language.\"<p>It's really, really hard. The language works against you at all levels. Type systems are much easier ways to achieve the same result.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mozilla and Samsung Collaborate on Next Generation Web Browser Engine",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://blog.mozilla.org/blog/2013/04/03/mozilla-and-samsung-collaborate-on-next-generation-web-browser-engine/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-18T18:41:50.000Z",
      "title": "",
      "url": "",
      "author": "hythloday",
      "points": 7,
      "story_text": null,
      "comment_text": "No, sorry. There are a bunch of factors that make the point a little more complicated.<p>If you're writing, let's say, scenegraph traversal, it's really tempting to get it working on the PPU and then port it to run on an SPU. A vtable dereference to main memory will crash your SPU job and it is not always obvious why. Obviously, you can't use static analysis tools to make sure the right instructions are transferred, so you have to do it by hand. A modern PS3 game has on the order of low hundreds f different SPU jobs...not much fun. Even discounting that, SPUs will work best when fed branchless parallelized jobs, I wouldn't be surprised to see an order of magnitude difference between a vtable call on a pointer array and a static call on an object array.<p>Keeping pointers to objects in a polymorphic array is a games performance anti-pattern because of the dereferencing cost, but it's necessary to call virtual functions...there's a hidden cost right there.<p>Which loop is faster, by eyeballing, and by how much?<p><pre><code>  void load(Assets* a) {\n    for (int j=0; j&#60;m_numAssets; j++) {\n      loadAsset(a[j]);\n      m_numLoadedAssets++;\n    }\n  }\n\n  void load(Assets* a) {\n    int numLoadedAssets=0;\n    for (int j=0; j&#60;m_numAssets; j++) {\n      loadAsset(a[j]);\n      numLoadedAssets++;\n    }\n    m_numLoadedAssets = numLoadedAssets;\n  }\n</code></pre>\nI've seen the former style run literally 1000 times slower than the latter...that's obvious? I submit in a world of out-of-order processors it is not at all.<p>I don't think that all the author's points are spot on...Koenig lookup is Byzantine but IDEs do a good job of it, ditto source-level reasoning about dispatch. The underlying theme, that C++ is not a good fit for modern game development, shouldn't be so trivially dismissed.",
      "num_comments": null,
      "story_id": 4539251,
      "story_title": "The hidden cost of C++ (2009)",
      "story_url": "http://www.rachelslabnotes.com/2009/10/the-hidden-cost-of-c/",
      "parent_id": 4539446,
      "created_at_i": 1347993710,
      "_tags": [
        "comment",
        "author_hythloday",
        "story_4539251"
      ],
      "objectID": "4539789",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "hythloday",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "No, sorry. There are a bunch of factors that make the point a little more complicated.<p>If you're writing, let's say, scenegraph traversal, it's really tempting to get it working on the PPU and then port it to run on an SPU. A vtable dereference to main memory will crash your SPU job and it is not always obvious why. Obviously, you can't use <em>static</em> <em>analysis</em> <em>tools</em> to make sure the right instructions are transferred, so you have to do it by hand. A modern PS3 game has on the order of low hundreds f different SPU jobs...not much fun. Even discounting that, SPUs will work best when fed branchless parallelized jobs, I wouldn't be surprised to see an order of magnitude difference between a vtable call on a pointer array and a <em>static</em> call on an object array.<p>Keeping pointers to objects in a polymorphic array is a games performance anti-pattern because of the dereferencing cost, but it's necessary to call virtual functions...there's a hidden cost right there.<p>Which loop is faster, by eyeballing, and by how much?<p><pre><code>  void load(Assets* a) {\n    for (int j=0; j<m_numAssets; j++) {\n      loadAsset(a[j]);\n      m_numLoadedAssets++;\n    }\n  }\n\n  void load(Assets* a) {\n    int numLoadedAssets=0;\n    for (int j=0; j<m_numAssets; j++) {\n      loadAsset(a[j]);\n      numLoadedAssets++;\n    }\n    m_numLoadedAssets = numLoadedAssets;\n  }\n</code></pre>\nI've seen the former style run literally 1000 times slower than the latter...that's obvious? I submit in a world of out-of-order processors it is not at all.<p>I don't think that all the author's points are spot on...Koenig lookup is Byzantine but IDEs do a good job of it, ditto source-level reasoning about dispatch. The underlying theme, that C++ is not a good fit for modern game development, shouldn't be so trivially dismissed.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The hidden cost of C++ (2009)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.rachelslabnotes.com/2009/10/the-hidden-cost-of-c/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-08-10T12:09:08.000Z",
      "title": "",
      "url": "",
      "author": "derleth",
      "points": 7,
      "story_text": null,
      "comment_text": "&#62; I'm conservative because I dislike complexity<p>Except a lot of conservatism as defined here is <i>all about</i> complexity in terms of 'big design up front' methodology and, really, <i>having</i> a big methodology in the first place, along with having a lot of testing and static analysis tools.<p>Ada is a conservative language. C is extremely, red-diaper liberal.",
      "num_comments": null,
      "story_id": 4365255,
      "story_title": "Steve Yegge: Notes from the Mystery Machine Bus",
      "story_url": "https://plus.google.com/u/0/110981030061712822816/posts/KaSKeg4vQtz",
      "parent_id": 4365606,
      "created_at_i": 1344600548,
      "_tags": [
        "comment",
        "author_derleth",
        "story_4365255"
      ],
      "objectID": "4365815",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "derleth",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> I'm conservative because I dislike complexity<p>Except a lot of conservatism as defined here is <i>all about</i> complexity in terms of 'big design up front' methodology and, really, <i>having</i> a big methodology in the first place, along with having a lot of testing and <em>static</em> <em>analysis</em> <em>tools</em>.<p>Ada is a conservative language. C is extremely, red-diaper liberal.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Steve Yegge: Notes from the Mystery Machine Bus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://plus.google.com/u/0/110981030061712822816/posts/KaSKeg4vQtz",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-06-11T15:33:02.000Z",
      "title": "",
      "url": "",
      "author": "pnathan",
      "points": 7,
      "story_text": null,
      "comment_text": "I really flipping \"hate\" C. It's used for <i>everything</i> in Linux it seems like. Things that really ought to be high level turn out to be a libfoo.so, requiring a C compiler.<p>It's not a gui programming language. It's not a text-handling programming language. It's not a symbolic programming language.<p>But it's used as those, constantly.<p>Pointer-based errors are endemic to C; they ought to be an expected part of the language usage by now. There are <i>reasons</i> why static analysis tools such as Klocwork are out there, and are <i>very</i> expensive... and keep being bought. Because C is <i>bad</i> for an incredibly large range of tasks that it keeps getting used for. I've done some of that, and using C (or C++) made things harder and more error-prone.<p>It's also very good at other tasks... like writing OS kernels or drivers. I've done some of that, and C made it <i>possible</i>.<p>Although at this point, I'd be interested to give writing an OS in D a spin to see how it works.",
      "num_comments": null,
      "story_id": 4093844,
      "story_title": "Whats to love about C?",
      "story_url": "http://mortoray.com/2012/06/11/whats-to-love-about-c/",
      "parent_id": 4094212,
      "created_at_i": 1339428782,
      "_tags": [
        "comment",
        "author_pnathan",
        "story_4093844"
      ],
      "objectID": "4095111",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pnathan",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I really flipping \"hate\" C. It's used for <i>everything</i> in Linux it seems like. Things that really ought to be high level turn out to be a libfoo.so, requiring a C compiler.<p>It's not a gui programming language. It's not a text-handling programming language. It's not a symbolic programming language.<p>But it's used as those, constantly.<p>Pointer-based errors are endemic to C; they ought to be an expected part of the language usage by now. There are <i>reasons</i> why <em>static</em> <em>analysis</em> <em>tools</em> such as Klocwork are out there, and are <i>very</i> expensive... and keep being bought. Because C is <i>bad</i> for an incredibly large range of tasks that it keeps getting used for. I've done some of that, and using C (or C++) made things harder and more error-prone.<p>It's also very good at other tasks... like writing OS kernels or drivers. I've done some of that, and C made it <i>possible</i>.<p>Although at this point, I'd be interested to give writing an OS in D a spin to see how it works.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Whats to love about C?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://mortoray.com/2012/06/11/whats-to-love-about-c/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-06-02T12:29:27.000Z",
      "title": "",
      "url": "",
      "author": "pjmlp",
      "points": 7,
      "story_text": null,
      "comment_text": "Tools only created to solve the lack of safe constructs in C.<p>C made lots of sense in the context it was developed, but the world would be better if we had safer systems programming languages.<p>Valgrind, purify and friends are required to C, the same way Java requires IDEs, to improve language usability.<p>Have said this, the new trend in having static analysis tools integrated in the development process, like Clang, Eclipse CODA, Visual Studio's tools or HP Code Advisor, among others, can bring a bit more safety into C.",
      "num_comments": null,
      "story_id": 4057564,
      "story_title": "A Boggling Return to C",
      "story_url": "http://thraxil.org/users/anders/posts/2011/04/17/A-Boggling-Return-to-C/",
      "parent_id": 4057718,
      "created_at_i": 1338640167,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_4057564"
      ],
      "objectID": "4057923",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<em>Tools</em> only created to solve the lack of safe constructs in C.<p>C made lots of sense in the context it was developed, but the world would be better if we had safer systems programming languages.<p>Valgrind, purify and friends are required to C, the same way Java requires IDEs, to improve language usability.<p>Have said this, the new trend in having <em>static</em> <em>analysis</em> <em>tools</em> integrated in the development process, like Clang, Eclipse CODA, Visual Studio's <em>tools</em> or HP Code Advisor, among others, can bring a bit more safety into C.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "A Boggling Return to C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://thraxil.org/users/anders/posts/2011/04/17/A-Boggling-Return-to-C/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-23T22:03:33.000Z",
      "title": "",
      "url": "",
      "author": "MartinCron",
      "points": 7,
      "story_text": null,
      "comment_text": "If you haven't already, you owe it to yourself to try ReSharper. The automated refactoring and static analysis tools are best described as \"pair programming with a genius robot\".",
      "num_comments": null,
      "story_id": 3746692,
      "story_title": "Poll: What's Your Favorite Programming Language?",
      "story_url": null,
      "parent_id": 3747159,
      "created_at_i": 1332540213,
      "_tags": [
        "comment",
        "author_MartinCron",
        "story_3746692"
      ],
      "objectID": "3747582",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "MartinCron",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "If you haven't already, you owe it to yourself to try ReSharper. The automated refactoring and <em>static</em> <em>analysis</em> <em>tools</em> are best described as \"pair programming with a genius robot\".",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Poll: What's Your Favorite Programming Language?",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T10:58:51.000Z",
      "title": "",
      "url": "",
      "author": "masklinn",
      "points": 7,
      "story_text": null,
      "comment_text": "&#62; They already use a massive amount of testing though.<p>Yes, as the page notes the SQLite codebase has a &#62; 1000:1 tests to code ratio. I don't think there's any other codebase this thoroughly tested, and it makes sense that static analysis tools won't discover anything not already covered by tests.",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388542,
      "created_at_i": 1324724331,
      "_tags": [
        "comment",
        "author_masklinn",
        "story_3388290"
      ],
      "objectID": "3388708",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "masklinn",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> They already use a massive amount of testing though.<p>Yes, as the page notes the SQLite codebase has a > 1000:1 tests to code ratio. I don't think there's any other codebase this thoroughly tested, and it makes sense that <em>static</em> <em>analysis</em> <em>tools</em> won't discover anything not already covered by tests.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2014-04-13T17:18:28.000Z",
      "title": null,
      "url": null,
      "author": "reality_czech",
      "points": 6,
      "story_text": null,
      "comment_text": "This is the path that all dynamically typed scripting languages must follow.  Over time, change becomes impossible because the lack of typechecking or static analysis tools means that any change might break something in a subtle and hard-to-diagnose way.  And so the language grows by accretion.  You end up with something like bash or perl, where there are a million ways to do any one thing.  Each way was added at a particular phase of the language&#x27;s life, and it could never be removed after that.  And so the language becomes difficult to learn and unattractive to newcomers, so another scripting langauge pops up, and the cycle of life begins again.<p>Compare this to a language like golang, where you can just run &quot;go fix&quot; on your code to update it to the latest version.  And you don&#x27;t have compatibility hell, because when you distribute your application, it&#x27;s a standalone binary.  Stuff like go is the future.  Get off the dynamic language hamster wheel.",
      "num_comments": null,
      "story_id": 7581434,
      "story_title": "Extend Python 2.7 life till 2020",
      "story_url": "http://hg.python.org/peps/rev/76d43e52d978",
      "parent_id": 7581434,
      "created_at_i": 1397409508,
      "_tags": [
        "comment",
        "author_reality_czech",
        "story_7581434"
      ],
      "objectID": "7581952",
      "_highlightResult": {
        "author": {
          "value": "reality_czech",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is the path that all dynamically typed scripting languages must follow.  Over time, change becomes impossible because the lack of typechecking or <em>static</em> <em>analysis</em> <em>tools</em> means that any change might break something in a subtle and hard-to-diagnose way.  And so the language grows by accretion.  You end up with something like bash or perl, where there are a million ways to do any one thing.  Each way was added at a particular phase of the language's life, and it could never be removed after that.  And so the language becomes difficult to learn and unattractive to newcomers, so another scripting langauge pops up, and the cycle of life begins again.<p>Compare this to a language like golang, where you can just run &quot;go fix&quot; on your code to update it to the latest version.  And you don't have compatibility hell, because when you distribute your application, it's a standalone binary.  Stuff like go is the future.  Get off the dynamic language hamster wheel.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Extend Python 2.7 life till 2020",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://hg.python.org/peps/rev/76d43e52d978",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-06T13:41:16.000Z",
      "title": "",
      "url": "",
      "author": "lnanek2",
      "points": 6,
      "story_text": null,
      "comment_text": "What's funny is that math people know this is impossible and will never attempt it, but it's quite easy to write something practically useful that does the job most of the way. It's possible for static analysis tools to identify many loops that will never end. E.g. in Java if there's no break or return and the guard is a boolean that is never written to and no runtime class loading is used.<p>It can be very valuable to have static analysis tools in an organization, I know my own company has them, and we don't share them. IBM as well puts tons of work into it. Motorola has shared one of their tools. Every bug and issue your tool can find is one much more cheaply solved.<p>Similarly, the client may be doing coding education, or interview, or other software where just a few limited lines and limited operations need to be checked, or it is OK to say if you hit n^4 loops you lose, etc..",
      "num_comments": null,
      "story_id": 5660860,
      "story_title": "Rent-a-coder hilarity (2008)",
      "story_url": "http://blog.willbenton.com/2008/11/rent-a-coder-hilarity/",
      "parent_id": 5660860,
      "created_at_i": 1367847676,
      "_tags": [
        "comment",
        "author_lnanek2",
        "story_5660860"
      ],
      "objectID": "5662278",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "lnanek2",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "What's funny is that math people know this is impossible and will never attempt it, but it's quite easy to write something practically useful that does the job most of the way. It's possible for <em>static</em> <em>analysis</em> <em>tools</em> to identify many loops that will never end. E.g. in Java if there's no break or return and the guard is a boolean that is never written to and no runtime class loading is used.<p>It can be very valuable to have <em>static</em> <em>analysis</em> <em>tools</em> in an organization, I know my own company has them, and we don't share them. IBM as well puts tons of work into it. Motorola has shared one of their <em>tools</em>. Every bug and issue your tool can find is one much more cheaply solved.<p>Similarly, the client may be doing coding education, or interview, or other software where just a few limited lines and limited operations need to be checked, or it is OK to say if you hit n^4 loops you lose, etc..",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Rent-a-coder hilarity (2008)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.willbenton.com/2008/11/rent-a-coder-hilarity/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-19T18:43:35.000Z",
      "title": "",
      "url": "",
      "author": "jerf",
      "points": 6,
      "story_text": null,
      "comment_text": "Part of what I mean is that some of what Coverity and friends cover aren't just <i>bugs</i> bugs, but things that are bad style and contribute to bugs in the future. For instance, you can put too many things in IO when you should be separating the IO code from the pure code. This can be perfectly correct at a given moment inasmuch as the program works correctly, but it certainly might encourage bugs in the future as the code gets modified. It would be interesting to see how much of this could be automatically detected.<p>As another for instance, partial functions can already be caught by some static analysis tools and we tend to think they are <i>at least</i> bad style (I would rate them as a serious code smell; every time I thought I wanted one, it was trying to tell me I had a fundamental design flaw), but they are certainly syntactically valid Haskell.",
      "num_comments": null,
      "story_id": 4543553,
      "story_title": "John Carmack on Static Code Analysis",
      "story_url": "http://www.altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 4544468,
      "created_at_i": 1348080215,
      "_tags": [
        "comment",
        "author_jerf",
        "story_4543553"
      ],
      "objectID": "4544892",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jerf",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Part of what I mean is that some of what Coverity and friends cover aren't just <i>bugs</i> bugs, but things that are bad style and contribute to bugs in the future. For instance, you can put too many things in IO when you should be separating the IO code from the pure code. This can be perfectly correct at a given moment inasmuch as the program works correctly, but it certainly might encourage bugs in the future as the code gets modified. It would be interesting to see how much of this could be automatically detected.<p>As another for instance, partial functions can already be caught by some <em>static</em> <em>analysis</em> <em>tools</em> and we tend to think they are <i>at least</i> bad style (I would rate them as a serious code smell; every time I thought I wanted one, it was trying to tell me I had a fundamental design flaw), but they are certainly syntactically valid Haskell.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://www.altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2012-04-10T15:51:13.000Z",
      "title": "",
      "url": "",
      "author": "angersock",
      "points": 6,
      "story_text": null,
      "comment_text": "<i>\"1. Where are those bug searching tools used?\"</i><p>Microsoft has some good static code analysis tools ( <a href=\"http://msdn.microsoft.com/en-us/gg712340\" rel=\"nofollow\">http://msdn.microsoft.com/en-us/gg712340</a> ), for a start.<p><i>\"3. Apple clearly is doing this too.\"</i><p>They seem more concerned about not letting users jailbreak their devices than anything else.<p><i>\"Windows clearly has decent technical code-signing infrastructure, but Apple seems far ahead in terms of effectively deploying this model into the field.\"</i><p>\"Far ahead\"? How do you justify that claim? Most charitably, it seems that both companies work on security.<p>Of the two, Microsoft seems to have better documentation, better openness, and better tools.",
      "num_comments": null,
      "story_id": 3821549,
      "story_title": "Apple Snubs Firm That Discovered Mac Botnet",
      "story_url": "http://www.forbes.com/sites/andygreenberg/2012/04/09/apple-snubs-firm-who-discovered-mac-botnet-tries-to-cut-off-its-server-monitoring-infections/",
      "parent_id": 3822507,
      "created_at_i": 1334073073,
      "_tags": [
        "comment",
        "author_angersock",
        "story_3821549"
      ],
      "objectID": "3822737",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "angersock",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>\"1. Where are those bug searching <em>tools</em> used?\"</i><p>Microsoft has some good <em>static</em> code <em>analysis</em> <em>tools</em> ( <a href=\"http://msdn.microsoft.com/en-us/gg712340\" rel=\"nofollow\">http://msdn.microsoft.com/en-us/gg712340</a> ), for a start.<p><i>\"3. Apple clearly is doing this too.\"</i><p>They seem more concerned about not letting users jailbreak their devices than anything else.<p><i>\"Windows clearly has decent technical code-signing infrastructure, but Apple seems far ahead in terms of effectively deploying this model into the field.\"</i><p>\"Far ahead\"? How do you justify that claim? Most charitably, it seems that both companies work on security.<p>Of the two, Microsoft seems to have better documentation, better openness, and better <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Apple Snubs Firm That Discovered Mac Botnet",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.forbes.com/sites/andygreenberg/2012/04/09/apple-snubs-firm-who-discovered-mac-botnet-tries-to-cut-off-its-server-monitoring-infections/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T13:40:02.000Z",
      "title": "",
      "url": "",
      "author": "barkmadley",
      "points": 6,
      "story_text": null,
      "comment_text": "<p><pre><code>    and it makes sense that static analysis tools won't discover anything not already covered by tests\n</code></pre>\nThat assertion doesn't make a lot of sense to me.  Most static analysers are capable of looking at the edge cases that a human may forget to write a test for, or may not even notice are there.",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388708,
      "created_at_i": 1324734002,
      "_tags": [
        "comment",
        "author_barkmadley",
        "story_3388290"
      ],
      "objectID": "3388855",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "barkmadley",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<p><pre><code>    and it makes sense that <em>static</em> <em>analysis</em> <em>tools</em> won't discover anything not already covered by tests\n</code></pre>\nThat assertion doesn't make a lot of sense to me.  Most <em>static</em> analysers are capable of looking at the edge cases that a human may forget to write a test for, or may not even notice are there.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2011-04-22T15:22:14.000Z",
      "title": "",
      "url": "",
      "author": "jdp23",
      "points": 6,
      "story_text": null,
      "comment_text": "One of the lessons I took away from the static analysis tools I architected (PREfix and PREfast) was just how many bugs you can find with simple pattern-matching.<p>To make it work in practice, you need some UX support -- including explanations (so in this case, making it clear that the results are undefined if the integer starts with a 0) and recommended fixes (specify the radix).  Otherwise, people are likely to dismiss the messages as a false positive.",
      "num_comments": null,
      "story_id": 2474143,
      "story_title": "Another common bug in published code ",
      "story_url": "http://www.google.com/codesearch?hl=en&lr=&q=parseInt%5C%28*%5B%5E%2C%5D%5C%29&sbtn=Search",
      "parent_id": 2474143,
      "created_at_i": 1303485734,
      "_tags": [
        "comment",
        "author_jdp23",
        "story_2474143"
      ],
      "objectID": "2474333",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jdp23",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "One of the lessons I took away from the <em>static</em> <em>analysis</em> <em>tools</em> I architected (PREfix and PREfast) was just how many bugs you can find with simple pattern-matching.<p>To make it work in practice, you need some UX support -- including explanations (so in this case, making it clear that the results are undefined if the integer starts with a 0) and recommended fixes (specify the radix).  Otherwise, people are likely to dismiss the messages as a false positive.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Another common bug in published code ",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.google.com/codesearch?hl=en&lr=&q=parseInt%5C%28*%5B%5E%2C%5D%5C%29&sbtn=Search",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-18T23:17:11.000Z",
      "title": null,
      "url": null,
      "author": "cletus",
      "points": 5,
      "story_text": null,
      "comment_text": "I&#x27;ve started getting back into C++ after many years away and it&#x27;s all coming back to me.<p>Now of course it&#x27;s C++11, which does have some nice features, but really I think we&#x27;ve reached the point where we need to start again (downvote away).<p>Let me give you an example: I recently came across some code that was written years ago that has two size types: one 32&#x2F;64 bit signed and the other 32 bit unsigned. This creates a bunch of issues when compiled on 32 and 64 bit architectures and there is a substantial amount of effort to clean it up.<p>I point out things like this to colleagues who are very pro-C++ and I inevitably get the same response: &quot;well that&#x27;s just bad API design&quot;.<p>Thing is, if you look at the history of this example it&#x27;s a series of incremental changes, all well-meaning and reasoned, some of which are done by people who I could only call luminaries, and even they make significant and far-reaching mistakes.<p>So what hope do the rest of us have?<p>But my biggest problem with the C-dialects is pointers. Namely if you return or receive a pointer, it&#x27;s not necessarily clear who owns it. The way this is handled is comments like &quot;DO NOT delete this&quot; or &quot;you MUST delete this&quot;.<p>I like that a language like Rust is trying to formalize the concept of object ownership. I&#x27;d really like to see that idea mature and take hold.<p>Until now there hasn&#x27;t really been a competitive alternative to C&#x2F;C++. It&#x27;s not Go (as much I love Go). Maybe it&#x27;s Rust. We can but hope.<p>My other big problem (and this applies to Java too) is directly dealing with low-level multithreading primitives like threads, thread groups and mutexes. I really like that Go has taken a different approach here.<p>What I find with particularly young programmers is they don&#x27;t have the appropriate fear of writing multithreaded code. It&#x27;s really, really hard to write correct multithreaded code with low-level primitives. It&#x27;s why (excellent) books like <i>Java Concurrency in Practice</i> exist.<p>As for the feature list of C++14 [1], I wonder what all these &quot;auto&quot; declarations will do to the significant work required for static analysis tools, that are an essential part of modern, large-scale C++ codebases.<p>The literal types (like &quot;s&quot; for std::string or seconds) are cute but at some point the STL was optional. I&#x27;m a little leery of embedding it directly in the language but hey I&#x27;m no expert.<p>[1]: <a href=\"http://en.wikipedia.org/wiki/C%2B%2B14\" rel=\"nofollow\">http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;C%2B%2B14</a>",
      "num_comments": null,
      "story_id": 8193754,
      "story_title": "We have C++14",
      "story_url": "http://isocpp.org/blog/2014/08/we-have-cpp14",
      "parent_id": 8193754,
      "created_at_i": 1408403831,
      "_tags": [
        "comment",
        "author_cletus",
        "story_8193754"
      ],
      "objectID": "8195220",
      "_highlightResult": {
        "author": {
          "value": "cletus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I've started getting back into C++ after many years away and it's all coming back to me.<p>Now of course it's C++11, which does have some nice features, but really I think we've reached the point where we need to start again (downvote away).<p>Let me give you an example: I recently came across some code that was written years ago that has two size types: one 32/64 bit signed and the other 32 bit unsigned. This creates a bunch of issues when compiled on 32 and 64 bit architectures and there is a substantial amount of effort to clean it up.<p>I point out things like this to colleagues who are very pro-C++ and I inevitably get the same response: &quot;well that's just bad API design&quot;.<p>Thing is, if you look at the history of this example it's a series of incremental changes, all well-meaning and reasoned, some of which are done by people who I could only call luminaries, and even they make significant and far-reaching mistakes.<p>So what hope do the rest of us have?<p>But my biggest problem with the C-dialects is pointers. Namely if you return or receive a pointer, it's not necessarily clear who owns it. The way this is handled is comments like &quot;DO NOT delete this&quot; or &quot;you MUST delete this&quot;.<p>I like that a language like Rust is trying to formalize the concept of object ownership. I'd really like to see that idea mature and take hold.<p>Until now there hasn't really been a competitive alternative to C/C++. It's not Go (as much I love Go). Maybe it's Rust. We can but hope.<p>My other big problem (and this applies to Java too) is directly dealing with low-level multithreading primitives like threads, thread groups and mutexes. I really like that Go has taken a different approach here.<p>What I find with particularly young programmers is they don't have the appropriate fear of writing multithreaded code. It's really, really hard to write correct multithreaded code with low-level primitives. It's why (excellent) books like <i>Java Concurrency in Practice</i> exist.<p>As for the feature list of C++14 [1], I wonder what all these &quot;auto&quot; declarations will do to the significant work required for <em>static</em> <em>analysis</em> <em>tools</em>, that are an essential part of modern, large-scale C++ codebases.<p>The literal types (like &quot;s&quot; for std::string or seconds) are cute but at some point the STL was optional. I'm a little leery of embedding it directly in the language but hey I'm no expert.<p>[1]: <a href=\"http://en.wikipedia.org/wiki/C%2B%2B14\" rel=\"nofollow\">http://en.wikipedia.org/wiki/C%2B%2B14</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "We have C++14",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://isocpp.org/blog/2014/08/we-have-cpp14",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-19T03:24:18.000Z",
      "title": null,
      "url": null,
      "author": "dllthomas",
      "points": 5,
      "story_text": null,
      "comment_text": "I love refactoring in a good, statically typed language.  Change the types in a carefully breaking way, and you&#x27;re immediately told every single place you need to change.  Seven times out of ten I can manage to squeeze this out of my C, even before static analysis tools, though certainly wind up leaning more heavily on my tests than in some other languages.",
      "num_comments": null,
      "story_id": 7913435,
      "story_title": "The Safyness of Static Typing",
      "story_url": "http://blog.metaobject.com/2014/06/the-safyness-of-static-typing.html",
      "parent_id": 7913693,
      "created_at_i": 1403148258,
      "_tags": [
        "comment",
        "author_dllthomas",
        "story_7913435"
      ],
      "objectID": "7914241",
      "_highlightResult": {
        "author": {
          "value": "dllthomas",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I love refactoring in a good, statically typed language.  Change the types in a carefully breaking way, and you're immediately told every single place you need to change.  Seven times out of ten I can manage to squeeze this out of my C, even before <em>static</em> <em>analysis</em> <em>tools</em>, though certainly wind up leaning more heavily on my tests than in some other languages.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Safyness of <em>Static</em> Typing",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "http://blog.metaobject.com/2014/06/the-safyness-of-<em>static</em>-typing.html",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        }
      }
    },
    {
      "created_at": "2014-04-28T03:49:02.000Z",
      "title": null,
      "url": null,
      "author": "aaronblohowiak",
      "points": 5,
      "story_text": null,
      "comment_text": "&gt;Like say build tools static analysis tools to check if go-routines end up accessing shared state<p>I believe this is what the go race detector does: <a href=\"http://blog.golang.org/race-detector\" rel=\"nofollow\">http:&#x2F;&#x2F;blog.golang.org&#x2F;race-detector</a>",
      "num_comments": null,
      "story_id": 7657394,
      "story_title": "Some thoughts on Go and Erlang",
      "story_url": "http://blog.erlware.org/2014/04/27/some-thoughts-on-go-and-erlang/",
      "parent_id": 7657873,
      "created_at_i": 1398656942,
      "_tags": [
        "comment",
        "author_aaronblohowiak",
        "story_7657394"
      ],
      "objectID": "7658139",
      "_highlightResult": {
        "author": {
          "value": "aaronblohowiak",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;Like say build <em>tools</em> <em>static</em> <em>analysis</em> <em>tools</em> to check if go-routines end up accessing shared state<p>I believe this is what the go race detector does: <a href=\"http://blog.golang.org/race-detector\" rel=\"nofollow\">http://blog.golang.org/race-detector</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Some thoughts on Go and Erlang",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.erlware.org/2014/04/27/some-thoughts-on-go-and-erlang/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-09T06:17:04.000Z",
      "title": "",
      "url": "",
      "author": "jzelinskie",
      "points": 5,
      "story_text": null,
      "comment_text": "In addition to your point, I&#x27;d like to stress that it is the game engines that are C++. Many engines provide a higher level interface for developers actually make games. You probably won&#x27;t hook the game developers on Rust. If you want to pitch Rust to the engine guys, you&#x27;re going to be battling against their toolchains that have been developed for decades and have some of the best static analysis tools under the sun. Not to mention, you&#x27;ll also be battling against the traction of their current codebase, which they&#x27;ll probably hesitant to rewrite in a new language. From a business perspective, I don&#x27;t think management in some of the larger companies would let that decision fly, either.",
      "num_comments": null,
      "story_id": 6181897,
      "story_title": "New Rust runtime turned on. What next?",
      "story_url": "https://mail.mozilla.org/pipermail/rust-dev/2013-August/005158.html",
      "parent_id": 6183729,
      "created_at_i": 1376029024,
      "_tags": [
        "comment",
        "author_jzelinskie",
        "story_6181897"
      ],
      "objectID": "6184017",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jzelinskie",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In addition to your point, I'd like to stress that it is the game engines that are C++. Many engines provide a higher level interface for developers actually make games. You probably won't hook the game developers on Rust. If you want to pitch Rust to the engine guys, you're going to be battling against their toolchains that have been developed for decades and have some of the best <em>static</em> <em>analysis</em> <em>tools</em> under the sun. Not to mention, you'll also be battling against the traction of their current codebase, which they'll probably hesitant to rewrite in a new language. From a business perspective, I don't think management in some of the larger companies would let that decision fly, either.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "New Rust runtime turned on. What next?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://mail.mozilla.org/pipermail/rust-dev/2013-August/005158.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-30T16:14:23.000Z",
      "title": "",
      "url": "",
      "author": "notaddicted",
      "points": 5,
      "story_text": null,
      "comment_text": "I'm not a grandmaster by any means, but these are things that I focus on:<p>1. Aggressively avoid techniques and abstractions that have produced bugs in the past. The \"backwards conditional\" is an example of this, in languages like C that will accept <i>x = 0</i> as a conditional, it is safer to do <i>0 == x</i> in an if statement in case you mistype. Mutability trips me up sometimes, so I try to never re-assign a variable. I keep links to the source code of key libraries in my bookmarks bar so I never have the guess how something actually works. Static analysis tools, and bug prediction tools [1] are two steps I haven't taken.<p>2. Seek out code written by experts and inspect it [2]. If I'm considering using a new language or library one of the first things I do is to search for large scale OSS projects. For a new language looking at some of the popular 3rd party libraries can be really illuminating. Especially if you're already familiar with the problem space.<p>3. two words: learn to fuckin' type.<p>4. Get familiar with what the history researchers call the <i>Primary Sources</i>. Not just the actual source code but the proposals, the specifications, and the research reports that are written by the people who conceived the tools that you are using.<p>[1] <a href=\"http://google-engtools.blogspot.ca/2011/12/bug-prediction-at-google.html\" rel=\"nofollow\">http://google-engtools.blogspot.ca/2011/12/bug-prediction-at...</a><p>[2] (EDIT) According to Paul Allen, in high school Bill Gates actually went dumpster diving for source code: <a href=\"http://www.businessinsider.com/10-things-you-didnt-know-about-bill-gates-2011-4?op=1\" rel=\"nofollow\">http://www.businessinsider.com/10-things-you-didnt-know-abou...</a>",
      "num_comments": null,
      "story_id": 5792979,
      "story_title": "Deliberate Programming",
      "story_url": "https://medium.com/on-coding/2204cfa35233",
      "parent_id": 5792979,
      "created_at_i": 1369930463,
      "_tags": [
        "comment",
        "author_notaddicted",
        "story_5792979"
      ],
      "objectID": "5793358",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "notaddicted",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm not a grandmaster by any means, but these are things that I focus on:<p>1. Aggressively avoid techniques and abstractions that have produced bugs in the past. The \"backwards conditional\" is an example of this, in languages like C that will accept <i>x = 0</i> as a conditional, it is safer to do <i>0 == x</i> in an if statement in case you mistype. Mutability trips me up sometimes, so I try to never re-assign a variable. I keep links to the source code of key libraries in my bookmarks bar so I never have the guess how something actually works. <em>Static</em> <em>analysis</em> <em>tools</em>, and bug prediction <em>tools</em> [1] are two steps I haven't taken.<p>2. Seek out code written by experts and inspect it [2]. If I'm considering using a new language or library one of the first things I do is to search for large scale OSS projects. For a new language looking at some of the popular 3rd party libraries can be really illuminating. Especially if you're already familiar with the problem space.<p>3. two words: learn to fuckin' type.<p>4. Get familiar with what the history researchers call the <i>Primary Sources</i>. Not just the actual source code but the proposals, the specifications, and the research reports that are written by the people who conceived the <em>tools</em> that you are using.<p>[1] <a href=\"http://google-engtools.blogspot.ca/2011/12/bug-prediction-at-google.html\" rel=\"nofollow\">http://google-engtools.blogspot.ca/2011/12/bug-prediction-at...</a><p>[2] (EDIT) According to Paul Allen, in high school Bill Gates actually went dumpster diving for source code: <a href=\"http://www.businessinsider.com/10-things-you-didnt-know-about-bill-gates-2011-4?op=1\" rel=\"nofollow\">http://www.businessinsider.com/10-things-you-didnt-know-abou...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Deliberate Programming",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://medium.com/on-coding/2204cfa35233",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-08T15:16:55.000Z",
      "title": "",
      "url": "",
      "author": "Ixiaus",
      "points": 5,
      "story_text": null,
      "comment_text": "On the topic of languages and static analysis:<p>You can do <i>some</i> static-analysis on languages like Ruby/Python but their lack of rigorous typing makes that job quite hard, actually.<p>Then you have other languages, king of the hill being Haskell - where practically all of these tools exist (minus the web-browsable/social aspect) because they are straight-forward (not easy, but straight-forward) to build as the language's type system is much deeper and it also encourages the programmer to be more thorough with their program.<p>Could you imagine having static-analysis built into your linter, where it gives you recommendations, optimizations, and warnings WHILE you are writing code? Yes, thank you Haskell. The best part about it too is the people contributing to that eco-system aren't <i>average</i> programmers, they are typically PhD holding industry programmers or academics (who contribute for free because there's no economic incentive to hide your work) that know far more than I do; all I have to do is be smart enough <i>to use what they build</i>.<p>On the topic of these \"engineering\" tools available for devs:<p>It's funny because engineering (if you can even call it that) for web applications only recently became a big juicy market [for engineers]. Most of the \"engineers\" were working on software for embedded systems or really big systems that were rarely ever end-user consumed as web applications are today. So tooling for engineers has actually been around; <i>very good tooling</i> in fact.<p>It's just that we now have a slew of people writing software in a very big market using languages that <i>ARE NOT SAFE</i> to program in! That's the story though, these languages {python | ruby | php | perl} are much easier to learn and \"get going\" in than something like Haskell, O'Caml, Mercury, Scala, Erlang, C++ &#38;c... By being easier to pick up, [the languages] CREATED the market we are all now participating in. The downside though, is we have a sewer of code floating around because humans by nature, are terrible engineers. Our #1 priority SHOULD BE building tools to check and verify our end product. Some teams go so far as to have teams that are dedicated to writing that software and another team dedicated to writing the software that verifies the verification software! (this is typically when lives are at stake though - side-thought: with the bitcoin thefts and loss of identity on the net now though; one could argue that \"lives\" are at stake in an existential sense)<p>I consider Haskell itself to be top of the line tooling for engineerings - of all sorts, even web! Aside from the static analysis tools outside of the language, the language <i>itself</i> is a dream-come-true for real-world programmers such as myself. I fuck up my programs all the time, and my Python programs are ugly and if my tests don't catch an error in my programming my users end up catching it. With Haskell the only thing my users EVER catch are <i>business logic bugs</i> and not programmer error.",
      "num_comments": null,
      "story_id": 5511280,
      "story_title": "Show HN: CommitQ  Programming language-aware Git repository hosting",
      "story_url": "http://commitq.com/blog/2013/04/01/hello/",
      "parent_id": 5511593,
      "created_at_i": 1365434215,
      "_tags": [
        "comment",
        "author_Ixiaus",
        "story_5511280"
      ],
      "objectID": "5512190",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Ixiaus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "On the topic of languages and <em>static</em> <em>analysis</em>:<p>You can do <i>some</i> <em>static</em>-<em>analysis</em> on languages like Ruby/Python but their lack of rigorous typing makes that job quite hard, actually.<p>Then you have other languages, king of the hill being Haskell - where practically all of these <em>tools</em> exist (minus the web-browsable/social aspect) because they are straight-forward (not easy, but straight-forward) to build as the language's type system is much deeper and it also encourages the programmer to be more thorough with their program.<p>Could you imagine having <em>static</em>-<em>analysis</em> built into your linter, where it gives you recommendations, optimizations, and warnings WHILE you are writing code? Yes, thank you Haskell. The best part about it too is the people contributing to that eco-system aren't <i>average</i> programmers, they are typically PhD holding industry programmers or academics (who contribute for free because there's no economic incentive to hide your work) that know far more than I do; all I have to do is be smart enough <i>to use what they build</i>.<p>On the topic of these \"engineering\" <em>tools</em> available for devs:<p>It's funny because engineering (if you can even call it that) for web applications only recently became a big juicy market [for engineers]. Most of the \"engineers\" were working on software for embedded systems or really big systems that were rarely ever end-user consumed as web applications are today. So tooling for engineers has actually been around; <i>very good tooling</i> in fact.<p>It's just that we now have a slew of people writing software in a very big market using languages that <i>ARE NOT SAFE</i> to program in! That's the story though, these languages {python | ruby | php | perl} are much easier to learn and \"get going\" in than something like Haskell, O'Caml, Mercury, Scala, Erlang, C++ &c... By being easier to pick up, [the languages] CREATED the market we are all now participating in. The downside though, is we have a sewer of code floating around because humans by nature, are terrible engineers. Our #1 priority SHOULD BE building <em>tools</em> to check and verify our end product. Some teams go so far as to have teams that are dedicated to writing that software and another team dedicated to writing the software that verifies the verification software! (this is typically when lives are at stake though - side-thought: with the bitcoin thefts and loss of identity on the net now though; one could argue that \"lives\" are at stake in an existential sense)<p>I consider Haskell itself to be top of the line tooling for engineerings - of all sorts, even web! Aside from the <em>static</em> <em>analysis</em> <em>tools</em> outside of the language, the language <i>itself</i> is a dream-come-true for real-world programmers such as myself. I fuck up my programs all the time, and my Python programs are ugly and if my tests don't catch an error in my programming my users end up catching it. With Haskell the only thing my users EVER catch are <i>business logic bugs</i> and not programmer error.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Show HN: CommitQ  Programming language-aware Git repository hosting",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://commitq.com/blog/2013/04/01/hello/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-08T22:59:51.000Z",
      "title": null,
      "url": null,
      "author": "Natsu",
      "points": 4,
      "story_text": null,
      "comment_text": "Static analysis tools are essentially automatic checklists applied to code.",
      "num_comments": null,
      "story_id": 7865917,
      "story_title": "How mistakes can save lives: one man’s mission to revolutionise the NHS",
      "story_url": "http://www.newstatesman.com/2014/05/how-mistakes-can-save-lives",
      "parent_id": 7866069,
      "created_at_i": 1402268391,
      "_tags": [
        "comment",
        "author_Natsu",
        "story_7865917"
      ],
      "objectID": "7866243",
      "_highlightResult": {
        "author": {
          "value": "Natsu",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<em>Static</em> <em>analysis</em> <em>tools</em> are essentially automatic checklists applied to code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How mistakes can save lives: one man’s mission to revolutionise the NHS",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.newstatesman.com/2014/05/how-mistakes-can-save-lives",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-15T13:23:09.000Z",
      "title": null,
      "url": null,
      "author": "jerf",
      "points": 4,
      "story_text": null,
      "comment_text": "On the other hand, there&#x27;s more to testing than traditional unit testing in which a programmer enumerates a series of cases and verifies that what they think should happen (which may or may not even be correct) happens.<p>There&#x27;s fuzz testing. There&#x27;s QuickTest-like testing, which is tricky in this sort of situation, but powerful if you take the time. There&#x27;s static analysis, which are basically a form of automated testing. In fact, static analysis <i>can</i> in fact test some of the things you claim can&#x27;t be tested. Some of the other things are also more testable than you are saying, such as resource exhaustion, which can be both simulated via injection or via simply exhausting resources in the test case.<p>Further, even the relatively-weak guarantees that traditional unit testing can provide are a <i>foundation</i> for further analysis. What&#x27;s the point of analyzing a bit of code for whether or not it uses entropy correctly if you miss the fact that the code is straight-up <i>buggy</i>? Given the demonstrated difficulty of writing code even before it&#x27;s <i>security</i> code without solid testing, this is hardly the time to be claiming that testing isn&#x27;t necessary.<p>This strikes me as another iteration of the Real Man argument (&quot;Real Men write in assembler&quot; being one of the originals). The truth is we need all the help we can get because we humans aren&#x27;t very good at programming in the end... and of <i>all the places</i> I&#x27;m not inclined to accept the Real Man argument, it&#x27;s in security code. This is the sort of code that ought to be getting covered by two or three separate static analysis tools, <i>and</i> getting reviewed by skilled developers, <i>and</i> getting fuzz tested, <i>and</i> getting basic unit tests.",
      "num_comments": null,
      "story_id": 7589943,
      "story_title": "OpenBSD has started a massive strip-down and cleanup of OpenSSL",
      "story_url": "https://lobste.rs/s/3utipo/openbsd_has_started_a_massive_strip-down_and_cleanup_of_openssl",
      "parent_id": 7591350,
      "created_at_i": 1397568189,
      "_tags": [
        "comment",
        "author_jerf",
        "story_7589943"
      ],
      "objectID": "7591625",
      "_highlightResult": {
        "author": {
          "value": "jerf",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "On the other hand, there's more to testing than traditional unit testing in which a programmer enumerates a series of cases and verifies that what they think should happen (which may or may not even be correct) happens.<p>There's fuzz testing. There's QuickTest-like testing, which is tricky in this sort of situation, but powerful if you take the time. There's <em>static</em> <em>analysis</em>, which are basically a form of automated testing. In fact, <em>static</em> <em>analysis</em> <i>can</i> in fact test some of the things you claim can't be tested. Some of the other things are also more testable than you are saying, such as resource exhaustion, which can be both simulated via injection or via simply exhausting resources in the test case.<p>Further, even the relatively-weak guarantees that traditional unit testing can provide are a <i>foundation</i> for further <em>analysis.</em> What's the point of analyzing a bit of code for whether or not it uses entropy correctly if you miss the fact that the code is straight-up <i>buggy</i>? Given the demonstrated difficulty of writing code even before it's <i>security</i> code without solid testing, this is hardly the time to be claiming that testing isn't necessary.<p>This strikes me as another iteration of the Real Man argument (&quot;Real Men write in assembler&quot; being one of the originals). The truth is we need all the help we can get because we humans aren't very good at programming in the end... and of <i>all the places</i> I'm not inclined to accept the Real Man argument, it's in security code. This is the sort of code that ought to be getting covered by two or three separate <em>static</em> <em>analysis</em> <em>tools</em>, <i>and</i> getting reviewed by skilled developers, <i>and</i> getting fuzz tested, <i>and</i> getting basic unit tests.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "OpenBSD has started a massive strip-down and cleanup of OpenSSL",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://lobste.rs/s/3utipo/openbsd_has_started_a_massive_strip-down_and_cleanup_of_openssl",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T21:18:35.000Z",
      "title": null,
      "url": null,
      "author": "hackinthebochs",
      "points": 4,
      "story_text": null,
      "comment_text": "Yeah--it should be a no-brainer. Running such critical code through as many static analysis tools you can get your hands on should be standard practice. I wonder why Coverity and the rest havent taken it upon themselves. I remember a story about Coverity running their tool on random open source projects and emailing them about issues they found. Maybe OpenSSL is too far in the hole to start that now.",
      "num_comments": null,
      "story_id": 7565577,
      "story_title": "Were Intelligence Agencies Using Heartbleed in November 2013?",
      "story_url": "https://www.eff.org/deeplinks/2014/04/wild-heart-were-intelligence-agencies-using-heartbleed-november-2013",
      "parent_id": 7569755,
      "created_at_i": 1397164715,
      "_tags": [
        "comment",
        "author_hackinthebochs",
        "story_7565577"
      ],
      "objectID": "7569797",
      "_highlightResult": {
        "author": {
          "value": "hackinthebochs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Yeah--it should be a no-brainer. Running such critical code through as many <em>static</em> <em>analysis</em> <em>tools</em> you can get your hands on should be standard practice. I wonder why Coverity and the rest havent taken it upon themselves. I remember a story about Coverity running their tool on random open source projects and emailing them about issues they found. Maybe OpenSSL is too far in the hole to start that now.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Were Intelligence Agencies Using Heartbleed in November 2013?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.eff.org/deeplinks/2014/04/wild-heart-were-intelligence-agencies-using-heartbleed-november-2013",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-28T21:19:04.000Z",
      "title": null,
      "url": null,
      "author": "al2o3cr",
      "points": 4,
      "story_text": null,
      "comment_text": "I&#x27;m not buying these conclusions - on a quick scan, the &quot;strange expression&quot; isn&#x27;t wrong: the code is scanning to find the first character that isn&#x27;t a colon. The check against the zero byte is harmless, and I could imagine <i>other</i> static analysis tools insisting on it (as cheap insurance against scanning off-the-end).<p>As for the &quot;shifting negative integers is undefined behavior&quot;, this is a technically-true statement that&#x27;s been practically-false for quite a few years - does <i>anybody</i> still use a machine that doesn&#x27;t use two&#x27;s-complement integers?",
      "num_comments": null,
      "story_id": 7320398,
      "story_title": "An Experiment with Checking the glibc Library",
      "story_url": "http://www.viva64.com/en/b/0237/",
      "parent_id": 7320398,
      "created_at_i": 1393622344,
      "_tags": [
        "comment",
        "author_al2o3cr",
        "story_7320398"
      ],
      "objectID": "7321567",
      "_highlightResult": {
        "author": {
          "value": "al2o3cr",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm not buying these conclusions - on a quick scan, the &quot;strange expression&quot; isn't wrong: the code is scanning to find the first character that isn't a colon. The check against the zero byte is harmless, and I could imagine <i>other</i> <em>static</em> <em>analysis</em> <em>tools</em> insisting on it (as cheap insurance against scanning off-the-end).<p>As for the &quot;shifting negative integers is undefined behavior&quot;, this is a technically-true statement that's been practically-false for quite a few years - does <i>anybody</i> still use a machine that doesn't use two's-complement integers?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "An Experiment with Checking the glibc Library",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0237/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-24T13:39:23.000Z",
      "title": null,
      "url": null,
      "author": "slashdotaccount",
      "points": 4,
      "story_text": null,
      "comment_text": "Troll harder, greenhorn. (account &quot;metsgrets&quot; created 7 hours ago)<p>&gt; CPAN is awful […] Navigating it is a pain […] the issue tracker is a nightmare<p>These are opinions. I cannot see any facts to substantiate the claims.<p>&gt; most of the documentation is done very poorly because no one puts time into formatting their readmes<p>No, most of the documentation is the best among libraries in any programming language because everyone uses documentation templates and then fills in the details in copious amount. These templates have been honed over years, and the docs are regularly quality checked by automated services. It also helps that the documentation format POD is so so stupidly simple that it never gets in the way of work: a programmer spends all the time writing content, none on formatting.<p>&gt; None of the modules are in github<p>All of the modules are in Github.<p>&gt; the links make no sense ( &quot;Source (raw) Browse (raw)&quot; )<p>&quot;Source&quot; shows the module&#x27;s source (HTML, syntax highlighted). &quot;Browse&quot; browses the directory structure of the unpacked distribution. The raw links are the plain text equivalents served by the API primarily for programmatic access. All of this is readily obvious by just following a link.<p>&gt; many of the modules we have worked with have bugs and poor documentation<p>Unsubstantiated, no details.<p>&gt; and almost all of them are unmaintained<p>CPAN freshness tells a different story.<p>&gt; owners either gave up or actually died<p>There&#x27;s a process in place for taking over maintenance. It is used a couple of times a month.<p>&gt; There is absolutely no support for trying to do common tasks with CPAN modules<p>Wrong. Any common task has several modules.<p>&gt; You can&#x27;t Google for your error<p>Unsubstantiated, no details.<p>&gt; you won&#x27;t get a response on StackOverflow<p>Wrong. Unanswered quota is only 10%.<p>&gt; CPAN is just messy all around<p>Same is true for any file archive. Show me a programming language where this is not the case. At least it&#x27;s centralised, not strewn across the Web! On top of the archive, curated indexes such as <a href=\"http://p3rl.org/Task::Kensho\" rel=\"nofollow\">http:&#x2F;&#x2F;p3rl.org&#x2F;Task::Kensho</a> exist.<p>&gt; There&#x27;s not even a command line flag to find out what version of a module you have installed. You have to hack into its internals to figure out what versions you&#x27;re running.<p>Wrong.<p><pre><code>    $ pmvers Catalyst\\n    5.90060\\n\\n    $ perl -MCatalyst -E&#x27;say Catalyst-&gt;VERSION&#x27;\\n    5.90060\\n</code></pre>\\n&gt; Some modules are hosted in foreign countries that intermittently decide not to download. Builds have broken due to inability to download from a mirror.<p>Then pick a mirror near you. <a href=\"http://mirrors.cpan.org/\" rel=\"nofollow\">http:&#x2F;&#x2F;mirrors.cpan.org&#x2F;</a> The standard CPAN client does this automatically during first run.<p>&gt; The only known benefit of CPAN - automated test running, has never once proved helpful.<p>Unsubstantiated, no details.<p>&gt; It seems like Larry Wall (creator of Perl) has a no-one-likes-this-langauge-so-try-to-please-everyone-by-offering-every-way-to-do-it complex.<p>Wrong, this is because humans have different ways to think and preferences how to express themselves. The programming language works <i>with</i> the grain of the human mindset, not against it. <a href=\"http://c2.com/cgi/wiki?ThereIsMoreThanOneWayToDoIt\" rel=\"nofollow\">http:&#x2F;&#x2F;c2.com&#x2F;cgi&#x2F;wiki?ThereIsMoreThanOneWayToDoIt</a><p>&gt; I have to Google for how to iterate over a hash every time, because there&#x27;s multiple ways to do it, and they all suck. I never know if iterating over a $hash is the same as iterating over a %hash or a \\\\%hash.<p>Then you know less than a beginner in his third lesson.<p><pre><code>    ⎆ my %hash = qw(a b c d); my $hash = \\\\%hash\\n    ⎆ while (my ($key, $value) = each $hash) { say &quot;$key =&gt; $value&quot; }\\n    a =&gt; b\\n    c =&gt; d\\n    ⎆ while (my ($key, $value) = each %hash) { say &quot;$key =&gt; $value&quot; }\\n    a =&gt; b\\n    c =&gt; d\\n    ⎆ while (my ($key, $value) = each \\\\%hash) { say &quot;$key =&gt; $value&quot; }\\n    a =&gt; b\\n    c =&gt; d\\n</code></pre>\\n&gt; if I should be searching for &quot;hash&quot; or &quot;hashref&quot; or if I should be using a &quot;list&quot; or an &quot;array&quot; or a scalar or who cares<p>Only bash and Tcl free you from thinking about and selecting the appropriate data type.<p>&gt; The multiple ways to do things only amounts to one asshole on the team will exploit some unknown feature of map to write shorter code, not document it, and no one can read it.<p>This is a social problem, and not the responsibility of the programming language or its designer. Anyone can write crap code in any language. Enforce code style and policy locally. Static analysis tools like <a href=\"http://p3rl.org/perlcritic\" rel=\"nofollow\">http:&#x2F;&#x2F;p3rl.org&#x2F;perlcritic</a> exist. Apply them.<p>&gt; Perl is not efficient<p>Perl remains the fastest of the scripting languages.<p>&gt; Beauty is subjective, readable code is not.<p>Unreadable code is a social problem across all programming languages. This has nothing to do with Perl per se.<p>&gt; The prefixing of variable names with @, % et all makes dissecting code hard<p>Wrong, sigils make the nouns stand out, just like capitalisation in written German. Both empirically make reading faster and comprehension easier.<p>&gt; Googling impossible<p>Wrong. It is true that search engines drop sigil characters from the query, but the context words still find the result in the index.<p>&gt; References are one of, if not the, biggest design flaw in Perl […] make reading and writing code confusing, overly complicated<p>Unsubstantiated, no details.<p>&gt; haven not once offered us any benefit<p>Wrong, as references are the basis for objects (OOP).<p>&gt; the language is gross. It has magic built in, and the syntax is a nightmare<p>Unsubstantiated, no details.<p>&gt; You get function arguments as @_<p>Concept stolen from Shell, already remedied in version 20. Signatures have been available for years with modules.<p>&gt; You do a regex match with $string =~ &#x2F;(capture)&#x2F;. This will magically populate $1 through $n with capture groups. This is bad.<p>Agreed, side effects are evil. That&#x27;s the legacy interface and impossible to deprecate&#x2F;remove. The expression will also return a list of the captures which you can then assign or mangle as you wish.<p><pre><code>    my @results = $string =~ &#x2F;(capture)&#x2F;\\n</code></pre>\\nGood style dictates to prefer this interface.<p>&gt; $string =~ s&#x2F;a&#x2F;b. This modifies the string in place. Try to Google for how to not modify the string in place. Seriously, try and Google for it.<p>Yes, and?<p><pre><code>    g perl substitute return modification\\n</code></pre>\\n(Type it out to see Google suggestion&#x2F;autocompletion.) First five results all teach:<p><pre><code>    my $new = $string =~ s&#x2F;a&#x2F;b&#x2F;r\\n</code></pre>\\n&gt; If you forget to include an even number of values in a list it becomes another data structure entirely.<p>Wrong, a list is a list no matter how many elements.<p>&gt; If you don&#x27;t put a &#x27;1;&#x27; at the end of your module code it will fail to work (no, really).<p>Valid complaint. Again, it&#x27;s too late to fix it because existing code needs to keep working, back-compat is serious business for perl5-porters. New projects with modern Perl just avoid the need for that last line: <a href=\"http://p3rl.org/true\" rel=\"nofollow\">http:&#x2F;&#x2F;p3rl.org&#x2F;true</a><p>&gt; bless […] but it still is out of place in a programming language.<p>The word is religion neutral. Your biases show.<p>&gt; The &quot;features&quot; of Perl ruin it for a team environment.<p>Unsubstantiated, no details.",
      "num_comments": null,
      "story_id": 7288884,
      "story_title": "The Fall Of Perl, The Web's Most Promising Language",
      "story_url": "http://www.fastcolabs.com/3026446/the-fall-of-perl-the-webs-most-promising-language",
      "parent_id": 7289338,
      "created_at_i": 1393249163,
      "_tags": [
        "comment",
        "author_slashdotaccount",
        "story_7288884"
      ],
      "objectID": "7290637",
      "_highlightResult": {
        "author": {
          "value": "slashdotaccount",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Troll harder, greenhorn. (account &quot;metsgrets&quot; created 7 hours ago)<p>&gt; CPAN is awful […] Navigating it is a pain […] the issue tracker is a nightmare<p>These are opinions. I cannot see any facts to substantiate the claims.<p>&gt; most of the documentation is done very poorly because no one puts time into formatting their readmes<p>No, most of the documentation is the best among libraries in any programming language because everyone uses documentation templates and then fills in the details in copious amount. These templates have been honed over years, and the docs are regularly quality checked by automated services. It also helps that the documentation format POD is so so stupidly simple that it never gets in the way of work: a programmer spends all the time writing content, none on formatting.<p>&gt; None of the modules are in github<p>All of the modules are in Github.<p>&gt; the links make no sense ( &quot;Source (raw) Browse (raw)&quot; )<p>&quot;Source&quot; shows the module's source (HTML, syntax highlighted). &quot;Browse&quot; browses the directory structure of the unpacked distribution. The raw links are the plain text equivalents served by the API primarily for programmatic access. All of this is readily obvious by just following a link.<p>&gt; many of the modules we have worked with have bugs and poor documentation<p>Unsubstantiated, no details.<p>&gt; and almost all of them are unmaintained<p>CPAN freshness tells a different story.<p>&gt; owners either gave up or actually died<p>There's a process in place for taking over maintenance. It is used a couple of times a month.<p>&gt; There is absolutely no support for trying to do common tasks with CPAN modules<p>Wrong. Any common task has several modules.<p>&gt; You can't Google for your error<p>Unsubstantiated, no details.<p>&gt; you won't get a response on StackOverflow<p>Wrong. Unanswered quota is only 10%.<p>&gt; CPAN is just messy all around<p>Same is true for any file archive. Show me a programming language where this is not the case. At least it's centralised, not strewn across the Web! On top of the archive, curated indexes such as <a href=\"http://p3rl.org/Task::Kensho\" rel=\"nofollow\">http://p3rl.org/Task::Kensho</a> exist.<p>&gt; There's not even a command line flag to find out what version of a module you have installed. You have to hack into its internals to figure out what versions you're running.<p>Wrong.<p><pre><code>    $ pmvers Catalyst\\n    5.90060\\n\\n    $ perl -MCatalyst -E'say Catalyst-&gt;VERSION'\\n    5.90060\\n</code></pre>\\n&gt; Some modules are hosted in foreign countries that intermittently decide not to download. Builds have broken due to inability to download from a mirror.<p>Then pick a mirror near you. <a href=\"http://mirrors.cpan.org/\" rel=\"nofollow\">http://mirrors.cpan.org/</a> The standard CPAN client does this automatically during first run.<p>&gt; The only known benefit of CPAN - automated test running, has never once proved helpful.<p>Unsubstantiated, no details.<p>&gt; It seems like Larry Wall (creator of Perl) has a no-one-likes-this-langauge-so-try-to-please-everyone-by-offering-every-way-to-do-it complex.<p>Wrong, this is because humans have different ways to think and preferences how to express themselves. The programming language works <i>with</i> the grain of the human mindset, not against it. <a href=\"http://c2.com/cgi/wiki?ThereIsMoreThanOneWayToDoIt\" rel=\"nofollow\">http://c2.com/cgi/wiki?ThereIsMoreThanOneWayToDoIt</a><p>&gt; I have to Google for how to iterate over a hash every time, because there's multiple ways to do it, and they all suck. I never know if iterating over a $hash is the same as iterating over a %hash or a \\\\%hash.<p>Then you know less than a beginner in his third lesson.<p><pre><code>    ⎆ my %hash = qw(a b c d); my $hash = \\\\%hash\\n    ⎆ while (my ($key, $value) = each $hash) { say &quot;$key =&gt; $value&quot; }\\n    a =&gt; b\\n    c =&gt; d\\n    ⎆ while (my ($key, $value) = each %hash) { say &quot;$key =&gt; $value&quot; }\\n    a =&gt; b\\n    c =&gt; d\\n    ⎆ while (my ($key, $value) = each \\\\%hash) { say &quot;$key =&gt; $value&quot; }\\n    a =&gt; b\\n    c =&gt; d\\n</code></pre>\\n&gt; if I should be searching for &quot;hash&quot; or &quot;hashref&quot; or if I should be using a &quot;list&quot; or an &quot;array&quot; or a scalar or who cares<p>Only bash and Tcl free you from thinking about and selecting the appropriate data type.<p>&gt; The multiple ways to do things only amounts to one asshole on the team will exploit some unknown feature of map to write shorter code, not document it, and no one can read it.<p>This is a social problem, and not the responsibility of the programming language or its designer. Anyone can write crap code in any language. Enforce code style and policy locally. <em>Static</em> <em>analysis</em> <em>tools</em> like <a href=\"http://p3rl.org/perlcritic\" rel=\"nofollow\">http://p3rl.org/perlcritic</a> exist. Apply them.<p>&gt; Perl is not efficient<p>Perl remains the fastest of the scripting languages.<p>&gt; Beauty is subjective, readable code is not.<p>Unreadable code is a social problem across all programming languages. This has nothing to do with Perl per se.<p>&gt; The prefixing of variable names with @, % et all makes dissecting code hard<p>Wrong, sigils make the nouns stand out, just like capitalisation in written German. Both empirically make reading faster and comprehension easier.<p>&gt; Googling impossible<p>Wrong. It is true that search engines drop sigil characters from the query, but the context words still find the result in the index.<p>&gt; References are one of, if not the, biggest design flaw in Perl […] make reading and writing code confusing, overly complicated<p>Unsubstantiated, no details.<p>&gt; haven not once offered us any benefit<p>Wrong, as references are the basis for objects (OOP).<p>&gt; the language is gross. It has magic built in, and the syntax is a nightmare<p>Unsubstantiated, no details.<p>&gt; You get function arguments as @_<p>Concept stolen from Shell, already remedied in version 20. Signatures have been available for years with modules.<p>&gt; You do a regex match with $string =~ /(capture)/. This will magically populate $1 through $n with capture groups. This is bad.<p>Agreed, side effects are evil. That's the legacy interface and impossible to deprecate/remove. The expression will also return a list of the captures which you can then assign or mangle as you wish.<p><pre><code>    my @results = $string =~ /(capture)/\\n</code></pre>\\nGood style dictates to prefer this interface.<p>&gt; $string =~ s/a/b. This modifies the string in place. Try to Google for how to not modify the string in place. Seriously, try and Google for it.<p>Yes, and?<p><pre><code>    g perl substitute return modification\\n</code></pre>\\n(Type it out to see Google suggestion/autocompletion.) First five results all teach:<p><pre><code>    my $new = $string =~ s/a/b/r\\n</code></pre>\\n&gt; If you forget to include an even number of values in a list it becomes another data structure entirely.<p>Wrong, a list is a list no matter how many elements.<p>&gt; If you don't put a '1;' at the end of your module code it will fail to work (no, really).<p>Valid complaint. Again, it's too late to fix it because existing code needs to keep working, back-compat is serious business for perl5-porters. New projects with modern Perl just avoid the need for that last line: <a href=\"http://p3rl.org/true\" rel=\"nofollow\">http://p3rl.org/true</a><p>&gt; bless […] but it still is out of place in a programming language.<p>The word is religion neutral. Your biases show.<p>&gt; The &quot;features&quot; of Perl ruin it for a team environment.<p>Unsubstantiated, no details.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Fall Of Perl, The Web's Most Promising Language",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.fastcolabs.com/3026446/the-fall-of-perl-the-webs-most-promising-language",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-23T04:05:02.000Z",
      "title": null,
      "url": null,
      "author": "judk",
      "points": 4,
      "story_text": null,
      "comment_text": "Your conspiracy theory is a bit too complicated. Here is how it works in practice: Bad actor shows up (compromised employee, or vendor with system access, whatever).  Bad actor notices that code reviews are not required or a reviewer can be buffaloed with a 10k line commit, and static analysis tools aren&#x27;t a commit hook, or employees don&#x27;t lock their computers, or he has access to scp a binary on to a production server, or dozens of possible exploits that everyone knows about and is planing to fix eventually...",
      "num_comments": null,
      "story_id": 7284099,
      "story_title": "On the Timing of iOS’s SSL Vulnerability and Apple’s ‘Addition’ to NSA’s PRISM",
      "story_url": "http://daringfireball.net/2014/02/apple_prism",
      "parent_id": 7284315,
      "created_at_i": 1393128302,
      "_tags": [
        "comment",
        "author_judk",
        "story_7284099"
      ],
      "objectID": "7284872",
      "_highlightResult": {
        "author": {
          "value": "judk",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Your conspiracy theory is a bit too complicated. Here is how it works in practice: Bad actor shows up (compromised employee, or vendor with system access, whatever).  Bad actor notices that code reviews are not required or a reviewer can be buffaloed with a 10k line commit, and <em>static</em> <em>analysis</em> <em>tools</em> aren't a commit hook, or employees don't lock their computers, or he has access to scp a binary on to a production server, or dozens of possible exploits that everyone knows about and is planing to fix eventually...",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "On the Timing of iOS’s SSL Vulnerability and Apple’s ‘Addition’ to NSA’s PRISM",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://daringfireball.net/2014/02/apple_prism",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-12T13:58:08.000Z",
      "title": null,
      "url": null,
      "author": "zamalek",
      "points": 4,
      "story_text": null,
      "comment_text": "If you want reasons other than negligence.<p>The biggest reason is likely universities: I was there not too long ago (6-7 years), I wrote code that was secure against SQL injection - which lost me marks. They teach you to write insecure code and so help you God if you don&#x27;t stick to what they have taught you.<p>Secondly is human error - that&#x27;s to do with buffer overflows etc. You might say that we have static analysis, but...<p>Thirdly is that our static analysis tools simply are not &quot;there&quot; yet. They will catch the vast majority of vulnerabilities (especially when coupled together with contracts) but there are those corner cases that only a very creative security analyst will find.<p><i>Honestly though, if I was ever in a fire&#x2F;hire position bringing SQL-injectable-code to a code review would be grounds for being fired on the spot.</i>",
      "num_comments": null,
      "story_id": 7224097,
      "story_title": "Ask HN: Why do you think vulnerable code is still being released today?",
      "story_url": "",
      "parent_id": 7224097,
      "created_at_i": 1392213488,
      "_tags": [
        "comment",
        "author_zamalek",
        "story_7224097"
      ],
      "objectID": "7224255",
      "_highlightResult": {
        "author": {
          "value": "zamalek",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "If you want reasons other than negligence.<p>The biggest reason is likely universities: I was there not too long ago (6-7 years), I wrote code that was secure against SQL injection - which lost me marks. They teach you to write insecure code and so help you God if you don't stick to what they have taught you.<p>Secondly is human error - that's to do with buffer overflows etc. You might say that we have <em>static</em> <em>analysis</em>, but...<p>Thirdly is that our <em>static</em> <em>analysis</em> <em>tools</em> simply are not &quot;there&quot; yet. They will catch the vast majority of vulnerabilities (especially when coupled together with contracts) but there are those corner cases that only a very creative security analyst will find.<p><i>Honestly though, if I was ever in a fire/hire position bringing SQL-injectable-code to a code review would be grounds for being fired on the spot.</i>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Why do you think vulnerable code is still being released today?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-24T12:18:51.000Z",
      "title": null,
      "url": null,
      "author": "peterhunt",
      "points": 4,
      "story_text": null,
      "comment_text": "PyExecJS is slow :)<p>We are actively working on more static analysis tools for React: it&#x27;s certainly one of our major priorities.",
      "num_comments": null,
      "story_id": 7111049,
      "story_title": "React: Finally, a great server/client web stack",
      "story_url": "http://eflorenzano.com/blog/2013/01/23/react-finally-server-client/",
      "parent_id": 7113953,
      "created_at_i": 1390565931,
      "_tags": [
        "comment",
        "author_peterhunt",
        "story_7111049"
      ],
      "objectID": "7114551",
      "_highlightResult": {
        "author": {
          "value": "peterhunt",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "PyExecJS is slow :)<p>We are actively working on more <em>static</em> <em>analysis</em> <em>tools</em> for React: it's certainly one of our major priorities.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "React: Finally, a great server/client web stack",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://eflorenzano.com/blog/2013/01/23/react-finally-server-client/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-10T13:40:05.000Z",
      "title": null,
      "url": null,
      "author": "stevoski",
      "points": 4,
      "story_text": null,
      "comment_text": "Writing a background thread that does a long-running calculation? easy.<p>Writing a background thread that can be cancelled immediately, that gives useful progress information, that doesn&#x27;t leave other threads indefinitely blocked if cancelled, and that cleans up after itself if cancelled? hard.<p>For my single-threaded code I have great static analysis tools, IDE magic, and testing frameworks. For my multi-threaded code, I&#x27;m on my own...",
      "num_comments": null,
      "story_id": 6880361,
      "story_title": "Why Johnny Can’t Write Multithreaded Programs",
      "story_url": "http://blog.smartbear.com/programming/why-johnny-cant-write-multithreaded-programs/",
      "parent_id": 6880361,
      "created_at_i": 1386682805,
      "_tags": [
        "comment",
        "author_stevoski",
        "story_6880361"
      ],
      "objectID": "6880606",
      "_highlightResult": {
        "author": {
          "value": "stevoski",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Writing a background thread that does a long-running calculation? easy.<p>Writing a background thread that can be cancelled immediately, that gives useful progress information, that doesn't leave other threads indefinitely blocked if cancelled, and that cleans up after itself if cancelled? hard.<p>For my single-threaded code I have great <em>static</em> <em>analysis</em> <em>tools</em>, IDE magic, and testing frameworks. For my multi-threaded code, I'm on my own...",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Johnny Can’t Write Multithreaded Programs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.smartbear.com/programming/why-johnny-cant-write-multithreaded-programs/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-02T08:42:21.000Z",
      "title": "",
      "url": "",
      "author": "bazzargh",
      "points": 4,
      "story_text": null,
      "comment_text": "Just thinking about that - this class of error gets reported by Findbugs and other static analysis tools. So, this bug indicates that there aren&#x27;t tools like that in the build - for a security app, where correctness should be top priority, that&#x27;s surprising.",
      "num_comments": null,
      "story_id": 6313707,
      "story_title": "Surespot app - free and open source encryption for everyone",
      "story_url": "https://www.surespot.me/",
      "parent_id": 6314086,
      "created_at_i": 1378111341,
      "_tags": [
        "comment",
        "author_bazzargh",
        "story_6313707"
      ],
      "objectID": "6314115",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "bazzargh",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Just thinking about that - this class of error gets reported by Findbugs and other <em>static</em> <em>analysis</em> <em>tools</em>. So, this bug indicates that there aren't <em>tools</em> like that in the build - for a security app, where correctness should be top priority, that's surprising.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Surespot app - free and open source encryption for everyone",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.surespot.me/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-29T22:53:16.000Z",
      "title": "",
      "url": "",
      "author": "amasad",
      "points": 4,
      "story_text": null,
      "comment_text": "Looks really nice for creating components. However, two quick notes:<p>* This breaks code editors, static analysis tools like jshint etc.<p>* I think Web Components is landing soon, and this seems like it could leverage that.",
      "num_comments": null,
      "story_id": 5789055,
      "story_title": "React, a JavaScript library for building user interfaces",
      "story_url": "http://facebook.github.io/react/",
      "parent_id": 5789055,
      "created_at_i": 1369867996,
      "_tags": [
        "comment",
        "author_amasad",
        "story_5789055"
      ],
      "objectID": "5789775",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "amasad",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Looks really nice for creating components. However, two quick notes:<p>* This breaks code editors, <em>static</em> <em>analysis</em> <em>tools</em> like jshint etc.<p>* I think Web Components is landing soon, and this seems like it could leverage that.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "React, a JavaScript library for building user interfaces",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://facebook.github.io/react/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-24T23:00:19.000Z",
      "title": "",
      "url": "",
      "author": "logn",
      "points": 4,
      "story_text": null,
      "comment_text": "As much as people feel negatively about Java, it really has fantastic static code analysis tools. PMD, FindBugs, CheckStyle are all very helpful when properly configured. They're basically on the checklist level.<p>I think checklist level thinking for code reviews is bad though. It ends up being a pretty soul destroying experience when someone tells you that you need to validate arguments to all methods as not null (for the 100 you wrote), or that you should take the data in your test cases and put it in a text file. Or that you've re-used the same string in several places and should make it constant. Robots can tell me that, and I can get their feedback while I'm developing or choose to ignore it. People are invaluable for helping you step back and see how to re-organize your code, introduce new abstractions, re-interpret requirements, and see actual bugs that no QA person or tool would ever discover (likely affecting some unlucky user who would hit an extremely rare bug that couldn't be reproduced easily). Those types of reviews are invaluable. Put down the checklist and automate it instead.",
      "num_comments": null,
      "story_id": 5604291,
      "story_title": "Using checklists for code review",
      "story_url": "http://blog.rbcommons.com/2013/04/24/using-checklists-for-code-review/",
      "parent_id": 5604291,
      "created_at_i": 1366844419,
      "_tags": [
        "comment",
        "author_logn",
        "story_5604291"
      ],
      "objectID": "5604542",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "logn",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "As much as people feel negatively about Java, it really has fantastic <em>static</em> code <em>analysis</em> <em>tools</em>. PMD, FindBugs, CheckStyle are all very helpful when properly configured. They're basically on the checklist level.<p>I think checklist level thinking for code reviews is bad though. It ends up being a pretty soul destroying experience when someone tells you that you need to validate arguments to all methods as not null (for the 100 you wrote), or that you should take the data in your test cases and put it in a text file. Or that you've re-used the same string in several places and should make it constant. Robots can tell me that, and I can get their feedback while I'm developing or choose to ignore it. People are invaluable for helping you step back and see how to re-organize your code, introduce new abstractions, re-interpret requirements, and see actual bugs that no QA person or tool would ever discover (likely affecting some unlucky user who would hit an extremely rare bug that couldn't be reproduced easily). Those types of reviews are invaluable. Put down the checklist and automate it instead.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Using checklists for code review",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.rbcommons.com/2013/04/24/using-checklists-for-code-review/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-02-20T23:40:47.000Z",
      "title": "",
      "url": "",
      "author": "skittlebrau",
      "points": 4,
      "story_text": null,
      "comment_text": "I worked at Ensemble Studios (Age of Empires) and by the time we shipped Age of Mythology we had much better tools for dealing with sync bugs. Most of the run of the mill ones could be tracked down pretty quickly, but there were still plenty of painful ones. What made them easier to track down was a more advanced tracking/logging system for the simulation state history. The simulation was littered with tons of sync logging code that tracked the execution flow and values of things as they were calculated/updated. When the state went out of sync, all the machines would dump their last couple updates worth of logging (often several gigs) and you could diff them to see where things diverged. If you were making a synced simulation game, a nicely done version of this type of thing would be pretty useful to have, especially if you made a good diff tool to go with it.<p>It's not completely obvious what technology you could make that would make it easier to avoid sync bugs in the first place. You could make a good network command-passing and simulation timing library, but in my experience the majority of problems did not come from bugs with the networking itself.  Most of the sync bugs were from things like uninitialized variables, memory overwrites, using user input or other local machine state directly in the simulation without going through a multiplayer command, using a non-synced random number generator in the sim, DirectX changing the FPU rounding mode on you, etc. (Using a \"safer\" language would help with stuff like uninitialized variables/memory overwrites of course, but at an inevitable performance cost. Static code analysis tools are pretty good at finding these type of problems now too.)",
      "num_comments": null,
      "story_id": 5252003,
      "story_title": "The StarCraft path-finding hack",
      "story_url": "http://www.codeofhonor.com/blog/the-starcraft-path-finding-hack",
      "parent_id": 5253009,
      "created_at_i": 1361403647,
      "_tags": [
        "comment",
        "author_skittlebrau",
        "story_5252003"
      ],
      "objectID": "5254188",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "skittlebrau",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I worked at Ensemble Studios (Age of Empires) and by the time we shipped Age of Mythology we had much better <em>tools</em> for dealing with sync bugs. Most of the run of the mill ones could be tracked down pretty quickly, but there were still plenty of painful ones. What made them easier to track down was a more advanced tracking/logging system for the simulation state history. The simulation was littered with tons of sync logging code that tracked the execution flow and values of things as they were calculated/updated. When the state went out of sync, all the machines would dump their last couple updates worth of logging (often several gigs) and you could diff them to see where things diverged. If you were making a synced simulation game, a nicely done version of this type of thing would be pretty useful to have, especially if you made a good diff tool to go with it.<p>It's not completely obvious what technology you could make that would make it easier to avoid sync bugs in the first place. You could make a good network command-passing and simulation timing library, but in my experience the majority of problems did not come from bugs with the networking itself.  Most of the sync bugs were from things like uninitialized variables, memory overwrites, using user input or other local machine state directly in the simulation without going through a multiplayer command, using a non-synced random number generator in the sim, DirectX changing the FPU rounding mode on you, etc. (Using a \"safer\" language would help with stuff like uninitialized variables/memory overwrites of course, but at an inevitable performance cost. <em>Static</em> code <em>analysis</em> <em>tools</em> are pretty good at finding these type of problems now too.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The StarCraft path-finding hack",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.codeofhonor.com/blog/the-starcraft-path-finding-hack",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-11-26T01:04:48.000Z",
      "title": "",
      "url": "",
      "author": "larsberg",
      "points": 4,
      "story_text": null,
      "comment_text": "Having spent a long time targeting the market for developer tools, I think you're underestimating that market based on your own experiences and social circle. It was a multi-billion dollar market in ~2006, only including IDEs, SCC, static analysis tools, architecture, and process-related infrastructure, and seems to only have grown since then.",
      "num_comments": null,
      "story_id": 4829229,
      "story_title": "Enterprise is sexy now. But B2D is sexier.",
      "story_url": "http://blog.yonas.io/post/36534887793/b2d-is-sexier",
      "parent_id": 4829727,
      "created_at_i": 1353891888,
      "_tags": [
        "comment",
        "author_larsberg",
        "story_4829229"
      ],
      "objectID": "4829891",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "larsberg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Having spent a long time targeting the market for developer <em>tools</em>, I think you're underestimating that market based on your own experiences and social circle. It was a multi-billion dollar market in ~2006, only including IDEs, SCC, <em>static</em> <em>analysis</em> <em>tools</em>, architecture, and process-related infrastructure, and seems to only have grown since then.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Enterprise is sexy now. But B2D is sexier.",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.yonas.io/post/36534887793/b2d-is-sexier",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-30T17:19:42.000Z",
      "title": "",
      "url": "",
      "author": "zeteo",
      "points": 4,
      "story_text": null,
      "comment_text": "&#62;There are plenty of static analysis tools that can determine if programs written in turing-complete languages will halt.<p>But they're heuristic, which means if their use ever becomes widespread it will be very easy for malicious software writers to defeat them on a case-by-case basis.",
      "num_comments": null,
      "story_id": 3776150,
      "story_title": "Why we should adopt a non-Turing complete language for client-side scripting",
      "story_url": "http://doriantaylor.com/something-i-would-like-to-do",
      "parent_id": 3776934,
      "created_at_i": 1333127982,
      "_tags": [
        "comment",
        "author_zeteo",
        "story_3776150"
      ],
      "objectID": "3777030",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "zeteo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": ">There are plenty of <em>static</em> <em>analysis</em> <em>tools</em> that can determine if programs written in turing-complete languages will halt.<p>But they're heuristic, which means if their use ever becomes widespread it will be very easy for malicious software writers to defeat them on a case-by-case basis.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why we should adopt a non-Turing complete language for client-side scripting",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://doriantaylor.com/something-i-would-like-to-do",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-30T17:03:55.000Z",
      "title": "",
      "url": "",
      "author": "aidenn0",
      "points": 4,
      "story_text": null,
      "comment_text": "\"It is a mathematical impossibility for the behaviour of Turing-complete code to be analyzed by machine.\"<p>This is categorically false.  There are plenty of static analysis tools that can determine if programs written in turing-complete languages will halt.  They can't do it for every program, but they can do it for large numbers of useful programs.<p>Simple counterexample: python is turing complete, yet it is possible to mechanically analyze and determine a whole lot about this program:<p><pre><code>    print \"Hello, World!\"\n</code></pre>\nYes, that's a stupid example, but it demonstrates that the premise of this article is false.<p>As further example that the author misunderstands the issue is the quote: \"That, or viewing your website means I have to pore over every line.\" If good static analysis tools can't figure it out, it is less likely that a person will.<p>Static analysis tools running on Turing complete languages are a useful tool.  Sometimes they answer \"I don't know\" at which point you will have to decide if you trust the author or not, but the vast majority of code out there is fairly tractable.<p>[edit] It is true that it is a mathematical impossibility for all possible programs in a turing-complete language to be analyzed, but that doesn't mean that there don't exist programs that are analyzable and has little bearing on whether or not real-world programs are analyzable.",
      "num_comments": null,
      "story_id": 3776150,
      "story_title": "Why we should adopt a non-Turing complete language for client-side scripting",
      "story_url": "http://doriantaylor.com/something-i-would-like-to-do",
      "parent_id": 3776150,
      "created_at_i": 1333127035,
      "_tags": [
        "comment",
        "author_aidenn0",
        "story_3776150"
      ],
      "objectID": "3776934",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "aidenn0",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "\"It is a mathematical impossibility for the behaviour of Turing-complete code to be analyzed by machine.\"<p>This is categorically false.  There are plenty of <em>static</em> <em>analysis</em> <em>tools</em> that can determine if programs written in turing-complete languages will halt.  They can't do it for every program, but they can do it for large numbers of useful programs.<p>Simple counterexample: python is turing complete, yet it is possible to mechanically analyze and determine a whole lot about this program:<p><pre><code>    print \"Hello, World!\"\n</code></pre>\nYes, that's a stupid example, but it demonstrates that the premise of this article is false.<p>As further example that the author misunderstands the issue is the quote: \"That, or viewing your website means I have to pore over every line.\" If good <em>static</em> <em>analysis</em> <em>tools</em> can't figure it out, it is less likely that a person will.<p><em>Static</em> <em>analysis</em> <em>tools</em> running on Turing complete languages are a useful tool.  Sometimes they answer \"I don't know\" at which point you will have to decide if you trust the author or not, but the vast majority of code out there is fairly tractable.<p>[edit] It is true that it is a mathematical impossibility for all possible programs in a turing-complete language to be analyzed, but that doesn't mean that there don't exist programs that are analyzable and has little bearing on whether or not real-world programs are analyzable.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why we should adopt a non-Turing complete language for client-side scripting",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://doriantaylor.com/something-i-would-like-to-do",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-05-14T20:54:40.000Z",
      "title": "",
      "url": "",
      "author": "bhickey",
      "points": 4,
      "story_text": null,
      "comment_text": "Can you elaborate on your question?<p>I don't think what you're saying is intrinsic to FP. There are static analysis tools for non-functional languages. At the end of the day, everything is getting turned into an abstract syntax tree, so style should be irrelevant.<p>Do you mean pure (side-effect free) functional languages?",
      "num_comments": null,
      "story_id": 2548410,
      "story_title": "What Every C Programmer Should Know About Undefined Behavior #2/3",
      "story_url": "http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_14.html",
      "parent_id": 2548485,
      "created_at_i": 1305406480,
      "_tags": [
        "comment",
        "author_bhickey",
        "story_2548410"
      ],
      "objectID": "2548523",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "bhickey",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Can you elaborate on your question?<p>I don't think what you're saying is intrinsic to FP. There are <em>static</em> <em>analysis</em> <em>tools</em> for non-functional languages. At the end of the day, everything is getting turned into an abstract syntax tree, so style should be irrelevant.<p>Do you mean pure (side-effect free) functional languages?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What Every C Programmer Should Know About Undefined Behavior #2/3",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_14.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-04T03:38:59.000Z",
      "title": null,
      "url": null,
      "author": "bastawhiz",
      "points": 3,
      "story_text": null,
      "comment_text": "So..uh...this was a thing. And nobody wanted it. So it was deprecated and killed. See the &quot;Prior Art&quot; section at the bottom of the page.<p><a href=\"http://en.wikipedia.org/wiki/ECMAScript_for_XML\" rel=\"nofollow\">http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ECMAScript_for_XML</a><p>Brendan Eich was quoted as saying something along the lines of &quot;E4X is crazyland&quot;. Parsing it is hard as hell to do right. Think of all the tooling that&#x27;s out there for JavaScript right now that will either a.) not support JSX code or b.) bloat up beyond belief as it takes into account the suddenly absurd requirements necessary to deal with a similar-but-not-quite-XML-or-even-HTML-for-that-matter syntax. Oh, you want to lint that JavaScript? Bless your heart! You want to add syntax highlighting? Love will find a way. You want to use other static analysis tools, sweet.js macros, or anything else non-trivial? How cute!<p>So essentially, it&#x27;s a great way for Facebook to push React.js without making React.js a standard.",
      "num_comments": null,
      "story_id": 8265945,
      "story_title": "JSX: XML-like syntax extension to ECMAScript – Draft specification",
      "story_url": "http://facebook.github.io/jsx/",
      "parent_id": 8265945,
      "created_at_i": 1409801939,
      "_tags": [
        "comment",
        "author_bastawhiz",
        "story_8265945"
      ],
      "objectID": "8266648",
      "_highlightResult": {
        "author": {
          "value": "bastawhiz",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "So..uh...this was a thing. And nobody wanted it. So it was deprecated and killed. See the &quot;Prior Art&quot; section at the bottom of the page.<p><a href=\"http://en.wikipedia.org/wiki/ECMAScript_for_XML\" rel=\"nofollow\">http://en.wikipedia.org/wiki/ECMAScript_for_XML</a><p>Brendan Eich was quoted as saying something along the lines of &quot;E4X is crazyland&quot;. Parsing it is hard as hell to do right. Think of all the tooling that's out there for JavaScript right now that will either a.) not support JSX code or b.) bloat up beyond belief as it takes into account the suddenly absurd requirements necessary to deal with a similar-but-not-quite-XML-or-even-HTML-for-that-matter syntax. Oh, you want to lint that JavaScript? Bless your heart! You want to add syntax highlighting? Love will find a way. You want to use other <em>static</em> <em>analysis</em> <em>tools</em>, sweet.js macros, or anything else non-trivial? How cute!<p>So essentially, it's a great way for Facebook to push React.js without making React.js a standard.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "JSX: XML-like syntax extension to ECMAScript – Draft specification",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://facebook.github.io/jsx/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-15T19:26:42.000Z",
      "title": null,
      "url": null,
      "author": "collingreene",
      "points": 3,
      "story_text": null,
      "comment_text": "Maybe you just enjoy hyperbole but while part of what you say is correct (finding security vulns in software is unavoidably a bit of a crapshoot) your conclusions are wrong.<p>Finding deep, serious vulns like this in software can currently only be done by human beings. Tools are better at being authoritative but can only find vulns of a given type. For example static analysis is a great fit for any vuln that boils down to a dataflow problem, user controlled source -&gt; ... -&gt; dangerous sink. XSS, sql injection, etc fit this model. Fuzzers are great at finding bugs in parsers (and there are a surprising amount of parsers in the world, 90% of which should never have been written). Instrumented dynamic analysis can do awesome work for memory issues. I explain all this to show there are areas where tools are fantastic for their area. But there are many areas for which tools cannot help at all, heartbleed was one of these areas.<p>The best security tools available were (presumably) run across openssl before and (certainly) with increased scrutiny after heartbleed. None of them found it. Simple limitations in static analysis lead me to believe they would never have found it on their own (most static analysis tools stop at 5 levels of indirection) Some background:<p>1. <a href=\"http://blog.trailofbits.com/2014/04/27/using-static-analysis-and-clang-to-find-heartbleed/\" rel=\"nofollow\">http:&#x2F;&#x2F;blog.trailofbits.com&#x2F;2014&#x2F;04&#x2F;27&#x2F;using-static-analysis...</a>\\n2. <a href=\"http://security.coverity.com/blog/2014/Apr/on-detecting-heartbleed-with-static-analysis.html\" rel=\"nofollow\">http:&#x2F;&#x2F;security.coverity.com&#x2F;blog&#x2F;2014&#x2F;Apr&#x2F;on-detecting-hear...</a>\\n3. <a href=\"http://www.grammatech.com/blog/finding-heartbleed-with-codesonar\" rel=\"nofollow\">http:&#x2F;&#x2F;www.grammatech.com&#x2F;blog&#x2F;finding-heartbleed-with-codes...</a><p>If you have immature projects sure run tools against it and some bugs will shake out. But if you want to find the next heartbleed a tool wont do it which is your mistaken conclusion.<p>The question then becomes how to cultivate and encourage more people to find vulns like this. Money seems like a good incentive for most, although Neel Mehta did it of his own volition. I dont know the answer to that question but things like googles project zero are exactly what I would try first.",
      "num_comments": null,
      "story_id": 8182713,
      "story_title": "Quality Software Costs Money – Heartbleed Was Free",
      "story_url": "http://queue.acm.org/detail.cfm?id=2636165",
      "parent_id": 8183540,
      "created_at_i": 1408130802,
      "_tags": [
        "comment",
        "author_collingreene",
        "story_8182713"
      ],
      "objectID": "8183721",
      "_highlightResult": {
        "author": {
          "value": "collingreene",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Maybe you just enjoy hyperbole but while part of what you say is correct (finding security vulns in software is unavoidably a bit of a crapshoot) your conclusions are wrong.<p>Finding deep, serious vulns like this in software can currently only be done by human beings. <em>Tools</em> are better at being authoritative but can only find vulns of a given type. For example <em>static</em> <em>analysis</em> is a great fit for any vuln that boils down to a dataflow problem, user controlled source -&gt; ... -&gt; dangerous sink. XSS, sql injection, etc fit this model. Fuzzers are great at finding bugs in parsers (and there are a surprising amount of parsers in the world, 90% of which should never have been written). Instrumented dynamic <em>analysis</em> can do awesome work for memory issues. I explain all this to show there are areas where <em>tools</em> are fantastic for their area. But there are many areas for which <em>tools</em> cannot help at all, heartbleed was one of these areas.<p>The best security <em>tools</em> available were (presumably) run across openssl before and (certainly) with increased scrutiny after heartbleed. None of them found it. Simple limitations in <em>static</em> <em>analysis</em> lead me to believe they would never have found it on their own (most <em>static</em> <em>analysis</em> <em>tools</em> stop at 5 levels of indirection) Some background:<p>1. <a href=\"http://blog.trailofbits.com/2014/04/27/using-static-analysis-and-clang-to-find-heartbleed/\" rel=\"nofollow\">http://blog.trailofbits.com/2014/04/27/using-<em>static</em>-<em>analysis...</em></a>\\n2. <a href=\"http://security.coverity.com/blog/2014/Apr/on-detecting-heartbleed-with-static-analysis.html\" rel=\"nofollow\">http://security.coverity.com/blog/2014/Apr/on-detecting-hear...</a>\\n3. <a href=\"http://www.grammatech.com/blog/finding-heartbleed-with-codesonar\" rel=\"nofollow\">http://www.grammatech.com/blog/finding-heartbleed-with-codes...</a><p>If you have immature projects sure run <em>tools</em> against it and some bugs will shake out. But if you want to find the next heartbleed a tool wont do it which is your mistaken conclusion.<p>The question then becomes how to cultivate and encourage more people to find vulns like this. Money seems like a good incentive for most, although Neel Mehta did it of his own volition. I dont know the answer to that question but things like googles project zero are exactly what I would try first.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Quality Software Costs Money – Heartbleed Was Free",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://queue.acm.org/detail.cfm?id=2636165",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-29T17:25:31.000Z",
      "title": null,
      "url": null,
      "author": "supersillyus",
      "points": 3,
      "story_text": null,
      "comment_text": "I read that they have static analysis tools to track the flow of Contexts, making it much easier to verify that Contexts are threaded through correctly, which can make things a bit safer statically. It seems Go-like I guess: instead of language support for that sort of type system, simple enough lang and good enough tooling to implement the analysis externally.",
      "num_comments": null,
      "story_id": 8103128,
      "story_title": "Go Concurrency Patterns: Context",
      "story_url": "http://blog.golang.org/context",
      "parent_id": 8103429,
      "created_at_i": 1406654731,
      "_tags": [
        "comment",
        "author_supersillyus",
        "story_8103128"
      ],
      "objectID": "8103464",
      "_highlightResult": {
        "author": {
          "value": "supersillyus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I read that they have <em>static</em> <em>analysis</em> <em>tools</em> to track the flow of Contexts, making it much easier to verify that Contexts are threaded through correctly, which can make things a bit safer statically. It seems Go-like I guess: instead of language support for that sort of type system, simple enough lang and good enough tooling to implement the <em>analysis</em> externally.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Go Concurrency Patterns: Context",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.golang.org/context",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-13T21:15:46.000Z",
      "title": null,
      "url": null,
      "author": "dragonwriter",
      "points": 3,
      "story_text": null,
      "comment_text": "&gt;  Dynamically typed languages are OK for smaller projects but as projects grow in size, you have to write a lot of tests to be sure that everything works.<p>Or build your large systems as compositions of smaller systems. If dynamically typed languages are really okay for smaller systmes, than avoiding bad architecture of large tightly-coupled systems in favor of loosely coupled compositions of smaller subsystems means that it is also okay for large systems.<p>&gt; Also, projects written in statically typed languages are easier to read and navigate for humans<p>This is not my experience.<p>&gt; and it&#x27;s also easier to write static analysis tools for them.<p>Well, yes, since you <i>have</i> to write a static analysis tool for a statically typed language (since the compiler <i>must include</i> such a tool), its not at all surprising that the structure of statically-typed languages is always designed specifically to serve static analysis tools.<p>IME, that&#x27;s why they&#x27;ve historically been <i>harder</i> to read and navigate for humans, though some exceptional modern statically typed languages have largely closed that gap (but not reversed it, IMO.)",
      "num_comments": null,
      "story_id": 7890449,
      "story_title": "Typed Lua: An Optional Type System for Lua [pdf]",
      "story_url": "http://www.lifl.fr/dyla14/papers/dyla14-4-typed-lua-an-optional-type-system.pdf",
      "parent_id": 7890633,
      "created_at_i": 1402694146,
      "_tags": [
        "comment",
        "author_dragonwriter",
        "story_7890449"
      ],
      "objectID": "7890872",
      "_highlightResult": {
        "author": {
          "value": "dragonwriter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;  Dynamically typed languages are OK for smaller projects but as projects grow in size, you have to write a lot of tests to be sure that everything works.<p>Or build your large systems as compositions of smaller systems. If dynamically typed languages are really okay for smaller systmes, than avoiding bad architecture of large tightly-coupled systems in favor of loosely coupled compositions of smaller subsystems means that it is also okay for large systems.<p>&gt; Also, projects written in statically typed languages are easier to read and navigate for humans<p>This is not my experience.<p>&gt; and it's also easier to write <em>static</em> <em>analysis</em> <em>tools</em> for them.<p>Well, yes, since you <i>have</i> to write a <em>static</em> <em>analysis</em> tool for a statically typed language (since the compiler <i>must include</i> such a tool), its not at all surprising that the structure of statically-typed languages is always designed specifically to serve <em>static</em> <em>analysis</em> <em>tools</em>.<p>IME, that's why they've historically been <i>harder</i> to read and navigate for humans, though some exceptional modern statically typed languages have largely closed that gap (but not reversed it, IMO.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Typed Lua: An Optional Type System for Lua [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.lifl.fr/dyla14/papers/dyla14-4-typed-lua-an-optional-type-system.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-05-03T16:31:52.000Z",
      "title": null,
      "url": null,
      "author": "JackMorgan",
      "points": 3,
      "story_text": null,
      "comment_text": "That is true, but checking all the values of an enum is just the tip of the iceburg. Consider something as sophisticated as the second to last example in the post, where, because of pattern matching, I am able to to &quot;flatten&quot; an if and a switch into a single match. Since it is a single expression, the compiler can provide completeness checking on the _combination_ of the two. I am very curious if there are any static analysis tools that can provide that level of safety without pattern matching.",
      "num_comments": null,
      "story_id": 7690736,
      "story_title": "Pattern Matching – Make the Compiler Work for You",
      "story_url": "http://deliberate-software.com/function-pattern-matching/",
      "parent_id": 7691306,
      "created_at_i": 1399134712,
      "_tags": [
        "comment",
        "author_JackMorgan",
        "story_7690736"
      ],
      "objectID": "7691346",
      "_highlightResult": {
        "author": {
          "value": "JackMorgan",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That is true, but checking all the values of an enum is just the tip of the iceburg. Consider something as sophisticated as the second to last example in the post, where, because of pattern matching, I am able to to &quot;flatten&quot; an if and a switch into a single match. Since it is a single expression, the compiler can provide completeness checking on the _combination_ of the two. I am very curious if there are any <em>static</em> <em>analysis</em> <em>tools</em> that can provide that level of safety without pattern matching.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Pattern Matching – Make the Compiler Work for You",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://deliberate-software.com/function-pattern-matching/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-11T08:12:05.000Z",
      "title": null,
      "url": null,
      "author": "chriswarbo",
      "points": 3,
      "story_text": null,
      "comment_text": "Your reimplementation would either be very different from the original, and hence not suffer the same bugs, or the compiler wouldn&#x27;t get further than a couple of function calls before giving you a cryptic error message since it doesn&#x27;t understand the control flow.<p>Static analysis tools are useful for finding bugs in existing code, but safe programming languages won&#x27;t magically point out all of the errors in some arbitrary code written in another language. They&#x27;re safe precisely because they do not allow you to write code in the way that an unsafe language would.<p>As an analogy, if you were looking for use-after-free errors in some C code, it wouldn&#x27;t do you any good to check a Python version.",
      "num_comments": null,
      "story_id": 7571385,
      "story_title": "Preventing heartbleed bugs with safe programming languages",
      "story_url": "http://bluishcoder.co.nz/2014/04/11/preventing-heartbleed-bugs-with-safe-languages.html",
      "parent_id": 7571710,
      "created_at_i": 1397203925,
      "_tags": [
        "comment",
        "author_chriswarbo",
        "story_7571385"
      ],
      "objectID": "7571727",
      "_highlightResult": {
        "author": {
          "value": "chriswarbo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Your reimplementation would either be very different from the original, and hence not suffer the same bugs, or the compiler wouldn't get further than a couple of function calls before giving you a cryptic error message since it doesn't understand the control flow.<p><em>Static</em> <em>analysis</em> <em>tools</em> are useful for finding bugs in existing code, but safe programming languages won't magically point out all of the errors in some arbitrary code written in another language. They're safe precisely because they do not allow you to write code in the way that an unsafe language would.<p>As an analogy, if you were looking for use-after-free errors in some C code, it wouldn't do you any good to check a Python version.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Preventing heartbleed bugs with safe programming languages",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://bluishcoder.co.nz/2014/04/11/preventing-heartbleed-bugs-with-safe-languages.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-04T17:02:37.000Z",
      "title": null,
      "url": null,
      "author": "ibmthrowaway218",
      "points": 3,
      "story_text": null,
      "comment_text": "My employer (IBM) allows people to do things in their spare time with the following kinds of exceptions (off the top of my head, sure there are more):-<p>a) Do not use company time or equipment. Pretty obvious that one.<p>b) No doing something that competes directly with IBM. This has to be more specific than &quot;working with computers&quot;. It means I can still get beer money for helping friends&#x2F;family fix their computers&#x2F;servers, but I can&#x27;t start a small consultancy that aims to take possible business away from IBM. I can start a social sports related side project website because IBM aren&#x27;t in that space. But if I worked on Websphere Application Server (I don&#x27;t!) I couldn&#x27;t contribute to, for example, Apache Tomcat&#x2F;Geronimo or JBoss AS. I could write my own game Apps and sell them through the App Store. Etc.<p>c) Contributing to OSS in your spare time needs to be cleared with IBM, just in case. The main reason is that everyone loves to sue IBM and OSS is fertile ground given the various OSS licenses and implications. If I do some work on some OSS package in my spare time it means I&#x27;m tainted in that area. If I then do any work on a commercial application in the same area then it opens the door for people to claim that the commercial work I&#x27;ve done has some work that could have been influenced by the OSS code and part of the commercial application is therefore derivative of the OSS work. With some OSS licenses this could mean that the entire commercial application is considered a derivative work and, depending on the license, the source code would need to be released or IBM could not charge for the software, etc.<p>It&#x27;s not all doom and gloom. I work with some people that have got clearance to work on OSS software, they just have to make sure they avoid working with anything related to it on the commercial side (to the point of not having access to the source code to provide plausible deniability). You also need to think in advance and not work on anything that we could reasonably be working on in the future.<p>We are also regularly warned to avoid even looking at any OSS related to the commercial code we work on, for fear of tainting. Same for Googling for answers to technical questions and copy-and-pasting code from SO or elsewhere. You&#x27;ve generally got no idea of the copyright&#x2F;licensing aspects of any code you see in the results.<p>IBM does use OSS in some of its commercial applications. Its use is always cleared with the lawyers first though. Certain licenses must be avoided simply because they are incompatible with selling commercial software. Where the license is permissive we always make sure we follow the rules and I&#x27;ve personally contributed many bug fixes in the OSS code back to the community as required (or even if not required!); these have often been found as the result of formal code inspections (which IBM is effectively funding by paying employees to perform it), peer review, static analysis tools, or general SQA testing.",
      "num_comments": null,
      "story_id": 7532130,
      "story_title": "Ask HN: Should I cash out my 401K and try to get my dream job?",
      "story_url": "",
      "parent_id": 7532465,
      "created_at_i": 1396630957,
      "_tags": [
        "comment",
        "author_ibmthrowaway218",
        "story_7532130"
      ],
      "objectID": "7532742",
      "_highlightResult": {
        "author": {
          "value": "ibmthrowaway218",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "My employer (IBM) allows people to do things in their spare time with the following kinds of exceptions (off the top of my head, sure there are more):-<p>a) Do not use company time or equipment. Pretty obvious that one.<p>b) No doing something that competes directly with IBM. This has to be more specific than &quot;working with computers&quot;. It means I can still get beer money for helping friends/family fix their computers/servers, but I can't start a small consultancy that aims to take possible business away from IBM. I can start a social sports related side project website because IBM aren't in that space. But if I worked on Websphere Application Server (I don't!) I couldn't contribute to, for example, Apache Tomcat/Geronimo or JBoss AS. I could write my own game Apps and sell them through the App Store. Etc.<p>c) Contributing to OSS in your spare time needs to be cleared with IBM, just in case. The main reason is that everyone loves to sue IBM and OSS is fertile ground given the various OSS licenses and implications. If I do some work on some OSS package in my spare time it means I'm tainted in that area. If I then do any work on a commercial application in the same area then it opens the door for people to claim that the commercial work I've done has some work that could have been influenced by the OSS code and part of the commercial application is therefore derivative of the OSS work. With some OSS licenses this could mean that the entire commercial application is considered a derivative work and, depending on the license, the source code would need to be released or IBM could not charge for the software, etc.<p>It's not all doom and gloom. I work with some people that have got clearance to work on OSS software, they just have to make sure they avoid working with anything related to it on the commercial side (to the point of not having access to the source code to provide plausible deniability). You also need to think in advance and not work on anything that we could reasonably be working on in the future.<p>We are also regularly warned to avoid even looking at any OSS related to the commercial code we work on, for fear of tainting. Same for Googling for answers to technical questions and copy-and-pasting code from SO or elsewhere. You've generally got no idea of the copyright/licensing aspects of any code you see in the results.<p>IBM does use OSS in some of its commercial applications. Its use is always cleared with the lawyers first though. Certain licenses must be avoided simply because they are incompatible with selling commercial software. Where the license is permissive we always make sure we follow the rules and I've personally contributed many bug fixes in the OSS code back to the community as required (or even if not required!); these have often been found as the result of formal code inspections (which IBM is effectively funding by paying employees to perform it), peer review, <em>static</em> <em>analysis</em> <em>tools</em>, or general SQA testing.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Should I cash out my 401K and try to get my dream job?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-29T23:08:36.000Z",
      "title": "",
      "url": "",
      "author": "zpao",
      "points": 3,
      "story_text": null,
      "comment_text": "&#62; This breaks code editors, static analysis tools like jshint etc.<p>You're right. One of our goals in the coming months is to try to make some language files for editors. Vim actually does a pretty good job of this already thanks to the similarity to E4X.<p>JSHint is another thing we'd like to improve upon. At Facebook &#38; Instagram, we actually lint against the transformed code. Right now the transforms don't modify line numbers so it's been easy to match up. We'd like to build some tooling around this for people who make use of React and JSX.<p>&#62; I think Web Components is landing soon, and this seems like it could leverage that.<p>I like the way you think! We've started thinking about that already.",
      "num_comments": null,
      "story_id": 5789055,
      "story_title": "React, a JavaScript library for building user interfaces",
      "story_url": "http://facebook.github.io/react/",
      "parent_id": 5789775,
      "created_at_i": 1369868916,
      "_tags": [
        "comment",
        "author_zpao",
        "story_5789055"
      ],
      "objectID": "5789847",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "zpao",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> This breaks code editors, <em>static</em> <em>analysis</em> <em>tools</em> like jshint etc.<p>You're right. One of our goals in the coming months is to try to make some language files for editors. Vim actually does a pretty good job of this already thanks to the similarity to E4X.<p>JSHint is another thing we'd like to improve upon. At Facebook & Instagram, we actually lint against the transformed code. Right now the transforms don't modify line numbers so it's been easy to match up. We'd like to build some tooling around this for people who make use of React and JSX.<p>> I think Web Components is landing soon, and this seems like it could leverage that.<p>I like the way you think! We've started thinking about that already.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "React, a JavaScript library for building user interfaces",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://facebook.github.io/react/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-15T14:57:01.000Z",
      "title": "",
      "url": "",
      "author": "npsimons",
      "points": 3,
      "story_text": null,
      "comment_text": "I've often felt that more developers (or even interested power users), should be running with things like MALLOC_CHECK_=3 (<a href=\"http://www.novell.com/support/kb/doc.php?id=3113982\" rel=\"nofollow\">http://www.novell.com/support/kb/doc.php?id=3113982</a>) enabled by default for everything. On top of that, when we have plenty of FLOSS static analysis tools (<a href=\"https://news.ycombinator.com/item?id=4545188\" rel=\"nofollow\">https://news.ycombinator.com/item?id=4545188</a>), plus things like valgrind, gprof and gcov, I don't understand why more people don't use them. As for compiler flags, if we can build a whole distro around optimization (Gentoo), why can't we build a whole distro around debugging (-fstack-protector-all, -D_FORTIFY_SOURCE=2, -g3, etc)? I realize some distros already enable things like this, but usually they are looking to harden things, not necessarily diagnose bugs.",
      "num_comments": null,
      "story_id": 5711296,
      "story_title": "Linux code is the 'benchmark of quality,' study concludes ",
      "story_url": "http://www.pcworld.in/news/linux-code-benchmark-quality-study-concludes-98752013",
      "parent_id": 5711739,
      "created_at_i": 1368629821,
      "_tags": [
        "comment",
        "author_npsimons",
        "story_5711296"
      ],
      "objectID": "5712401",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "npsimons",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I've often felt that more developers (or even interested power users), should be running with things like MALLOC_CHECK_=3 (<a href=\"http://www.novell.com/support/kb/doc.php?id=3113982\" rel=\"nofollow\">http://www.novell.com/support/kb/doc.php?id=3113982</a>) enabled by default for everything. On top of that, when we have plenty of FLOSS <em>static</em> <em>analysis</em> <em>tools</em> (<a href=\"https://news.ycombinator.com/item?id=4545188\" rel=\"nofollow\">https://news.ycombinator.com/item?id=4545188</a>), plus things like valgrind, gprof and gcov, I don't understand why more people don't use them. As for compiler flags, if we can build a whole distro around optimization (Gentoo), why can't we build a whole distro around debugging (-fstack-protector-all, -D_FORTIFY_SOURCE=2, -g3, etc)? I realize some distros already enable things like this, but usually they are looking to harden things, not necessarily diagnose bugs.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Linux code is the 'benchmark of quality,' study concludes ",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.pcworld.in/news/linux-code-benchmark-quality-study-concludes-98752013",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-19T21:14:44.000Z",
      "title": "",
      "url": "",
      "author": "DannyBee",
      "points": 3,
      "story_text": null,
      "comment_text": "I don't know off hand if they use it.  I know they do in static analysis tools.\nAs nice as MS is, they seem to consider compilers solely a cost center.  Their compilers produce \"relatively good code\", but have never really been state of the art.",
      "num_comments": null,
      "story_id": 5080210,
      "story_title": "When Haskell is Faster than C",
      "story_url": "http://paulspontifications.blogspot.com/2013/01/when-haskell-is-faster-than-c.html",
      "parent_id": 5084736,
      "created_at_i": 1358630084,
      "_tags": [
        "comment",
        "author_DannyBee",
        "story_5080210"
      ],
      "objectID": "5084770",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "DannyBee",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't know off hand if they use it.  I know they do in <em>static</em> <em>analysis</em> <em>tools</em>.\nAs nice as MS is, they seem to consider compilers solely a cost center.  Their compilers produce \"relatively good code\", but have never really been state of the art.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "When Haskell is Faster than C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://paulspontifications.blogspot.com/2013/01/when-haskell-is-faster-than-c.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-10T16:20:00.000Z",
      "title": "",
      "url": "",
      "author": "MichaelGG",
      "points": 3,
      "story_text": null,
      "comment_text": "That's a misleading statement and I think you know it. In general, you have to go extremely out of your way to end up with a remote code execution exploit with Java or C#.<p>Look at Microsoft's CVEs for 2012. Approximately all of the serious ones would be impossible with a proper type system. This is after all of Microsoft's static analysis tools and code reviews and security focus.",
      "num_comments": null,
      "story_id": 5037089,
      "story_title": "The Unreasonable Effectiveness of C",
      "story_url": "http://damienkatz.net/2013/01/the_unreasonable_effectiveness_of_c.html",
      "parent_id": 5037317,
      "created_at_i": 1357834800,
      "_tags": [
        "comment",
        "author_MichaelGG",
        "story_5037089"
      ],
      "objectID": "5037761",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "MichaelGG",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's a misleading statement and I think you know it. In general, you have to go extremely out of your way to end up with a remote code execution exploit with Java or C#.<p>Look at Microsoft's CVEs for 2012. Approximately all of the serious ones would be impossible with a proper type system. This is after all of Microsoft's <em>static</em> <em>analysis</em> <em>tools</em> and code reviews and security focus.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Unreasonable Effectiveness of C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://damienkatz.net/2013/01/the_unreasonable_effectiveness_of_c.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-11-10T15:21:18.000Z",
      "title": "",
      "url": "",
      "author": "taliesinb",
      "points": 3,
      "story_text": null,
      "comment_text": "My answer at this very moment in time is around 1/3. Which seems a lot. Though these projects have been less about automating drudgery and more about unlocking new workflows and ways of understanding things.<p>When I first started working at my job I sneakily built a suite of tools for visually working with NL grammars (instead of just buckling down and writing the grammars). Although I don't maintain it anymore, it's now used by an entire team. It was great that my then-managers saw that I was on to something and let me obsess about it for a few weeks.<p>I recently spent a few weekends writing static code analysis tools to analyze our codebase. There is some pretty exciting stuff that can be done there. It hasn't paid off quite yet, though I know it will.<p>Another project I've been juggling with my 'official job' is a nice new logging system with all kinds of cool features. There are so many challenges about making a piece of infrastructure work technically <i>and</i> culturally across a large team, however. It's much easier to estimate how long the technical part will take.<p>I've also written a bunch of tools that just failed to find any real use. In retrospect, these were mostly vanity projects of some kind, whereas the projects that have worked have always been about scratching an itch that I can see other people have (whether or not they articulate it).",
      "num_comments": null,
      "story_id": 4766666,
      "story_title": "Ask HN: Percent of time spent developing internal tools?",
      "story_url": "",
      "parent_id": 4766666,
      "created_at_i": 1352560878,
      "_tags": [
        "comment",
        "author_taliesinb",
        "story_4766666"
      ],
      "objectID": "4766832",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "taliesinb",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "My answer at this very moment in time is around 1/3. Which seems a lot. Though these projects have been less about automating drudgery and more about unlocking new workflows and ways of understanding things.<p>When I first started working at my job I sneakily built a suite of <em>tools</em> for visually working with NL grammars (instead of just buckling down and writing the grammars). Although I don't maintain it anymore, it's now used by an entire team. It was great that my then-managers saw that I was on to something and let me obsess about it for a few weeks.<p>I recently spent a few weekends writing <em>static</em> code <em>analysis</em> <em>tools</em> to analyze our codebase. There is some pretty exciting stuff that can be done there. It hasn't paid off quite yet, though I know it will.<p>Another project I've been juggling with my 'official job' is a nice new logging system with all kinds of cool features. There are so many challenges about making a piece of infrastructure work technically <i>and</i> culturally across a large team, however. It's much easier to estimate how long the technical part will take.<p>I've also written a bunch of <em>tools</em> that just failed to find any real use. In retrospect, these were mostly vanity projects of some kind, whereas the projects that have worked have always been about scratching an itch that I can see other people have (whether or not they articulate it).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Percent of time spent developing internal <em>tools</em>?",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-19T23:35:51.000Z",
      "title": "",
      "url": "",
      "author": "mark_story",
      "points": 3,
      "story_text": null,
      "comment_text": "Probably not, but you might want to give phpcpd, pdepend and pmd a try.  They're all open source static analysis tools for PHP, and will find a number of potential issues.<p>I also find getting a good set of rules for phpcs is extremely helpful in PHP.  You can use its sniffs to catch past mistakes and enforce consistent coding standards.",
      "num_comments": null,
      "story_id": 4543553,
      "story_title": "John Carmack on Static Code Analysis",
      "story_url": "http://www.altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 4543837,
      "created_at_i": 1348097751,
      "_tags": [
        "comment",
        "author_mark_story",
        "story_4543553"
      ],
      "objectID": "4546122",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "mark_story",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Probably not, but you might want to give phpcpd, pdepend and pmd a try.  They're all open source <em>static</em> <em>analysis</em> <em>tools</em> for PHP, and will find a number of potential issues.<p>I also find getting a good set of rules for phpcs is extremely helpful in PHP.  You can use its sniffs to catch past mistakes and enforce consistent coding standards.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://www.altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2012-05-02T14:14:57.000Z",
      "title": "",
      "url": "",
      "author": "mynegation",
      "points": 3,
      "story_text": null,
      "comment_text": "Static analysis is a method, not a goal. Static analysis in compilers is done for the purposes of optimization, so it is meaningless without a compiler. There are commercial and open source products that do static analysis to find logical errors and security vulnerabilities in your code like Klocwork, Coverity, or Gimpel Lint. There are formal verifiers. Decompilers, indenters and obfuscators can be considered sort of static analysis tools too, although on a shallower level.",
      "num_comments": null,
      "story_id": 3918404,
      "story_title": "GCC and static analysis",
      "story_url": "http://lwn.net/SubscriberLink/493599/7621ec4c8ab14f15/",
      "parent_id": 3919076,
      "created_at_i": 1335968097,
      "_tags": [
        "comment",
        "author_mynegation",
        "story_3918404"
      ],
      "objectID": "3919132",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "mynegation",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<em>Static</em> <em>analysis</em> is a method, not a goal. <em>Static</em> <em>analysis</em> in compilers is done for the purposes of optimization, so it is meaningless without a compiler. There are commercial and open source products that do <em>static</em> <em>analysis</em> to find logical errors and security vulnerabilities in your code like Klocwork, Coverity, or Gimpel Lint. There are formal verifiers. Decompilers, indenters and obfuscators can be considered sort of <em>static</em> <em>analysis</em> <em>tools</em> too, although on a shallower level.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "GCC and <em>static</em> <em>analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://lwn.net/SubscriberLink/493599/7621ec4c8ab14f15/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T21:20:11.000Z",
      "title": "",
      "url": "",
      "author": "sriramk",
      "points": 3,
      "story_text": null,
      "comment_text": "Happy that all the static code analysis tools from MSR ( which form the basis of /analyze) are getting good PR. Microsoft is great with code analysis tools but rarely gets recognized for it.",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388290,
      "created_at_i": 1324761611,
      "_tags": [
        "comment",
        "author_sriramk",
        "story_3388290"
      ],
      "objectID": "3389696",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "sriramk",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Happy that all the <em>static</em> code <em>analysis</em> <em>tools</em> from MSR ( which form the basis of /analyze) are getting good PR. Microsoft is great with code <em>analysis</em> <em>tools</em> but rarely gets recognized for it.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2011-07-11T18:25:46.000Z",
      "title": "",
      "url": "",
      "author": "HamletDRC3",
      "points": 3,
      "story_text": null,
      "comment_text": "I am the main author for a static analysis tool for a dynamic language on the JVM. My tool also has many rules that could be considered controversial, some rules that conflict with each other, and (I hope) many rules that are genuinely useful. Our message has always been: configure the ruleset based on the coding guidelines that you want for your project. There is no one ruleset to rule them all.<p>I, myself, have written many rules that I personally would never apply to my own codebase, but perhaps someone else might. My belief is that the world can benefit from static analysis tools and that adoption will be faster if we focus on providing as many rules as possible even if some are (in my opinion) questionable.<p>So CSS-Lint can be configured to only enforce the rules you want. If a user can find 5-10 rules that they like, then it seems like a good idea to start using the tool, especially if the team is larger and less highly skilled. But it seems petty to me to lambast a project just because you disagree with the name. Yes the intent of CSS-Lint is something different than base Lint, but I can say from experience that people looking for static analysis tools often google for \"css lint\" or \"java lint\" before understanding that Lint is a product and Static Analysis is the general term.<p>To summarize: CSS-Lint is just a name and the product is aggressively marketed. That doesn't mean it can't be useful.",
      "num_comments": null,
      "story_id": 2750100,
      "story_title": "CSS Lint is harmful",
      "story_url": "http://mattwilcox.net/archive/entry/id/1054/",
      "parent_id": 2750100,
      "created_at_i": 1310408746,
      "_tags": [
        "comment",
        "author_HamletDRC3",
        "story_2750100"
      ],
      "objectID": "2751861",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "HamletDRC3",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I am the main author for a <em>static</em> <em>analysis</em> tool for a dynamic language on the JVM. My tool also has many rules that could be considered controversial, some rules that conflict with each other, and (I hope) many rules that are genuinely useful. Our message has always been: configure the ruleset based on the coding guidelines that you want for your project. There is no one ruleset to rule them all.<p>I, myself, have written many rules that I personally would never apply to my own codebase, but perhaps someone else might. My belief is that the world can benefit from <em>static</em> <em>analysis</em> <em>tools</em> and that adoption will be faster if we focus on providing as many rules as possible even if some are (in my opinion) questionable.<p>So CSS-Lint can be configured to only enforce the rules you want. If a user can find 5-10 rules that they like, then it seems like a good idea to start using the tool, especially if the team is larger and less highly skilled. But it seems petty to me to lambast a project just because you disagree with the name. Yes the intent of CSS-Lint is something different than base Lint, but I can say from experience that people looking for <em>static</em> <em>analysis</em> <em>tools</em> often google for \"css lint\" or \"java lint\" before understanding that Lint is a product and <em>Static</em> <em>Analysis</em> is the general term.<p>To summarize: CSS-Lint is just a name and the product is aggressively marketed. That doesn't mean it can't be useful.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "CSS Lint is harmful",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://mattwilcox.net/archive/entry/id/1054/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-07-03T04:12:28.000Z",
      "title": "",
      "url": "",
      "author": "JoshTriplett",
      "points": 3,
      "story_text": null,
      "comment_text": "The original lint tools seem entirely superseded by modern compiler warnings.  On the other hand, a whole new class of static analysis tools exist now, such as Sparse, Coccinelle, Frama-C, and in the proprietary world Coverity.",
      "num_comments": null,
      "story_id": 2722833,
      "story_title": "Learn C The Hard Way",
      "story_url": "http://learncodethehardway.org/",
      "parent_id": 2723002,
      "created_at_i": 1309666348,
      "_tags": [
        "comment",
        "author_JoshTriplett",
        "story_2722833"
      ],
      "objectID": "2723054",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "JoshTriplett",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The original lint <em>tools</em> seem entirely superseded by modern compiler warnings.  On the other hand, a whole new class of <em>static</em> <em>analysis</em> <em>tools</em> exist now, such as Sparse, Coccinelle, Frama-C, and in the proprietary world Coverity.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Learn C The Hard Way",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://learncodethehardway.org/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-04-13T17:01:12.000Z",
      "title": null,
      "url": null,
      "author": "euroclydon",
      "points": 3,
      "story_text": null,
      "comment_text": "I don't know any thing about CoffeeScript, but static analysis tools like the Google Closure Compiler can help you take care of global variable problems and a whole lot more. Using Closure Compiler, you are forced to document your code with their enhanced version of jsDocs, so CC will make sure that if your method returns null or a list of strings, that anywhere that method is used, you don't try to treat the returned value as a string or object, for instance.<p>How does coffee script play with existing object oriented JS libraries? Is there compile-time type checking?",
      "num_comments": null,
      "story_id": 2442663,
      "story_title": "Rails 3.1 shipping with CoffeeScript",
      "story_url": "https://github.com/rails/rails/compare/9333ca7...23aa7da",
      "parent_id": 2442968,
      "created_at_i": 1302714072,
      "_tags": [
        "comment",
        "author_euroclydon",
        "story_2442663"
      ],
      "objectID": "2443135",
      "_highlightResult": {
        "author": {
          "value": "euroclydon",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't know any thing about CoffeeScript, but <em>static</em> <em>analysis</em> <em>tools</em> like the Google Closure Compiler can help you take care of global variable problems and a whole lot more. Using Closure Compiler, you are forced to document your code with their enhanced version of jsDocs, so CC will make sure that if your method returns null or a list of strings, that anywhere that method is used, you don't try to treat the returned value as a string or object, for instance.<p>How does coffee script play with existing object oriented JS libraries? Is there compile-time type checking?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Rails 3.1 shipping with CoffeeScript",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/rails/rails/compare/9333ca7...23aa7da",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-28T00:29:40.000Z",
      "title": null,
      "url": null,
      "author": "mindcrime",
      "points": 2,
      "story_text": null,
      "comment_text": "Well said.  rms is still The Man as far as I&#x27;m concerned.  So bash had a bug, big whoop-do-freaking-do... I guess Windows or Internet Explorer or ActiveX or Firefox or Chrome or Opera or Java or Flash never had exploitable bugs; oh, wait....<p>The takeaway from all this, to me, is simply to acknowledge that while &quot;with enough eyeballs all bugs are shallow&quot; may or may not be true, there&#x27;s no easy way to know, a priori, how many eyeballs are &quot;enough&quot; - and Open Source projects (right alongside ALL software projects) should still utilize tools like static code analysis, fuzzing tools, should still have dedicated security audits from time to time, etc.<p>The other takeway is that &quot;defense in depth&quot; is <i>still</i> mantra number one for security. You can have a hole at any level, which means that <i>every</i> level must work to limit access to the greatest possible extent.  A hope and prayer and expecting all software to be bug-free isn&#x27;t going to cut it.",
      "num_comments": null,
      "story_id": 8378286,
      "story_title": "Stop Bashing Bash and GNU",
      "story_url": "http://weev.livejournal.com/409835.html",
      "parent_id": 8378286,
      "created_at_i": 1411864180,
      "_tags": [
        "comment",
        "author_mindcrime",
        "story_8378286"
      ],
      "objectID": "8378572",
      "_highlightResult": {
        "author": {
          "value": "mindcrime",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Well said.  rms is still The Man as far as I'm concerned.  So bash had a bug, big whoop-do-freaking-do... I guess Windows or Internet Explorer or ActiveX or Firefox or Chrome or Opera or Java or Flash never had exploitable bugs; oh, wait....<p>The takeaway from all this, to me, is simply to acknowledge that while &quot;with enough eyeballs all bugs are shallow&quot; may or may not be true, there's no easy way to know, a priori, how many eyeballs are &quot;enough&quot; - and Open Source projects (right alongside ALL software projects) should still utilize <em>tools</em> like <em>static</em> code <em>analysis</em>, fuzzing <em>tools</em>, should still have dedicated security audits from time to time, etc.<p>The other takeway is that &quot;defense in depth&quot; is <i>still</i> mantra number one for security. You can have a hole at any level, which means that <i>every</i> level must work to limit access to the greatest possible extent.  A hope and prayer and expecting all software to be bug-free isn't going to cut it.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Stop Bashing Bash and GNU",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://weev.livejournal.com/409835.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-22T23:11:52.000Z",
      "title": null,
      "url": null,
      "author": "drblast",
      "points": 2,
      "story_text": null,
      "comment_text": "The backstory is pretty simple; I analyze malware and this was a sample.  It&#x27;s difficult to talk about publicly because if you reveal too much, it&#x27;s a chance for the malware authors to recognize they&#x27;ve been made and change what they&#x27;re doing.<p>What&#x27;s interesting is that if you&#x27;ve seen enough samples, you can make educated guesses about the authors, their intentions, and level of competence.  In this case, the authors were obviously aware that someone might try to reverse engineer the software so they threw that little red herring in.  I have no idea why, and it was only in certain functions and not others.  But you do know the authors had a clue about IDA and similar static analysis tools and were trying to make it more painful to analyze.  It certainly wasted a couple of hours of my time.<p>Fortunately the obfuscations make software like that easier to detect, so it&#x27;s a balancing act the author has to play.<p>If I ever stop analyzing malware there might be a very interesting blog series on all the boneheaded mistakes malware authors make when they obfuscate their code.  I could teach a six-month course on what not to do with crypto just from all the approaches I&#x27;ve seen.",
      "num_comments": null,
      "story_id": 8350915,
      "story_title": "I was asked to crack a program in a job interview, part 2",
      "story_url": "http://erenyagdiran.github.io/I-was-just-asked-to-crack-a-program-Part-2/",
      "parent_id": 8351538,
      "created_at_i": 1411427512,
      "_tags": [
        "comment",
        "author_drblast",
        "story_8350915"
      ],
      "objectID": "8353211",
      "_highlightResult": {
        "author": {
          "value": "drblast",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The backstory is pretty simple; I analyze malware and this was a sample.  It's difficult to talk about publicly because if you reveal too much, it's a chance for the malware authors to recognize they've been made and change what they're doing.<p>What's interesting is that if you've seen enough samples, you can make educated guesses about the authors, their intentions, and level of competence.  In this case, the authors were obviously aware that someone might try to reverse engineer the software so they threw that little red herring in.  I have no idea why, and it was only in certain functions and not others.  But you do know the authors had a clue about IDA and similar <em>static</em> <em>analysis</em> <em>tools</em> and were trying to make it more painful to analyze.  It certainly wasted a couple of hours of my time.<p>Fortunately the obfuscations make software like that easier to detect, so it's a balancing act the author has to play.<p>If I ever stop analyzing malware there might be a very interesting blog series on all the boneheaded mistakes malware authors make when they obfuscate their code.  I could teach a six-month course on what not to do with crypto just from all the approaches I've seen.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "I was asked to crack a program in a job interview, part 2",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://erenyagdiran.github.io/I-was-just-asked-to-crack-a-program-Part-2/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-16T18:48:26.000Z",
      "title": null,
      "url": null,
      "author": "cdwhite",
      "points": 2,
      "story_text": null,
      "comment_text": "&gt; probably incorrect use of = instead of :=<p>Oh, man, that bit me so many times, especially when it had to interact with some kind of scoping trick. I read that tutorial (or the equivalent from before the WL), and never really got good intuition for how immediate &amp; delayed evaluation worked and when to use which.<p>&gt; There might have been higher level ways to do this using functions like Array and Table, but perhaps not.<p>I was actually using Table, but I was thinking of it as &quot;iterate over these variables&quot;. Table&#x27;s nice, although every once in a while it would break the picture I had in my head of it as &quot;map-over-cartesian-products&quot;.<p>&gt; Plus, I think we have a chance in the next year or two to really leapfrog other languages with some amazing static analysis tools.<p>Great! Another beef I have with Mathematica (and Scheme, for that matter) is that it doesn&#x27;t have types: since I learned bits and pieces of Haskell and started using Julia seriously, I&#x27;ve come to love the way a type system can save me from my own stupidity. This is <i>definitely</i> a matter of taste, though.",
      "num_comments": null,
      "story_id": 8321054,
      "story_title": "Launching Today: Mathematica Online",
      "story_url": "http://blog.wolfram.com/2014/09/15/launching-today-mathematica-online/",
      "parent_id": 8325999,
      "created_at_i": 1410893306,
      "_tags": [
        "comment",
        "author_cdwhite",
        "story_8321054"
      ],
      "objectID": "8326246",
      "_highlightResult": {
        "author": {
          "value": "cdwhite",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; probably incorrect use of = instead of :=<p>Oh, man, that bit me so many times, especially when it had to interact with some kind of scoping trick. I read that tutorial (or the equivalent from before the WL), and never really got good intuition for how immediate &amp; delayed evaluation worked and when to use which.<p>&gt; There might have been higher level ways to do this using functions like Array and Table, but perhaps not.<p>I was actually using Table, but I was thinking of it as &quot;iterate over these variables&quot;. Table's nice, although every once in a while it would break the picture I had in my head of it as &quot;map-over-cartesian-products&quot;.<p>&gt; Plus, I think we have a chance in the next year or two to really leapfrog other languages with some amazing <em>static</em> <em>analysis</em> <em>tools</em>.<p>Great! Another beef I have with Mathematica (and Scheme, for that matter) is that it doesn't have types: since I learned bits and pieces of Haskell and started using Julia seriously, I've come to love the way a type system can save me from my own stupidity. This is <i>definitely</i> a matter of taste, though.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Launching Today: Mathematica Online",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.wolfram.com/2014/09/15/launching-today-mathematica-online/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-16T18:11:49.000Z",
      "title": null,
      "url": null,
      "author": "taliesinb",
      "points": 2,
      "story_text": null,
      "comment_text": "&gt; f[x] = x^2` and `f[x_] = x^2<p>That&#x27;s a really good example: you&#x27;d have to find the tutorial [0] to know what to do. And we could make that job easier by detecting your probably incorrect use of = instead of := and giving you a &quot;I see you&#x27;re trying to define a function&quot; kind of deal. Of course people hated Clippy, so we have to tread carefully with that kind of thing :)<p>&gt; This is important, I think, but I also think the problem&#x27;s less in your documentation than in how I &quot;learned&quot; Mathematica.<p>Yes, I think you hit the nail on the head with this paragraph. It is possible to &#x27;accrete&#x27; tricks in a way that potentially blocks you from having a holistic knowledge of the language. The workflows for symbolic manipulation, which involve lots of global state and symbols representing variables, is probably a prime culprit.<p>&gt; My problem was in setting up the matrix to be diagonalized. The state space had something like seven degrees of freedom (four two-dimensional and three with arbitrary dimensions), so I was calculating matrix elements for up to something like N = 10^5 basis states.<p>That makes more sense. There might have been higher level ways to do this using functions like Array and Table, but perhaps not. And Julia is a really interesting language, I think we can learn a lot from them.<p>&gt; I can&#x27;t shake the feeling, though, that I&#x27;d want to run away very quickly from a large Mathematica&#x2F;WL project like Wolfram|Alpha.<p>Huge codebases in any language get hairy. I&#x27;d say we&#x27;re on a par with C++ in that respect (meaning: not very good, but workable).<p>Modern languages have had some innovations with clean package systems and API boundaries (though the ML family showed the way), so it&#x27;s perhaps good we&#x27;re still waiting to modernize our package system. Plus, I think we have a chance in the next year or two to really leapfrog other languages with some amazing static analysis tools.<p>Still in the lab, though :)<p>[0] <a href=\"http://reference.wolfram.com/language/tutorial/ImmediateAndDelayedDefinitions.html\" rel=\"nofollow\">http:&#x2F;&#x2F;reference.wolfram.com&#x2F;language&#x2F;tutorial&#x2F;ImmediateAndD...</a><p>[1] <a href=\"http://reference.wolfram.com/language/ref/Array.html\" rel=\"nofollow\">http:&#x2F;&#x2F;reference.wolfram.com&#x2F;language&#x2F;ref&#x2F;Array.html</a>, <a href=\"http://reference.wolfram.com/language/ref/Table.html\" rel=\"nofollow\">http:&#x2F;&#x2F;reference.wolfram.com&#x2F;language&#x2F;ref&#x2F;Table.html</a>",
      "num_comments": null,
      "story_id": 8321054,
      "story_title": "Launching Today: Mathematica Online",
      "story_url": "http://blog.wolfram.com/2014/09/15/launching-today-mathematica-online/",
      "parent_id": 8325485,
      "created_at_i": 1410891109,
      "_tags": [
        "comment",
        "author_taliesinb",
        "story_8321054"
      ],
      "objectID": "8325999",
      "_highlightResult": {
        "author": {
          "value": "taliesinb",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; f[x] = x^2` and `f[x_] = x^2<p>That's a really good example: you'd have to find the tutorial [0] to know what to do. And we could make that job easier by detecting your probably incorrect use of = instead of := and giving you a &quot;I see you're trying to define a function&quot; kind of deal. Of course people hated Clippy, so we have to tread carefully with that kind of thing :)<p>&gt; This is important, I think, but I also think the problem's less in your documentation than in how I &quot;learned&quot; Mathematica.<p>Yes, I think you hit the nail on the head with this paragraph. It is possible to 'accrete' tricks in a way that potentially blocks you from having a holistic knowledge of the language. The workflows for symbolic manipulation, which involve lots of global state and symbols representing variables, is probably a prime culprit.<p>&gt; My problem was in setting up the matrix to be diagonalized. The state space had something like seven degrees of freedom (four two-dimensional and three with arbitrary dimensions), so I was calculating matrix elements for up to something like N = 10^5 basis states.<p>That makes more sense. There might have been higher level ways to do this using functions like Array and Table, but perhaps not. And Julia is a really interesting language, I think we can learn a lot from them.<p>&gt; I can't shake the feeling, though, that I'd want to run away very quickly from a large Mathematica/WL project like Wolfram|Alpha.<p>Huge codebases in any language get hairy. I'd say we're on a par with C++ in that respect (meaning: not very good, but workable).<p>Modern languages have had some innovations with clean package systems and API boundaries (though the ML family showed the way), so it's perhaps good we're still waiting to modernize our package system. Plus, I think we have a chance in the next year or two to really leapfrog other languages with some amazing <em>static</em> <em>analysis</em> <em>tools</em>.<p>Still in the lab, though :)<p>[0] <a href=\"http://reference.wolfram.com/language/tutorial/ImmediateAndDelayedDefinitions.html\" rel=\"nofollow\">http://reference.wolfram.com/language/tutorial/ImmediateAndD...</a><p>[1] <a href=\"http://reference.wolfram.com/language/ref/Array.html\" rel=\"nofollow\">http://reference.wolfram.com/language/ref/Array.html</a>, <a href=\"http://reference.wolfram.com/language/ref/Table.html\" rel=\"nofollow\">http://reference.wolfram.com/language/ref/Table.html</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Launching Today: Mathematica Online",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.wolfram.com/2014/09/15/launching-today-mathematica-online/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-15T19:01:36.000Z",
      "title": null,
      "url": null,
      "author": "walterbell",
      "points": 2,
      "story_text": null,
      "comment_text": "How about funding improvements in static analysis toolsets and competitive&#x2F;bounty penetration testing?",
      "num_comments": null,
      "story_id": 8182713,
      "story_title": "Quality Software Costs Money – Heartbleed Was Free",
      "story_url": "http://queue.acm.org/detail.cfm?id=2636165",
      "parent_id": 8183540,
      "created_at_i": 1408129296,
      "_tags": [
        "comment",
        "author_walterbell",
        "story_8182713"
      ],
      "objectID": "8183624",
      "_highlightResult": {
        "author": {
          "value": "walterbell",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "How about funding improvements in <em>static</em> <em>analysis</em> <em>tools</em>ets and competitive/bounty penetration testing?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Quality Software Costs Money – Heartbleed Was Free",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://queue.acm.org/detail.cfm?id=2636165",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-11T13:53:39.000Z",
      "title": null,
      "url": null,
      "author": "pjmlp",
      "points": 2,
      "story_text": null,
      "comment_text": "Might be, but it also shows how many C and C++ developers still don&#x27;t care about static analysis tools, given the amount of issues that always get found and used as advertising material.",
      "num_comments": null,
      "story_id": 8162259,
      "story_title": "Can We Trust the Libraries We Use?",
      "story_url": "http://www.viva64.com/en/b/0271/",
      "parent_id": 8162512,
      "created_at_i": 1407765219,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_8162259"
      ],
      "objectID": "8163227",
      "_highlightResult": {
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Might be, but it also shows how many C and C++ developers still don't care about <em>static</em> <em>analysis</em> <em>tools</em>, given the amount of issues that always get found and used as advertising material.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Can We Trust the Libraries We Use?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0271/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-08T23:35:03.000Z",
      "title": null,
      "url": null,
      "author": "taeric",
      "points": 2,
      "story_text": null,
      "comment_text": "Actually, I think I&#x27;m just having more of this conversation in my head than I am in this forum.  For better and worse. :)<p>My point here was more that just because you have a file handle doesn&#x27;t mean you have a valid place to write data.  Making it optional would possibly prevent some bugs, true.  However, it doesn&#x27;t really help as soon as you have a filehandle to a full filesystem, for example.  (Or, well, any other problem that usually happens to cause grief with the filesystems.  You got a file, but by the time you went to use it the system was full and you couldn&#x27;t, etc.)<p>Regardless, I should have been clearer on many points (and I fully accept I was flat out wrong on at least a few :) ).  I do think null pointers are bad.  I also know with proper static analysis tools, you don&#x27;t need a whole new type system to make things better.  Unless you are considering tools such as Coverity and friends some form of type system.",
      "num_comments": null,
      "story_id": 8005156,
      "story_title": "Option and Null in Dynamic Languages",
      "story_url": "http://www.rntz.net/post/2014-07-02-option-in-dynlangs.html",
      "parent_id": 8007084,
      "created_at_i": 1404862503,
      "_tags": [
        "comment",
        "author_taeric",
        "story_8005156"
      ],
      "objectID": "8007326",
      "_highlightResult": {
        "author": {
          "value": "taeric",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Actually, I think I'm just having more of this conversation in my head than I am in this forum.  For better and worse. :)<p>My point here was more that just because you have a file handle doesn't mean you have a valid place to write data.  Making it optional would possibly prevent some bugs, true.  However, it doesn't really help as soon as you have a filehandle to a full filesystem, for example.  (Or, well, any other problem that usually happens to cause grief with the filesystems.  You got a file, but by the time you went to use it the system was full and you couldn't, etc.)<p>Regardless, I should have been clearer on many points (and I fully accept I was flat out wrong on at least a few :) ).  I do think null pointers are bad.  I also know with proper <em>static</em> <em>analysis</em> <em>tools</em>, you don't need a whole new type system to make things better.  Unless you are considering <em>tools</em> such as Coverity and friends some form of type system.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Option and Null in Dynamic Languages",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.rntz.net/post/2014-07-02-option-in-dynlangs.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-24T13:13:35.000Z",
      "title": null,
      "url": null,
      "author": "zenbowman",
      "points": 2,
      "story_text": null,
      "comment_text": "The difference between engineering and tinkering is discipline.<p>Not to say tinkering is bad, its perfectly fine when trying to create the latest viral app or when learning how to do something. When engineering something, discipline is required.<p>And nothing stops any institution seriously committed to engineering to adopting practices that restrict language use to a subset (mandatory code review, static analysis tools that highlight deviant code and disallow it to be pushed, etc).",
      "num_comments": null,
      "story_id": 7934548,
      "story_title": "Why C++ Sails When the Vasa Sank [pdf]",
      "story_url": "http://files.meetup.com/1455470/Why%20C%2B%2B%20Sails%20When%20the%20Vasa%20Sank.pdf",
      "parent_id": 7934907,
      "created_at_i": 1403615615,
      "_tags": [
        "comment",
        "author_zenbowman",
        "story_7934548"
      ],
      "objectID": "7937479",
      "_highlightResult": {
        "author": {
          "value": "zenbowman",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The difference between engineering and tinkering is discipline.<p>Not to say tinkering is bad, its perfectly fine when trying to create the latest viral app or when learning how to do something. When engineering something, discipline is required.<p>And nothing stops any institution seriously committed to engineering to adopting practices that restrict language use to a subset (mandatory code review, <em>static</em> <em>analysis</em> <em>tools</em> that highlight deviant code and disallow it to be pushed, etc).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why C++ Sails When the Vasa Sank [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://files.meetup.com/1455470/Why%20C%2B%2B%20Sails%20When%20the%20Vasa%20Sank.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-13T17:16:44.000Z",
      "title": null,
      "url": null,
      "author": "Jtsummers",
      "points": 2,
      "story_text": null,
      "comment_text": "Nothing about making programs requires static typing ever. If you&#x27;re targetting reliable, performant programs, then static typing is a boon.<p>Dynamically typed languages require additional tooling beyond the language itself to provide a lot of the reliability&#x2F;correctness assistance that good statically typed languages can offer. See the dialyzer for erlang, a very useful tool, but a separate tool. If you want to see an example of statically typed languages that require extra tools, see C and its various static analysis tools. Swift, Rust, Ada, etc. (I&#x27;m sticking with the more imperative ones with good or better than average type systems) don&#x27;t require that extra tooling. It&#x27;s not an additional step. It&#x27;s just part of the language.<p>If you want good performance, that is C&#x2F;Fortran level performance, you either need a sufficiently smart compiler (see SBCL) that can take type hints (derived from the static analysis tools perhaps), or static typing. Static typing (and good static typing like the languages I&#x27;ve mentioned seem to have) improves performance compared to dynamically typed languages. You can remove all the possible branches based on the types used for addition if you <i>know</i> that you&#x27;re adding two ints, two floats, an int and a float at compile time. In a tight loop, having to select between all those options is a drag on performance. Statically typed languages can reduce that to a single path, instead of the 3 branching paths I just came up with (and there are probably more for most languages).<p>Besides, performance on mobile is critical. We&#x27;re depending on miniscule (relatively) batteries. The better performance we can get out of our code, the better battery life we&#x27;ll see. Every app that&#x27;s written in a dynamically typed language that doesn&#x27;t have good type hints (like CL, there are probably others) is going to be a huge drag on battery performance.<p>Fuck, a friend writes python to run on clusters for numeric code (simulations, he&#x27;s an Aerospace Engineer). Fucking brilliant, the type system hinders his performance compared to Fortran&#x2F;C&#x2F;others. He has jobs that take 24 hours to run on an 80-machine cluster. I hate to consider how much time is wasted because they don&#x27;t use a language with even a simple static type system like Fortran and C offer.<p>I love dynamically typed languages, my favorite languages are erlang and common lisp, scheme is a close 3rd. But they have their place, and if performance is one of your requirements they (in general) are not what you want. If reliability is what you want, something that knocks out a huge percentage of errors right off the bat is wonderful, dynamically typed languages (without extra tooling) can&#x27;t tell you, until you run the program, that you added an integer to a binary blob. And delightfully some are also weakly typed, meaning they&#x27;d permit such an operation and you&#x27;d get bizarre errors later on in your execution.<p>--<p>EDIT: Some scheme implementations offer good performance. Do they, like SBCL, implement static analysis under the hood?<p>EDIT: I may have left in words that should&#x27;ve been removed when I switched gears in mid-sentence.",
      "num_comments": null,
      "story_id": 7889117,
      "story_title": "Why Rubyist Will Love Swift",
      "story_url": "http://littlelines.com/blog/2014/06/11/why-rubyist-will-love-swift/",
      "parent_id": 7889652,
      "created_at_i": 1402679804,
      "_tags": [
        "comment",
        "author_Jtsummers",
        "story_7889117"
      ],
      "objectID": "7889847",
      "_highlightResult": {
        "author": {
          "value": "Jtsummers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Nothing about making programs requires <em>static</em> typing ever. If you're targetting reliable, performant programs, then <em>static</em> typing is a boon.<p>Dynamically typed languages require additional tooling beyond the language itself to provide a lot of the reliability/correctness assistance that good statically typed languages can offer. See the dialyzer for erlang, a very useful tool, but a separate tool. If you want to see an example of statically typed languages that require extra <em>tools</em>, see C and its various <em>static</em> <em>analysis</em> <em>tools</em>. Swift, Rust, Ada, etc. (I'm sticking with the more imperative ones with good or better than average type systems) don't require that extra tooling. It's not an additional step. It's just part of the language.<p>If you want good performance, that is C/Fortran level performance, you either need a sufficiently smart compiler (see SBCL) that can take type hints (derived from the <em>static</em> <em>analysis</em> <em>tools</em> perhaps), or <em>static</em> typing. <em>Static</em> typing (and good <em>static</em> typing like the languages I've mentioned seem to have) improves performance compared to dynamically typed languages. You can remove all the possible branches based on the types used for addition if you <i>know</i> that you're adding two ints, two floats, an int and a float at compile time. In a tight loop, having to select between all those options is a drag on performance. Statically typed languages can reduce that to a single path, instead of the 3 branching paths I just came up with (and there are probably more for most languages).<p>Besides, performance on mobile is critical. We're depending on miniscule (relatively) batteries. The better performance we can get out of our code, the better battery life we'll see. Every app that's written in a dynamically typed language that doesn't have good type hints (like CL, there are probably others) is going to be a huge drag on battery performance.<p>Fuck, a friend writes python to run on clusters for numeric code (simulations, he's an Aerospace Engineer). Fucking brilliant, the type system hinders his performance compared to Fortran/C/others. He has jobs that take 24 hours to run on an 80-machine cluster. I hate to consider how much time is wasted because they don't use a language with even a simple <em>static</em> type system like Fortran and C offer.<p>I love dynamically typed languages, my favorite languages are erlang and common lisp, scheme is a close 3rd. But they have their place, and if performance is one of your requirements they (in general) are not what you want. If reliability is what you want, something that knocks out a huge percentage of errors right off the bat is wonderful, dynamically typed languages (without extra tooling) can't tell you, until you run the program, that you added an integer to a binary blob. And delightfully some are also weakly typed, meaning they'd permit such an operation and you'd get bizarre errors later on in your execution.<p>--<p>EDIT: Some scheme implementations offer good performance. Do they, like SBCL, implement <em>static</em> <em>analysis</em> under the hood?<p>EDIT: I may have left in words that should've been removed when I switched gears in mid-sentence.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Rubyist Will Love Swift",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://littlelines.com/blog/2014/06/11/why-rubyist-will-love-swift/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-11T08:05:44.000Z",
      "title": null,
      "url": null,
      "author": "pinealservo",
      "points": 2,
      "story_text": null,
      "comment_text": "This is too much machinery to build into a general-purpose compiler today, but there are static analysis tools (see Frama-C and the like) that will analyze your program text (optionally with annotations like you&#x27;ve mentioned) and figure out constraint violations.",
      "num_comments": null,
      "story_id": 7873414,
      "story_title": "Types Are The Truth",
      "story_url": "http://michaelrbernste.in/2014/06/10/types-are-the-truth.html",
      "parent_id": 7874779,
      "created_at_i": 1402473944,
      "_tags": [
        "comment",
        "author_pinealservo",
        "story_7873414"
      ],
      "objectID": "7876911",
      "_highlightResult": {
        "author": {
          "value": "pinealservo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is too much machinery to build into a general-purpose compiler today, but there are <em>static</em> <em>analysis</em> <em>tools</em> (see Frama-C and the like) that will analyze your program text (optionally with annotations like you've mentioned) and figure out constraint violations.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Types Are The Truth",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://michaelrbernste.in/2014/06/10/types-are-the-truth.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-29T18:01:15.000Z",
      "title": null,
      "url": null,
      "author": "romaniv",
      "points": 2,
      "story_text": null,
      "comment_text": "<i>I don&#x27;t really see DHH giving any arguments as to why designing for tests leads to poor design decisions.</i><p>It results in pointless levels of abstraction that aren&#x27;t used to abstract anything in real code, but destroy readability and screw up static analysis tools. It also results in over-splitting of entities to the point where they don&#x27;t represent anything remotely similar to problem domain. Finally, it encourages &quot;old stuff plus this addition&quot; kind of design. (For example, using a switch statement to cover 7 different cases for days of the week, rather than using a math formula.)",
      "num_comments": null,
      "story_id": 7666866,
      "story_title": "Test-induced design damage",
      "story_url": "http://david.heinemeierhansson.com/2014/test-induced-design-damage.html",
      "parent_id": 7668254,
      "created_at_i": 1398794475,
      "_tags": [
        "comment",
        "author_romaniv",
        "story_7666866"
      ],
      "objectID": "7668813",
      "_highlightResult": {
        "author": {
          "value": "romaniv",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>I don't really see DHH giving any arguments as to why designing for tests leads to poor design decisions.</i><p>It results in pointless levels of abstraction that aren't used to abstract anything in real code, but destroy readability and screw up <em>static</em> <em>analysis</em> <em>tools</em>. It also results in over-splitting of entities to the point where they don't represent anything remotely similar to problem domain. Finally, it encourages &quot;old stuff plus this addition&quot; kind of design. (For example, using a switch statement to cover 7 different cases for days of the week, rather than using a math formula.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Test-induced design damage",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://david.heinemeierhansson.com/2014/test-induced-design-damage.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-27T15:24:26.000Z",
      "title": null,
      "url": null,
      "author": "fdej",
      "points": 2,
      "story_text": null,
      "comment_text": "With some discipline, it&#x27;s possible to achieve the same level of security in C as in pretty much any other high-level language.<p>Some useful techniques: always strive for simplicity, use types to encapsulate data dependencies and enforce error checking (e.g. store the length and pointer of an array as part of a struct and use methods that perform bounds checks to modify or read from it -- granted, this style of programming can add overhead, but C is so fast to begin with that it rarely matters), don&#x27;t use unsafe standard library functions, test rigorously, valgrind everything, use static code analysis tools.<p>Doing any of these things goes a long way to eliminate the vast majority of bugs specific to C, but unfortunately way too many C projects hardly do any of them. It can evidently be done, though, as there are some very robust C libraries out there.<p>See also djb&#x27;s comments about qmail (<a href=\"http://cr.yp.to/qmail/guarantee.html\" rel=\"nofollow\">http:&#x2F;&#x2F;cr.yp.to&#x2F;qmail&#x2F;guarantee.html</a>).",
      "num_comments": null,
      "story_id": 7655018,
      "story_title": "Software Checklist",
      "story_url": "http://www.solipsys.co.uk/new/SoftwareChecklist.html?ColinsBlog",
      "parent_id": 7655133,
      "created_at_i": 1398612266,
      "_tags": [
        "comment",
        "author_fdej",
        "story_7655018"
      ],
      "objectID": "7655416",
      "_highlightResult": {
        "author": {
          "value": "fdej",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "With some discipline, it's possible to achieve the same level of security in C as in pretty much any other high-level language.<p>Some useful techniques: always strive for simplicity, use types to encapsulate data dependencies and enforce error checking (e.g. store the length and pointer of an array as part of a struct and use methods that perform bounds checks to modify or read from it -- granted, this style of programming can add overhead, but C is so fast to begin with that it rarely matters), don't use unsafe standard library functions, test rigorously, valgrind everything, use <em>static</em> code <em>analysis</em> <em>tools</em>.<p>Doing any of these things goes a long way to eliminate the vast majority of bugs specific to C, but unfortunately way too many C projects hardly do any of them. It can evidently be done, though, as there are some very robust C libraries out there.<p>See also djb's comments about qmail (<a href=\"http://cr.yp.to/qmail/guarantee.html\" rel=\"nofollow\">http://cr.yp.to/qmail/guarantee.html</a>).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Software Checklist",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.solipsys.co.uk/new/SoftwareChecklist.html?ColinsBlog",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-22T20:09:18.000Z",
      "title": null,
      "url": null,
      "author": "cbab",
      "points": 2,
      "story_text": null,
      "comment_text": "On recent C++ projects, I used the TAP [0] test format. It&#x27;s quite minimalistic and does the job.<p>Debugging tools have improved quite a bit. I suggest you take a look at asan [1] for memory related errors. Also, tsan [2] looks very promising for data races detection. I think both tools have been integrated within LLVM&#x2F;Clang&#x2F;GCC.<p>Also, you might want to take a look at tracing tools such as (shameless plug!) LTTng [3] for userspace.<p>Static analysis tools are quite &quot;en vogue&quot; right now. IMO, nothing comes close to Coverity Scan [4]. It&#x27;s free for open source projects, but you will have to fork (quite) a bit of money to run this tool on proprietary applications. On the other hand, purely FOSS static-analyzer such as clang-analyzer and cppcheck can catch nasty errors. I would suggest using a mix of all these tools.<p>[0] - <a href=\"http://testanything.org/testing-with-tap/c-plus-plus.html\" rel=\"nofollow\">http:&#x2F;&#x2F;testanything.org&#x2F;testing-with-tap&#x2F;c-plus-plus.html</a><p>[1] - <a href=\"https://code.google.com/p/address-sanitizer/\" rel=\"nofollow\">https:&#x2F;&#x2F;code.google.com&#x2F;p&#x2F;address-sanitizer&#x2F;</a><p>[2] - <a href=\"https://code.google.com/p/data-race-test/wiki/ThreadSanitizer\" rel=\"nofollow\">https:&#x2F;&#x2F;code.google.com&#x2F;p&#x2F;data-race-test&#x2F;wiki&#x2F;ThreadSanitize...</a><p>[3] - <a href=\"http://lttng.org/ust\" rel=\"nofollow\">http:&#x2F;&#x2F;lttng.org&#x2F;ust</a><p>[4] - <a href=\"https://scan.coverity.com/\" rel=\"nofollow\">https:&#x2F;&#x2F;scan.coverity.com&#x2F;</a>",
      "num_comments": null,
      "story_id": 7629514,
      "story_title": "Ask HN: jumping back into C++ after 4 years, what did I miss?",
      "story_url": "",
      "parent_id": 7629514,
      "created_at_i": 1398197358,
      "_tags": [
        "comment",
        "author_cbab",
        "story_7629514"
      ],
      "objectID": "7630092",
      "_highlightResult": {
        "author": {
          "value": "cbab",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "On recent C++ projects, I used the TAP [0] test format. It's quite minimalistic and does the job.<p>Debugging <em>tools</em> have improved quite a bit. I suggest you take a look at asan [1] for memory related errors. Also, tsan [2] looks very promising for data races detection. I think both <em>tools</em> have been integrated within LLVM/Clang/GCC.<p>Also, you might want to take a look at tracing <em>tools</em> such as (shameless plug!) LTTng [3] for userspace.<p><em>Static</em> <em>analysis</em> <em>tools</em> are quite &quot;en vogue&quot; right now. IMO, nothing comes close to Coverity Scan [4]. It's free for open source projects, but you will have to fork (quite) a bit of money to run this tool on proprietary applications. On the other hand, purely FOSS <em>static</em>-analyzer such as clang-analyzer and cppcheck can catch nasty errors. I would suggest using a mix of all these <em>tools</em>.<p>[0] - <a href=\"http://testanything.org/testing-with-tap/c-plus-plus.html\" rel=\"nofollow\">http://testanything.org/testing-with-tap/c-plus-plus.html</a><p>[1] - <a href=\"https://code.google.com/p/address-sanitizer/\" rel=\"nofollow\">https://code.google.com/p/address-sanitizer/</a><p>[2] - <a href=\"https://code.google.com/p/data-race-test/wiki/ThreadSanitizer\" rel=\"nofollow\">https://code.google.com/p/data-race-test/wiki/ThreadSanitize...</a><p>[3] - <a href=\"http://lttng.org/ust\" rel=\"nofollow\">http://lttng.org/ust</a><p>[4] - <a href=\"https://scan.coverity.com/\" rel=\"nofollow\">https://scan.coverity.com/</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: jumping back into C++ after 4 years, what did I miss?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-09T17:57:12.000Z",
      "title": null,
      "url": null,
      "author": "rossjudson",
      "points": 2,
      "story_text": null,
      "comment_text": "I am curious about which static code analysis tools pick up this problem. Could it have been found automatically by Coverity, for example?",
      "num_comments": null,
      "story_id": 7558563,
      "story_title": "Heartbleed",
      "story_url": "https://www.schneier.com/blog/archives/2014/04/heartbleed.html",
      "parent_id": 7558752,
      "created_at_i": 1397066232,
      "_tags": [
        "comment",
        "author_rossjudson",
        "story_7558563"
      ],
      "objectID": "7560981",
      "_highlightResult": {
        "author": {
          "value": "rossjudson",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I am curious about which <em>static</em> code <em>analysis</em> <em>tools</em> pick up this problem. Could it have been found automatically by Coverity, for example?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Heartbleed",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.schneier.com/blog/archives/2014/04/heartbleed.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-02T10:00:29.000Z",
      "title": null,
      "url": null,
      "author": "Totoradio",
      "points": 2,
      "story_text": null,
      "comment_text": "This works until you refactor the new code, and the commented out code becomes out of sync with the production code it is supposed to mirror.\\nCommented code isn&#x27;t checked by the compiler nor by the static code analysis tools, nor by the tests, so it can become out of sync fast and silently.",
      "num_comments": null,
      "story_id": 7514265,
      "story_title": "Delete your code",
      "story_url": "http://www.anton-pirker.at/delete-your-code/",
      "parent_id": 7514384,
      "created_at_i": 1396432829,
      "_tags": [
        "comment",
        "author_Totoradio",
        "story_7514265"
      ],
      "objectID": "7514483",
      "_highlightResult": {
        "author": {
          "value": "Totoradio",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This works until you refactor the new code, and the commented out code becomes out of sync with the production code it is supposed to mirror.\\nCommented code isn't checked by the compiler nor by the <em>static</em> code <em>analysis</em> <em>tools</em>, nor by the tests, so it can become out of sync fast and silently.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Delete your code",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.anton-pirker.at/delete-your-code/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-03-06T15:38:21.000Z",
      "title": null,
      "url": null,
      "author": "radicalbyte",
      "points": 2,
      "story_text": null,
      "comment_text": "Spot on.<p>Unit Tests aren&#x27;t there to ensure that you get the right answer.  It&#x27;s there to ensure that you&#x27;ve asked the right question.<p>Or at the very least to document the thought process of the person implementing code.<p>Use static analysis tools + code reviews to improve correctness, and unit tests to guide design + document.",
      "num_comments": null,
      "story_id": 7353767,
      "story_title": "Why Most Unit Testing is Waste [pdf]",
      "story_url": "http://www.rbcs-us.com/documents/Why-Most-Unit-Testing-is-Waste.pdf",
      "parent_id": 7354128,
      "created_at_i": 1394120301,
      "_tags": [
        "comment",
        "author_radicalbyte",
        "story_7353767"
      ],
      "objectID": "7354284",
      "_highlightResult": {
        "author": {
          "value": "radicalbyte",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Spot on.<p>Unit Tests aren't there to ensure that you get the right answer.  It's there to ensure that you've asked the right question.<p>Or at the very least to document the thought process of the person implementing code.<p>Use <em>static</em> <em>analysis</em> <em>tools</em> + code reviews to improve correctness, and unit tests to guide design + document.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Most Unit Testing is Waste [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.rbcs-us.com/documents/Why-Most-Unit-Testing-is-Waste.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-03-01T23:22:10.000Z",
      "title": null,
      "url": null,
      "author": "stusmall",
      "points": 2,
      "story_text": null,
      "comment_text": "Static code analysis tools exist in many languages even very high level, safe ones.  A lot of them are even named after lint or as a tip of the hat to it.<p>Their presence isn&#x27;t a sign of flaws of the language.  They are signs of flaws in programmers.  They give the designers the ability to extend the power of the compiler&#x27;s warnings to help catch common mistakes and tune the automated feedback to fit the needs of the project.",
      "num_comments": null,
      "story_id": 7325534,
      "story_title": "A brief history of one line fixes",
      "story_url": "http://www.tedunangst.com/flak/post/a-brief-history-of-one-line-fixes",
      "parent_id": 7326459,
      "created_at_i": 1393716130,
      "_tags": [
        "comment",
        "author_stusmall",
        "story_7325534"
      ],
      "objectID": "7326652",
      "_highlightResult": {
        "author": {
          "value": "stusmall",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<em>Static</em> code <em>analysis</em> <em>tools</em> exist in many languages even very high level, safe ones.  A lot of them are even named after lint or as a tip of the hat to it.<p>Their presence isn't a sign of flaws of the language.  They are signs of flaws in programmers.  They give the designers the ability to extend the power of the compiler's warnings to help catch common mistakes and tune the automated feedback to fit the needs of the project.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "A brief history of one line fixes",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.tedunangst.com/flak/post/a-brief-history-of-one-line-fixes",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-27T16:44:12.000Z",
      "title": null,
      "url": null,
      "author": "spiralpolitik",
      "points": 2,
      "story_text": null,
      "comment_text": "The question I have is how many Open Source projects use static analysis tools as part of their development process?<p>Given that the code is publicly available it seems likely that bad actors would be using such tools (both proprietary and open) to find exploits for each release.<p>I remember Eric Raymond blogging about using Coverity to analyze gpsd but beyond that I don&#x27;t recall any wider discussion about the issue.",
      "num_comments": null,
      "story_id": 7311879,
      "story_title": "Was the iOS SSL Flaw Deliberate?",
      "story_url": "https://www.schneier.com/blog/archives/2014/02/was_the_ios_ssl.html",
      "parent_id": 7312305,
      "created_at_i": 1393519452,
      "_tags": [
        "comment",
        "author_spiralpolitik",
        "story_7311879"
      ],
      "objectID": "7313157",
      "_highlightResult": {
        "author": {
          "value": "spiralpolitik",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The question I have is how many Open Source projects use <em>static</em> <em>analysis</em> <em>tools</em> as part of their development process?<p>Given that the code is publicly available it seems likely that bad actors would be using such <em>tools</em> (both proprietary and open) to find exploits for each release.<p>I remember Eric Raymond blogging about using Coverity to analyze gpsd but beyond that I don't recall any wider discussion about the issue.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Was the iOS SSL Flaw Deliberate?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.schneier.com/blog/archives/2014/02/was_the_ios_ssl.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-23T15:31:55.000Z",
      "title": null,
      "url": null,
      "author": "billyhoffman",
      "points": 2,
      "story_text": null,
      "comment_text": "HP&#x27;s WebInspect, a blackbox testing tool, also can find XXE&#x27;s. However, as the OP shows, XXE&#x27;s can be tricky and involve a lot of nuance to cox them out. General dynamic testing tools aren&#x27;t as good at uncovering XXE&#x27;s as static analysis tools.<p>Disclaimer: I used to work on WebInspect&#x27;s audit engines",
      "num_comments": null,
      "story_id": 7105712,
      "story_title": "How I found a Remote Code Execution bug affecting Facebook's servers",
      "story_url": "http://www.ubercomp.com/posts/2014-01-16_facebook_remote_code_execution",
      "parent_id": 7106880,
      "created_at_i": 1390491115,
      "_tags": [
        "comment",
        "author_billyhoffman",
        "story_7105712"
      ],
      "objectID": "7108744",
      "_highlightResult": {
        "author": {
          "value": "billyhoffman",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "HP's WebInspect, a blackbox testing tool, also can find XXE's. However, as the OP shows, XXE's can be tricky and involve a lot of nuance to cox them out. General dynamic testing <em>tools</em> aren't as good at uncovering XXE's as <em>static</em> <em>analysis</em> <em>tools</em>.<p>Disclaimer: I used to work on WebInspect's audit engines",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How I found a Remote Code Execution bug affecting Facebook's servers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.ubercomp.com/posts/2014-01-16_facebook_remote_code_execution",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-20T05:43:47.000Z",
      "title": null,
      "url": null,
      "author": "Mikera",
      "points": 2,
      "story_text": null,
      "comment_text": "Agree with everything you say, but it is worth noting that the insights you get from static analysis on desugared forms (which can be very large and complex!) is much harder to interpret than static analysis on the original forms.<p>So to make static analysis tools useful on macros, they really need some way to map back to the original source forms. Not all tools do this (either at all, or well) - and to the extent that they don&#x27;t it is an big impediment for static analysis.<p>Also the killer challenge: macro expansion in Clojure can depend on a mutable environment at the time of macro expansion. This makes it impossible to do reliable static analysis, unless you are able to recreate the runtime environment at the time of macro expansion in your static analysis tool, which is hard&#x2F;impossible in general.<p>This is part of the motivation for my little Kiss language experiment: with immutable environments you can keep the power of macros, but avoid the mutable environment problem. Ideally, macro expansion would be governed only by things that are provably compile-time constants (not sure how feasible this is while maintaining the dynamic flexibility of Clojure that we all love... but it&#x27;s an attractive idea at least).",
      "num_comments": null,
      "story_id": 7085682,
      "story_title": "Lisp: More is less",
      "story_url": "http://jameso.be/2014/01/19/lisp.html",
      "parent_id": 7086363,
      "created_at_i": 1390196627,
      "_tags": [
        "comment",
        "author_Mikera",
        "story_7085682"
      ],
      "objectID": "7087798",
      "_highlightResult": {
        "author": {
          "value": "Mikera",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Agree with everything you say, but it is worth noting that the insights you get from <em>static</em> <em>analysis</em> on desugared forms (which can be very large and complex!) is much harder to interpret than <em>static</em> <em>analysis</em> on the original forms.<p>So to make <em>static</em> <em>analysis</em> <em>tools</em> useful on macros, they really need some way to map back to the original source forms. Not all <em>tools</em> do this (either at all, or well) - and to the extent that they don't it is an big impediment for <em>static</em> <em>analysis.</em><p>Also the killer challenge: macro expansion in Clojure can depend on a mutable environment at the time of macro expansion. This makes it impossible to do reliable <em>static</em> <em>analysis</em>, unless you are able to recreate the runtime environment at the time of macro expansion in your <em>static</em> <em>analysis</em> tool, which is hard/impossible in general.<p>This is part of the motivation for my little Kiss language experiment: with immutable environments you can keep the power of macros, but avoid the mutable environment problem. Ideally, macro expansion would be governed only by things that are provably compile-time constants (not sure how feasible this is while maintaining the dynamic flexibility of Clojure that we all love... but it's an attractive idea at least).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lisp: More is less",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://jameso.be/2014/01/19/lisp.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-02T22:59:15.000Z",
      "title": null,
      "url": null,
      "author": "gkuan",
      "points": 2,
      "story_text": null,
      "comment_text": "HRL Laboratories - Malibu, California (No remote) - <a href\"http://www.hrl.co\" rel\"nofollo\">http:&#x2F;&#x2F;www.hrl.com</a> - Interns - works on cutting edge research as a prime on DARPA and other ARPA-style research programs and for Boeing and GM. The organization is about 400 strong, mainly consisting of engineers and researchers. My team is looking for talented developers and researchers. Experience in building development tools (i.e., compilers, static analysis tools, JIT&#x2F;VMs, and debuggers) and development tool plugins would be a huge plus. We use Haskell, C++, Java, and Matlab&#x2F;Simulink&#x2F;Stateflow.<p>Perks include:<p>- get to work with Fortune 30 owners in a medium-size company environment with small, flexible teams and a flat structure<p>- opportunities to publish and patent<p>- the office is near the Malibu Civic Center with a cafeteria facing the Pacific and the Malibu Colony area and amazing hiking trails<p>- free latte, coffee, and mocha from a fancy new coffee machine<p>Please contact me at my username at hrl dot com.",
      "num_comments": null,
      "story_id": 7002824,
      "story_title": "Ask HN: Summer internships (2014)",
      "story_url": "",
      "parent_id": 7002824,
      "created_at_i": 1388703555,
      "_tags": [
        "comment",
        "author_gkuan",
        "story_7002824"
      ],
      "objectID": "7002993",
      "_highlightResult": {
        "author": {
          "value": "gkuan",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "HRL Laboratories - Malibu, California (No remote) - <a href\"http://www.hrl.co\" rel\"nofollo\">http://www.hrl.com</a> - Interns - works on cutting edge research as a prime on DARPA and other ARPA-style research programs and for Boeing and GM. The organization is about 400 strong, mainly consisting of engineers and researchers. My team is looking for talented developers and researchers. Experience in building development <em>tools</em> (i.e., compilers, <em>static</em> <em>analysis</em> <em>tools</em>, JIT/VMs, and debuggers) and development tool plugins would be a huge plus. We use Haskell, C++, Java, and Matlab/Simulink/Stateflow.<p>Perks include:<p>- get to work with Fortune 30 owners in a medium-size company environment with small, flexible teams and a flat structure<p>- opportunities to publish and patent<p>- the office is near the Malibu Civic Center with a cafeteria facing the Pacific and the Malibu Colony area and amazing hiking trails<p>- free latte, coffee, and mocha from a fancy new coffee machine<p>Please contact me at my username at hrl dot com.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Summer internships (2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-19T17:29:12.000Z",
      "title": null,
      "url": null,
      "author": "mseepgood",
      "points": 2,
      "story_text": null,
      "comment_text": "The whole Go standard library, which is more code than just a compiler (and it even includes a complete Go AST parser as well), is developed in Go (&quot;dogfooded&quot;) and so are the documentation tools (godoc, the web site, present) and the static code analysis tools (SSA, oracle, go&#x2F;types etc.) in the go.tools repository.",
      "num_comments": null,
      "story_id": 6932026,
      "story_title": "Go 1.3+ Compiler Overhaul",
      "story_url": "https://docs.google.com/document/d/1P3BLR31VA8cvLJLfMibSuTdwTuF7WWLux71CYD0eeD8/preview?sle=true",
      "parent_id": 6934097,
      "created_at_i": 1387474152,
      "_tags": [
        "comment",
        "author_mseepgood",
        "story_6932026"
      ],
      "objectID": "6936151",
      "_highlightResult": {
        "author": {
          "value": "mseepgood",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The whole Go standard library, which is more code than just a compiler (and it even includes a complete Go AST parser as well), is developed in Go (&quot;dogfooded&quot;) and so are the documentation <em>tools</em> (godoc, the web site, present) and the <em>static</em> code <em>analysis</em> <em>tools</em> (SSA, oracle, go/types etc.) in the go.<em>tools</em> repository.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Go 1.3+ Compiler Overhaul",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://docs.google.com/document/d/1P3BLR31VA8cvLJLfMibSuTdwTuF7WWLux71CYD0eeD8/preview?sle=true",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-02T08:52:43.000Z",
      "title": null,
      "url": null,
      "author": "kodablah",
      "points": 2,
      "story_text": null,
      "comment_text": "This was discussed in the August review [1]. Basically, they found ~3500 problems, and whittled it down to ~1200 after removing just one warning about a strangely implemented macro. This is similar to many other static analysis tools (e.g. findbugs)...you have to work the ruleset for your app sometimes.<p>1 - <a href=\\\"http://www.viva64.com/en/b/0205/#ID0EV4AO\\\" rel=\\\"nofollow\\\">http:&#x2F;&#x2F;www.viva64.com&#x2F;en&#x2F;b&#x2F;0205&#x2F;#ID0EV4AO</a>",
      "num_comments": null,
      "story_id": 6831892,
      "story_title": "Trying to Sell PVS-Studio to Google, or New Bugs in Chromium",
      "story_url": "http://www.viva64.com/en/b/0225/",
      "parent_id": 6832109,
      "created_at_i": 1385974363,
      "_tags": [
        "comment",
        "author_kodablah",
        "story_6831892"
      ],
      "objectID": "6832561",
      "_highlightResult": {
        "author": {
          "value": "kodablah",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This was discussed in the August review [1]. Basically, they found ~3500 problems, and whittled it down to ~1200 after removing just one warning about a strangely implemented macro. This is similar to many other <em>static</em> <em>analysis</em> <em>tools</em> (e.g. findbugs)...you have to work the ruleset for your app sometimes.<p>1 - <a href=\\\"http://www.viva64.com/en/b/0205/#ID0EV4AO\\\" rel=\\\"nofollow\\\">http://www.viva64.com/en/b/0205/#ID0EV4AO</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Trying to Sell PVS-Studio to Google, or New Bugs in Chromium",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0225/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-10-10T15:13:38.000Z",
      "title": "",
      "url": "",
      "author": "tel",
      "points": 2,
      "story_text": null,
      "comment_text": "I&#x27;ve heard a few interesting arguments (mostly by Gilad Bracha) against type-dependent semantics, though I don&#x27;t think these arguments usually apply in this situation where you&#x27;re just talking about polymorphism in (+). The argument is that if your language doesn&#x27;t have type-dependent semantics then you can plug and play type systems as completely independent static analysis tools.<p>I don&#x27;t know that I buy that those tradeoffs are best, but there is something really interesting there.",
      "num_comments": null,
      "story_id": 6527104,
      "story_title": "Poll: What are your liked and disliked programming languages?",
      "story_url": null,
      "parent_id": 6527843,
      "created_at_i": 1381418018,
      "_tags": [
        "comment",
        "author_tel",
        "story_6527104"
      ],
      "objectID": "6528154",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "tel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I've heard a few interesting arguments (mostly by Gilad Bracha) against type-dependent semantics, though I don't think these arguments usually apply in this situation where you're just talking about polymorphism in (+). The argument is that if your language doesn't have type-dependent semantics then you can plug and play type systems as completely independent <em>static</em> <em>analysis</em> <em>tools</em>.<p>I don't know that I buy that those tradeoffs are best, but there is something really interesting there.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Poll: What are your liked and disliked programming languages?",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-25T23:49:26.000Z",
      "title": "",
      "url": "",
      "author": "nknighthb",
      "points": 2,
      "story_text": null,
      "comment_text": "The tl;dr seems to be that Mozilla&#x27;s static analysis tools have some significant issues, their review team&#x27;s apparent understanding of policies seems at odds with the understanding of at least some important Mozilla devs, and the review process itself lacks a mechanism for dialogue with the reviewers.<p>Unfortunate for a platform that&#x27;s already launched.",
      "num_comments": null,
      "story_id": 6274024,
      "story_title": "My Firefox OS app was rejected for using jQuery in a privileged app",
      "story_url": "https://jeena.net/firefox-os-app-rejected",
      "parent_id": 6274268,
      "created_at_i": 1377474566,
      "_tags": [
        "comment",
        "author_nknighthb",
        "story_6274024"
      ],
      "objectID": "6274280",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "nknighthb",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The tl;dr seems to be that Mozilla's <em>static</em> <em>analysis</em> <em>tools</em> have some significant issues, their review team's apparent understanding of policies seems at odds with the understanding of at least some important Mozilla devs, and the review process itself lacks a mechanism for dialogue with the reviewers.<p>Unfortunate for a platform that's already launched.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "My Firefox OS app was rejected for using jQuery in a privileged app",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://jeena.net/firefox-os-app-rejected",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-07T14:42:07.000Z",
      "title": "",
      "url": "",
      "author": "sdevlin",
      "points": 2,
      "story_text": null,
      "comment_text": "Your point is well taken, but I think it has value. Compile-time error checking is useful because it gives you flexibility to make changes in a big program. It&#x27;s kind of like a big suite of automatic tests that make sure all the parts of your program talk to each other correctly.<p>Does it catch everything? Can you stop thinking critically? No, but it&#x27;s still nice to have.<p>This sort of goes hand in hand with IDE tools (e.g. &quot;change method name&quot; sorts of things), so I don&#x27;t think we necessarily disagree.<p>&gt; I&#x27;ve never seen a bug in production that could have been prevented with static analysis.<p>That seems unlikely to me.<p>I do application penetration testing for a living, and I&#x27;ll often use static analysis tools in my work. (Both robust, established tools and ad hoc scripts.) For example, check out Brakeman for Rails apps. These tools find actual bugs in actual production software.<p>Do they find everything? No, you can&#x27;t rely on them completely. But they&#x27;re still nice to have.",
      "num_comments": null,
      "story_id": 6170117,
      "story_title": "Announcing TypeScript 0.9.1",
      "story_url": "http://blogs.msdn.com/b/typescript/archive/2013/08/06/announcing-0-9-1.aspx",
      "parent_id": 6172814,
      "created_at_i": 1375886527,
      "_tags": [
        "comment",
        "author_sdevlin",
        "story_6170117"
      ],
      "objectID": "6173145",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "sdevlin",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Your point is well taken, but I think it has value. Compile-time error checking is useful because it gives you flexibility to make changes in a big program. It's kind of like a big suite of automatic tests that make sure all the parts of your program talk to each other correctly.<p>Does it catch everything? Can you stop thinking critically? No, but it's still nice to have.<p>This sort of goes hand in hand with IDE <em>tools</em> (e.g. &quot;change method name&quot; sorts of things), so I don't think we necessarily disagree.<p>&gt; I've never seen a bug in production that could have been prevented with <em>static</em> <em>analysis.</em><p>That seems unlikely to me.<p>I do application penetration testing for a living, and I'll often use <em>static</em> <em>analysis</em> <em>tools</em> in my work. (Both robust, established <em>tools</em> and ad hoc scripts.) For example, check out Brakeman for Rails apps. These <em>tools</em> find actual bugs in actual production software.<p>Do they find everything? No, you can't rely on them completely. But they're still nice to have.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Announcing TypeScript 0.9.1",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.msdn.com/b/typescript/archive/2013/08/06/announcing-0-9-1.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-07-31T00:35:58.000Z",
      "title": "",
      "url": "",
      "author": "jrockway",
      "points": 2,
      "story_text": null,
      "comment_text": "It&#x27;s not particularly constructive to think of individuals as being responsible for single bugs.  Bugs are random events, and their probability increases as people and processes become complacent.<p>A good way to react to this bug is to come up with ideas for reducing the possibility of future bugs: static analysis tools, making code reviews easier, and so on.  One might also think up ways to lower the impact of future bugs; make session cookies unavailable to JavaScript, propose new standards for the web, etc.<p>It&#x27;s important to think of it from a statistical standpoint.  Given two equally skilled developers, the one that implements more features is more likely to be involved in a production incident.  If we punish people for bugs, we&#x27;re punishing productivity in addition to sloppiness.  That sets the incentives incorrectly.  It isn&#x27;t even a good idea to blame one person: if you scare one person into compliance, you still have the 29,999 other SWEs that aren&#x27;t scared into compliance.  Much better to develop tools that make bugs easier to spot, because every hour you spend doing that helps 29,999x as many people.",
      "num_comments": null,
      "story_id": 6130376,
      "story_title": "XSS in Google Finance",
      "story_url": "http://miki.it/blog/2013/7/30/xss-in-google-finance/",
      "parent_id": 6130681,
      "created_at_i": 1375230958,
      "_tags": [
        "comment",
        "author_jrockway",
        "story_6130376"
      ],
      "objectID": "6131107",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jrockway",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's not particularly constructive to think of individuals as being responsible for single bugs.  Bugs are random events, and their probability increases as people and processes become complacent.<p>A good way to react to this bug is to come up with ideas for reducing the possibility of future bugs: <em>static</em> <em>analysis</em> <em>tools</em>, making code reviews easier, and so on.  One might also think up ways to lower the impact of future bugs; make session cookies unavailable to JavaScript, propose new standards for the web, etc.<p>It's important to think of it from a statistical standpoint.  Given two equally skilled developers, the one that implements more features is more likely to be involved in a production incident.  If we punish people for bugs, we're punishing productivity in addition to sloppiness.  That sets the incentives incorrectly.  It isn't even a good idea to blame one person: if you scare one person into compliance, you still have the 29,999 other SWEs that aren't scared into compliance.  Much better to develop <em>tools</em> that make bugs easier to spot, because every hour you spend doing that helps 29,999x as many people.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "XSS in Google Finance",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://miki.it/blog/2013/7/30/xss-in-google-finance/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-07-04T14:47:03.000Z",
      "title": "",
      "url": "",
      "author": "dasil003",
      "points": 2,
      "story_text": null,
      "comment_text": "&gt; <i>Maybe I&#x27;m just too familiar with Ruby and multithreading, but I don&#x27;t understand why people have trouble with multithreaded Ruby. [...] In my opinion, the situation is not much different in Python, Java or C++.</i><p>I think the problem is a mix of language features and culture.  Ruby does not have a history good thread-safe practices, and the language has some extremely convenient features which are death for thread-safety (eg. class instance variables).  Combine that with prolific meta-programming and a lack of static analysis tools, and it can become very very difficult to be certain that a given application is thread safe.  As long as all developers are well-versed and keep thread-safety front and center from the beginning of application developer then I agree it&#x27;s not hard per se, but in practice that is so rarely the case that if I knew I needed heavy multi-threading for memory efficiency and CPU utilization I might disqualify Ruby on cultural reasons alone (and I say this as a full-time rubyist who knows no language better).",
      "num_comments": null,
      "story_id": 5990208,
      "story_title": "Puma vs Phusion Passenger",
      "story_url": "https://github.com/FooBarWidget/passenger/wiki/Puma-vs-Phusion-Passenger",
      "parent_id": 5990499,
      "created_at_i": 1372949223,
      "_tags": [
        "comment",
        "author_dasil003",
        "story_5990208"
      ],
      "objectID": "5990848",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dasil003",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; <i>Maybe I'm just too familiar with Ruby and multithreading, but I don't understand why people have trouble with multithreaded Ruby. [...] In my opinion, the situation is not much different in Python, Java or C++.</i><p>I think the problem is a mix of language features and culture.  Ruby does not have a history good thread-safe practices, and the language has some extremely convenient features which are death for thread-safety (eg. class instance variables).  Combine that with prolific meta-programming and a lack of <em>static</em> <em>analysis</em> <em>tools</em>, and it can become very very difficult to be certain that a given application is thread safe.  As long as all developers are well-versed and keep thread-safety front and center from the beginning of application developer then I agree it's not hard per se, but in practice that is so rarely the case that if I knew I needed heavy multi-threading for memory efficiency and CPU utilization I might disqualify Ruby on cultural reasons alone (and I say this as a full-time rubyist who knows no language better).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Puma vs Phusion Passenger",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/FooBarWidget/passenger/wiki/Puma-vs-Phusion-Passenger",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-06-20T12:34:06.000Z",
      "title": "",
      "url": "",
      "author": "TheAnimus",
      "points": 2,
      "story_text": null,
      "comment_text": "&gt;Sorry, but you obviously have not been taking notice over the past year or two.<p>I&#x27;ll admit, I haven&#x27;t really, because I&#x27;ll turn it round, why would I?<p>We&#x27;ve seen Erlang start to be used quite a lot, Scala is becoming very interesting, and F# is appearing suitably mainstreme.<p>What features would make me think &quot;hmm, I should check out what they are doing in PHP&quot;?<p>Looking now I still see a cluttered array of APIs, some pretending they are C from the 80s, others hinting that they at least knew of objects in their design.<p>A quick look for static analysis rule systems for say our CI system:\n<a href=\"http:&#x2F;&#x2F;mark-story.com&#x2F;posts&#x2F;view&#x2F;static-analysis-tools-for-php\" rel=\"nofollow\">http:&#x2F;&#x2F;mark-story.com&#x2F;posts&#x2F;view&#x2F;static-analysis-tools-for-p...</a><p>Wow, that&#x27;s pretty poor.<p>What I do again see, are PHP developers who are not fluent in any other language.  I always find that odd.  For instance I&#x27;ve been doing mostly C# since version 2.  But I would probably pass most Java or CamL interview questions anyone had.  I am happy in C# knowing what I am missing from other languages (well, not happy, just its the right choice for the things I&#x27;ve been doing).<p>In short, PHP has an image problem with plenty of people.  I am one of them.  They can&#x27;t easily solve it, without breaking a whole bunch of existing code, as most of my complaints are inherent languages <i>features</i> and core API design (or lack there off).  I don&#x27;t nock languages that eschew OO, but I do nock ones that implement it, just very, very badly.",
      "num_comments": null,
      "story_id": 5911053,
      "story_title": "PHP 5.5",
      "story_url": "https://github.com/php/php-src/blob/php-5.5.0/NEWS",
      "parent_id": 5911549,
      "created_at_i": 1371731646,
      "_tags": [
        "comment",
        "author_TheAnimus",
        "story_5911053"
      ],
      "objectID": "5911629",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "TheAnimus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;Sorry, but you obviously have not been taking notice over the past year or two.<p>I'll admit, I haven't really, because I'll turn it round, why would I?<p>We've seen Erlang start to be used quite a lot, Scala is becoming very interesting, and F# is appearing suitably mainstreme.<p>What features would make me think &quot;hmm, I should check out what they are doing in PHP&quot;?<p>Looking now I still see a cluttered array of APIs, some pretending they are C from the 80s, others hinting that they at least knew of objects in their design.<p>A quick look for <em>static</em> <em>analysis</em> rule systems for say our CI system:\n<a href=\"http://mark-story.com/posts/view/static-analysis-tools-for-php\" rel=\"nofollow\">http://mark-story.com/posts/view/<em>static</em>-<em>analysis</em>-<em>tools</em>-for-p...</a><p>Wow, that's pretty poor.<p>What I do again see, are PHP developers who are not fluent in any other language.  I always find that odd.  For instance I've been doing mostly C# since version 2.  But I would probably pass most Java or CamL interview questions anyone had.  I am happy in C# knowing what I am missing from other languages (well, not happy, just its the right choice for the things I've been doing).<p>In short, PHP has an image problem with plenty of people.  I am one of them.  They can't easily solve it, without breaking a whole bunch of existing code, as most of my complaints are inherent languages <i>features</i> and core API design (or lack there off).  I don't nock languages that eschew OO, but I do nock ones that implement it, just very, very badly.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "PHP 5.5",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/php/php-src/blob/php-5.5.0/NEWS",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-03-24T07:42:36.000Z",
      "title": "",
      "url": "",
      "author": "pjmlp",
      "points": 2,
      "story_text": null,
      "comment_text": "Actually I am really scared that they use C or C++ instead of something sane like Ada.<p>Unless their static analysis tools just make C or C++ look like Ada.",
      "num_comments": null,
      "story_id": 5430891,
      "story_title": "Lessons Learned Developing Software for Space Vehicles",
      "story_url": "http://lwn.net/Articles/540368/",
      "parent_id": 5431270,
      "created_at_i": 1364110956,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_5430891"
      ],
      "objectID": "5431420",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Actually I am really scared that they use C or C++ instead of something sane like Ada.<p>Unless their <em>static</em> <em>analysis</em> <em>tools</em> just make C or C++ look like Ada.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lessons Learned Developing Software for Space Vehicles",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lwn.net/Articles/540368/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-03-24T05:38:04.000Z",
      "title": "",
      "url": "",
      "author": "jacques_chester",
      "points": 2,
      "story_text": null,
      "comment_text": "A common example is the incomplete case problem (currently fixed by static analysis tools, I believe, but bear with me).<p>Suppose you have an enum:<p><pre><code>   enum rocket_states { ROCKET_WAITING, ROCKET_FLYING, ROCKET_FAULT }\n</code></pre>\nAnd a switch that runs off that enum:<p><pre><code>    switch ( some_rocket_state ) {\n      ROCKET_WAITING:\n        wait_foo();\n        wait_bar();\n        break;\n      ROCKET_FLYING:\n        fly_foo();\n        break;\n      }\n    }\n</code></pre>\nThis will compile. (Or maybe it won't, I haven't cut C for some time now).<p>But you've missed the ROCKET_FAULT case. In languages which check for case completeness, this kind of logical construction would cause a compiler failure. ML, F#, Rust etc will all complain that you haven't addressed all cases.<p>Sometimes this or something like it is added to a code template:<p><pre><code>      default: assert(false);\n</code></pre>\nWhich is defensive code that's great for test. But not as great for rockets. Better if bad code simply can't be written.<p>I believe static analysis tools can now pick up on missing cases, but there are still lots of reasons why C can't be as fully analysed as a language like ML, Haskell, ATS, Rust etc can be. Putting aside the obvious problem of undefined behaviour meaning you really want to push C code through multiple compilers and multiple static analysis tools, there's also the great universal escape hatch for C: direct memory access.<p>When you can simply go in and change memory, type systems and analysis are strictly speaking no longer going to work <i>without positive human effort to refrain from doing that</i>. Analysis can only make guarantees under certain assumptions; introduce direct memory access and all bets are off.<p>Yes, discipline and coding standards can also cut this down. Some analysis tools will do partial analysis of memory accesses. But it still requires <i>positive human action</i>. A computing system includes the humans who make it, run it and use it. Cutting down on the avenues for mistakes is a good thing.",
      "num_comments": null,
      "story_id": 5430891,
      "story_title": "Lessons Learned Developing Software for Space Vehicles",
      "story_url": "http://lwn.net/Articles/540368/",
      "parent_id": 5431215,
      "created_at_i": 1364103484,
      "_tags": [
        "comment",
        "author_jacques_chester",
        "story_5430891"
      ],
      "objectID": "5431269",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jacques_chester",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "A common example is the incomplete case problem (currently fixed by <em>static</em> <em>analysis</em> <em>tools</em>, I believe, but bear with me).<p>Suppose you have an enum:<p><pre><code>   enum rocket_states { ROCKET_WAITING, ROCKET_FLYING, ROCKET_FAULT }\n</code></pre>\nAnd a switch that runs off that enum:<p><pre><code>    switch ( some_rocket_state ) {\n      ROCKET_WAITING:\n        wait_foo();\n        wait_bar();\n        break;\n      ROCKET_FLYING:\n        fly_foo();\n        break;\n      }\n    }\n</code></pre>\nThis will compile. (Or maybe it won't, I haven't cut C for some time now).<p>But you've missed the ROCKET_FAULT case. In languages which check for case completeness, this kind of logical construction would cause a compiler failure. ML, F#, Rust etc will all complain that you haven't addressed all cases.<p>Sometimes this or something like it is added to a code template:<p><pre><code>      default: assert(false);\n</code></pre>\nWhich is defensive code that's great for test. But not as great for rockets. Better if bad code simply can't be written.<p>I believe <em>static</em> <em>analysis</em> <em>tools</em> can now pick up on missing cases, but there are still lots of reasons why C can't be as fully analysed as a language like ML, Haskell, ATS, Rust etc can be. Putting aside the obvious problem of undefined behaviour meaning you really want to push C code through multiple compilers and multiple <em>static</em> <em>analysis</em> <em>tools</em>, there's also the great universal escape hatch for C: direct memory access.<p>When you can simply go in and change memory, type systems and <em>analysis</em> are strictly speaking no longer going to work <i>without positive human effort to refrain from doing that</i>. <em>Analysis</em> can only make guarantees under certain assumptions; introduce direct memory access and all bets are off.<p>Yes, discipline and coding standards can also cut this down. Some <em>analysis</em> <em>tools</em> will do partial <em>analysis</em> of memory accesses. But it still requires <i>positive human action</i>. A computing system includes the humans who make it, run it and use it. Cutting down on the avenues for mistakes is a good thing.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lessons Learned Developing Software for Space Vehicles",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lwn.net/Articles/540368/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-02-16T08:43:03.000Z",
      "title": "",
      "url": "",
      "author": "TeeWEE",
      "points": 2,
      "story_text": null,
      "comment_text": "Why do they use strings as function using to-function\n(<a href=\"https://github.com/component/to-function\" rel=\"nofollow\">https://github.com/component/to-function</a>).\nLike .select(\"age&#62;10\").map(\"adress.streetname\");<p>While to-function is cool and your code is shorter and more readable. You must be aware that you miss<p>- static code analysis such as synax checking\n- compile time optimizations (because the AST is missing)\n- static code analysis tools\n- code coverage checking tools<p>I would recommend using real functions, or using clojurescript or coffeescript in order to get shorter code.",
      "num_comments": null,
      "story_id": 5228570,
      "story_title": "Array.js: A better array for the browser and Node.js",
      "story_url": "https://github.com/MatthewMueller/array",
      "parent_id": 5228570,
      "created_at_i": 1361004183,
      "_tags": [
        "comment",
        "author_TeeWEE",
        "story_5228570"
      ],
      "objectID": "5230905",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "TeeWEE",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Why do they use strings as function using to-function\n(<a href=\"https://github.com/component/to-function\" rel=\"nofollow\">https://github.com/component/to-function</a>).\nLike .select(\"age>10\").map(\"adress.streetname\");<p>While to-function is cool and your code is shorter and more readable. You must be aware that you miss<p>- <em>static</em> code <em>analysis</em> such as synax checking\n- compile time optimizations (because the AST is missing)\n- <em>static</em> code <em>analysis</em> <em>tools</em>\n- code coverage checking <em>tools</em><p>I would recommend using real functions, or using clojurescript or coffeescript in order to get shorter code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Array.js: A better array for the browser and Node.js",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/MatthewMueller/array",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-18T22:06:13.000Z",
      "title": "",
      "url": "",
      "author": "jrockway",
      "points": 2,
      "story_text": null,
      "comment_text": "Dart is basically Java Script.  It's not called that because some language completely unrelated to Java called itself that already :)<p>To reply to some of your points:<p>The syntax is designed to look like Java.  It's there for Java programmers, not to be the best syntax ever.  (new is important, however, because you can also create objects with const.)  Yeah, it's not Python.<p>Production and development mode are a common optimization in other languages.  Remember: type annotations in Dart cannot, by design, change the behavior of the application.  So in production mode, that part of the language spec is enforced.  Static analysis tools, etc., are free to do whatever they want, however.  I'd rather catch type errors at code review time rather than at runtime in production anyway.<p>The constructors make sense to me.  They work like Java, and there is better syntax for initializing fields (which is all I ever do in constructors anyway).<p>Ultimately, it's Java in client-side form.  Compare it to GWT, not Python or Haskell.",
      "num_comments": null,
      "story_id": 5079597,
      "story_title": "Interview with Lars Bak about Dart",
      "story_url": "http://www.theregister.co.uk/2013/01/18/google_dart_interview/",
      "parent_id": 5080178,
      "created_at_i": 1358546773,
      "_tags": [
        "comment",
        "author_jrockway",
        "story_5079597"
      ],
      "objectID": "5081340",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jrockway",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Dart is basically Java Script.  It's not called that because some language completely unrelated to Java called itself that already :)<p>To reply to some of your points:<p>The syntax is designed to look like Java.  It's there for Java programmers, not to be the best syntax ever.  (new is important, however, because you can also create objects with const.)  Yeah, it's not Python.<p>Production and development mode are a common optimization in other languages.  Remember: type annotations in Dart cannot, by design, change the behavior of the application.  So in production mode, that part of the language spec is enforced.  <em>Static</em> <em>analysis</em> <em>tools</em>, etc., are free to do whatever they want, however.  I'd rather catch type errors at code review time rather than at runtime in production anyway.<p>The constructors make sense to me.  They work like Java, and there is better syntax for initializing fields (which is all I ever do in constructors anyway).<p>Ultimately, it's Java in client-side form.  Compare it to GWT, not Python or Haskell.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Interview with Lars Bak about Dart",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.theregister.co.uk/2013/01/18/google_dart_interview/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-12-08T09:38:37.000Z",
      "title": "",
      "url": "",
      "author": "koko775",
      "points": 2,
      "story_text": null,
      "comment_text": "While I don't have personal experience with it myself, things like games lend themselves well to a limited use of OOP but also require performance-critical code and tight control over the language. With static analysis tools, I bet that C++ could be audited more comprehensive through automated tests than C could be.",
      "num_comments": null,
      "story_id": 4888762,
      "story_title": "Guido says goodbye to Google",
      "story_url": "https://plus.google.com/u/0/115212051037621986145/posts/hNV7PxgFg2J",
      "parent_id": 4891139,
      "created_at_i": 1354959517,
      "_tags": [
        "comment",
        "author_koko775",
        "story_4888762"
      ],
      "objectID": "4891249",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "koko775",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "While I don't have personal experience with it myself, things like games lend themselves well to a limited use of OOP but also require performance-critical code and tight control over the language. With <em>static</em> <em>analysis</em> <em>tools</em>, I bet that C++ could be audited more comprehensive through automated tests than C could be.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Guido says goodbye to Google",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://plus.google.com/u/0/115212051037621986145/posts/hNV7PxgFg2J",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-19T19:31:44.000Z",
      "title": "",
      "url": "",
      "author": "calpaterson",
      "points": 2,
      "story_text": null,
      "comment_text": "Code analysis is nice but stand alone static analysis tools are a lot more advanced.  Even the free ones, like FindBugs catch a lot of issues.",
      "num_comments": null,
      "story_id": 4543553,
      "story_title": "John Carmack on Static Code Analysis",
      "story_url": "http://www.altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 4544777,
      "created_at_i": 1348083104,
      "_tags": [
        "comment",
        "author_calpaterson",
        "story_4543553"
      ],
      "objectID": "4545130",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "calpaterson",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Code <em>analysis</em> is nice but stand alone <em>static</em> <em>analysis</em> <em>tools</em> are a lot more advanced.  Even the free ones, like FindBugs catch a lot of issues.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://www.altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2012-06-15T04:36:54.000Z",
      "title": "",
      "url": "",
      "author": "WTPayne",
      "points": 2,
      "story_text": null,
      "comment_text": "Better programming tools; particularly mutation-based fuzz-testing tools; code structure visualisation; statistical, nonlinear code quality metrics, structure-based code similarity metrics and similarity-based code search/suggestion; better linting &#38; static analysis tools; refactoring tools that integrate with unit tests; continuous testing tools; better documentation for existing tools.",
      "num_comments": null,
      "story_id": 4114931,
      "story_title": "Ask HN: Any interesting problems/ideas to tap into?",
      "story_url": "",
      "parent_id": 4114931,
      "created_at_i": 1339735014,
      "_tags": [
        "comment",
        "author_WTPayne",
        "story_4114931"
      ],
      "objectID": "4115020",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "WTPayne",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Better programming <em>tools</em>; particularly mutation-based fuzz-testing <em>tools</em>; code structure visualisation; statistical, nonlinear code quality metrics, structure-based code similarity metrics and similarity-based code search/suggestion; better linting & <em>static</em> <em>analysis</em> <em>tools</em>; refactoring <em>tools</em> that integrate with unit tests; continuous testing <em>tools</em>; better documentation for existing <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Any interesting problems/ideas to tap into?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-14T01:50:31.000Z",
      "title": "",
      "url": "",
      "author": "sehugg",
      "points": 2,
      "story_text": null,
      "comment_text": "I have -- and I'm not busting on Ada, quite the contrary -- I'm pointing out that many of the rules in the C++ document would not be necessary were they coding in Ada.<p>(I'm sure they use static analysis tools for C++ that enforce some of these rules, so I'll defer to someone who is more current in that world)",
      "num_comments": null,
      "story_id": 3967316,
      "story_title": "F-35 Joint Strike Fighter Coding Standard Documentation",
      "story_url": "http://www2.research.att.com/~bs/JSF-AV-rules.pdf",
      "parent_id": 3968831,
      "created_at_i": 1336960231,
      "_tags": [
        "comment",
        "author_sehugg",
        "story_3967316"
      ],
      "objectID": "3969059",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "sehugg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I have -- and I'm not busting on Ada, quite the contrary -- I'm pointing out that many of the rules in the C++ document would not be necessary were they coding in Ada.<p>(I'm sure they use <em>static</em> <em>analysis</em> <em>tools</em> for C++ that enforce some of these rules, so I'll defer to someone who is more current in that world)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "F-35 Joint Strike Fighter Coding Standard Documentation",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www2.research.att.com/~bs/JSF-AV-rules.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-04-23T08:07:00.000Z",
      "title": "",
      "url": "",
      "author": "sparkie",
      "points": 2,
      "story_text": null,
      "comment_text": "The feature those languages are missing in order to do actors correctly, is enforced isolation of state. While you can emulate actors and message passing in nearly any language, you need this guarantee so that any actor can be executed anywhere at any time, without worrying that it is going to cause a race condition or hit a mutex somewhere. The big sin in Java and C++ which makes them quite unsuitable is \"static\"<p>It might be possible to achieve that isolation if you stick to strict coding practices, but the point where it's going to fail is when you import another library, written by someone else.<p>Because C++, Java and many other languages (including F#, Scala and others which have message passing libraries) do not have the enforced isolation of state, nor the ability to add notation to indicate that some piece of code is free of side effects (including all of it's dependencies), you're always going to have the risk of breakage when importing a library. The only way you can be sure that a library is actor-safe is to read it's source code - and if the source code is not available, then you're out of luck.<p>Java and C++ could have the potential to do actors correctly by adding the notation for side-effect-free code, using custom annotations/attributes on all functions which are actor-safe, and using some compiler extension or static analysis tools to prove correctness. I'm not aware of anything that does this for the mentioned languages though.<p>On the other hand, if you implement message passing in any purely functional programming language, your actors are automatically safe for free.",
      "num_comments": null,
      "story_id": 3875816,
      "story_title": "Why Erlang? ",
      "story_url": "http://smyck.net/2012/04/22/why-erlang/",
      "parent_id": 3876191,
      "created_at_i": 1335168420,
      "_tags": [
        "comment",
        "author_sparkie",
        "story_3875816"
      ],
      "objectID": "3877817",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "sparkie",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The feature those languages are missing in order to do actors correctly, is enforced isolation of state. While you can emulate actors and message passing in nearly any language, you need this guarantee so that any actor can be executed anywhere at any time, without worrying that it is going to cause a race condition or hit a mutex somewhere. The big sin in Java and C++ which makes them quite unsuitable is \"<em>static</em>\"<p>It might be possible to achieve that isolation if you stick to strict coding practices, but the point where it's going to fail is when you import another library, written by someone else.<p>Because C++, Java and many other languages (including F#, Scala and others which have message passing libraries) do not have the enforced isolation of state, nor the ability to add notation to indicate that some piece of code is free of side effects (including all of it's dependencies), you're always going to have the risk of breakage when importing a library. The only way you can be sure that a library is actor-safe is to read it's source code - and if the source code is not available, then you're out of luck.<p>Java and C++ could have the potential to do actors correctly by adding the notation for side-effect-free code, using custom annotations/attributes on all functions which are actor-safe, and using some compiler extension or <em>static</em> <em>analysis</em> <em>tools</em> to prove correctness. I'm not aware of anything that does this for the mentioned languages though.<p>On the other hand, if you implement message passing in any purely functional programming language, your actors are automatically safe for free.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Erlang? ",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://smyck.net/2012/04/22/why-erlang/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T07:24:26.000Z",
      "title": null,
      "url": null,
      "author": "pnathan",
      "points": 2,
      "story_text": null,
      "comment_text": "I really look forward to seeing what Haskell (&#38; friends) will be getting us in the coming years with its static analysis suite and all-errors-checked mentality.  I am hopeful that the static analysis toolsets developed in pure languages will be making their way down to the dynamic languages, leading to an overall code improvement for new code.",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388290,
      "created_at_i": 1324711466,
      "_tags": [
        "comment",
        "author_pnathan",
        "story_3388290"
      ],
      "objectID": "3388441",
      "_highlightResult": {
        "author": {
          "value": "pnathan",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I really look forward to seeing what Haskell (& friends) will be getting us in the coming years with its <em>static</em> <em>analysis</em> suite and all-errors-checked mentality.  I am hopeful that the <em>static</em> <em>analysis</em> <em>tools</em>ets developed in pure languages will be making their way down to the dynamic languages, leading to an overall code improvement for new code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2011-08-23T18:21:06.000Z",
      "title": null,
      "url": null,
      "author": "babar",
      "points": 2,
      "story_text": null,
      "comment_text": "Can you give some more detail about what your process was for determining code quality? Just getting people to get a checkout and read through it? Running static analysis tools? Examining commit histories?",
      "num_comments": null,
      "story_id": 2916102,
      "story_title": "The Due Diligence Survival Guide",
      "story_url": "http://www.jacquesmattheij.com/Due+Diligence+survival+guide",
      "parent_id": 2916918,
      "created_at_i": 1314123666,
      "_tags": [
        "comment",
        "author_babar",
        "story_2916102"
      ],
      "objectID": "2917697",
      "_highlightResult": {
        "author": {
          "value": "babar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Can you give some more detail about what your process was for determining code quality? Just getting people to get a checkout and read through it? Running <em>static</em> <em>analysis</em> <em>tools</em>? Examining commit histories?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Due Diligence Survival Guide",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.jacquesmattheij.com/Due+Diligence+survival+guide",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-08-01T16:53:03.000Z",
      "title": "",
      "url": "",
      "author": "stock_toaster",
      "points": 2,
      "story_text": null,
      "comment_text": "<p><pre><code>    &#62; On the other hand, many people seem to come out and say that Ruby is _very_ slow. \n    &#62; Is it heaven-and-earth slow?\n</code></pre>\nComparatively, I would say yes. Granted, most of the time it won't matter because you are waiting on IO (disk/network), but if you are doing cpu intensive work, it is slow and you probably need to drop down to C or offload that work to another service.<p><pre><code>    &#62; How is Erlang more scalable than Java? In what area? horizontal vs vertical scaling?\n    &#62; developer's productivity (or team performance) scale? performance? speed? Erlang seems \n    &#62; to excel in a niche area (in a positive speaking).\n</code></pre>\nMy guess would be in single server scalability. Erlang's write-once variables and actor model, combined with a good VM (\"green processes\") make it very single-server-scalable (verticle). It also has good built in node-to-node communication mechanisms (horizontal). Performance is probably slower than Java though. And I imagine the developer pool is much more limited than that of Java.<p><pre><code>    &#62; What about Haskell/Ada, how are they safer than Java? \n    &#62; Do they have better type-systems? handles NULL better than Java? \n    &#62; Bulletproof from developers? detect more bugs?\n</code></pre>\nI meant safer in the type-safety sense, yes. There are also classes of static analysis tools for both. Granted, my knowledge of these languages is quite limited.<p>I certainly see your points (especially about liking the code hygiene of python), and agree that Java is not going anywhere soon. I guess I don't understand why a startup, or individual developer, would choose Java over other languages, even other languages on the JVM, for new projects.<p>Thanks for the good discussion. :)",
      "num_comments": null,
      "story_id": 2825689,
      "story_title": "Twitter: From Ruby on Rails to the JVM [video]",
      "story_url": "http://ontwik.com/rails/oreilly-oscon-java-2011-raffi-krikorian-twitter-from-ruby-on-rails-to-the-jvm/",
      "parent_id": 2830987,
      "created_at_i": 1312217583,
      "_tags": [
        "comment",
        "author_stock_toaster",
        "story_2825689"
      ],
      "objectID": "2833162",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "stock_toaster",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<p><pre><code>    > On the other hand, many people seem to come out and say that Ruby is _very_ slow. \n    > Is it heaven-and-earth slow?\n</code></pre>\nComparatively, I would say yes. Granted, most of the time it won't matter because you are waiting on IO (disk/network), but if you are doing cpu intensive work, it is slow and you probably need to drop down to C or offload that work to another service.<p><pre><code>    > How is Erlang more scalable than Java? In what area? horizontal vs vertical scaling?\n    > developer's productivity (or team performance) scale? performance? speed? Erlang seems \n    > to excel in a niche area (in a positive speaking).\n</code></pre>\nMy guess would be in single server scalability. Erlang's write-once variables and actor model, combined with a good VM (\"green processes\") make it very single-server-scalable (verticle). It also has good built in node-to-node communication mechanisms (horizontal). Performance is probably slower than Java though. And I imagine the developer pool is much more limited than that of Java.<p><pre><code>    > What about Haskell/Ada, how are they safer than Java? \n    > Do they have better type-systems? handles NULL better than Java? \n    > Bulletproof from developers? detect more bugs?\n</code></pre>\nI meant safer in the type-safety sense, yes. There are also classes of <em>static</em> <em>analysis</em> <em>tools</em> for both. Granted, my knowledge of these languages is quite limited.<p>I certainly see your points (especially about liking the code hygiene of python), and agree that Java is not going anywhere soon. I guess I don't understand why a startup, or individual developer, would choose Java over other languages, even other languages on the JVM, for new projects.<p>Thanks for the good discussion. :)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Twitter: From Ruby on Rails to the JVM [video]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ontwik.com/rails/oreilly-oscon-java-2011-raffi-krikorian-twitter-from-ruby-on-rails-to-the-jvm/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-27T11:26:29.000Z",
      "title": null,
      "url": null,
      "author": "d2p",
      "points": 1,
      "story_text": null,
      "comment_text": "Not really; I was highlighting that every editor is not going to add support for every new javascript framework&#x27;s proprietary implementations. There are tons of tools out there for JavaScript that you can run on any plain JavaScript, and almost none for all these syntaxes.<p>I don&#x27;t just mean code-completion and debugging, but things like validators&#x2F;linters and other static analysis tools; code coverage, formatting, refactoring.<p>It&#x27;s not a good use of time for every IDE to try and implement every one of these for every crazy JS framework.<p>If we stick to using languages as they&#x27;re intended (and defined), we&#x27;d have full coverage for these tools.",
      "num_comments": null,
      "story_id": 8222760,
      "story_title": "You have ruined HTML",
      "story_url": "http://blog.dantup.com/2014/08/you-have-ruined-html/",
      "parent_id": 8223811,
      "created_at_i": 1409138789,
      "_tags": [
        "comment",
        "author_d2p",
        "story_8222760"
      ],
      "objectID": "8231607",
      "_highlightResult": {
        "author": {
          "value": "d2p",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Not really; I was highlighting that every editor is not going to add support for every new javascript framework's proprietary implementations. There are tons of <em>tools</em> out there for JavaScript that you can run on any plain JavaScript, and almost none for all these syntaxes.<p>I don't just mean code-completion and debugging, but things like validators/linters and other <em>static</em> <em>analysis</em> <em>tools</em>; code coverage, formatting, refactoring.<p>It's not a good use of time for every IDE to try and implement every one of these for every crazy JS framework.<p>If we stick to using languages as they're intended (and defined), we'd have full coverage for these <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "You have ruined HTML",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.dantup.com/2014/08/you-have-ruined-html/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-28T08:31:07.000Z",
      "title": null,
      "url": null,
      "author": "fabriceleal",
      "points": 1,
      "story_text": null,
      "comment_text": "Personally I would be a lot more interested in a good platform for writing static analysis tools. I believe the community in general would take a more immediate benefit (and what a benefit!...) from this than from a lone PHP to Go transpiler.",
      "num_comments": null,
      "story_id": 8093753,
      "story_title": "Parsing PHP in Go",
      "story_url": "https://stephensearles.com/?p=288",
      "parent_id": 8093753,
      "created_at_i": 1406536267,
      "_tags": [
        "comment",
        "author_fabriceleal",
        "story_8093753"
      ],
      "objectID": "8095713",
      "_highlightResult": {
        "author": {
          "value": "fabriceleal",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Personally I would be a lot more interested in a good platform for writing <em>static</em> <em>analysis</em> <em>tools</em>. I believe the community in general would take a more immediate benefit (and what a benefit!...) from this than from a lone PHP to Go transpiler.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Parsing PHP in Go",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://stephensearles.com/?p=288",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-08T23:43:35.000Z",
      "title": null,
      "url": null,
      "author": "taeric",
      "points": 1,
      "story_text": null,
      "comment_text": "My main hypothesis, which I of course never said, is that current static analysis tools should be able to catch the majority of these cases anyway.  Especially the ones that matter.<p>That is, a type system is not the only tool we have in static analysis.  So, I&#x27;m not completely convinced that moving to a type system is the best way to go.<p>Granted, it large part, it is clear it doesn&#x27;t matter &quot;what I think.&quot;  Statically typed languages have a massive amount of support.",
      "num_comments": null,
      "story_id": 8005156,
      "story_title": "Option and Null in Dynamic Languages",
      "story_url": "http://www.rntz.net/post/2014-07-02-option-in-dynlangs.html",
      "parent_id": 8007015,
      "created_at_i": 1404863015,
      "_tags": [
        "comment",
        "author_taeric",
        "story_8005156"
      ],
      "objectID": "8007352",
      "_highlightResult": {
        "author": {
          "value": "taeric",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "My main hypothesis, which I of course never said, is that current <em>static</em> <em>analysis</em> <em>tools</em> should be able to catch the majority of these cases anyway.  Especially the ones that matter.<p>That is, a type system is not the only tool we have in <em>static</em> <em>analysis.</em>  So, I'm not completely convinced that moving to a type system is the best way to go.<p>Granted, it large part, it is clear it doesn't matter &quot;what I think.&quot;  Statically typed languages have a massive amount of support.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Option and Null in Dynamic Languages",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.rntz.net/post/2014-07-02-option-in-dynlangs.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-05-03T03:24:29.000Z",
      "title": null,
      "url": null,
      "author": "sigterm",
      "points": 1,
      "story_text": null,
      "comment_text": "I just want to point out that nowadays people don&#x27;t usually catch timing issues in digital designs with simulation. It&#x27;s mostly done by static timing analysis tools such as PrimeTime, which is much more accurate, efficient, and thorough than running logic simulations with annotated delays.",
      "num_comments": null,
      "story_id": 7688700,
      "story_title": "The bug that hides from breakpoints",
      "story_url": "http://drewdevault.com/2014/02/02/The-worst-bugs.html",
      "parent_id": 7689294,
      "created_at_i": 1399087469,
      "_tags": [
        "comment",
        "author_sigterm",
        "story_7688700"
      ],
      "objectID": "7689431",
      "_highlightResult": {
        "author": {
          "value": "sigterm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I just want to point out that nowadays people don't usually catch timing issues in digital designs with simulation. It's mostly done by <em>static</em> timing <em>analysis</em> <em>tools</em> such as PrimeTime, which is much more accurate, efficient, and thorough than running logic simulations with annotated delays.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The bug that hides from breakpoints",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://drewdevault.com/2014/02/02/The-worst-bugs.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-21T14:41:36.000Z",
      "title": null,
      "url": null,
      "author": "jeffreyrogers",
      "points": 1,
      "story_text": null,
      "comment_text": "If my understanding of model checking is correct (which I believe is the primary method of formal verification) I don&#x27;t think this would help much in the case of Heartbleed. The Heartbleed error had to do with an expression being in the wrong scope if I recall correctly. (I think someone forgot to put brackets around an if statement that contained two expressions).<p>In this case the model would be correct, but the implementation would be wrong. So I don&#x27;t think formal verification would be of much help. That said, I think there are a number of static analysis tools that would pick up on the error, so a combination of approaches would work.<p>And of course, it would be great if we could verify that our security critical code was sound in theory, even if we can&#x27;t necessarily verify that our implementation is free of coding errors, so I agree with your main argument. Of course, whether we&#x27;re at the point where doing this verification is feasible in practice is another matter unto itself.",
      "num_comments": null,
      "story_id": 7618406,
      "story_title": "The Case for Formal Verification (2013)",
      "story_url": "http://permalink.gmane.org/gmane.comp.encryption.general/14818",
      "parent_id": 7620284,
      "created_at_i": 1398091296,
      "_tags": [
        "comment",
        "author_jeffreyrogers",
        "story_7618406"
      ],
      "objectID": "7621243",
      "_highlightResult": {
        "author": {
          "value": "jeffreyrogers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "If my understanding of model checking is correct (which I believe is the primary method of formal verification) I don't think this would help much in the case of Heartbleed. The Heartbleed error had to do with an expression being in the wrong scope if I recall correctly. (I think someone forgot to put brackets around an if statement that contained two expressions).<p>In this case the model would be correct, but the implementation would be wrong. So I don't think formal verification would be of much help. That said, I think there are a number of <em>static</em> <em>analysis</em> <em>tools</em> that would pick up on the error, so a combination of approaches would work.<p>And of course, it would be great if we could verify that our security critical code was sound in theory, even if we can't necessarily verify that our implementation is free of coding errors, so I agree with your main argument. Of course, whether we're at the point where doing this verification is feasible in practice is another matter unto itself.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Case for Formal Verification (2013)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://permalink.gmane.org/gmane.comp.encryption.general/14818",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-11T18:57:28.000Z",
      "title": null,
      "url": null,
      "author": "humanrebar",
      "points": 1,
      "story_text": null,
      "comment_text": "Inevitably, that is what is attempted. But it doesn&#x27;t solve the use cases I mentioned.<p>To take a diff for example, not only do you need to illustrate the diff version of (I drew a new line from here to here and made this other box green), you would also need to illustrate patches to textual details and how they related to the graphical code.<p>Maybe I can imagine a solution that could do that (at great expense). I cannot imagine the language being friendly enough that third-party compilers, IDEs, or static-analysis tools would be feasible.",
      "num_comments": null,
      "story_id": 7565153,
      "story_title": "Programming paradigms that change how you think about coding",
      "story_url": "http://brikis98.blogspot.com/2014/04/six-programming-paradigms-that-will.html",
      "parent_id": 7571502,
      "created_at_i": 1397242648,
      "_tags": [
        "comment",
        "author_humanrebar",
        "story_7565153"
      ],
      "objectID": "7574744",
      "_highlightResult": {
        "author": {
          "value": "humanrebar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Inevitably, that is what is attempted. But it doesn't solve the use cases I mentioned.<p>To take a diff for example, not only do you need to illustrate the diff version of (I drew a new line from here to here and made this other box green), you would also need to illustrate patches to textual details and how they related to the graphical code.<p>Maybe I can imagine a solution that could do that (at great expense). I cannot imagine the language being friendly enough that third-party compilers, IDEs, or <em>static</em>-<em>analysis</em> <em>tools</em> would be feasible.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Programming paradigms that change how you think about coding",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://brikis98.blogspot.com/2014/04/six-programming-paradigms-that-will.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T16:35:33.000Z",
      "title": null,
      "url": null,
      "author": "ajanuary",
      "points": 1,
      "story_text": null,
      "comment_text": "I absolutely agree it would be beneficial for static analysis tools to regularly be run on openssl.<p>My stance (which I made clearer elsewhere in the thread) is more along the lines of: if it&#x27;s not being done by the core maintainers, but just by concerned third parties, it&#x27;s very easy to lose the signal in noise you don&#x27;t have the ability to refactor away (because of time, difficulty getting it merged upstream etc.)<p>So I&#x27;m not surprised that given the context it was missed by people running static analysis over it. That context is wrong, and it should have changed a long time ago, but under that context I can see it getting missed [1].<p>[1] By interpreting static analysis results, not necessarily by the code author and reviewer.",
      "num_comments": null,
      "story_id": 7565764,
      "story_title": "'Heartbleed' contributor denies he inserted it deliberately",
      "story_url": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
      "parent_id": 7567301,
      "created_at_i": 1397147733,
      "_tags": [
        "comment",
        "author_ajanuary",
        "story_7565764"
      ],
      "objectID": "7567628",
      "_highlightResult": {
        "author": {
          "value": "ajanuary",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I absolutely agree it would be beneficial for <em>static</em> <em>analysis</em> <em>tools</em> to regularly be run on openssl.<p>My stance (which I made clearer elsewhere in the thread) is more along the lines of: if it's not being done by the core maintainers, but just by concerned third parties, it's very easy to lose the signal in noise you don't have the ability to refactor away (because of time, difficulty getting it merged upstream etc.)<p>So I'm not surprised that given the context it was missed by people running <em>static</em> <em>analysis</em> over it. That context is wrong, and it should have changed a long time ago, but under that context I can see it getting missed [1].<p>[1] By interpreting <em>static</em> <em>analysis</em> results, not necessarily by the code author and reviewer.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "'Heartbleed' contributor denies he inserted it deliberately",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T15:32:58.000Z",
      "title": null,
      "url": null,
      "author": "ajanuary",
      "points": 1,
      "story_text": null,
      "comment_text": "From my experience with static analysis tools it&#x27;s very easy to write perfectly valid code that the tool doesn&#x27;t like, so it wouldn&#x27;t surprise me too much.<p>Of course, the argument can often be made that if it isn&#x27;t clear enough for the tool to find, it&#x27;s not clear enough for a person to understand quickly.",
      "num_comments": null,
      "story_id": 7565764,
      "story_title": "'Heartbleed' contributor denies he inserted it deliberately",
      "story_url": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
      "parent_id": 7566855,
      "created_at_i": 1397143978,
      "_tags": [
        "comment",
        "author_ajanuary",
        "story_7565764"
      ],
      "objectID": "7567026",
      "_highlightResult": {
        "author": {
          "value": "ajanuary",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "From my experience with <em>static</em> <em>analysis</em> <em>tools</em> it's very easy to write perfectly valid code that the tool doesn't like, so it wouldn't surprise me too much.<p>Of course, the argument can often be made that if it isn't clear enough for the tool to find, it's not clear enough for a person to understand quickly.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "'Heartbleed' contributor denies he inserted it deliberately",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T10:41:14.000Z",
      "title": null,
      "url": null,
      "author": "ProblemFactory",
      "points": 1,
      "story_text": null,
      "comment_text": "The Heartbleed bug was a C buffer overflow. Entirely unrelated to the heartbeat feature, its spec, or the functionality of SSL as a whole. It had serious impact because was in a popular network-accessible library - something similar could also happen in the Linux TCP stack, in a popular web or database server, or any other network-accessible C program.<p>But something that seems just wrong is the expectation that &quot;someone else&quot; (the small all-volunteer OpenSSL team) should have taken more time away from their day jobs and family to: have different people writing specs and implementation, writing more tests, running static analysis tools, have code more reviews, and refactored code to be more readable. But if OpenSSL is so critical to your privacy, security and business, where were your contributions to writing those tests and code reviews?<p>I don&#x27;t mean that every developer must contribute code to be allowed to have an opinion - but most of the lamentation at &quot;what the OpenSSL team should have done&quot; never considers who exactly should be spending time or money on this extra effort.",
      "num_comments": null,
      "story_id": 7558394,
      "story_title": "RFC 6520 and the OpenSSL Heartbleed bug share the same author",
      "story_url": "",
      "parent_id": 7558394,
      "created_at_i": 1397126474,
      "_tags": [
        "comment",
        "author_ProblemFactory",
        "story_7558394"
      ],
      "objectID": "7565138",
      "_highlightResult": {
        "author": {
          "value": "ProblemFactory",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The Heartbleed bug was a C buffer overflow. Entirely unrelated to the heartbeat feature, its spec, or the functionality of SSL as a whole. It had serious impact because was in a popular network-accessible library - something similar could also happen in the Linux TCP stack, in a popular web or database server, or any other network-accessible C program.<p>But something that seems just wrong is the expectation that &quot;someone else&quot; (the small all-volunteer OpenSSL team) should have taken more time away from their day jobs and family to: have different people writing specs and implementation, writing more tests, running <em>static</em> <em>analysis</em> <em>tools</em>, have code more reviews, and refactored code to be more readable. But if OpenSSL is so critical to your privacy, security and business, where were your contributions to writing those tests and code reviews?<p>I don't mean that every developer must contribute code to be allowed to have an opinion - but most of the lamentation at &quot;what the OpenSSL team should have done&quot; never considers who exactly should be spending time or money on this extra effort.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "RFC 6520 and the OpenSSL Heartbleed bug share the same author",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-22T21:06:28.000Z",
      "title": null,
      "url": null,
      "author": "Someone",
      "points": 1,
      "story_text": null,
      "comment_text": "Oops. I was doing this from an iPad, and iOS Safari is extremely bad at rendering source code (it&#x27;s plain text, so it wraps it. It also chooses an incredibly large font size, so lines wrap at 50 characters or so in portrait mode. That made me bail out early, after reading this and not spotting the SRVR = SERVER abbreviation:<p><pre><code>    clientRandom.data = ctx-&gt;clientRandom;\\n    clientRandom.length = SSL_CLIENT_SRVR_RAND_SIZE;\\n    serverRandom.data = ctx-&gt;serverRandom;\\n    serverRandom.length = SSL_CLIENT_SRVR_RAND_SIZE;\\n</code></pre>\\nThat is something that I think static analysis tools could signal. It would be a red herring, though.",
      "num_comments": null,
      "story_id": 7279261,
      "story_title": "About the security content of iOS 7.0.6",
      "story_url": "http://support.apple.com/kb/HT6147",
      "parent_id": 7281566,
      "created_at_i": 1393103188,
      "_tags": [
        "comment",
        "author_Someone",
        "story_7279261"
      ],
      "objectID": "7283591",
      "_highlightResult": {
        "author": {
          "value": "Someone",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Oops. I was doing this from an iPad, and iOS Safari is extremely bad at rendering source code (it's plain text, so it wraps it. It also chooses an incredibly large font size, so lines wrap at 50 characters or so in portrait mode. That made me bail out early, after reading this and not spotting the SRVR = SERVER abbreviation:<p><pre><code>    clientRandom.data = ctx-&gt;clientRandom;\\n    clientRandom.length = SSL_CLIENT_SRVR_RAND_SIZE;\\n    serverRandom.data = ctx-&gt;serverRandom;\\n    serverRandom.length = SSL_CLIENT_SRVR_RAND_SIZE;\\n</code></pre>\\nThat is something that I think <em>static</em> <em>analysis</em> <em>tools</em> could signal. It would be a red herring, though.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "About the security content of iOS 7.0.6",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://support.apple.com/kb/HT6147",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-14T20:05:51.000Z",
      "title": null,
      "url": null,
      "author": "pjmlp",
      "points": 1,
      "story_text": null,
      "comment_text": "The problem is that in the early days Ada compilers were more expensive than C and C++ static analysis tools. :(<p>Nowadays we have cheaper options, but the harm is done.<p>However, from what I can infer from last years of FOSDEM, at least in Europe, Ada use seems to be slowly rising.",
      "num_comments": null,
      "story_id": 7238009,
      "story_title": "CppCat, an Ambitious C++ Code Analyzer from Tula",
      "story_url": "http://www.viva64.com/en/b/0232/",
      "parent_id": 7239853,
      "created_at_i": 1392408351,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_7238009"
      ],
      "objectID": "7240684",
      "_highlightResult": {
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The problem is that in the early days Ada compilers were more expensive than C and C++ <em>static</em> <em>analysis</em> <em>tools</em>. :(<p>Nowadays we have cheaper options, but the harm is done.<p>However, from what I can infer from last years of FOSDEM, at least in Europe, Ada use seems to be slowly rising.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "CppCat, an Ambitious C++ Code Analyzer from Tula",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0232/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-14T17:51:47.000Z",
      "title": null,
      "url": null,
      "author": "sehugg",
      "points": 1,
      "story_text": null,
      "comment_text": "One group that <i>should</i> be willing to pay for it are those writing high-reliability and safety-critical code, e.g. DoD. It appears they have less of a preference for Ada nowadays, instead using a &quot;safer&quot; subset of C++ and static analysis tools.",
      "num_comments": null,
      "story_id": 7238009,
      "story_title": "CppCat, an Ambitious C++ Code Analyzer from Tula",
      "story_url": "http://www.viva64.com/en/b/0232/",
      "parent_id": 7238403,
      "created_at_i": 1392400307,
      "_tags": [
        "comment",
        "author_sehugg",
        "story_7238009"
      ],
      "objectID": "7239853",
      "_highlightResult": {
        "author": {
          "value": "sehugg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "One group that <i>should</i> be willing to pay for it are those writing high-reliability and safety-critical code, e.g. DoD. It appears they have less of a preference for Ada nowadays, instead using a &quot;safer&quot; subset of C++ and <em>static</em> <em>analysis</em> <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "CppCat, an Ambitious C++ Code Analyzer from Tula",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0232/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-19T23:01:55.000Z",
      "title": null,
      "url": null,
      "author": "Myk267",
      "points": 1,
      "story_text": null,
      "comment_text": "&quot;Part of it is due to the very strict Python standard of coding.&quot;<p>I don&#x27;t know about that. Good code is good code. It&#x27;s sort of one of those, &quot;I&#x27;ll know it when I see it&quot; things.<p>The ease of which you can code classes for the sake of classes in Python can make some really hairy code out of what should be simple programs. Was that necessarily the &#x27;one right way to do it&#x27;? Who&#x27;s to say. And all the static analysis tools and syntactic aren&#x27;t going to undo those hairballs anytime soon.<p>You might just feel more comfortable with languages with lower code density. &#x27;brandonbloom made a good blog about that[1]. I think it can be doubly applied to any situation where meta-programming is employed.<p>1: <a href=\"http://www.brandonbloom.name/blog/2013/06/24/code-density/\" rel=\"nofollow\">http:&#x2F;&#x2F;www.brandonbloom.name&#x2F;blog&#x2F;2013&#x2F;06&#x2F;24&#x2F;code-density&#x2F;</a>",
      "num_comments": null,
      "story_id": 7085682,
      "story_title": "Lisp: More is less",
      "story_url": "http://jameso.be/2014/01/19/lisp.html",
      "parent_id": 7086135,
      "created_at_i": 1390172515,
      "_tags": [
        "comment",
        "author_Myk267",
        "story_7085682"
      ],
      "objectID": "7086461",
      "_highlightResult": {
        "author": {
          "value": "Myk267",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&quot;Part of it is due to the very strict Python standard of coding.&quot;<p>I don't know about that. Good code is good code. It's sort of one of those, &quot;I'll know it when I see it&quot; things.<p>The ease of which you can code classes for the sake of classes in Python can make some really hairy code out of what should be simple programs. Was that necessarily the 'one right way to do it'? Who's to say. And all the <em>static</em> <em>analysis</em> <em>tools</em> and syntactic aren't going to undo those hairballs anytime soon.<p>You might just feel more comfortable with languages with lower code density. 'brandonbloom made a good blog about that[1]. I think it can be doubly applied to any situation where meta-programming is employed.<p>1: <a href=\"http://www.brandonbloom.name/blog/2013/06/24/code-density/\" rel=\"nofollow\">http://www.brandonbloom.name/blog/2013/06/24/code-density/</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lisp: More is less",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://jameso.be/2014/01/19/lisp.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-09T00:17:48.000Z",
      "title": null,
      "url": null,
      "author": "facorreia",
      "points": 1,
      "story_text": null,
      "comment_text": "I find it very interesting how static analysis tools can find bugs on even the most stable and audited code bases. The analysis of PostgreSQL earlier this year[1] comes to mind.<p>I&#x27;ll make sure to include static code analysis as part of my build workflow for my current project.<p>[1] <a href=\"https://news.ycombinator.com/item?id=6962475\" rel=\"nofollow\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=6962475</a>",
      "num_comments": null,
      "story_id": 7027690,
      "story_title": "Every X11 server release since 1991 may be rootable by buffer overflow",
      "story_url": "http://lists.x.org/archives/xorg-announce/2014-January/002389.html",
      "parent_id": 7027690,
      "created_at_i": 1389226668,
      "_tags": [
        "comment",
        "author_facorreia",
        "story_7027690"
      ],
      "objectID": "7027872",
      "_highlightResult": {
        "author": {
          "value": "facorreia",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I find it very interesting how <em>static</em> <em>analysis</em> <em>tools</em> can find bugs on even the most stable and audited code bases. The <em>analysis</em> of PostgreSQL earlier this year[1] comes to mind.<p>I'll make sure to include <em>static</em> code <em>analysis</em> as part of my build workflow for my current project.<p>[1] <a href=\"https://news.ycombinator.com/item?id=6962475\" rel=\"nofollow\">https://news.ycombinator.com/item?id=6962475</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Every X11 server release since 1991 may be rootable by buffer overflow",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lists.x.org/archives/xorg-announce/2014-January/002389.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-02T23:01:33.000Z",
      "title": null,
      "url": null,
      "author": "gkuan",
      "points": 1,
      "story_text": null,
      "comment_text": "HRL Laboratories - Malibu, California (No remote) - <a href\"http://www.hrl.co\" rel\"nofollo\">http:&#x2F;&#x2F;www.hrl.com</a> - Contract and Interns - works on cutting edge research as a prime on DARPA and other ARPA-style research programs and for Boeing and GM. The organization is about 400 strong, mainly consisting of engineers and researchers. My team is looking for talented developers and researchers. Experience in building development tools (i.e., compilers, static analysis tools, JIT&#x2F;VMs, and debuggers) and development tool plugins would be a huge plus. We use Haskell, C++, Java, and Matlab&#x2F;Simulink&#x2F;Stateflow.<p>Perks include:<p>- get to work with Fortune 30 owners in a medium-size company environment with small, flexible teams and a flat structure<p>- opportunities to publish and patent<p>- the office is near the Malibu Civic Center with a cafeteria facing the Pacific and the Malibu Colony area and amazing hiking trails<p>- free latte, coffee, and mocha from a fancy new coffee machine<p>Please contact me at my username at hrl dot com.",
      "num_comments": null,
      "story_id": 6995020,
      "story_title": "Ask HN: Who is hiring? (January 2014)",
      "story_url": "",
      "parent_id": 6995020,
      "created_at_i": 1388703693,
      "_tags": [
        "comment",
        "author_gkuan",
        "story_6995020"
      ],
      "objectID": "7003007",
      "_highlightResult": {
        "author": {
          "value": "gkuan",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "HRL Laboratories - Malibu, California (No remote) - <a href\"http://www.hrl.co\" rel\"nofollo\">http://www.hrl.com</a> - Contract and Interns - works on cutting edge research as a prime on DARPA and other ARPA-style research programs and for Boeing and GM. The organization is about 400 strong, mainly consisting of engineers and researchers. My team is looking for talented developers and researchers. Experience in building development <em>tools</em> (i.e., compilers, <em>static</em> <em>analysis</em> <em>tools</em>, JIT/VMs, and debuggers) and development tool plugins would be a huge plus. We use Haskell, C++, Java, and Matlab/Simulink/Stateflow.<p>Perks include:<p>- get to work with Fortune 30 owners in a medium-size company environment with small, flexible teams and a flat structure<p>- opportunities to publish and patent<p>- the office is near the Malibu Civic Center with a cafeteria facing the Pacific and the Malibu Colony area and amazing hiking trails<p>- free latte, coffee, and mocha from a fancy new coffee machine<p>Please contact me at my username at hrl dot com.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (January 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-10T15:39:53.000Z",
      "title": null,
      "url": null,
      "author": "Pxtl",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt; For my single-threaded code I have great static analysis tools, IDE magic, and testing frameworks. For my multi-threaded code, I&#x27;m on my own...<p>That&#x27;s a big point.  The tooling for parallel code is developing really slowly compared to the proliferation of multi-core processors.  Most of it seems to be &quot;we&#x27;ll make the library multi-threaded but all your code will still be single-threaded&quot; like we see in Node.",
      "num_comments": null,
      "story_id": 6880361,
      "story_title": "Why Johnny Can’t Write Multithreaded Programs",
      "story_url": "http://blog.smartbear.com/programming/why-johnny-cant-write-multithreaded-programs/",
      "parent_id": 6880606,
      "created_at_i": 1386689993,
      "_tags": [
        "comment",
        "author_Pxtl",
        "story_6880361"
      ],
      "objectID": "6881283",
      "_highlightResult": {
        "author": {
          "value": "Pxtl",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; For my single-threaded code I have great <em>static</em> <em>analysis</em> <em>tools</em>, IDE magic, and testing frameworks. For my multi-threaded code, I'm on my own...<p>That's a big point.  The tooling for parallel code is developing really slowly compared to the proliferation of multi-core processors.  Most of it seems to be &quot;we'll make the library multi-threaded but all your code will still be single-threaded&quot; like we see in Node.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Johnny Can’t Write Multithreaded Programs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.smartbear.com/programming/why-johnny-cant-write-multithreaded-programs/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-02T06:53:36.000Z",
      "title": null,
      "url": null,
      "author": "carterschonwald",
      "points": 1,
      "story_text": null,
      "comment_text": "well said! The false positive rate of most static analysis tools is the biggest barrier to wide spread use!",
      "num_comments": null,
      "story_id": 6831892,
      "story_title": "Trying to Sell PVS-Studio to Google, or New Bugs in Chromium",
      "story_url": "http://www.viva64.com/en/b/0225/",
      "parent_id": 6832109,
      "created_at_i": 1385967216,
      "_tags": [
        "comment",
        "author_carterschonwald",
        "story_6831892"
      ],
      "objectID": "6832192",
      "_highlightResult": {
        "author": {
          "value": "carterschonwald",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "well said! The false positive rate of most <em>static</em> <em>analysis</em> <em>tools</em> is the biggest barrier to wide spread use!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Trying to Sell PVS-Studio to Google, or New Bugs in Chromium",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0225/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-10-26T14:21:09.000Z",
      "title": "",
      "url": "",
      "author": "klibertp",
      "points": 1,
      "story_text": null,
      "comment_text": "It&#x27;s the same in Python, and it&#x27;s mostly solved by external static code analysis tools. The trick here is the assumption that misspelled variable will be used only once in a file - exactly where it got misspelled - and tools like pylint or pyflakes warn about such names. If you&#x27;re running these tools sufficiently often and have them integrated with your editor (my Emacs runs pyflakes once in 3 seconds, after enter is pressed and on save, whichever comes first) this kind of error is essentially eliminated.<p>OTOH, having a language which doesn&#x27;t need external tooling to eliminate such errors is an obvious win. Smalltalk, with it&#x27;s code browsers, refactoring tools and similar does this really well, for example - if you use a new name inside a method definition you are asked if you want to declare new instance or block variable, or turn it into selector, or if you want to rename it (and then it gets renamed throughout the method) and so on. And that&#x27;s at compile time!",
      "num_comments": null,
      "story_id": 6616924,
      "story_title": "The Slash Programming Language",
      "story_url": "http://slash-lang.org/",
      "parent_id": 6617218,
      "created_at_i": 1382797269,
      "_tags": [
        "comment",
        "author_klibertp",
        "story_6616924"
      ],
      "objectID": "6617470",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "klibertp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's the same in Python, and it's mostly solved by external <em>static</em> code <em>analysis</em> <em>tools</em>. The trick here is the assumption that misspelled variable will be used only once in a file - exactly where it got misspelled - and <em>tools</em> like pylint or pyflakes warn about such names. If you're running these <em>tools</em> sufficiently often and have them integrated with your editor (my Emacs runs pyflakes once in 3 seconds, after enter is pressed and on save, whichever comes first) this kind of error is essentially eliminated.<p>OTOH, having a language which doesn't need external tooling to eliminate such errors is an obvious win. Smalltalk, with it's code browsers, refactoring <em>tools</em> and similar does this really well, for example - if you use a new name inside a method definition you are asked if you want to declare new instance or block variable, or turn it into selector, or if you want to rename it (and then it gets renamed throughout the method) and so on. And that's at compile time!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Slash Programming Language",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://slash-lang.org/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-20T22:35:51.000Z",
      "title": "",
      "url": "",
      "author": "acdha",
      "points": 1,
      "story_text": null,
      "comment_text": "This is true but that&#x27;s a non-trivial task even before you get to the question of running it on all third-party code and getting the upstream to patch it. This would solve the problem only in the same way that static analysis tools mean C code no longer has buffer overflows or type conversion errors.",
      "num_comments": null,
      "story_id": 6417319,
      "story_title": "Less is exponentially more (2012)",
      "story_url": "http://commandcenter.blogspot.de/2012/06/less-is-exponentially-more.html",
      "parent_id": 6420109,
      "created_at_i": 1379716551,
      "_tags": [
        "comment",
        "author_acdha",
        "story_6417319"
      ],
      "objectID": "6420950",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "acdha",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is true but that's a non-trivial task even before you get to the question of running it on all third-party code and getting the upstream to patch it. This would solve the problem only in the same way that <em>static</em> <em>analysis</em> <em>tools</em> mean C code no longer has buffer overflows or type conversion errors.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Less is exponentially more (2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://commandcenter.blogspot.de/2012/06/less-is-exponentially-more.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-05T14:04:42.000Z",
      "title": "",
      "url": "",
      "author": "drderidder",
      "points": 1,
      "story_text": null,
      "comment_text": "As 1stamour suggested the whole function was pointless. Not a big deal by itself but if you have layers upon layers of this stuff, code quickly becomes a buggy, unmaintainable mess. There are some awesome static code analysis tools like PMD and PHPMD for measuring code quality. It&#x27;s not just &quot;all programmers think everyone else&#x27;s code is crap&quot;.",
      "num_comments": null,
      "story_id": 6325531,
      "story_title": "How not to check the validity of an email address",
      "story_url": "http://www.dellsystem.me/posts/dont-do-drugs-kids/",
      "parent_id": 6330851,
      "created_at_i": 1378389882,
      "_tags": [
        "comment",
        "author_drderidder",
        "story_6325531"
      ],
      "objectID": "6334229",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "drderidder",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "As 1stamour suggested the whole function was pointless. Not a big deal by itself but if you have layers upon layers of this stuff, code quickly becomes a buggy, unmaintainable mess. There are some awesome <em>static</em> code <em>analysis</em> <em>tools</em> like PMD and PHPMD for measuring code quality. It's not just &quot;all programmers think everyone else's code is crap&quot;.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How not to check the validity of an email address",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.dellsystem.me/posts/dont-do-drugs-kids/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-21T01:19:52.000Z",
      "title": "",
      "url": "",
      "author": "rickjames28",
      "points": 1,
      "story_text": null,
      "comment_text": "I&#x27;m becoming increasingly convinced that the way forward in software engineering isn&#x27;t &quot;better&quot; languages like Haskell or Clojure, but with better tooling.<p>I think Carmack&#x27;s talk shed light on the fact that as humans we have very limited cognitive capacities when it comes to programming and &quot;smarter&quot; languages help us a bit, but we need automated, &quot;smart&quot; tools - like static analysis tools.<p>I think of Visual Studio and Resharper and how much ReSharper finds that I can learn from and how it frees me to concentrate on business logic.<p>Years ago I remember reading an article or an interview with a Sun research scientist where she described programming of the future where languages and tools will be much more lenient of your mistakes and programming will be much more of a two-way conversation with your tooling.<p>That and tools like language work benches are the only ways I see to go forward.  Everybody using Haskell is just a modest (if that) step forward.",
      "num_comments": null,
      "story_id": 6243993,
      "story_title": "John Carmack discusses the art and science of software engineering (2012)",
      "story_url": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
      "parent_id": 6243993,
      "created_at_i": 1377047992,
      "_tags": [
        "comment",
        "author_rickjames28",
        "story_6243993"
      ],
      "objectID": "6247628",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "rickjames28",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm becoming increasingly convinced that the way forward in software engineering isn't &quot;better&quot; languages like Haskell or Clojure, but with better tooling.<p>I think Carmack's talk shed light on the fact that as humans we have very limited cognitive capacities when it comes to programming and &quot;smarter&quot; languages help us a bit, but we need automated, &quot;smart&quot; <em>tools</em> - like <em>static</em> <em>analysis</em> <em>tools</em>.<p>I think of Visual Studio and Resharper and how much ReSharper finds that I can learn from and how it frees me to concentrate on business logic.<p>Years ago I remember reading an article or an interview with a Sun research scientist where she described programming of the future where languages and <em>tools</em> will be much more lenient of your mistakes and programming will be much more of a two-way conversation with your tooling.<p>That and <em>tools</em> like language work benches are the only ways I see to go forward.  Everybody using Haskell is just a modest (if that) step forward.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack discusses the art and science of software engineering (2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-13T03:03:25.000Z",
      "title": "",
      "url": "",
      "author": "pcwalton",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt; Many developers working in the area of games or video and graphics decoding&#x2F;encoding needs access to native-level instruction sets to get maximum performance.<p>SIMD work for asm.js is actively underway.<p>&gt; Nevermind that I have no desire to attempt to debug my emscripten-translated C&#x2F;C++ application instead of just debugging the original source.<p>Source maps are designed to solve this problem.<p>&gt; There&#x27;s an entire ecosystem around supporting native apps in terms of tooling, debugging, libraries, etc. and FireFox OS seems to ignore all of that.<p>For tooling, Emscripten offers very close analogues to the native toolchainyou invoke emcc. Since what you write is C, you can use all the static analysis tools, such as clang&#x27;s static analysis framework, that you&#x27;re used to. Debugging is currently more difficult, it is true. For libraries, just compile them along with your app with Emscripten.",
      "num_comments": null,
      "story_id": 6198625,
      "story_title": "Yesterday I Wrote My First Firefox OS App",
      "story_url": "http://kvz.io/blog/2013/08/12/yesterday-i-wrote-my-first-firefox-os-app/",
      "parent_id": 6203486,
      "created_at_i": 1376363005,
      "_tags": [
        "comment",
        "author_pcwalton",
        "story_6198625"
      ],
      "objectID": "6203779",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pcwalton",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; Many developers working in the area of games or video and graphics decoding/encoding needs access to native-level instruction sets to get maximum performance.<p>SIMD work for asm.js is actively underway.<p>&gt; Nevermind that I have no desire to attempt to debug my emscripten-translated C/C++ application instead of just debugging the original source.<p>Source maps are designed to solve this problem.<p>&gt; There's an entire ecosystem around supporting native apps in terms of tooling, debugging, libraries, etc. and FireFox OS seems to ignore all of that.<p>For tooling, Emscripten offers very close analogues to the native toolchainyou invoke emcc. Since what you write is C, you can use all the <em>static</em> <em>analysis</em> <em>tools</em>, such as clang's <em>static</em> <em>analysis</em> framework, that you're used to. Debugging is currently more difficult, it is true. For libraries, just compile them along with your app with Emscripten.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Yesterday I Wrote My First Firefox OS App",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://kvz.io/blog/2013/08/12/yesterday-i-wrote-my-first-firefox-os-app/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-06-04T16:48:11.000Z",
      "title": "",
      "url": "",
      "author": "koffiezet",
      "points": 1,
      "story_text": null,
      "comment_text": "When I read \"C code\" in this thread - I assume people mean C and C++ together, since they're both capable of the same low-level stuff.<p>The thing is, the new compilers, static analysis, JIT'ing, ...  available these days for C++ makes it the best time ever to write C++ in a reliable way, and being technology that is being used in the real world, this will only improve.<p>There's a reason the C++ language is undergoing a lot of changes nowadays, for the better. After years of no movement at all, C++11 finally arrived, supporting features improving general reliability and memory-management (single pointers, smart pointers, auto type, ...), and C++14 is on it's way. While old programs will still work, the core language evolves and so do the generally accepted standard/best practices, that when generally accepted provide very reliable code.<p>I work on quite a large C++ code-base, and both our test-team and static analysis tools rarely find \"programming errors\". Functional bugs - sure, you still have those like you have in any program, but real end-of-the-world memory corruptions or leaks are rare to completely absent. The only tricky part I guess is threading, although analysis tools have massively improved here - and this is an issue in pretty much every language that understands threads.<p>The nice thing about learning C is that you get to understand what exactly is happening, and while a functional language like Haskell is very cool and can in certain situations offer massive optimizations due to it's language and runtime design, it presents you with a non-existing world. C is an \"easy\" way to understand low-level for as far as it's useful. I fooled around with a lot of languages, including Haskell - and knowing C gives you a much better insight in what the runtime is actually doing, because you KNOW a CPU doesn't work like that, and you're able to quickly understand it's limitations and advantages.<p>Another way to understand what happens +- on CPU level is implementing a simple bytecode compiler and interpreter - in any language of your choosing, but for some reason, most \"real world\" interpreters are implemented in C/C++.",
      "num_comments": null,
      "story_id": 5809012,
      "story_title": "Learn C",
      "story_url": "https://medium.com/tech-talk/afcfa2920c17",
      "parent_id": 5809258,
      "created_at_i": 1370364491,
      "_tags": [
        "comment",
        "author_koffiezet",
        "story_5809012"
      ],
      "objectID": "5820558",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "koffiezet",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "When I read \"C code\" in this thread - I assume people mean C and C++ together, since they're both capable of the same low-level stuff.<p>The thing is, the new compilers, <em>static</em> <em>analysis</em>, JIT'ing, ...  available these days for C++ makes it the best time ever to write C++ in a reliable way, and being technology that is being used in the real world, this will only improve.<p>There's a reason the C++ language is undergoing a lot of changes nowadays, for the better. After years of no movement at all, C++11 finally arrived, supporting features improving general reliability and memory-management (single pointers, smart pointers, auto type, ...), and C++14 is on it's way. While old programs will still work, the core language evolves and so do the generally accepted standard/best practices, that when generally accepted provide very reliable code.<p>I work on quite a large C++ code-base, and both our test-team and <em>static</em> <em>analysis</em> <em>tools</em> rarely find \"programming errors\". Functional bugs - sure, you still have those like you have in any program, but real end-of-the-world memory corruptions or leaks are rare to completely absent. The only tricky part I guess is threading, although <em>analysis</em> <em>tools</em> have massively improved here - and this is an issue in pretty much every language that understands threads.<p>The nice thing about learning C is that you get to understand what exactly is happening, and while a functional language like Haskell is very cool and can in certain situations offer massive optimizations due to it's language and runtime design, it presents you with a non-existing world. C is an \"easy\" way to understand low-level for as far as it's useful. I fooled around with a lot of languages, including Haskell - and knowing C gives you a much better insight in what the runtime is actually doing, because you KNOW a CPU doesn't work like that, and you're able to quickly understand it's limitations and advantages.<p>Another way to understand what happens +- on CPU level is implementing a simple bytecode compiler and interpreter - in any language of your choosing, but for some reason, most \"real world\" interpreters are implemented in C/C++.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Learn C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://medium.com/tech-talk/afcfa2920c17",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-24T23:46:36.000Z",
      "title": "",
      "url": "",
      "author": "obviouslygreen",
      "points": 1,
      "story_text": null,
      "comment_text": "<i>As much as people feel negatively about Java, it really has fantastic static code analysis tools.</i><p>My first experience with Java was at a job in high school... and my only reference was a book that weighed half as much as I did.  Needless to say it left me with a very, very poor impression of the language, which I'm only recently learning is very much wrong.<p>I definitely prefer writing Python, but the more I actually learn about Java, the worse I feed for being such a senseless detractor for so many years.",
      "num_comments": null,
      "story_id": 5604291,
      "story_title": "Using checklists for code review",
      "story_url": "http://blog.rbcommons.com/2013/04/24/using-checklists-for-code-review/",
      "parent_id": 5604542,
      "created_at_i": 1366847196,
      "_tags": [
        "comment",
        "author_obviouslygreen",
        "story_5604291"
      ],
      "objectID": "5604783",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "obviouslygreen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>As much as people feel negatively about Java, it really has fantastic <em>static</em> code <em>analysis</em> <em>tools</em>.</i><p>My first experience with Java was at a job in high school... and my only reference was a book that weighed half as much as I did.  Needless to say it left me with a very, very poor impression of the language, which I'm only recently learning is very much wrong.<p>I definitely prefer writing Python, but the more I actually learn about Java, the worse I feed for being such a senseless detractor for so many years.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Using checklists for code review",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.rbcommons.com/2013/04/24/using-checklists-for-code-review/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-19T18:36:45.000Z",
      "title": "",
      "url": "",
      "author": "radicalbyte",
      "points": 1,
      "story_text": null,
      "comment_text": "In object-oriented modelling you often see the Null Object pattern being used to the same effect.<p><a href=\"http://en.wikipedia.org/wiki/Null_Object_pattern\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Null_Object_pattern</a><p>It needs static analysis tools such as Code Contracts (C#) or SpringContracts (Java) to make it really robust.",
      "num_comments": null,
      "story_id": 5577364,
      "story_title": "Why Maybe Is Better Than Null",
      "story_url": "http://nickknowlson.com/blog/2013/04/16/why-maybe-is-better-than-null/",
      "parent_id": 5577364,
      "created_at_i": 1366396605,
      "_tags": [
        "comment",
        "author_radicalbyte",
        "story_5577364"
      ],
      "objectID": "5578037",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "radicalbyte",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In object-oriented modelling you often see the Null Object pattern being used to the same effect.<p><a href=\"http://en.wikipedia.org/wiki/Null_Object_pattern\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Null_Object_pattern</a><p>It needs <em>static</em> <em>analysis</em> <em>tools</em> such as Code Contracts (C#) or SpringContracts (Java) to make it really robust.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Maybe Is Better Than Null",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://nickknowlson.com/blog/2013/04/16/why-maybe-is-better-than-null/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-03T19:14:59.000Z",
      "title": "",
      "url": "",
      "author": "cromwellian",
      "points": 1,
      "story_text": null,
      "comment_text": "There's obviously benefits in using better languages for safety and error checking, it's one of the reasons why I like Closure Annotations/GWT/Dart over raw Javascript because of my experience on large projects and relatively simplistic bugs silently propagating through.<p>The traditional response to these kind of language imperfections is \"better tests, better practices\". Otherwise as, Unit Tests solve all problems. For C++, someone would say to use some set of abstractions or static analysis tools that confers additional safety that isn't available in the out-of-the-box language.<p>Language level support tends to encourage more consistent usage of something than just depending on vigilance.<p>My metapoint though, is that large code bases are hard to displace, especially if the enduser benefits can be achieved through iteration. Rewriting Gecko from scratch in Rust is a tall order, considering how long it took Gecko and WebKit to get to where they are now. It seems much more likely that WebKit/Gecko can be refactored to get most of the benefits in a much shorter period of time than a rewrite.",
      "num_comments": null,
      "story_id": 5486495,
      "story_title": "Mozilla and Samsung Collaborate on Next Generation Web Browser Engine",
      "story_url": "https://blog.mozilla.org/blog/2013/04/03/mozilla-and-samsung-collaborate-on-next-generation-web-browser-engine/",
      "parent_id": 5487335,
      "created_at_i": 1365016499,
      "_tags": [
        "comment",
        "author_cromwellian",
        "story_5486495"
      ],
      "objectID": "5488361",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "cromwellian",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "There's obviously benefits in using better languages for safety and error checking, it's one of the reasons why I like Closure Annotations/GWT/Dart over raw Javascript because of my experience on large projects and relatively simplistic bugs silently propagating through.<p>The traditional response to these kind of language imperfections is \"better tests, better practices\". Otherwise as, Unit Tests solve all problems. For C++, someone would say to use some set of abstractions or <em>static</em> <em>analysis</em> <em>tools</em> that confers additional safety that isn't available in the out-of-the-box language.<p>Language level support tends to encourage more consistent usage of something than just depending on vigilance.<p>My metapoint though, is that large code bases are hard to displace, especially if the enduser benefits can be achieved through iteration. Rewriting Gecko from scratch in Rust is a tall order, considering how long it took Gecko and WebKit to get to where they are now. It seems much more likely that WebKit/Gecko can be refactored to get most of the benefits in a much shorter period of time than a rewrite.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mozilla and Samsung Collaborate on Next Generation Web Browser Engine",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://blog.mozilla.org/blog/2013/04/03/mozilla-and-samsung-collaborate-on-next-generation-web-browser-engine/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-03-24T06:34:47.000Z",
      "title": "",
      "url": "",
      "author": "furyofantares",
      "points": 1,
      "story_text": null,
      "comment_text": "Thanks for the answer.  I'm curious about the implication that there aren't any mature static analysis tools that catch all undefined behavior and memory access to potentially invalid or mis-typed objects.  I expect such tools technically could exist but don't know if they actually do.<p>I might not understand what you mean regarding positive human action when talking about using static analysis tools -- are you referring to tools that require a manual process to run and evaluate, rather than having your tools outright fail to produce a program if static analysis isn't completely happy with the source code?",
      "num_comments": null,
      "story_id": 5430891,
      "story_title": "Lessons Learned Developing Software for Space Vehicles",
      "story_url": "http://lwn.net/Articles/540368/",
      "parent_id": 5431269,
      "created_at_i": 1364106887,
      "_tags": [
        "comment",
        "author_furyofantares",
        "story_5430891"
      ],
      "objectID": "5431350",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "furyofantares",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Thanks for the answer.  I'm curious about the implication that there aren't any mature <em>static</em> <em>analysis</em> <em>tools</em> that catch all undefined behavior and memory access to potentially invalid or mis-typed objects.  I expect such <em>tools</em> technically could exist but don't know if they actually do.<p>I might not understand what you mean regarding positive human action when talking about using <em>static</em> <em>analysis</em> <em>tools</em> -- are you referring to <em>tools</em> that require a manual process to run and evaluate, rather than having your <em>tools</em> outright fail to produce a program if <em>static</em> <em>analysis</em> isn't completely happy with the source code?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lessons Learned Developing Software for Space Vehicles",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lwn.net/Articles/540368/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-03-20T04:10:23.000Z",
      "title": null,
      "url": null,
      "author": "ndm",
      "points": 1,
      "story_text": null,
      "comment_text": "Having used static analysis security tools for other languages, no. Ignoring the fact that it is open source, it blows away every single other tool I have used in terms of speed, accuracy, and actionability.<p>I would _LOVE_ to be proven wrong on this one.",
      "num_comments": null,
      "story_id": 5400792,
      "story_title": "Code Climate launches Security Monitor",
      "story_url": "http://blog.codeclimate.com/blog/2013/03/19/launching-today-security-monitor-by-code-climate/",
      "parent_id": 5402092,
      "created_at_i": 1363752623,
      "_tags": [
        "comment",
        "author_ndm",
        "story_5400792"
      ],
      "objectID": "5405589",
      "_highlightResult": {
        "author": {
          "value": "ndm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Having used <em>static</em> <em>analysis</em> security <em>tools</em> for other languages, no. Ignoring the fact that it is open source, it blows away every single other tool I have used in terms of speed, accuracy, and actionability.<p>I would _LOVE_ to be proven wrong on this one.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Code Climate launches Security Monitor",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.codeclimate.com/blog/2013/03/19/launching-today-security-monitor-by-code-climate/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-02-27T16:15:42.000Z",
      "title": "",
      "url": "",
      "author": "papsosouid",
      "points": 1,
      "story_text": null,
      "comment_text": "And with C you can use static analysis tools to avoid simple issues as well, plus you get a simple language so you aren't making the mistakes that you get with a huge complex language.  OpenBSD is entirely C, and they have a far better track record than most C++ software.",
      "num_comments": null,
      "story_id": 5291750,
      "story_title": "Why is BIND 10 written in C++ and Python?",
      "story_url": "https://www.isc.org/wordpress/programming-languages-for-bind-10/",
      "parent_id": 5292937,
      "created_at_i": 1361981742,
      "_tags": [
        "comment",
        "author_papsosouid",
        "story_5291750"
      ],
      "objectID": "5293077",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "papsosouid",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "And with C you can use <em>static</em> <em>analysis</em> <em>tools</em> to avoid simple issues as well, plus you get a simple language so you aren't making the mistakes that you get with a huge complex language.  OpenBSD is entirely C, and they have a far better track record than most C++ software.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why is BIND 10 written in C++ and Python?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.isc.org/wordpress/programming-languages-for-bind-10/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-12-31T05:43:30.000Z",
      "title": "",
      "url": "",
      "author": "timestretch",
      "points": 1,
      "story_text": null,
      "comment_text": "This is pretty clever, and made me smile.<p>I'm not wild about the idea of weeding through bot generated pull requests. But, I like the idea of making tools like this available through GitHub.<p>It would be cool if GitHub provided a static analysis tools to find bugs, leaks, and security issues in uploaded code. Clang is updated pretty frequently and it would be cool to see new results against all repos when it is updated. Generating pull requests would make it easy to fix issues discovered too.",
      "num_comments": null,
      "story_id": 4988360,
      "story_title": "Imageoptimiser: Post Mortem of a GitHub Bob",
      "story_url": "http://port3000.co.uk/imageoptimiser-post-mortem-of-a-github-bot",
      "parent_id": 4988360,
      "created_at_i": 1356932610,
      "_tags": [
        "comment",
        "author_timestretch",
        "story_4988360"
      ],
      "objectID": "4988533",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "timestretch",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is pretty clever, and made me smile.<p>I'm not wild about the idea of weeding through bot generated pull requests. But, I like the idea of making <em>tools</em> like this available through GitHub.<p>It would be cool if GitHub provided a <em>static</em> <em>analysis</em> <em>tools</em> to find bugs, leaks, and security issues in uploaded code. Clang is updated pretty frequently and it would be cool to see new results against all repos when it is updated. Generating pull requests would make it easy to fix issues discovered too.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Imageoptimiser: Post Mortem of a GitHub Bob",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://port3000.co.uk/imageoptimiser-post-mortem-of-a-github-bot",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-10-15T01:46:19.000Z",
      "title": "",
      "url": "",
      "author": "kevinconroy",
      "points": 1,
      "story_text": null,
      "comment_text": "The tech community should have a discussion about the best way to move forward with CSS, but it will probably turn into this: <a href=\"http://xkcd.com/927/\" rel=\"nofollow\">http://xkcd.com/927/</a><p>Like it or not, CSS has legacy support built into millions and millions of devices that cannot be easily updated. Newer versions can come forward, but more likely than not, the best thing to do would be to build on frameworks such as LESS (or one of it's cousins) that allows you to code in a meta language. Combine it with some static analysis tools and you can create a system that warns you when you cascade too much (for some value of too much) and help keep you sane.",
      "num_comments": null,
      "story_id": 4648091,
      "story_title": "What the Heck Is CSS Specificity?",
      "story_url": "http://designshack.net/articles/css/what-the-heck-is-css-specificity/",
      "parent_id": 4648890,
      "created_at_i": 1350265579,
      "_tags": [
        "comment",
        "author_kevinconroy",
        "story_4648091"
      ],
      "objectID": "4653327",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "kevinconroy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The tech community should have a discussion about the best way to move forward with CSS, but it will probably turn into this: <a href=\"http://xkcd.com/927/\" rel=\"nofollow\">http://xkcd.com/927/</a><p>Like it or not, CSS has legacy support built into millions and millions of devices that cannot be easily updated. Newer versions can come forward, but more likely than not, the best thing to do would be to build on frameworks such as LESS (or one of it's cousins) that allows you to code in a meta language. Combine it with some <em>static</em> <em>analysis</em> <em>tools</em> and you can create a system that warns you when you cascade too much (for some value of too much) and help keep you sane.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What the Heck Is CSS Specificity?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://designshack.net/articles/css/what-the-heck-is-css-specificity/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-08-23T17:13:47.000Z",
      "title": "",
      "url": "",
      "author": "davidcuddeback",
      "points": 1,
      "story_text": null,
      "comment_text": "Static code analysis has a long-term benefit as well as the more obvious short-term benefit. That is, it teaches us to be better developers as we strive to have the static analysis catch less issues in our code the next time [1]. I used static analysis to improve my style for C, Python, and most recently Ruby [2].<p>I think it had a lasting effect on my personal coding habits. But every once in a while, I will use the tools on my new code and it still finds things. I would probably benefit from being more persistent in using these tools.<p>[1]: This assumes that the issues caught be your static analysis tool are valid concerns, which in my experience, they tend to be.<p>[2]: Some static analysis tools that I've used with Ruby are reek, roodi, flay, and flog. Reek and roodi report code smells. Flay reports structural similarities (opportunities for refactoring). And flog estimates the complexity of your methods.",
      "num_comments": null,
      "story_id": 4423031,
      "story_title": "John Carmack discusses the art and science of software engineering",
      "story_url": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
      "parent_id": 4423170,
      "created_at_i": 1345742027,
      "_tags": [
        "comment",
        "author_davidcuddeback",
        "story_4423031"
      ],
      "objectID": "4423557",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "davidcuddeback",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<em>Static</em> code <em>analysis</em> has a long-term benefit as well as the more obvious short-term benefit. That is, it teaches us to be better developers as we strive to have the <em>static</em> <em>analysis</em> catch less issues in our code the next time [1]. I used <em>static</em> <em>analysis</em> to improve my style for C, Python, and most recently Ruby [2].<p>I think it had a lasting effect on my personal coding habits. But every once in a while, I will use the <em>tools</em> on my new code and it still finds things. I would probably benefit from being more persistent in using these <em>tools</em>.<p>[1]: This assumes that the issues caught be your <em>static</em> <em>analysis</em> tool are valid concerns, which in my experience, they tend to be.<p>[2]: Some <em>static</em> <em>analysis</em> <em>tools</em> that I've used with Ruby are reek, roodi, flay, and flog. Reek and roodi report code smells. Flay reports structural similarities (opportunities for refactoring). And flog estimates the complexity of your methods.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack discusses the art and science of software engineering",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-07-08T17:10:40.000Z",
      "title": "",
      "url": "",
      "author": "pjmlp",
      "points": 1,
      "story_text": null,
      "comment_text": "Try to get the free MFC framework, with the free 64 bit C++ compiler and the free static code analysis tools.",
      "num_comments": null,
      "story_id": 4213806,
      "story_title": "Easy 6502 - Learn the 6502 Assembly Language",
      "story_url": "http://skilldrick.github.com/easy6502/index.html",
      "parent_id": 4214533,
      "created_at_i": 1341767440,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_4213806"
      ],
      "objectID": "4215008",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Try to get the free MFC framework, with the free 64 bit C++ compiler and the free <em>static</em> code <em>analysis</em> <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Easy 6502 - Learn the 6502 Assembly Language",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://skilldrick.github.com/easy6502/index.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-06-01T12:39:21.000Z",
      "title": "",
      "url": "",
      "author": "slurgfest",
      "points": 1,
      "story_text": null,
      "comment_text": "Monkey patching is NOT widely accepted in Python, just the opposite. For an example look at gevent, which is actually quite useful and elegant but often panned and avoided in the Python community because it works by monkey patching. The same attitude is not equally present in every dynamic language.<p>Where you are certainly right is that monkeypatching may occur in a project and this is only one of many ways that Python's being very dynamic makes it extra hard to write static analysis tools.<p>The rm -rf problem is not as bad if you are previewing (say) a page view, which hopefully is not being developed on a production server and hopefully doesn't contain an rm -rf. But I agree that solving this in the general case is probably intractable without some kind of container.",
      "num_comments": null,
      "story_id": 4051546,
      "story_title": "Light Table reaches 300k necessary for Python support",
      "story_url": "http://www.kickstarter.com/projects/ibdknox/light-table?ref=live",
      "parent_id": 4052510,
      "created_at_i": 1338554361,
      "_tags": [
        "comment",
        "author_slurgfest",
        "story_4051546"
      ],
      "objectID": "4053053",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "slurgfest",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Monkey patching is NOT widely accepted in Python, just the opposite. For an example look at gevent, which is actually quite useful and elegant but often panned and avoided in the Python community because it works by monkey patching. The same attitude is not equally present in every dynamic language.<p>Where you are certainly right is that monkeypatching may occur in a project and this is only one of many ways that Python's being very dynamic makes it extra hard to write <em>static</em> <em>analysis</em> <em>tools</em>.<p>The rm -rf problem is not as bad if you are previewing (say) a page view, which hopefully is not being developed on a production server and hopefully doesn't contain an rm -rf. But I agree that solving this in the general case is probably intractable without some kind of container.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Light Table reaches 300k necessary for Python support",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.kickstarter.com/projects/ibdknox/light-table?ref=live",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-17T15:31:29.000Z",
      "title": "",
      "url": "",
      "author": "mindcrime",
      "points": 1,
      "story_text": null,
      "comment_text": "<i>Java seems to possess the correct combination of features: mature platform, wide adoption, familiar syntax, readily-available developers, maintainability by those other than the original authors (Java isn't necessarily great at this, but better than many), and a quality that I'll describe only as hard to really fuck things up too badly. If it wasn't for that last requirement, I'd already be trying to sell Python to my boss; as it stands, if I can't find some really awesome static analysis and verification tools for Python</i><p>I think one can make a case that Groovy comes pretty damn close, and at least <i>as</i> close as any other \"scripting language on the JVM.\"<p>Platform:  Well, it's the JVM.<p>Wide Adoption:  Define \"wide?\"  But from what I can see, Groovy is pretty popular, especially Grails.  There are plenty of books on Groovy/Grails, Grails meetups / users groups in many cities, an active community of developers, etc.  There are even consulting companies that focus on Groovy and Grails.  SpanTree in Chicago, IL come to mind.<p>Familiar Syntax:  Groovy is great in this regard, as almost any .java file can be renamed to .groovy and compiled with groovyc.  Most of the syntax that's different between Java and Groovy is optional in Groovy, so you can start off writing Groovy that is very Java-like and slowly evolve to more idiomatic Groovy over time.<p>Maintainability:  No better or worse than any other dynamic language, IMO.  If you have access to metaprogramming and duck-typing and what-not, there opportunity for abuse is there.  But Groovy's culture does not seem to be big on a lot of BFM.<p><i>hard to really fuck things up too badly</i> - hmm... that's pretty subjective, but to that point, Groovy does have unit-testing tools, static analysis tools, etc. available.  The ecosystem might not quite as rich as of that for pure Java, but I think you can find what you need to create a sane development environment.",
      "num_comments": null,
      "story_id": 3986540,
      "story_title": "Jython 2.7 alpha1 released",
      "story_url": "http://fwierzbicki.blogspot.com/2012/05/jython-27-alpha1-released.html",
      "parent_id": 3987282,
      "created_at_i": 1337268689,
      "_tags": [
        "comment",
        "author_mindcrime",
        "story_3986540"
      ],
      "objectID": "3987408",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "mindcrime",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>Java seems to possess the correct combination of features: mature platform, wide adoption, familiar syntax, readily-available developers, maintainability by those other than the original authors (Java isn't necessarily great at this, but better than many), and a quality that I'll describe only as hard to really fuck things up too badly. If it wasn't for that last requirement, I'd already be trying to sell Python to my boss; as it stands, if I can't find some really awesome <em>static</em> <em>analysis</em> and verification <em>tools</em> for Python</i><p>I think one can make a case that Groovy comes pretty damn close, and at least <i>as</i> close as any other \"scripting language on the JVM.\"<p>Platform:  Well, it's the JVM.<p>Wide Adoption:  Define \"wide?\"  But from what I can see, Groovy is pretty popular, especially Grails.  There are plenty of books on Groovy/Grails, Grails meetups / users groups in many cities, an active community of developers, etc.  There are even consulting companies that focus on Groovy and Grails.  SpanTree in Chicago, IL come to mind.<p>Familiar Syntax:  Groovy is great in this regard, as almost any .java file can be renamed to .groovy and compiled with groovyc.  Most of the syntax that's different between Java and Groovy is optional in Groovy, so you can start off writing Groovy that is very Java-like and slowly evolve to more idiomatic Groovy over time.<p>Maintainability:  No better or worse than any other dynamic language, IMO.  If you have access to metaprogramming and duck-typing and what-not, there opportunity for abuse is there.  But Groovy's culture does not seem to be big on a lot of BFM.<p><i>hard to really fuck things up too badly</i> - hmm... that's pretty subjective, but to that point, Groovy does have unit-testing <em>tools</em>, <em>static</em> <em>analysis</em> <em>tools</em>, etc. available.  The ecosystem might not quite as rich as of that for pure Java, but I think you can find what you need to create a sane development environment.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Jython 2.7 alpha1 released",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://fwierzbicki.blogspot.com/2012/05/jython-27-alpha1-released.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-08T15:46:16.000Z",
      "title": "",
      "url": "",
      "author": "Arcticus",
      "points": 1,
      "story_text": null,
      "comment_text": "Safety Critical software is really about the confidence level in the software to function as intended and is really language agnostic.  This is why most Safety Critical projects focus on development and test practices.  You want to have a good warm and fuzzy that the product your outputting will work as intended when needed.  The traditional way to accomplish this is through rigorous design processes and robust testing.  So no one language has an advantage over another (unless real-time is a requirement which it often is) at the root level.  Over the years tools have been developed to help assist in testing and giving you that warm fuzzy feeling at the end.  Static analysis tools and code coverage tools are an example.  These tools tend to be more mature for traditional languages like C/C++ and ADA thus making them more popular for Safety Critical projects, but that's not to say another language that the development group was more familiar with wouldn't do better.  At the end of the day its all about your ability to detect defects and the systems ability to detect anomalies so the tool set that the development team thinks they can accomplish this the best with is the best choice.",
      "num_comments": null,
      "story_id": 3943556,
      "story_title": "What's The Best Language For Safety Critical Software?",
      "story_url": "http://stackoverflow.com/q/243387/347353",
      "parent_id": 3943556,
      "created_at_i": 1336491976,
      "_tags": [
        "comment",
        "author_Arcticus",
        "story_3943556"
      ],
      "objectID": "3944198",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Arcticus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Safety Critical software is really about the confidence level in the software to function as intended and is really language agnostic.  This is why most Safety Critical projects focus on development and test practices.  You want to have a good warm and fuzzy that the product your outputting will work as intended when needed.  The traditional way to accomplish this is through rigorous design processes and robust testing.  So no one language has an advantage over another (unless real-time is a requirement which it often is) at the root level.  Over the years <em>tools</em> have been developed to help assist in testing and giving you that warm fuzzy feeling at the end.  <em>Static</em> <em>analysis</em> <em>tools</em> and code coverage <em>tools</em> are an example.  These <em>tools</em> tend to be more mature for traditional languages like C/C++ and ADA thus making them more popular for Safety Critical projects, but that's not to say another language that the development group was more familiar with wouldn't do better.  At the end of the day its all about your ability to detect defects and the systems ability to detect anomalies so the tool set that the development team thinks they can accomplish this the best with is the best choice.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What's The Best Language For Safety Critical Software?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://stackoverflow.com/q/243387/347353",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-04-10T19:57:24.000Z",
      "title": "",
      "url": "",
      "author": "tedunangst",
      "points": 1,
      "story_text": null,
      "comment_text": "\"Microsoft has some good static code analysis tools ( <a href=\"http://msdn.microsoft.com/en-us/gg712340\" rel=\"nofollow\">http://msdn.microsoft.com/en-us/gg712340</a> ), for a start.\"<p><i>The compound word 'PreOrder' exists as a discrete term. ... case it as 'Preorder' or strip the first token entirely if it represents any sort of Hungarian notation.</i><p>Aw shit, Apple is gonna get fucked by all those remotely exploitable Hungarian notation bugs.",
      "num_comments": null,
      "story_id": 3821549,
      "story_title": "Apple Snubs Firm That Discovered Mac Botnet",
      "story_url": "http://www.forbes.com/sites/andygreenberg/2012/04/09/apple-snubs-firm-who-discovered-mac-botnet-tries-to-cut-off-its-server-monitoring-infections/",
      "parent_id": 3822737,
      "created_at_i": 1334087844,
      "_tags": [
        "comment",
        "author_tedunangst",
        "story_3821549"
      ],
      "objectID": "3824080",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "tedunangst",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "\"Microsoft has some good <em>static</em> code <em>analysis</em> <em>tools</em> ( <a href=\"http://msdn.microsoft.com/en-us/gg712340\" rel=\"nofollow\">http://msdn.microsoft.com/en-us/gg712340</a> ), for a start.\"<p><i>The compound word 'PreOrder' exists as a discrete term. ... case it as 'Preorder' or strip the first token entirely if it represents any sort of Hungarian notation.</i><p>Aw shit, Apple is gonna get fucked by all those remotely exploitable Hungarian notation bugs.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Apple Snubs Firm That Discovered Mac Botnet",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.forbes.com/sites/andygreenberg/2012/04/09/apple-snubs-firm-who-discovered-mac-botnet-tries-to-cut-off-its-server-monitoring-infections/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-27T12:24:04.000Z",
      "title": "",
      "url": "",
      "author": "stonemetal",
      "points": 1,
      "story_text": null,
      "comment_text": "Especially in the light of Windows 8 and ARM support.  Have they announced anything like Apple's Fat binaries?  Surely emulating ARM on x86 isn't the whole plan.  If it is the marketing of \"going native\" is a bit amusing.  I am just glad the static analysis tools are coming to the low end VS.",
      "num_comments": null,
      "story_id": 3638018,
      "story_title": "How to write good code with C++11",
      "story_url": "http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style/player",
      "parent_id": 3638478,
      "created_at_i": 1330345444,
      "_tags": [
        "comment",
        "author_stonemetal",
        "story_3638018"
      ],
      "objectID": "3638701",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "stonemetal",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Especially in the light of Windows 8 and ARM support.  Have they announced anything like Apple's Fat binaries?  Surely emulating ARM on x86 isn't the whole plan.  If it is the marketing of \"going native\" is a bit amusing.  I am just glad the <em>static</em> <em>analysis</em> <em>tools</em> are coming to the low end VS.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How to write good code with C++11",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style/player",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-19T23:43:11.000Z",
      "title": "",
      "url": "",
      "author": "drifkin",
      "points": 1,
      "story_text": null,
      "comment_text": "JS static analysis tools can help you find mistakes that are often more serious than a missing semicolon.<p>I've run into something like this before:<p><pre><code>  for (var i = 0, len = items.length; i &#60; len; i++)\n  {\n    var item = items[i];\n    // ...maybe some more code here...\n    var subItems = item.subItems;\n    for (var i = 0, len = subItems.length; i &#60; len; i++) {\n      // whoops\n    }\n  }\n</code></pre>\nThe inner for loop's i &#38; len variables are really the same as the outer for loop's i &#38; len variables (there's no shadowing going on here because they're all in the same scope in JS). Depending on the order of things and how many subItems there are, you could end up with an infinite loop, iterating over the same items multiple times, or skipping certain items. It seems like it'd be an obvious problem to see, but if there's a significant amount of code above the inner for loop, you might miss it. It also seems like it'd result in very obvious bugs, but if subItems are rare, most of the time this code will run just fine.<p>Most of the JS static analysis tools will complain about redeclaring i and len, which makes spotting this kind of problem much easier.",
      "num_comments": null,
      "story_id": 3598915,
      "story_title": "JSHint, A JavaScript Code Quality Tool",
      "story_url": "http://www.jshint.com/",
      "parent_id": 3599511,
      "created_at_i": 1329694991,
      "_tags": [
        "comment",
        "author_drifkin",
        "story_3598915"
      ],
      "objectID": "3610760",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "drifkin",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "JS <em>static</em> <em>analysis</em> <em>tools</em> can help you find mistakes that are often more serious than a missing semicolon.<p>I've run into something like this before:<p><pre><code>  for (var i = 0, len = items.length; i < len; i++)\n  {\n    var item = items[i];\n    // ...maybe some more code here...\n    var subItems = item.subItems;\n    for (var i = 0, len = subItems.length; i < len; i++) {\n      // whoops\n    }\n  }\n</code></pre>\nThe inner for loop's i & len variables are really the same as the outer for loop's i & len variables (there's no shadowing going on here because they're all in the same scope in JS). Depending on the order of things and how many subItems there are, you could end up with an infinite loop, iterating over the same items multiple times, or skipping certain items. It seems like it'd be an obvious problem to see, but if there's a significant amount of code above the inner for loop, you might miss it. It also seems like it'd result in very obvious bugs, but if subItems are rare, most of the time this code will run just fine.<p>Most of the JS <em>static</em> <em>analysis</em> <em>tools</em> will complain about redeclaring i and len, which makes spotting this kind of problem much easier.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "JSHint, A JavaScript Code Quality Tool",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.jshint.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-01-30T13:03:05.000Z",
      "title": null,
      "url": null,
      "author": "dazbradbury",
      "points": 1,
      "story_text": null,
      "comment_text": "You may want to look at some static code analysis tools for 1 and 2:<p><a href=\"http://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis\" rel=\"nofollow\">http://en.wikipedia.org/wiki/List_of_tools_for_static_code_a...</a><p>From my very limited understanding, the powerful ones are seemingly only in reach for large enterprises [1].<p>With regard to number 3, In C# and Java, resharper/IntelliJ has partially automated refactoring tools. I'm sure similar tools exist for other languages.<p>However, I think going down this route is substantially more work unless you are inheriting a code base. I would aim to learn some of the design patterns basics[2], perhaps read \"The Algorithm Design Manual\" [3], and aim to have a clear idea of how to design your latest algorithm from the offset.<p>[1] - <a href=\"http://semmle.com/solutions/what-we-do/index.html\" rel=\"nofollow\">http://semmle.com/solutions/what-we-do/index.html</a><p>[2] - <a href=\"http://en.wikipedia.org/wiki/Design_Patterns\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Design_Patterns</a><p>[3] - <a href=\"http://www.amazon.co.uk/Algorithm-Design-Manual-Steven-Skiena/dp/1848000693\" rel=\"nofollow\">http://www.amazon.co.uk/Algorithm-Design-Manual-Steven-Skien...</a>",
      "num_comments": null,
      "story_id": 3528532,
      "story_title": "Ask HN: Is it possible to semantically analyze code for design patterns?",
      "story_url": "",
      "parent_id": 3528532,
      "created_at_i": 1327928585,
      "_tags": [
        "comment",
        "author_dazbradbury",
        "story_3528532"
      ],
      "objectID": "3528571",
      "_highlightResult": {
        "author": {
          "value": "dazbradbury",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You may want to look at some <em>static</em> code <em>analysis</em> <em>tools</em> for 1 and 2:<p><a href=\"http://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis\" rel=\"nofollow\">http://en.wikipedia.org/wiki/List_of_<em>tools</em>_for_<em>static</em>_code_a...</a><p>From my very limited understanding, the powerful ones are seemingly only in reach for large enterprises [1].<p>With regard to number 3, In C# and Java, resharper/IntelliJ has partially automated refactoring <em>tools</em>. I'm sure similar <em>tools</em> exist for other languages.<p>However, I think going down this route is substantially more work unless you are inheriting a code base. I would aim to learn some of the design patterns basics[2], perhaps read \"The Algorithm Design Manual\" [3], and aim to have a clear idea of how to design your latest algorithm from the offset.<p>[1] - <a href=\"http://semmle.com/solutions/what-we-do/index.html\" rel=\"nofollow\">http://semmle.com/solutions/what-we-do/index.html</a><p>[2] - <a href=\"http://en.wikipedia.org/wiki/Design_Patterns\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Design_Patterns</a><p>[3] - <a href=\"http://www.amazon.co.uk/Algorithm-Design-Manual-Steven-Skiena/dp/1848000693\" rel=\"nofollow\">http://www.amazon.co.uk/Algorithm-Design-Manual-Steven-Skien...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Is it possible to semantically analyze code for design patterns?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-01-11T01:17:40.000Z",
      "title": null,
      "url": null,
      "author": "troygoode",
      "points": 1,
      "story_text": null,
      "comment_text": "The compiler won't, no - but many/most developers use static analysis tools like ReSharper which WILL tell you that you have a possible NullReferenceException there if you don't check it.",
      "num_comments": null,
      "story_id": 3446467,
      "story_title": "Don't return null; use a tail call",
      "story_url": "http://joelneely.wordpress.com/2010/04/17/dont-return-null-use-a-tail-call/",
      "parent_id": 3447746,
      "created_at_i": 1326244660,
      "_tags": [
        "comment",
        "author_troygoode",
        "story_3446467"
      ],
      "objectID": "3450010",
      "_highlightResult": {
        "author": {
          "value": "troygoode",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The compiler won't, no - but many/most developers use <em>static</em> <em>analysis</em> <em>tools</em> like ReSharper which WILL tell you that you have a possible NullReferenceException there if you don't check it.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Don't return null; use a tail call",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://joelneely.wordpress.com/2010/04/17/dont-return-null-use-a-tail-call/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-08-06T14:49:14.000Z",
      "title": "",
      "url": "",
      "author": "swah",
      "points": 1,
      "story_text": null,
      "comment_text": "He talks about static code analysis tools around 55 minutes.",
      "num_comments": null,
      "story_id": 2852118,
      "story_title": "QuakeCon 2011 - John Carmack Keynote",
      "story_url": "http://www.youtube.com/watch?v=4zgYG-_ha28",
      "parent_id": 2852118,
      "created_at_i": 1312642154,
      "_tags": [
        "comment",
        "author_swah",
        "story_2852118"
      ],
      "objectID": "2853962",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "swah",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "He talks about <em>static</em> code <em>analysis</em> <em>tools</em> around 55 minutes.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "QuakeCon 2011 - John Carmack Keynote",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.youtube.com/watch?v=4zgYG-_ha28",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-08-01T19:57:35.000Z",
      "title": "",
      "url": "",
      "author": "hello_moto",
      "points": 1,
      "story_text": null,
      "comment_text": "Java ecosystem has a lot of static analysis tools that can integrate to almost all popular IDEs and Continuous Integration systems. Findbugs, PMD, JDepend, Sonar (recommend to check Sonar).<p>Checkstyle is another tool that I use since I'm kind of the annoying dude when it comes to code-style. (Have you seen GWT API code? it's like written by one person as opposed to a few developers with different perceptions of \"readable\" code. I like that kind of thing).<p>There are a few reasons why startup/individual dev would choose Java:<p>1) Previous experience in Java<p>2) Java fits better for the type of problems to solve (intensive computational that requires Hadoop like infrastructure)<p>3) Emotionally attached to static/compiled language with nice IDE so that one can navigate the source code easily whether the code base is large or small (sometime not all decisions are rational and I'm okay with that because developing software requires more than technical skill; it also requires passion).<p>4) Marketing (if you're targeting the enterprises). Zimbra, Jive Software, Compiere, Alfresco, Day software, Liferay, Salesforce used to be startups.<p>Java ecosystem seems to learn and grow in a much better speed thanks to the following actors:<p>- Rails (Spring Roo, Spring MVC, JPA 2.0, and possibly MVC framework from the upcoming JEE releases)<p>- C# (Java 7 new features, Java 8 closures/lambda. Yes, Lisp does this first, but I think C# forces Java to implement closures more than any of its competitors).<p>- REST/JSON/WS (Check out the latest JAX-RS, supports REST, JSON, XML, Atom-Feed, and JAX-WS)<p>- I/P/SaaS + Cloud Computing (Targeted for Java EE7, deployment, infrastructure to support multi-tenant, etc).<p>NB: Just so that I don't sound like a Java fan-boy, I use Java by day but I use and help to promote and organize Python community overseas (of course by not comparing Python vs Java :)).",
      "num_comments": null,
      "story_id": 2825689,
      "story_title": "Twitter: From Ruby on Rails to the JVM [video]",
      "story_url": "http://ontwik.com/rails/oreilly-oscon-java-2011-raffi-krikorian-twitter-from-ruby-on-rails-to-the-jvm/",
      "parent_id": 2833162,
      "created_at_i": 1312228655,
      "_tags": [
        "comment",
        "author_hello_moto",
        "story_2825689"
      ],
      "objectID": "2834103",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "hello_moto",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Java ecosystem has a lot of <em>static</em> <em>analysis</em> <em>tools</em> that can integrate to almost all popular IDEs and Continuous Integration systems. Findbugs, PMD, JDepend, Sonar (recommend to check Sonar).<p>Checkstyle is another tool that I use since I'm kind of the annoying dude when it comes to code-style. (Have you seen GWT API code? it's like written by one person as opposed to a few developers with different perceptions of \"readable\" code. I like that kind of thing).<p>There are a few reasons why startup/individual dev would choose Java:<p>1) Previous experience in Java<p>2) Java fits better for the type of problems to solve (intensive computational that requires Hadoop like infrastructure)<p>3) Emotionally attached to <em>static</em>/compiled language with nice IDE so that one can navigate the source code easily whether the code base is large or small (sometime not all decisions are rational and I'm okay with that because developing software requires more than technical skill; it also requires passion).<p>4) Marketing (if you're targeting the enterprises). Zimbra, Jive Software, Compiere, Alfresco, Day software, Liferay, Salesforce used to be startups.<p>Java ecosystem seems to learn and grow in a much better speed thanks to the following actors:<p>- Rails (Spring Roo, Spring MVC, JPA 2.0, and possibly MVC framework from the upcoming JEE releases)<p>- C# (Java 7 new features, Java 8 closures/lambda. Yes, Lisp does this first, but I think C# forces Java to implement closures more than any of its competitors).<p>- REST/JSON/WS (Check out the latest JAX-RS, supports REST, JSON, XML, Atom-Feed, and JAX-WS)<p>- I/P/SaaS + Cloud Computing (Targeted for Java EE7, deployment, infrastructure to support multi-tenant, etc).<p>NB: Just so that I don't sound like a Java fan-boy, I use Java by day but I use and help to promote and organize Python community overseas (of course by not comparing Python vs Java :)).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Twitter: From Ruby on Rails to the JVM [video]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ontwik.com/rails/oreilly-oscon-java-2011-raffi-krikorian-twitter-from-ruby-on-rails-to-the-jvm/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-07-02T02:07:49.000Z",
      "title": "",
      "url": "",
      "author": "CPlatypus",
      "points": 1,
      "story_text": null,
      "comment_text": "If I worked on static code analysis tools for a living, this would make me cry.",
      "num_comments": null,
      "story_id": 2718252,
      "story_title": "Lambdas in C",
      "story_url": "http://walfield.org/blog/2010/08/25/lambdas-in-c.html",
      "parent_id": 2718252,
      "created_at_i": 1309572469,
      "_tags": [
        "comment",
        "author_CPlatypus",
        "story_2718252"
      ],
      "objectID": "2720829",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "CPlatypus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "If I worked on <em>static</em> code <em>analysis</em> <em>tools</em> for a living, this would make me cry.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lambdas in C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://walfield.org/blog/2010/08/25/lambdas-in-c.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-12-05T20:02:42.000Z",
      "title": null,
      "url": null,
      "author": "chromatic",
      "points": null,
      "story_text": null,
      "comment_text": "&#62; ... of course there's that nice feature that Python has that Perl never had in any version....<p>I expect better from HN comments.<p>\"I've tried, repeatedly, but I still find sigils difficult to understand\" is fine.<p>\"I prefer postfix method calls to infix or prefix symbolic operators\" is fine.<p>\"I've never figured out how to use Perl's copious testing libraries or static analysis tools to write maintainable code\" is honest.<p>\"I believe that consistent indentation is a primary factor in long-term maintainability\" starts to trip my hogwash-o-meter.",
      "num_comments": null,
      "story_id": 977211,
      "story_title": "Python Moratorium: Let's think about this",
      "story_url": "http://jessenoller.com/2009/12/04/pythons-moratorium-lets-think-about-this/",
      "parent_id": 977950,
      "created_at_i": 1260043362,
      "_tags": [
        "comment",
        "author_chromatic",
        "story_977211"
      ],
      "objectID": "978519",
      "_highlightResult": {
        "author": {
          "value": "chromatic",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> ... of course there's that nice feature that Python has that Perl never had in any version....<p>I expect better from HN comments.<p>\"I've tried, repeatedly, but I still find sigils difficult to understand\" is fine.<p>\"I prefer postfix method calls to infix or prefix symbolic operators\" is fine.<p>\"I've never figured out how to use Perl's copious testing libraries or <em>static</em> <em>analysis</em> <em>tools</em> to write maintainable code\" is honest.<p>\"I believe that consistent indentation is a primary factor in long-term maintainability\" starts to trip my hogwash-o-meter.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Python Moratorium: Let's think about this",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://jessenoller.com/2009/12/04/pythons-moratorium-lets-think-about-this/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-06-03T23:32:13.000Z",
      "title": null,
      "url": null,
      "author": "chimeracoder",
      "points": null,
      "story_text": null,
      "comment_text": "This is correct, with one addition:<p>&gt; Well, the theorem states that if there are more than 2 candidates, then there is no voting system that has all 4 properties above <i>in the general case</i>.<p>Nobel Laureate Amartya Sen[0] has demonstrated that, while there is no system that satisfies all four characteristics in the general case, there are systems that either satisfy all four conditions either probabilistically <i>or</i> satisfy all four conditions subject to some very weak assumptions.<p>The example I&#x27;ve heard him use is of the 2000 election in Florida, with Bush, Gore, and Nader (let&#x27;s ignore Buchanan for simplicity). While technically there are 3! = 6 possible ways to rank the candidates, in practice, the ranking (Nader, Bush, Gore) is much less likely than (Nader, Gore, Bush) or (Gore, Nader, Bush). If we introduce one minor assumption about the relative frequencies of the rankings, we can prove that instant-runoff voting[1] <i>does</i> always satisfy all four of Arrow&#x27;s criteria[2].<p>To use an analogy from computer science, the halting problem is undecidable in the general case, but that doesn&#x27;t prevent static analysis tools from spotting many infinite loops; it just means it can&#x27;t spot <i>all</i> infinite loops with 100% accuracy.<p>[0] <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Amartya_Sen\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Amartya_Sen</a><p>[1] <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Instant-runoff_voting\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Instant-runoff_voting</a><p>[2] A different example: instead of making assumptions about the relative frequencies, we could make assumptions about the number of axes that candidates may have and the way they cluster around them. This realistically depicts both two-party and multiparty elections in most parts of the world, since political positions are not uniformly distributed along <i>n</i> dimensions.",
      "num_comments": null,
      "story_id": 9655846,
      "story_title": "Arrow's impossibility theorem",
      "story_url": "http://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem",
      "parent_id": 9656482,
      "created_at_i": 1433374333,
      "_tags": [
        "comment",
        "author_chimeracoder",
        "story_9655846"
      ],
      "objectID": "9656558",
      "_highlightResult": {
        "author": {
          "value": "chimeracoder",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is correct, with one addition:<p>&gt; Well, the theorem states that if there are more than 2 candidates, then there is no voting system that has all 4 properties above <i>in the general case</i>.<p>Nobel Laureate Amartya Sen[0] has demonstrated that, while there is no system that satisfies all four characteristics in the general case, there are systems that either satisfy all four conditions either probabilistically <i>or</i> satisfy all four conditions subject to some very weak assumptions.<p>The example I've heard him use is of the 2000 election in Florida, with Bush, Gore, and Nader (let's ignore Buchanan for simplicity). While technically there are 3! = 6 possible ways to rank the candidates, in practice, the ranking (Nader, Bush, Gore) is much less likely than (Nader, Gore, Bush) or (Gore, Nader, Bush). If we introduce one minor assumption about the relative frequencies of the rankings, we can prove that instant-runoff voting[1] <i>does</i> always satisfy all four of Arrow's criteria[2].<p>To use an analogy from computer science, the halting problem is undecidable in the general case, but that doesn't prevent <em>static</em> <em>analysis</em> <em>tools</em> from spotting many infinite loops; it just means it can't spot <i>all</i> infinite loops with 100% accuracy.<p>[0] <a href=\"https://en.wikipedia.org/wiki/Amartya_Sen\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Amartya_Sen</a><p>[1] <a href=\"https://en.wikipedia.org/wiki/Instant-runoff_voting\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Instant-runoff_voting</a><p>[2] A different example: instead of making assumptions about the relative frequencies, we could make assumptions about the number of axes that candidates may have and the way they cluster around them. This realistically depicts both two-party and multiparty elections in most parts of the world, since political positions are not uniformly distributed along <i>n</i> dimensions.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Arrow's impossibility theorem",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-28T12:09:43.000Z",
      "title": null,
      "url": null,
      "author": "ngrilly",
      "points": null,
      "story_text": null,
      "comment_text": "Should we expect every discussion about PL to be an occasion to rant against languages designed at Google?<p>&gt; I think it&#x27;s fair to say that C# is a better language than Go.<p>According to what criteria?<p>&gt; The biggest flaw in Go (lack of generics) is met with the weak excuse that they haven&#x27;t figured out how to do it right.<p>I agree that generics would be useful in Go. But this is hardly a major issue for day-to-day programming in most projects.<p>Here is a better explanation of why Go has no generics, by Ian Lance Taylor, a member of the core team:<p><a href=\"https:&#x2F;&#x2F;groups.google.com&#x2F;d&#x2F;msg&#x2F;golang-nuts&#x2F;smT_0BhHfBs&#x2F;MWwGlB-n40kJ\" rel=\"nofollow\">https:&#x2F;&#x2F;groups.google.com&#x2F;d&#x2F;msg&#x2F;golang-nuts&#x2F;smT_0BhHfBs&#x2F;MWwG...</a><p>&gt; I don&#x27;t know much about Dart, but Typescript is a stellar language.<p>I don&#x27;t know Dart either, but I&#x27;m wondering how you can compare Typescript and Dart if you happen to know only the former.<p>&gt; Google, on the other hand, favors pragmatism over theory and prefers to draw on software engineering experience. Google&#x27;s languages aren&#x27;t bad, they just don&#x27;t seem to have much going for them as languages. Their failings are partly made up for in other things, like the toolchain, libraries, etc.<p>I mostly agree with this.<p>&gt; it&#x27;s clear that PL theory does lead to better languages<p>Languages are not everything. PL theory can also lead to better tools, that work on existing &quot;traditional&quot; languages (the obvious example being static analysis tools).",
      "num_comments": null,
      "story_id": 9614178,
      "story_title": "What is PL research and how is it useful?",
      "story_url": "http://www.pl-enthusiast.net/2015/05/27/what-is-pl-research-and-how-is-it-useful/",
      "parent_id": 9615529,
      "created_at_i": 1432814983,
      "_tags": [
        "comment",
        "author_ngrilly",
        "story_9614178"
      ],
      "objectID": "9617512",
      "_highlightResult": {
        "author": {
          "value": "ngrilly",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Should we expect every discussion about PL to be an occasion to rant against languages designed at Google?<p>&gt; I think it's fair to say that C# is a better language than Go.<p>According to what criteria?<p>&gt; The biggest flaw in Go (lack of generics) is met with the weak excuse that they haven't figured out how to do it right.<p>I agree that generics would be useful in Go. But this is hardly a major issue for day-to-day programming in most projects.<p>Here is a better explanation of why Go has no generics, by Ian Lance Taylor, a member of the core team:<p><a href=\"https://groups.google.com/d/msg/golang-nuts/smT_0BhHfBs/MWwGlB-n40kJ\" rel=\"nofollow\">https://groups.google.com/d/msg/golang-nuts/smT_0BhHfBs/MWwG...</a><p>&gt; I don't know much about Dart, but Typescript is a stellar language.<p>I don't know Dart either, but I'm wondering how you can compare Typescript and Dart if you happen to know only the former.<p>&gt; Google, on the other hand, favors pragmatism over theory and prefers to draw on software engineering experience. Google's languages aren't bad, they just don't seem to have much going for them as languages. Their failings are partly made up for in other things, like the toolchain, libraries, etc.<p>I mostly agree with this.<p>&gt; it's clear that PL theory does lead to better languages<p>Languages are not everything. PL theory can also lead to better <em>tools</em>, that work on existing &quot;traditional&quot; languages (the obvious example being <em>static</em> <em>analysis</em> <em>tools</em>).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What is PL research and how is it useful?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.pl-enthusiast.net/2015/05/27/what-is-pl-research-and-how-is-it-useful/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-27T21:48:52.000Z",
      "title": null,
      "url": null,
      "author": "nickcano",
      "points": null,
      "story_text": null,
      "comment_text": "So a structural engineer shouldn&#x27;t worry about the structural integrity of his buildings, only that they stand up under ideal conditions? A car manufacturer shouldn&#x27;t worry about crash-testing or other safety concerns, only that their car moves?<p>HOW DOES THAT MAKE ANY SENSE?!?!<p>Like it or not, we&#x27;re stuck on Von Neumann architecture, and as a result, data can be treated as code and vice-versa. The consequence of this is that, under certain circumstances, data can be carefully crafted to act as code, and can be executed in an unforeseen context. As a software engineer, <i>it is your job</i> to take precautions when developing software. Precautions that prevent this execution. Security people do the best they can to make it easy to develop safely, but all of that is <i>useless</i> if the developers ignore it. And, because security vulnerabilities are a manipulation of context-and-program-specific control flow, there&#x27;s not a way to encapsulate all security measures in a way that is transparent. It&#x27;s just not possible. Only developers know the specifics of their software, and only developers can protect certain edge cases. If you assert otherwise, you have a fundamental misunderstanding of the systems that you work with, and you need to re-evaluate your education before continuing to work in the industry (assuming you do). This isn&#x27;t an opinion. This is a fact.<p>Lastly, us &quot;security experts&quot; do contribute to our field. Security is one of the hard problems in computer science - far harder than whatever you&#x27;re doing that lets you <i>&quot;not think about databases, deployment, testing, scaling&quot;</i> - and there&#x27;s a lot of solutions that have been engineered to deal with software that has been created by people like you. There&#x27;s <i>static code analysis tools</i>, which can detect bugs in code before it is even compiled. There&#x27;s <i>memory analyzers</i> that can detect dozens of different classes of memory-related bugs by just watching your software run. There&#x27;s <i>memory allocators</i> and <i>garbage collectors</i> that can prevent issues with use-after-free and other heap-related exploitation bugs at run-time. There&#x27;s <i>data execution prevention</i> and <i>buffer execution prevention</i> that, at run-time, help prevent code from being executed from data pages. There&#x27;s <i>EMET</i> and other real-time exploit detection tools that exist outside of your software and can still prevent exploitation. That&#x27;s not even an exhaustive list. There are literally hundreds of tools out there that make finding and fixing security bugs easy, but those tools can&#x27;t patch your code for you. That&#x27;s why there are consultants, code auditors, and penetration-testers that can give advice on how to fix bugs, find bugs where automated tools fail, and even coach developers into writing more secure code; because having smart, security aware developers is one of the major ways to defend against security bugs.",
      "num_comments": null,
      "story_id": 9609887,
      "story_title": "Over 30% of Official Images in Docker Hub Contain Security Vulnerabilities",
      "story_url": "http://www.banyanops.com/blog/analyzing-docker-hub/",
      "parent_id": 9614391,
      "created_at_i": 1432763332,
      "_tags": [
        "comment",
        "author_nickcano",
        "story_9609887"
      ],
      "objectID": "9614612",
      "_highlightResult": {
        "author": {
          "value": "nickcano",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "So a structural engineer shouldn't worry about the structural integrity of his buildings, only that they stand up under ideal conditions? A car manufacturer shouldn't worry about crash-testing or other safety concerns, only that their car moves?<p>HOW DOES THAT MAKE ANY SENSE?!?!<p>Like it or not, we're stuck on Von Neumann architecture, and as a result, data can be treated as code and vice-versa. The consequence of this is that, under certain circumstances, data can be carefully crafted to act as code, and can be executed in an unforeseen context. As a software engineer, <i>it is your job</i> to take precautions when developing software. Precautions that prevent this execution. Security people do the best they can to make it easy to develop safely, but all of that is <i>useless</i> if the developers ignore it. And, because security vulnerabilities are a manipulation of context-and-program-specific control flow, there's not a way to encapsulate all security measures in a way that is transparent. It's just not possible. Only developers know the specifics of their software, and only developers can protect certain edge cases. If you assert otherwise, you have a fundamental misunderstanding of the systems that you work with, and you need to re-evaluate your education before continuing to work in the industry (assuming you do). This isn't an opinion. This is a fact.<p>Lastly, us &quot;security experts&quot; do contribute to our field. Security is one of the hard problems in computer science - far harder than whatever you're doing that lets you <i>&quot;not think about databases, deployment, testing, scaling&quot;</i> - and there's a lot of solutions that have been engineered to deal with software that has been created by people like you. There's <i><em>static</em> code <em>analysis</em> <em>tools</em></i>, which can detect bugs in code before it is even compiled. There's <i>memory analyzers</i> that can detect dozens of different classes of memory-related bugs by just watching your software run. There's <i>memory allocators</i> and <i>garbage collectors</i> that can prevent issues with use-after-free and other heap-related exploitation bugs at run-time. There's <i>data execution prevention</i> and <i>buffer execution prevention</i> that, at run-time, help prevent code from being executed from data pages. There's <i>EMET</i> and other real-time exploit detection <em>tools</em> that exist outside of your software and can still prevent exploitation. That's not even an exhaustive list. There are literally hundreds of <em>tools</em> out there that make finding and fixing security bugs easy, but those <em>tools</em> can't patch your code for you. That's why there are consultants, code auditors, and penetration-testers that can give advice on how to fix bugs, find bugs where automated <em>tools</em> fail, and even coach developers into writing more secure code; because having smart, security aware developers is one of the major ways to defend against security bugs.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Over 30% of Official Images in Docker Hub Contain Security Vulnerabilities",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.banyanops.com/blog/analyzing-docker-hub/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-19T16:07:45.000Z",
      "title": null,
      "url": null,
      "author": "lambdaelite",
      "points": null,
      "story_text": null,
      "comment_text": "Keep in mind they don&#x27;t use C&#x2F;C++.  They use C&#x2F;C++ with a coding standard (like MISRA), static analysis tools, validated compilers, development processes incorporating change control, documentation, verification and validation, etc.<p>What alternative are you suggesting?",
      "num_comments": null,
      "story_id": 9569077,
      "story_title": "A400M Airbus Flier crashed because of software issues",
      "story_url": "http://translate.google.com/translate?hl=en&sl=de&u=http://www.spiegel.de/politik/ausland/airbus-a400m-militaermaschine-stuerzte-wegen-software-problemen-ab-a-1034421.html",
      "parent_id": 9570903,
      "created_at_i": 1432051665,
      "_tags": [
        "comment",
        "author_lambdaelite",
        "story_9569077"
      ],
      "objectID": "9571136",
      "_highlightResult": {
        "author": {
          "value": "lambdaelite",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Keep in mind they don't use C/C++.  They use C/C++ with a coding standard (like MISRA), <em>static</em> <em>analysis</em> <em>tools</em>, validated compilers, development processes incorporating change control, documentation, verification and validation, etc.<p>What alternative are you suggesting?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "A400M Airbus Flier crashed because of software issues",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://translate.google.com/translate?hl=en&sl=de&u=http://www.spiegel.de/politik/ausland/airbus-a400m-militaermaschine-stuerzte-wegen-software-problemen-ab-a-1034421.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-19T15:57:35.000Z",
      "title": null,
      "url": null,
      "author": "Jtsummers",
      "points": null,
      "story_text": null,
      "comment_text": "Erlang&#x27;s model is entirely appropriate, but the language and VM aren&#x27;t. This code is often running on small embedded chips (so you&#x27;d need to port the VM) and the software has hard real-time requirements, which the Erlang VM is not (currently) set up to handle, nor would it necessarily be able to achieve on the commonly used processors. Another strike against the language (as much as I love it) is that it&#x27;s dynamically typed. That&#x27;s less appropriate for this sort of software. There are static analysis tools for Erlang that mitigate this, but it&#x27;s still an issue. Large classes of bugs and errors can be eliminated or minimized with statically typed languages or with static analysis tools if they&#x27;re well integrated into the build process. A real-time, statically typed language with Erlang&#x27;s semantics and compiled to native binaries would be a boon, however.<p>I&#x27;ll speak to the 787 avionics system. It used a system of channels&#x2F;buffers and processes very much like what Erlang and Go use for interprocess communication (I&#x27;m trying to remember now if channels could be received in multiple processes like Go or if only a single process could receive like in Erlang). This was an excellent model for what we were doing, and really for a lot of systems this sort of CSP and actor style model maps well.",
      "num_comments": null,
      "story_id": 9569077,
      "story_title": "A400M Airbus Flier crashed because of software issues",
      "story_url": "http://translate.google.com/translate?hl=en&sl=de&u=http://www.spiegel.de/politik/ausland/airbus-a400m-militaermaschine-stuerzte-wegen-software-problemen-ab-a-1034421.html",
      "parent_id": 9570489,
      "created_at_i": 1432051055,
      "_tags": [
        "comment",
        "author_Jtsummers",
        "story_9569077"
      ],
      "objectID": "9571053",
      "_highlightResult": {
        "author": {
          "value": "Jtsummers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Erlang's model is entirely appropriate, but the language and VM aren't. This code is often running on small embedded chips (so you'd need to port the VM) and the software has hard real-time requirements, which the Erlang VM is not (currently) set up to handle, nor would it necessarily be able to achieve on the commonly used processors. Another strike against the language (as much as I love it) is that it's dynamically typed. That's less appropriate for this sort of software. There are <em>static</em> <em>analysis</em> <em>tools</em> for Erlang that mitigate this, but it's still an issue. Large classes of bugs and errors can be eliminated or minimized with statically typed languages or with <em>static</em> <em>analysis</em> <em>tools</em> if they're well integrated into the build process. A real-time, statically typed language with Erlang's semantics and compiled to native binaries would be a boon, however.<p>I'll speak to the 787 avionics system. It used a system of channels/buffers and processes very much like what Erlang and Go use for interprocess communication (I'm trying to remember now if channels could be received in multiple processes like Go or if only a single process could receive like in Erlang). This was an excellent model for what we were doing, and really for a lot of systems this sort of CSP and actor style model maps well.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "A400M Airbus Flier crashed because of software issues",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://translate.google.com/translate?hl=en&sl=de&u=http://www.spiegel.de/politik/ausland/airbus-a400m-militaermaschine-stuerzte-wegen-software-problemen-ab-a-1034421.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-13T08:00:59.000Z",
      "title": null,
      "url": null,
      "author": "derefr",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; but a description of the algorithm plus language-specific information that&#x27;s supposed to help the particular platform execute the algorithm efficiently<p>Tracing JITs should be able to spit out, as they run, the tables of Bayesian confidences they&#x27;ve built up for various static properties of the code, which can sit along with things like source maps, and be confirmed&#x2F;rejected by the programmer in their IDE, or just live-reloaded into a new VM ala a Smalltalk image. (Future-tech, remember.) You can see the potential for this in things like Erlang&#x27;s typer+dialyzer system.<p>Likewise, static analysis tools should be able to work on foreign code after transpilation. There&#x27;s nothing stopping you from transforming C code into Rust code in order to get the Rust compiler&#x27;s opinion on its ownership semantics.<p>Note that I&#x27;m not saying that there&#x27;s one universal underlying language semantics. Just that language semantics (which consist of such things as a type system, a threading&#x2F;memory model, etc.) have no reason to be tied to either a particular syntax, or a particular VM. (Effectively, a language semantics forms an <i>abstract machine</i> that executes more or less efficiently on the substrate of any given VM. MRI Ruby is a direct substrate for Ruby semantics; IronRuby is less-clear substrate; etc.)<p>&gt; those may significantly affect the suitability of an algorithm for a certain language<p>This is a problem of transparent distribution. I&#x27;ve been working on an Elixir DSL for writing Haskell &quot;inside&quot; Elixir for efficiency. The result is not a Haskell compiled module getting linked into the Erlang VM, but rather a separate Erlang-VM-managed Haskell &quot;application server&quot; being run as a port program. I foresee much more of this, and much more cleverness about it: writing code that compiles to a bunch of separate modules <i>for separate VMs</i>, which then form a micro-distributed-system all within a Docker container or somesuch.<p>Again, it&#x27;s not about eliminating the plurality of runtimes—it&#x27;s about rendering that plurality <i>moot</i>, abstracting it away from the perspective of the programmer and leaving it up to the implementation to decide how to optimize abstract-machine-to-VM allocation.<p>There&#x27;s no reason that you can&#x27;t have every language semantics available to any library, to use in any combination (this parameterized type system with that green-threading and this other GC, etc.) It&#x27;s just that, in so doing, you&#x27;re either transparently importing into your single runtime some virtualization layers for all the other abstract machines you&#x27;ve coded in terms of (somewhat like writing a Windows app on Linux by linking it to Wine), or you&#x27;ve let the Sufficiently Smart Code-generator go beyond the premise of having a single target platform.",
      "num_comments": null,
      "story_id": 9537121,
      "story_title": "On Rust Hate-Writing",
      "story_url": "https://graydon2.dreamwidth.org/209581.html",
      "parent_id": 9537325,
      "created_at_i": 1431504059,
      "_tags": [
        "comment",
        "author_derefr",
        "story_9537121"
      ],
      "objectID": "9537435",
      "_highlightResult": {
        "author": {
          "value": "derefr",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; but a description of the algorithm plus language-specific information that's supposed to help the particular platform execute the algorithm efficiently<p>Tracing JITs should be able to spit out, as they run, the tables of Bayesian confidences they've built up for various <em>static</em> properties of the code, which can sit along with things like source maps, and be confirmed/rejected by the programmer in their IDE, or just live-reloaded into a new VM ala a Smalltalk image. (Future-tech, remember.) You can see the potential for this in things like Erlang's typer+dialyzer system.<p>Likewise, <em>static</em> <em>analysis</em> <em>tools</em> should be able to work on foreign code after transpilation. There's nothing stopping you from transforming C code into Rust code in order to get the Rust compiler's opinion on its ownership semantics.<p>Note that I'm not saying that there's one universal underlying language semantics. Just that language semantics (which consist of such things as a type system, a threading/memory model, etc.) have no reason to be tied to either a particular syntax, or a particular VM. (Effectively, a language semantics forms an <i>abstract machine</i> that executes more or less efficiently on the substrate of any given VM. MRI Ruby is a direct substrate for Ruby semantics; IronRuby is less-clear substrate; etc.)<p>&gt; those may significantly affect the suitability of an algorithm for a certain language<p>This is a problem of transparent distribution. I've been working on an Elixir DSL for writing Haskell &quot;inside&quot; Elixir for efficiency. The result is not a Haskell compiled module getting linked into the Erlang VM, but rather a separate Erlang-VM-managed Haskell &quot;application server&quot; being run as a port program. I foresee much more of this, and much more cleverness about it: writing code that compiles to a bunch of separate modules <i>for separate VMs</i>, which then form a micro-distributed-system all within a Docker container or somesuch.<p>Again, it's not about eliminating the plurality of runtimes—it's about rendering that plurality <i>moot</i>, abstracting it away from the perspective of the programmer and leaving it up to the implementation to decide how to optimize abstract-machine-to-VM allocation.<p>There's no reason that you can't have every language semantics available to any library, to use in any combination (this parameterized type system with that green-threading and this other GC, etc.) It's just that, in so doing, you're either transparently importing into your single runtime some virtualization layers for all the other abstract machines you've coded in terms of (somewhat like writing a Windows app on Linux by linking it to Wine), or you've let the Sufficiently Smart Code-generator go beyond the premise of having a single target platform.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "On Rust Hate-Writing",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://graydon2.dreamwidth.org/209581.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-04T09:12:02.000Z",
      "title": null,
      "url": null,
      "author": "weland",
      "points": null,
      "story_text": null,
      "comment_text": "Absolutely. If you&#x27;re audited for MISRA compliance, you need to follow it point by point.<p>The rules themselves are not meaningless or without a point, but there are a lot of companies that adopt MISRA without actually <i>having</i> (in the sense of audit and certification) to be compliant. Instead of focusing on <i>the point</i> of every provision, they rigidly follow them even when not applicable.<p>But it can be worse, really. The gem of a coding standard we have at $work forbids not only goto, but also break, without MISRA&#x27;s exception of one break per loop. And forbidding the use of goto and continue is cited as being done for readability reasons, rather than static analysis tools.",
      "num_comments": null,
      "story_id": 9477006,
      "story_title": "Death to C",
      "story_url": "http://techcrunch.com/2015/05/02/and-c-plus-plus-too/",
      "parent_id": 9482909,
      "created_at_i": 1430730722,
      "_tags": [
        "comment",
        "author_weland",
        "story_9477006"
      ],
      "objectID": "9485086",
      "_highlightResult": {
        "author": {
          "value": "weland",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Absolutely. If you're audited for MISRA compliance, you need to follow it point by point.<p>The rules themselves are not meaningless or without a point, but there are a lot of companies that adopt MISRA without actually <i>having</i> (in the sense of audit and certification) to be compliant. Instead of focusing on <i>the point</i> of every provision, they rigidly follow them even when not applicable.<p>But it can be worse, really. The gem of a coding standard we have at $work forbids not only goto, but also break, without MISRA's exception of one break per loop. And forbidding the use of goto and continue is cited as being done for readability reasons, rather than <em>static</em> <em>analysis</em> <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Death to C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://techcrunch.com/2015/05/02/and-c-plus-plus-too/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-04T05:55:56.000Z",
      "title": null,
      "url": null,
      "author": "kibwen",
      "points": null,
      "story_text": null,
      "comment_text": "NBD, I was being a little overzealous there myself. :) IME when most people say &quot;static analysis&quot; they&#x27;re referring to tools that attempt to detect the usual class of memory vulnerabilities that Rust prevents outright (or maybe they do even worse and just attempt to detect typical coding patterns which happen to be correlated with the same).<p>Part of my zeal is also that Rust&#x27;s semantics are strictly, er, stricter than C&#x27;s (disregarding the quagmire of C&#x27;s undefined behavior), which means that static analysis tools should be even easier to write for it.",
      "num_comments": null,
      "story_id": 9476139,
      "story_title": "Integer Overflow Bug in Boeing 787 Dreamliner",
      "story_url": "http://www.engadget.com/2015/05/01/boeing-787-dreamliner-software-bug/",
      "parent_id": 9480823,
      "created_at_i": 1430718956,
      "_tags": [
        "comment",
        "author_kibwen",
        "story_9476139"
      ],
      "objectID": "9484550",
      "_highlightResult": {
        "author": {
          "value": "kibwen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "NBD, I was being a little overzealous there myself. :) IME when most people say &quot;<em>static</em> <em>analysis</em>&quot; they're referring to <em>tools</em> that attempt to detect the usual class of memory vulnerabilities that Rust prevents outright (or maybe they do even worse and just attempt to detect typical coding patterns which happen to be correlated with the same).<p>Part of my zeal is also that Rust's semantics are strictly, er, stricter than C's (disregarding the quagmire of C's undefined behavior), which means that <em>static</em> <em>analysis</em> <em>tools</em> should be even easier to write for it.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Integer Overflow Bug in Boeing 787 Dreamliner",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.engadget.com/2015/05/01/boeing-787-dreamliner-software-bug/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-03T22:18:04.000Z",
      "title": null,
      "url": null,
      "author": "ufo",
      "points": null,
      "story_text": null,
      "comment_text": "Weird to see references to soft typing (something quite old that didn&#x27;t quite work out) and no references to the much more recent Diamondback Ruby: <a href=\"http:&#x2F;&#x2F;www.cs.umd.edu&#x2F;projects&#x2F;PL&#x2F;druby&#x2F;\" rel=\"nofollow\">http:&#x2F;&#x2F;www.cs.umd.edu&#x2F;projects&#x2F;PL&#x2F;druby&#x2F;</a>\nIt was a research project from the fine folks at the university of Maryland but it lost steam because Ruby is so dynamic that its very very hard to write static analysis tools for it.<p><a href=\"http:&#x2F;&#x2F;www.cs.purdue.edu&#x2F;homes&#x2F;jv&#x2F;events&#x2F;PBD13&#x2F;slides&#x2F;JeffFoster.pdf\" rel=\"nofollow\">http:&#x2F;&#x2F;www.cs.purdue.edu&#x2F;homes&#x2F;jv&#x2F;events&#x2F;PBD13&#x2F;slides&#x2F;JeffFo...</a><p>There are some misconceptions about the the Soft Typing approach though that I think I should clear out a bit:<p>* What a soft typing system does is use type inference techniques to try to figure out what locations in the program might raise dynamic type errors (accessing inexistent methods, etc).<p>* Soft typing systems do not check the types of function parameters and return values (since just passing a value around never cause the itnerpreter to throw an error). Some non-soft type systems might check though, adding runtime contract checks if needed.<p>* Soft typing can guarantee safety if you write your program in a way where the type checker manages to infer a static type for everything.<p>* On the other hand, writing things in a way that satisfies the type inferencer can be very hard. And to acomodate the flexibility of dynamic languages the type system might evolve into something quite complex. This is an even larger issue for Ruby, which is highly dynamic and has no formal spec.<p>* The 1991 soft typing paper focuses a lot on speed because back then dynamic type checks were a big reason for the slowness of dynamic language implementations. Nowadays we have tracing JITs (which &quot;inline&quot; away all the type checks, method dispatches, and so on) so there is less of a need to use type inference to speed things up.",
      "num_comments": null,
      "story_id": 9481186,
      "story_title": "Consider Static Typing in Ruby",
      "story_url": "http://codon.com/consider-static-typing",
      "parent_id": 9481186,
      "created_at_i": 1430691484,
      "_tags": [
        "comment",
        "author_ufo",
        "story_9481186"
      ],
      "objectID": "9483307",
      "_highlightResult": {
        "author": {
          "value": "ufo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Weird to see references to soft typing (something quite old that didn't quite work out) and no references to the much more recent Diamondback Ruby: <a href=\"http://www.cs.umd.edu/projects/PL/druby/\" rel=\"nofollow\">http://www.cs.umd.edu/projects/PL/druby/</a>\nIt was a research project from the fine folks at the university of Maryland but it lost steam because Ruby is so dynamic that its very very hard to write <em>static</em> <em>analysis</em> <em>tools</em> for it.<p><a href=\"http://www.cs.purdue.edu/homes/jv/events/PBD13/slides/JeffFoster.pdf\" rel=\"nofollow\">http://www.cs.purdue.edu/homes/jv/events/PBD13/slides/JeffFo...</a><p>There are some misconceptions about the the Soft Typing approach though that I think I should clear out a bit:<p>* What a soft typing system does is use type inference techniques to try to figure out what locations in the program might raise dynamic type errors (accessing inexistent methods, etc).<p>* Soft typing systems do not check the types of function parameters and return values (since just passing a value around never cause the itnerpreter to throw an error). Some non-soft type systems might check though, adding runtime contract checks if needed.<p>* Soft typing can guarantee safety if you write your program in a way where the type checker manages to infer a <em>static</em> type for everything.<p>* On the other hand, writing things in a way that satisfies the type inferencer can be very hard. And to acomodate the flexibility of dynamic languages the type system might evolve into something quite complex. This is an even larger issue for Ruby, which is highly dynamic and has no formal spec.<p>* The 1991 soft typing paper focuses a lot on speed because back then dynamic type checks were a big reason for the slowness of dynamic language implementations. Nowadays we have tracing JITs (which &quot;inline&quot; away all the type checks, method dispatches, and so on) so there is less of a need to use type inference to speed things up.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Consider <em>Static</em> Typing in Ruby",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "http://codon.com/consider-<em>static</em>-typing",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        }
      }
    },
    {
      "created_at": "2015-05-03T00:21:33.000Z",
      "title": null,
      "url": null,
      "author": "CHY872",
      "points": null,
      "story_text": null,
      "comment_text": "Ada is a good decision in this field.<p>Nevertheless, the parent was comparing C to Rust, where the language is immature, has no static analysis tools (to pick up the most important bugs), no well defined semantics and is entirely unproven in the field. This is the barrier for entry.",
      "num_comments": null,
      "story_id": 9476139,
      "story_title": "Integer Overflow Bug in Boeing 787 Dreamliner",
      "story_url": "http://www.engadget.com/2015/05/01/boeing-787-dreamliner-software-bug/",
      "parent_id": 9479023,
      "created_at_i": 1430612493,
      "_tags": [
        "comment",
        "author_CHY872",
        "story_9476139"
      ],
      "objectID": "9479161",
      "_highlightResult": {
        "author": {
          "value": "CHY872",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Ada is a good decision in this field.<p>Nevertheless, the parent was comparing C to Rust, where the language is immature, has no <em>static</em> <em>analysis</em> <em>tools</em> (to pick up the most important bugs), no well defined semantics and is entirely unproven in the field. This is the barrier for entry.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Integer Overflow Bug in Boeing 787 Dreamliner",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.engadget.com/2015/05/01/boeing-787-dreamliner-software-bug/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-02T18:57:55.000Z",
      "title": null,
      "url": null,
      "author": "weland",
      "points": null,
      "story_text": null,
      "comment_text": "In my experience, the major problem with standards like MISRA is that people read the rules, but rarely the rationale behind them, which makes every coding standard end up <i>encouraging</i> cargo cult bug avoidance.<p>Case in point: MISRA C forbids goto statements primarily because it can mess up static analysis. Yet this rule is gratuitously followed even when no static analysis tools are used, thus yielding none of the gains that you trade off for occasionally writing ugly code.",
      "num_comments": null,
      "story_id": 9477006,
      "story_title": "Death to C",
      "story_url": "http://techcrunch.com/2015/05/02/and-c-plus-plus-too/",
      "parent_id": 9477182,
      "created_at_i": 1430593075,
      "_tags": [
        "comment",
        "author_weland",
        "story_9477006"
      ],
      "objectID": "9478112",
      "_highlightResult": {
        "author": {
          "value": "weland",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In my experience, the major problem with standards like MISRA is that people read the rules, but rarely the rationale behind them, which makes every coding standard end up <i>encouraging</i> cargo cult bug avoidance.<p>Case in point: MISRA C forbids goto statements primarily because it can mess up <em>static</em> <em>analysis.</em> Yet this rule is gratuitously followed even when no <em>static</em> <em>analysis</em> <em>tools</em> are used, thus yielding none of the gains that you trade off for occasionally writing ugly code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Death to C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://techcrunch.com/2015/05/02/and-c-plus-plus-too/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-02T07:07:09.000Z",
      "title": null,
      "url": null,
      "author": "task_queue",
      "points": null,
      "story_text": null,
      "comment_text": "Text editors aren&#x27;t IDEs. However, static analysis tools are available for both emacs and vim.",
      "num_comments": null,
      "story_id": 9457973,
      "story_title": "Ask HN: Is anyone using a web IDE for most of their development work?",
      "story_url": "",
      "parent_id": 9459254,
      "created_at_i": 1430550429,
      "_tags": [
        "comment",
        "author_task_queue",
        "story_9457973"
      ],
      "objectID": "9476187",
      "_highlightResult": {
        "author": {
          "value": "task_queue",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Text editors aren't IDEs. However, <em>static</em> <em>analysis</em> <em>tools</em> are available for both emacs and vim.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Is anyone using a web IDE for most of their development work?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-28T11:48:42.000Z",
      "title": null,
      "url": null,
      "author": "geromek",
      "points": null,
      "story_text": null,
      "comment_text": "It is really interesting. You pointed that the static analysis tools are aimed at developers but even the guys from PVS-Studio admit their main customers are big companies with teams of developers and I agree. From my experience such companies &quot;force&quot; their developers to use these kind of tools. It is somehow paradoxical that such tools are so technical only developers understand their results but only managers want (or think they want) to consume them.",
      "num_comments": null,
      "story_id": 9450743,
      "story_title": "We Are Closing Down the CppCat Project",
      "story_url": "http://www.viva64.com/en/b/0320/",
      "parent_id": 9451497,
      "created_at_i": 1430221722,
      "_tags": [
        "comment",
        "author_geromek",
        "story_9450743"
      ],
      "objectID": "9451535",
      "_highlightResult": {
        "author": {
          "value": "geromek",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It is really interesting. You pointed that the <em>static</em> <em>analysis</em> <em>tools</em> are aimed at developers but even the guys from PVS-Studio admit their main customers are big companies with teams of developers and I agree. From my experience such companies &quot;force&quot; their developers to use these kind of <em>tools</em>. It is somehow paradoxical that such <em>tools</em> are so technical only developers understand their results but only managers want (or think they want) to consume them.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "We Are Closing Down the CppCat Project",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0320/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-27T14:52:24.000Z",
      "title": null,
      "url": null,
      "author": "wyldfire",
      "points": null,
      "story_text": null,
      "comment_text": "If they&#x27;d have called it a &quot;static analyzer&quot; they might have had an easier time selling it.  Businesses regularly shell out big bucks for C&#x2F;C++&#x2F;Java static analysis tools like Coverity, Klocwork, etc.<p>Static analysis is less likely to yield fruit (design errors and not false positives) in a language like Python.  So the bar&#x27;s definitely higher for these guys than it is for the static analysis tools for static-typed languages.",
      "num_comments": null,
      "story_id": 9446080,
      "story_title": "Automated code review for Python, Django, etc.",
      "story_url": "https://www.quantifiedcode.com",
      "parent_id": 9446522,
      "created_at_i": 1430146344,
      "_tags": [
        "comment",
        "author_wyldfire",
        "story_9446080"
      ],
      "objectID": "9446647",
      "_highlightResult": {
        "author": {
          "value": "wyldfire",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "If they'd have called it a &quot;<em>static</em> analyzer&quot; they might have had an easier time selling it.  Businesses regularly shell out big bucks for C/C++/Java <em>static</em> <em>analysis</em> <em>tools</em> like Coverity, Klocwork, etc.<p><em>Static</em> <em>analysis</em> is less likely to yield fruit (design errors and not false positives) in a language like Python.  So the bar's definitely higher for these guys than it is for the <em>static</em> <em>analysis</em> <em>tools</em> for <em>static</em>-typed languages.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Automated code review for Python, Django, etc.",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.quantifiedcode.com",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-27T01:31:38.000Z",
      "title": null,
      "url": null,
      "author": "TazeTSchnitzel",
      "points": null,
      "story_text": null,
      "comment_text": "The difference isn&#x27;t between the systems, it&#x27;s a difference in tooling, in that Hack comes with its own type checker. Part of the motivation for PHP 7&#x27;s expanded type hinting support was to enable better static analysis tools. I expect we&#x27;ll see something similar to Hack&#x27;s type checker for PHP 7 in not too long. Actually, some IDEs already check types, I think.<p>Of course, a tool for PHP 7 can only go so far, because PHP 7&#x27;s type hints aren&#x27;t sufficient to cover everything, unlike Hack which has things like nullable support.",
      "num_comments": null,
      "story_id": 9443241,
      "story_title": "Comparing the PHP 7 and Hack Type Systems",
      "story_url": "http://www.dmiller.io/blog/2015/4/26/comparing-the-php7-and-hack-type-systems",
      "parent_id": 9443705,
      "created_at_i": 1430098298,
      "_tags": [
        "comment",
        "author_TazeTSchnitzel",
        "story_9443241"
      ],
      "objectID": "9443998",
      "_highlightResult": {
        "author": {
          "value": "TazeTSchnitzel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The difference isn't between the systems, it's a difference in tooling, in that Hack comes with its own type checker. Part of the motivation for PHP 7's expanded type hinting support was to enable better <em>static</em> <em>analysis</em> <em>tools</em>. I expect we'll see something similar to Hack's type checker for PHP 7 in not too long. Actually, some IDEs already check types, I think.<p>Of course, a tool for PHP 7 can only go so far, because PHP 7's type hints aren't sufficient to cover everything, unlike Hack which has things like nullable support.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Comparing the PHP 7 and Hack Type Systems",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.dmiller.io/blog/2015/4/26/comparing-the-php7-and-hack-type-systems",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-26T12:22:59.000Z",
      "title": null,
      "url": null,
      "author": "EliRivers",
      "points": null,
      "story_text": null,
      "comment_text": "<i>Maybe the MISRA-C industry standard practices are ridiculous, out of touch and impractical.</i><p>I currently work in the static analysis industry. Broadly speaking, the MISRA-C ruleset is, in my experience and in the experience of many customers who apply it, not impractical, clearly of benefit, and the majority of rule violations (including a number of rules violated by Toyota) easily found with static analysis tools.<p>I even know that Toyota is a customer of (at least) one of the static analysis tool companies (obviously Toyota is a huge company, and I&#x27;ve no idea if the specific muppets making this clusterf had any static analysis tools; just that Toyota as a company definitely has someone buying them). It seems that they either just didn&#x27;t use it, or just didn&#x27;t care (or were told not to care).<p>As an extra point of data, I sit opposite someone who is on the MISRA-C committee. He is a solid C coder who knows a great deal about the language and how to get it wrong. His day job is writing&#x2F;maintaining static analysis tools for C programmes. Obviously this is no guarantee that the committee as a whole is good at maintaining the MISRA-C ruleset, but they do have at least one active, experienced and competent C coder (with lots of experience of having to actually automate detection of rule violations) at the table.",
      "num_comments": null,
      "story_id": 9440094,
      "story_title": "Toyota's killer firmware: Bad design and its consequences (2013)",
      "story_url": "http://www.edn.com/design/automotive/4423428/Toyota-s-killer-firmware--Bad-design-and-its-consequences",
      "parent_id": 9441152,
      "created_at_i": 1430050979,
      "_tags": [
        "comment",
        "author_EliRivers",
        "story_9440094"
      ],
      "objectID": "9441510",
      "_highlightResult": {
        "author": {
          "value": "EliRivers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>Maybe the MISRA-C industry standard practices are ridiculous, out of touch and impractical.</i><p>I currently work in the <em>static</em> <em>analysis</em> industry. Broadly speaking, the MISRA-C ruleset is, in my experience and in the experience of many customers who apply it, not impractical, clearly of benefit, and the majority of rule violations (including a number of rules violated by Toyota) easily found with <em>static</em> <em>analysis</em> <em>tools</em>.<p>I even know that Toyota is a customer of (at least) one of the <em>static</em> <em>analysis</em> tool companies (obviously Toyota is a huge company, and I've no idea if the specific muppets making this clusterf had any <em>static</em> <em>analysis</em> <em>tools</em>; just that Toyota as a company definitely has someone buying them). It seems that they either just didn't use it, or just didn't care (or were told not to care).<p>As an extra point of data, I sit opposite someone who is on the MISRA-C committee. He is a solid C coder who knows a great deal about the language and how to get it wrong. His day job is writing/maintaining <em>static</em> <em>analysis</em> <em>tools</em> for C programmes. Obviously this is no guarantee that the committee as a whole is good at maintaining the MISRA-C ruleset, but they do have at least one active, experienced and competent C coder (with lots of experience of having to actually automate detection of rule violations) at the table.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Toyota's killer firmware: Bad design and its consequences (2013)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.edn.com/design/automotive/4423428/Toyota-s-killer-firmware--Bad-design-and-its-consequences",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-26T05:05:29.000Z",
      "title": null,
      "url": null,
      "author": "cpeterso",
      "points": null,
      "story_text": null,
      "comment_text": "How much code reuse is there between the firmware in a manufacturer&#x27;s different car models? I&#x27;m surprised there isn&#x27;t a consortium (like Symbian was) to create a standard firmware kernel to share the benefits (and costs) of testing and auditing the code.<p>I&#x27;m also surprised C is still so commonly used for mission critical software. I understand that C is familiar, has many static analysis tools (to make up for the language&#x27;s deficiencies), and has a straight-forward translation from C to object code (though only when using simple optimizations). For example, if MISRA-C&#x27;s coding guidelines disallow recursion, why not design a language that only supports DAG function dependencies?",
      "num_comments": null,
      "story_id": 9440094,
      "story_title": "Toyota's killer firmware: Bad design and its consequences (2013)",
      "story_url": "http://www.edn.com/design/automotive/4423428/Toyota-s-killer-firmware--Bad-design-and-its-consequences",
      "parent_id": 9440094,
      "created_at_i": 1430024729,
      "_tags": [
        "comment",
        "author_cpeterso",
        "story_9440094"
      ],
      "objectID": "9440611",
      "_highlightResult": {
        "author": {
          "value": "cpeterso",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "How much code reuse is there between the firmware in a manufacturer's different car models? I'm surprised there isn't a consortium (like Symbian was) to create a standard firmware kernel to share the benefits (and costs) of testing and auditing the code.<p>I'm also surprised C is still so commonly used for mission critical software. I understand that C is familiar, has many <em>static</em> <em>analysis</em> <em>tools</em> (to make up for the language's deficiencies), and has a straight-forward translation from C to object code (though only when using simple optimizations). For example, if MISRA-C's coding guidelines disallow recursion, why not design a language that only supports DAG function dependencies?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Toyota's killer firmware: Bad design and its consequences (2013)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.edn.com/design/automotive/4423428/Toyota-s-killer-firmware--Bad-design-and-its-consequences",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-08T21:23:08.000Z",
      "title": null,
      "url": null,
      "author": "konceptz",
      "points": null,
      "story_text": null,
      "comment_text": "I often run static analysis tools against large code bases.<p>As a consultant I need to be able to travel and won&#x27;t always have access, or be able to send code across the internet.<p>I think my case is common for technical consultants doing deep code inspection.",
      "num_comments": null,
      "story_id": 9341238,
      "story_title": "Dell XPS 13 Developer Edition",
      "story_url": "http://www.dell.com/us/business/p/xps-13-linux/pd",
      "parent_id": 9341496,
      "created_at_i": 1428528188,
      "_tags": [
        "comment",
        "author_konceptz",
        "story_9341238"
      ],
      "objectID": "9344096",
      "_highlightResult": {
        "author": {
          "value": "konceptz",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I often run <em>static</em> <em>analysis</em> <em>tools</em> against large code bases.<p>As a consultant I need to be able to travel and won't always have access, or be able to send code across the internet.<p>I think my case is common for technical consultants doing deep code inspection.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dell XPS 13 Developer Edition",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.dell.com/us/business/p/xps-13-linux/pd",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-06T14:28:17.000Z",
      "title": null,
      "url": null,
      "author": "dsacco",
      "points": null,
      "story_text": null,
      "comment_text": "<i>&gt;&gt; The same logic means that people shouldn&#x27;t use static code analysis tools, or valgrind, or even debuggers, until they acquire deep technical knowledge. While I think all of these tools help reinforce the principles.</i><p>This probably sounds controversial, but I agree. I don&#x27;t think you should use Valgrind until you understand how Valgrind works. This doesn&#x27;t mean early C programmers shouldn&#x27;t use Valgrind - you can read the documentation and theory behind Valgrind in a day. But definitely <i>do</i> that. I think maybe &quot;deep technical knowledge&quot; wasn&#x27;t the right term for me to use. A better term would be &quot;technical understanding&quot; - know how it works, and know how to find the different classes of bugs it can find, but you do not need to be capable of writing the tool yourself.<p>Now let me clarify this, and my earlier point about afl - I think you <i>should</i> use them, and generously, and pretty much always once you know what you&#x27;re doing. But if you use them without understanding the fundamentals, you will get caught up in false positives&#x2F;negatives. Always use it as a supplement, not a crutch.<p>However, I agree with what you&#x27;re saying about someone&#x27;s level of dedication to security analysis. Using afl is better than not using afl, so if you&#x27;re not a dedicated security guy, then you&#x27;re definitely right that someone should use it.<p>I would still caution anyone that using an automated tool without fully understanding how it works will lead to an incomplete picture of the application&#x27;s security posture.",
      "num_comments": null,
      "story_id": 9327394,
      "story_title": "$9000 bounty paid for Python bugs",
      "story_url": "https://hackerone.com/reports/55017",
      "parent_id": 9328174,
      "created_at_i": 1428330497,
      "_tags": [
        "comment",
        "author_dsacco",
        "story_9327394"
      ],
      "objectID": "9328215",
      "_highlightResult": {
        "author": {
          "value": "dsacco",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>&gt;&gt; The same logic means that people shouldn't use <em>static</em> code <em>analysis</em> <em>tools</em>, or valgrind, or even debuggers, until they acquire deep technical knowledge. While I think all of these <em>tools</em> help reinforce the principles.</i><p>This probably sounds controversial, but I agree. I don't think you should use Valgrind until you understand how Valgrind works. This doesn't mean early C programmers shouldn't use Valgrind - you can read the documentation and theory behind Valgrind in a day. But definitely <i>do</i> that. I think maybe &quot;deep technical knowledge&quot; wasn't the right term for me to use. A better term would be &quot;technical understanding&quot; - know how it works, and know how to find the different classes of bugs it can find, but you do not need to be capable of writing the tool yourself.<p>Now let me clarify this, and my earlier point about afl - I think you <i>should</i> use them, and generously, and pretty much always once you know what you're doing. But if you use them without understanding the fundamentals, you will get caught up in false positives/negatives. Always use it as a supplement, not a crutch.<p>However, I agree with what you're saying about someone's level of dedication to security <em>analysis.</em> Using afl is better than not using afl, so if you're not a dedicated security guy, then you're definitely right that someone should use it.<p>I would still caution anyone that using an automated tool without fully understanding how it works will lead to an incomplete picture of the application's security posture.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "$9000 bounty paid for Python bugs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://hackerone.com/reports/55017",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-06T14:17:18.000Z",
      "title": null,
      "url": null,
      "author": "dalke",
      "points": null,
      "story_text": null,
      "comment_text": "I realize there&#x27;s a philosophy that it&#x27;s best to start from the lowest levels and work one&#x27;s way up. It&#x27;s one I can empathize with, in spirit, though I disagree.<p>The same logic means that people shouldn&#x27;t use static code analysis tools, or valgrind, or even debuggers, until they acquire deep technical knowledge. While I think all of these tools help reinforce the principles.<p><i>If</i> someone starts with the fixed and unwavering goal of security analysis in mind, then perhaps I can agree with you. If however someone is only curious about security analysis, and finds that spending a year to &quot;grok the theory&quot; is a high barrier, then even clumsy use of semi-automated tools may provide more concrete incentive to learn the underlying skills.<p>While I don&#x27;t believe you are correct, another question is, how many white hats do we end up with? Even if it takes 2 years to learn security skills by using automation, and only 1 year without automation, if after 10 years there are 500 following your path, while 10,000 following my path, then that&#x27;s a net gain for the good side, yes? (I assume that there is such a thing as &quot;good enough&quot;, and that it&#x27;s relatively stable. Obviously if there is only a market for 500, and your 500 are always better than my 10,000 then that changes the dynamics.)<p>Finally, it&#x27;s also good to have even the script kiddies on the side of good than the side of lolz.",
      "num_comments": null,
      "story_id": 9327394,
      "story_title": "$9000 bounty paid for Python bugs",
      "story_url": "https://hackerone.com/reports/55017",
      "parent_id": 9328003,
      "created_at_i": 1428329838,
      "_tags": [
        "comment",
        "author_dalke",
        "story_9327394"
      ],
      "objectID": "9328174",
      "_highlightResult": {
        "author": {
          "value": "dalke",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I realize there's a philosophy that it's best to start from the lowest levels and work one's way up. It's one I can empathize with, in spirit, though I disagree.<p>The same logic means that people shouldn't use <em>static</em> code <em>analysis</em> <em>tools</em>, or valgrind, or even debuggers, until they acquire deep technical knowledge. While I think all of these <em>tools</em> help reinforce the principles.<p><i>If</i> someone starts with the fixed and unwavering goal of security <em>analysis</em> in mind, then perhaps I can agree with you. If however someone is only curious about security <em>analysis</em>, and finds that spending a year to &quot;grok the theory&quot; is a high barrier, then even clumsy use of semi-automated <em>tools</em> may provide more concrete incentive to learn the underlying skills.<p>While I don't believe you are correct, another question is, how many white hats do we end up with? Even if it takes 2 years to learn security skills by using automation, and only 1 year without automation, if after 10 years there are 500 following your path, while 10,000 following my path, then that's a net gain for the good side, yes? (I assume that there is such a thing as &quot;good enough&quot;, and that it's relatively stable. Obviously if there is only a market for 500, and your 500 are always better than my 10,000 then that changes the dynamics.)<p>Finally, it's also good to have even the script kiddies on the side of good than the side of lolz.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "$9000 bounty paid for Python bugs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://hackerone.com/reports/55017",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-06T14:01:18.000Z",
      "title": null,
      "url": null,
      "author": "exDM69",
      "points": null,
      "story_text": null,
      "comment_text": "I agree with you if we&#x27;re talking about someone who is just getting started in programming and debugging. It&#x27;s not a good starting point if you want to understand why these bugs exist or how to exploit them.<p>But if we&#x27;re talking about someone who is already a competent programmer, perhaps looking to learn a new tool, there&#x27;s just no point (except perhaps learning) in trying to find bugs manually in production software by reading code or by trying to write test inputs that invoke unwanted behavior. After all, most code works fine at least 99% of the time, finding the 1% manually is a lot of effort.<p>Tools like afl-fuzz or static analysis tools are so much faster (when you throw enough CPU time at them) in finding unwanted behavior that there aren&#x27;t many reasons not to use them.<p>For learning and getting started with exploits, I like your idea of using some kind of &quot;weakened&quot; VM, but that&#x27;s a whole different deal than finding and fixing bugs (not even talking about exploiting) in production code (which is where the bounties are).",
      "num_comments": null,
      "story_id": 9327394,
      "story_title": "$9000 bounty paid for Python bug",
      "story_url": "https://hackerone.com/reports/55017",
      "parent_id": 9328003,
      "created_at_i": 1428328878,
      "_tags": [
        "comment",
        "author_exDM69",
        "story_9327394"
      ],
      "objectID": "9328105",
      "_highlightResult": {
        "author": {
          "value": "exDM69",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I agree with you if we're talking about someone who is just getting started in programming and debugging. It's not a good starting point if you want to understand why these bugs exist or how to exploit them.<p>But if we're talking about someone who is already a competent programmer, perhaps looking to learn a new tool, there's just no point (except perhaps learning) in trying to find bugs manually in production software by reading code or by trying to write test inputs that invoke unwanted behavior. After all, most code works fine at least 99% of the time, finding the 1% manually is a lot of effort.<p><em>Tools</em> like afl-fuzz or <em>static</em> <em>analysis</em> <em>tools</em> are so much faster (when you throw enough CPU time at them) in finding unwanted behavior that there aren't many reasons not to use them.<p>For learning and getting started with exploits, I like your idea of using some kind of &quot;weakened&quot; VM, but that's a whole different deal than finding and fixing bugs (not even talking about exploiting) in production code (which is where the bounties are).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "$9000 bounty paid for Python bug",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://hackerone.com/reports/55017",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-25T19:35:08.000Z",
      "title": null,
      "url": null,
      "author": "Scuds",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; While we&#x27;re at it, is the static analysis tools you built for this public?<p>maybe this?<p><a href=\"http://nodejstools.codeplex.com/SourceControl/latest#Nodejs/Product/Analysis/\" rel=\"nofollow\">http:&#x2F;&#x2F;nodejstools.codeplex.com&#x2F;SourceControl&#x2F;latest#Nodejs&#x2F;...</a>",
      "num_comments": null,
      "story_id": 9264873,
      "story_title": "Node.js Tools 1.0 for Visual Studio released",
      "story_url": "http://blogs.msdn.com/b/visualstudio/archive/2015/03/25/node-js-tools-1-0-for-visual-studio.aspx",
      "parent_id": 9265300,
      "created_at_i": 1427312108,
      "_tags": [
        "comment",
        "author_Scuds",
        "story_9264873"
      ],
      "objectID": "9265370",
      "_highlightResult": {
        "author": {
          "value": "Scuds",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; While we're at it, is the <em>static</em> <em>analysis</em> <em>tools</em> you built for this public?<p>maybe this?<p><a href=\"http://nodejstools.codeplex.com/SourceControl/latest#Nodejs/Product/Analysis/\" rel=\"nofollow\">http://nodejstools.codeplex.com/SourceControl/latest#Nodejs/...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Node.js <em>Tools</em> 1.0 for Visual Studio released",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "http://blogs.msdn.com/b/visualstudio/archive/2015/03/25/node-js-<em>tools</em>-1-0-for-visual-studio.aspx",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        }
      }
    },
    {
      "created_at": "2015-03-25T19:25:49.000Z",
      "title": null,
      "url": null,
      "author": "pdpi",
      "points": null,
      "story_text": null,
      "comment_text": "Great work, looks very nice. Will give it a whirl when I get home.<p>In the meanwhile, I noticed that you support intellisense. What are the limitations to this? What patterns will get correctly picked up? I assume prototypal inheritance will work fine (of course), but will any of the BaseClass.extend()-style inheritance mechanisms that some frameworks seem to favour (e.g. Backbone) work?<p>While we&#x27;re at it, is the static analysis tools you built for this public? I&#x27;d love to have a look at them.",
      "num_comments": null,
      "story_id": 9264873,
      "story_title": "Node.js Tools 1.0 for Visual Studio released",
      "story_url": "http://blogs.msdn.com/b/visualstudio/archive/2015/03/25/node-js-tools-1-0-for-visual-studio.aspx",
      "parent_id": 9264914,
      "created_at_i": 1427311549,
      "_tags": [
        "comment",
        "author_pdpi",
        "story_9264873"
      ],
      "objectID": "9265300",
      "_highlightResult": {
        "author": {
          "value": "pdpi",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Great work, looks very nice. Will give it a whirl when I get home.<p>In the meanwhile, I noticed that you support intellisense. What are the limitations to this? What patterns will get correctly picked up? I assume prototypal inheritance will work fine (of course), but will any of the BaseClass.extend()-style inheritance mechanisms that some frameworks seem to favour (e.g. Backbone) work?<p>While we're at it, is the <em>static</em> <em>analysis</em> <em>tools</em> you built for this public? I'd love to have a look at them.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Node.js <em>Tools</em> 1.0 for Visual Studio released",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "http://blogs.msdn.com/b/visualstudio/archive/2015/03/25/node-js-<em>tools</em>-1-0-for-visual-studio.aspx",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        }
      }
    },
    {
      "created_at": "2015-03-19T20:27:56.000Z",
      "title": null,
      "url": null,
      "author": "bbcbasic",
      "points": null,
      "story_text": null,
      "comment_text": "Where I work, in .NET we use various static analysis tools: StyleCop, CodeAnalysis and CodeContract. Warnings fail the build. And we are using a statically typed language of course. Oh... and gated check-ins.<p>It takes a few more minutes to write some code that build but it sure avoids a lot of silly bugs. Code contracts especially so!",
      "num_comments": null,
      "story_id": 9231960,
      "story_title": "Can We Trust the Libraries We Use?",
      "story_url": "http://bytes.com/topic/c/insights/961541-can-we-trust-libraries-we-use",
      "parent_id": 9231960,
      "created_at_i": 1426796876,
      "_tags": [
        "comment",
        "author_bbcbasic",
        "story_9231960"
      ],
      "objectID": "9234392",
      "_highlightResult": {
        "author": {
          "value": "bbcbasic",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Where I work, in .NET we use various <em>static</em> <em>analysis</em> <em>tools</em>: StyleCop, CodeAnalysis and CodeContract. Warnings fail the build. And we are using a statically typed language of course. Oh... and gated check-ins.<p>It takes a few more minutes to write some code that build but it sure avoids a lot of silly bugs. Code contracts especially so!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Can We Trust the Libraries We Use?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://bytes.com/topic/c/insights/961541-can-we-trust-libraries-we-use",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-11-05T02:58:37.000Z",
      "title": null,
      "url": null,
      "author": "snprbob86",
      "points": null,
      "story_text": null,
      "comment_text": "TDD says \"no line of product code is written until there is a unit test that fails for it\". I'm just pointing out that there is a spectrum of practicality in TDD. Our automated regression tests for graphics routinely require humans to re-verify every single screen capture because a single pixel may render slightly differently with some other change and there is no algorithm to determine \"is this artifact objectionable to humans\". Tests are good, but they are not a panacea.<p>As for the \"proper exceptions\" or error codes or what not. That always drove me NUTS to see that. The first line of the function is `if (foo == null) throw new ArgumentNullException(\"foo\")` -- do I really need to write a unit test for that? Furthermore, static analysis tools tell us when your public interface (including exception types we may throw) changes, that is code reviewed too. Writing `AssertThrows(typeof(ArgumentNullException)...` is just a waste of time.<p>Again: this is not an argument about whether tests have merit or not. All the author (and I) are saying, at the core of our argument, is that write tests when it makes sense to write tests. He's also going a step further to say \"it makes sense to write tests less frequently than TDD nuts would have you believe\". I may or may not agree with him, but I'm going to publicly denounce that belief simply because I'd rather developers write too many tests than too few.",
      "num_comments": null,
      "story_id": 922715,
      "story_title": "It's OK Not to Write Unit Tests",
      "story_url": "http://blogs.msdn.com/cashto/archive/2009/03/31/it-s-ok-not-to-write-unit-tests.aspx",
      "parent_id": 923080,
      "created_at_i": 1257389917,
      "_tags": [
        "comment",
        "author_snprbob86",
        "story_922715"
      ],
      "objectID": "923219",
      "_highlightResult": {
        "author": {
          "value": "snprbob86",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TDD says \"no line of product code is written until there is a unit test that fails for it\". I'm just pointing out that there is a spectrum of practicality in TDD. Our automated regression tests for graphics routinely require humans to re-verify every single screen capture because a single pixel may render slightly differently with some other change and there is no algorithm to determine \"is this artifact objectionable to humans\". Tests are good, but they are not a panacea.<p>As for the \"proper exceptions\" or error codes or what not. That always drove me NUTS to see that. The first line of the function is `if (foo == null) throw new ArgumentNullException(\"foo\")` -- do I really need to write a unit test for that? Furthermore, <em>static</em> <em>analysis</em> <em>tools</em> tell us when your public interface (including exception types we may throw) changes, that is code reviewed too. Writing `AssertThrows(typeof(ArgumentNullException)...` is just a waste of time.<p>Again: this is not an argument about whether tests have merit or not. All the author (and I) are saying, at the core of our argument, is that write tests when it makes sense to write tests. He's also going a step further to say \"it makes sense to write tests less frequently than TDD nuts would have you believe\". I may or may not agree with him, but I'm going to publicly denounce that belief simply because I'd rather developers write too many tests than too few.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "It's OK Not to Write Unit Tests",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.msdn.com/cashto/archive/2009/03/31/it-s-ok-not-to-write-unit-tests.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-18T01:04:52.000Z",
      "title": null,
      "url": null,
      "author": "Danack",
      "points": null,
      "story_text": null,
      "comment_text": "&gt;  Is there any other benefit?<p>Strict types make it easier to reason about code, that the tl;dr version.<p>&gt; To me it seems that Ze&#x27;ev&#x27;s proposal would be even better for you - \n&gt; it does the equivalent of the validation and conversion automatically \n&gt; including with an error if it doesn&#x27;t validate.<p>Rather than having int &#x27;types&#x27; which we can reason about, it has int &#x27;values&#x27; which are harder to reason about. Types can be reasoned about just by looking at the code. Values can only be reasoned about when running code. A contrived example:<p><pre><code>    function foo(int $bar){...}\n\n    foo(36&#x2F;$value);\n</code></pre>\nIn strict mode, this would be reported as an error by code analysis.<p>For the coercive scalar type proposal, this code works - except when it doesn&#x27;t. This code works when $value = 1, 2, 3, 4 and breaks when $value = 5.<p>This is the fundamental difference; whether conversions between types have to be explicitly done by code, and so any implicit or incorrect conversion can be detected by static code analysis tools, or whether the conversions are done at run time, and so cannot be analyzed fully.<p>This means most of these errors will be discovered by users on the production servers. Strict mode allows you to eliminate these types of errors.<p>Yes, this means I need to add a bit of code to do the explicit conversion, but I just don&#x27;t convert between values that much. Once a value is loaded from a users request, config file or wherever, it is converted once into the type it needs to be. After that, any further change in type is far more likely to be me making a mistake, rather than an actual need to change the type.<p>&gt; Any idea why it was rejected so badly? Is it because the coercion rules are different from the rest of PHP?<p>At least in part it was because the RFC was seen as a way to block strict types; about half of the RFC text is shitting on people desires for strict types, which did not make people who want strict types be very receptive. If it had been brought up 6 months ago, there is a good chance it would have passed, or at least would have been closer.<p>Some parts of the proposal were good - other parts were nuts that were pretty obvious the result of the RFC only being created once the dual mode RFC was announced and about to be put to the vote, with a very high chance of passing.<p>* Good - &quot;7 dogs&quot; not longer being converted to &quot;7&quot; if someone tries to use it as an int.<p>* Bad - Different mode for internal function vs userland functions e.g. &quot;Unlike user-land scalar type hints, internal functions will accept nulls as valid scalars.&quot; and other small differences. This is even more nuts than you might realise as it means if you extend an internal class, and overload some of the methods on the class, those methods will behave differently to the non-overloaded methods.<p>* Bad - Subtle and hard to fix BC breaks in conversion which are probably not right anyway. e.g.\n    false -&gt; int           # No more conversion from bool\n    true -&gt; string         # No more conversion from bool<p>It is a shame that the discussion became so contentious. It would have been good if the conversion rules could have been tidied up, but all the time and energy had been used up the not particularly productive discussion.",
      "num_comments": null,
      "story_id": 9214464,
      "story_title": "PHP7 Gains Scalar Type Hints",
      "story_url": "https://wiki.php.net/rfc/scalar_type_hints_v5#vote",
      "parent_id": 9221482,
      "created_at_i": 1426640692,
      "_tags": [
        "comment",
        "author_Danack",
        "story_9214464"
      ],
      "objectID": "9222871",
      "_highlightResult": {
        "author": {
          "value": "Danack",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;  Is there any other benefit?<p>Strict types make it easier to reason about code, that the tl;dr version.<p>&gt; To me it seems that Ze'ev's proposal would be even better for you - \n&gt; it does the equivalent of the validation and conversion automatically \n&gt; including with an error if it doesn't validate.<p>Rather than having int 'types' which we can reason about, it has int 'values' which are harder to reason about. Types can be reasoned about just by looking at the code. Values can only be reasoned about when running code. A contrived example:<p><pre><code>    function foo(int $bar){...}\n\n    foo(36/$value);\n</code></pre>\nIn strict mode, this would be reported as an error by code <em>analysis.</em><p>For the coercive scalar type proposal, this code works - except when it doesn't. This code works when $value = 1, 2, 3, 4 and breaks when $value = 5.<p>This is the fundamental difference; whether conversions between types have to be explicitly done by code, and so any implicit or incorrect conversion can be detected by <em>static</em> code <em>analysis</em> <em>tools</em>, or whether the conversions are done at run time, and so cannot be analyzed fully.<p>This means most of these errors will be discovered by users on the production servers. Strict mode allows you to eliminate these types of errors.<p>Yes, this means I need to add a bit of code to do the explicit conversion, but I just don't convert between values that much. Once a value is loaded from a users request, config file or wherever, it is converted once into the type it needs to be. After that, any further change in type is far more likely to be me making a mistake, rather than an actual need to change the type.<p>&gt; Any idea why it was rejected so badly? Is it because the coercion rules are different from the rest of PHP?<p>At least in part it was because the RFC was seen as a way to block strict types; about half of the RFC text is shitting on people desires for strict types, which did not make people who want strict types be very receptive. If it had been brought up 6 months ago, there is a good chance it would have passed, or at least would have been closer.<p>Some parts of the proposal were good - other parts were nuts that were pretty obvious the result of the RFC only being created once the dual mode RFC was announced and about to be put to the vote, with a very high chance of passing.<p>* Good - &quot;7 dogs&quot; not longer being converted to &quot;7&quot; if someone tries to use it as an int.<p>* Bad - Different mode for internal function vs userland functions e.g. &quot;Unlike user-land scalar type hints, internal functions will accept nulls as valid scalars.&quot; and other small differences. This is even more nuts than you might realise as it means if you extend an internal class, and overload some of the methods on the class, those methods will behave differently to the non-overloaded methods.<p>* Bad - Subtle and hard to fix BC breaks in conversion which are probably not right anyway. e.g.\n    false -&gt; int           # No more conversion from bool\n    true -&gt; string         # No more conversion from bool<p>It is a shame that the discussion became so contentious. It would have been good if the conversion rules could have been tidied up, but all the time and energy had been used up the not particularly productive discussion.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "PHP7 Gains Scalar Type Hints",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://wiki.php.net/rfc/scalar_type_hints_v5#vote",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-26T19:53:14.000Z",
      "title": null,
      "url": null,
      "author": "jaimefjorge",
      "points": null,
      "story_text": null,
      "comment_text": "<i>&quot;And that adds up like compound interest into making the code a lot better.&quot;</i><p>Like inverse (or reverse) technical debt. Excellent way of putting why code reviews are important.<p>I would just add that while improving adds up, it shouldn&#x27;t cover the fact that blocking the team because of camel case issues is not the best use of time.\nThere are static analysis tools that are free and open source that can do this work.<p>We are spending between 1&#x2F;5th to 1&#x2F;10th of our time reviewing code[1]. Most of the times the disciplined have to carry the burden of being &#x27;that guy&#x27; that always has something to say.<p>1: <a href=\"http://www.quora.com/How-much-per-day-or-week-do-engineers-spend-doing-code-review-at-companies-such-as-Google-Facebook-GitHub-Twitter-Foursquare-etc\" rel=\"nofollow\">http:&#x2F;&#x2F;www.quora.com&#x2F;How-much-per-day-or-week-do-engineers-s...</a>",
      "num_comments": null,
      "story_id": 9113474,
      "story_title": "Why Code Snobs Are Invaluable",
      "story_url": "http://mjswensen.com/blog/2015/01/30/why-code-snobs-are-invaluable/",
      "parent_id": 9113694,
      "created_at_i": 1424980394,
      "_tags": [
        "comment",
        "author_jaimefjorge",
        "story_9113474"
      ],
      "objectID": "9114981",
      "_highlightResult": {
        "author": {
          "value": "jaimefjorge",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>&quot;And that adds up like compound interest into making the code a lot better.&quot;</i><p>Like inverse (or reverse) technical debt. Excellent way of putting why code reviews are important.<p>I would just add that while improving adds up, it shouldn't cover the fact that blocking the team because of camel case issues is not the best use of time.\nThere are <em>static</em> <em>analysis</em> <em>tools</em> that are free and open source that can do this work.<p>We are spending between 1/5th to 1/10th of our time reviewing code[1]. Most of the times the disciplined have to carry the burden of being 'that guy' that always has something to say.<p>1: <a href=\"http://www.quora.com/How-much-per-day-or-week-do-engineers-spend-doing-code-review-at-companies-such-as-Google-Facebook-GitHub-Twitter-Foursquare-etc\" rel=\"nofollow\">http://www.quora.com/How-much-per-day-or-week-do-engineers-s...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Code Snobs Are Invaluable",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://mjswensen.com/blog/2015/01/30/why-code-snobs-are-invaluable/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-24T16:19:14.000Z",
      "title": null,
      "url": null,
      "author": "stonemetal",
      "points": null,
      "story_text": null,
      "comment_text": "I would say both are correct.  From a psychological\\SE standpoint know your faults and develop defenses for them. That could be use a language that doesn&#x27;t allow them to even be thought in the first place, or develop defensive coding standards that prevent them.  But that answer is more stochastic, it helps but anything short of formal proof is just raising the likely hood of success not a guarantee.<p>I also wonder if a static analysis tool would have caught the bug.  Are there any good static analysis tools for Java or Python that might have caught the bug without the overhead of writing the formal proof?",
      "num_comments": null,
      "story_id": 9100107,
      "story_title": "Proving that Android’s, Java’s and Python’s sorting algorithm is broken",
      "story_url": "http://envisage-project.eu/proving-android-java-and-python-sorting-algorithm-is-broken-and-how-to-fix-it/",
      "parent_id": 9101333,
      "created_at_i": 1424794754,
      "_tags": [
        "comment",
        "author_stonemetal",
        "story_9100107"
      ],
      "objectID": "9101539",
      "_highlightResult": {
        "author": {
          "value": "stonemetal",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I would say both are correct.  From a psychological\\SE standpoint know your faults and develop defenses for them. That could be use a language that doesn't allow them to even be thought in the first place, or develop defensive coding standards that prevent them.  But that answer is more stochastic, it helps but anything short of formal proof is just raising the likely hood of success not a guarantee.<p>I also wonder if a <em>static</em> <em>analysis</em> tool would have caught the bug.  Are there any good <em>static</em> <em>analysis</em> <em>tools</em> for Java or Python that might have caught the bug without the overhead of writing the formal proof?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Proving that Android’s, Java’s and Python’s sorting algorithm is broken",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://envisage-project.eu/proving-android-java-and-python-sorting-algorithm-is-broken-and-how-to-fix-it/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-15T21:04:31.000Z",
      "title": null,
      "url": null,
      "author": "nhaehnle",
      "points": null,
      "story_text": null,
      "comment_text": "It&#x27;s not that simple, because of inlining and macros.<p>Those optimizations can be used to quickly throw out unnecessary code like null-pointer checks inside inlined functions, so they <i>are</i> valuable and good to have.<p>So it&#x27;s a matter of how much energy you spend on diagnostics, which ends up a rather heuristic field and perhaps we&#x27;d just be better off focusing on better static analysis tools that are separate from or can otherwise be decoupled from compilers.",
      "num_comments": null,
      "story_id": 9052735,
      "story_title": "Zero size objects",
      "story_url": "http://www.tedunangst.com/flak/post/zero-size-objects",
      "parent_id": 9054088,
      "created_at_i": 1424034271,
      "_tags": [
        "comment",
        "author_nhaehnle",
        "story_9052735"
      ],
      "objectID": "9054122",
      "_highlightResult": {
        "author": {
          "value": "nhaehnle",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's not that simple, because of inlining and macros.<p>Those optimizations can be used to quickly throw out unnecessary code like null-pointer checks inside inlined functions, so they <i>are</i> valuable and good to have.<p>So it's a matter of how much energy you spend on diagnostics, which ends up a rather heuristic field and perhaps we'd just be better off focusing on better <em>static</em> <em>analysis</em> <em>tools</em> that are separate from or can otherwise be decoupled from compilers.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Zero size objects",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.tedunangst.com/flak/post/zero-size-objects",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-14T06:03:35.000Z",
      "title": null,
      "url": null,
      "author": "jpgvm",
      "points": null,
      "story_text": null,
      "comment_text": "You missed the whole point.<p>By making the language simple you can easily implement your own parser. This opens up the ability to write native parsers in other languages, say vimscript. By keeping it super simple there -are- no corner-cases.<p>There are many benefits to this (like the formatters etc that others have alluded to) from things like IDE integration (imagine lifetime elision visualisation, invalid move notifications, etc) static analysis tools and more. None of these tools then need to be written in Rust. It also means it&#x27;s easier to implement support in pre-existing multi-language tools.<p>Don&#x27;t underestimate the necessity of a simple parseable grammar. Besides, people have endured much worse slights in syntax (see here Erlang).",
      "num_comments": null,
      "story_id": 9046526,
      "story_title": "Rust 1.0: Status report and final timeline",
      "story_url": "http://blog.rust-lang.org/2015/02/13/Final-1.0-timeline.html",
      "parent_id": 9048399,
      "created_at_i": 1423893815,
      "_tags": [
        "comment",
        "author_jpgvm",
        "story_9046526"
      ],
      "objectID": "9048896",
      "_highlightResult": {
        "author": {
          "value": "jpgvm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You missed the whole point.<p>By making the language simple you can easily implement your own parser. This opens up the ability to write native parsers in other languages, say vimscript. By keeping it super simple there -are- no corner-cases.<p>There are many benefits to this (like the formatters etc that others have alluded to) from things like IDE integration (imagine lifetime elision visualisation, invalid move notifications, etc) <em>static</em> <em>analysis</em> <em>tools</em> and more. None of these <em>tools</em> then need to be written in Rust. It also means it's easier to implement support in pre-existing multi-language <em>tools</em>.<p>Don't underestimate the necessity of a simple parseable grammar. Besides, people have endured much worse slights in syntax (see here Erlang).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Rust 1.0: Status report and final timeline",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.rust-lang.org/2015/02/13/Final-1.0-timeline.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-13T22:48:50.000Z",
      "title": null,
      "url": null,
      "author": "mike_hearn",
      "points": null,
      "story_text": null,
      "comment_text": "It depends what you mean by &quot;language&quot; and what you include.<p>Rust and Go include the compiler, the runtime, some libraries, some package management and some tutorials.<p>Other things you might want include IDE support, static analysis tools, advanced garbage collectors, GUI toolkit (bindings), slick debugger support, monitoring and profiling engines. These will all add a large amount of time and money to the development of your new platform.",
      "num_comments": null,
      "story_id": 9046526,
      "story_title": "Rust 1.0 final timeline",
      "story_url": "http://blog.rust-lang.org/2015/02/13/Final-1.0-timeline.html",
      "parent_id": 9047090,
      "created_at_i": 1423867730,
      "_tags": [
        "comment",
        "author_mike_hearn",
        "story_9046526"
      ],
      "objectID": "9047721",
      "_highlightResult": {
        "author": {
          "value": "mike_hearn",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It depends what you mean by &quot;language&quot; and what you include.<p>Rust and Go include the compiler, the runtime, some libraries, some package management and some tutorials.<p>Other things you might want include IDE support, <em>static</em> <em>analysis</em> <em>tools</em>, advanced garbage collectors, GUI toolkit (bindings), slick debugger support, monitoring and profiling engines. These will all add a large amount of time and money to the development of your new platform.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Rust 1.0 final timeline",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.rust-lang.org/2015/02/13/Final-1.0-timeline.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-13T14:25:06.000Z",
      "title": null,
      "url": null,
      "author": "MrDosu",
      "points": null,
      "story_text": null,
      "comment_text": "Just interested: Do you use static analysis tools (like for example coverity) in the gamedev industry?",
      "num_comments": null,
      "story_id": 9037151,
      "story_title": "The bell has tolled for rand()",
      "story_url": "http://cpp.indi.frih.net/blog/2014/12/the-bell-has-tolled-for-rand/",
      "parent_id": 9040587,
      "created_at_i": 1423837506,
      "_tags": [
        "comment",
        "author_MrDosu",
        "story_9037151"
      ],
      "objectID": "9044437",
      "_highlightResult": {
        "author": {
          "value": "MrDosu",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Just interested: Do you use <em>static</em> <em>analysis</em> <em>tools</em> (like for example coverity) in the gamedev industry?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The bell has tolled for rand()",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cpp.indi.frih.net/blog/2014/12/the-bell-has-tolled-for-rand/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-12T00:18:05.000Z",
      "title": null,
      "url": null,
      "author": "sanderjd",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; Type checkers are one way to gain assurance about software in advance of running it. Wonderful as they can be, they&#x27;re not the only one.<p>This is true, but in my experience they are far and away the most common and easily tooled <i>automatic</i> way. Tests may run automatically, but they must be manually written, and static analysis tools are not (yet?) very widespread.",
      "num_comments": null,
      "story_id": 9035549,
      "story_title": "Seven deadly sins of talking about “types” (2014)",
      "story_url": "http://www.cl.cam.ac.uk/~srk31/blog/2014/10/07/",
      "parent_id": 9035549,
      "created_at_i": 1423700285,
      "_tags": [
        "comment",
        "author_sanderjd",
        "story_9035549"
      ],
      "objectID": "9036579",
      "_highlightResult": {
        "author": {
          "value": "sanderjd",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; Type checkers are one way to gain assurance about software in advance of running it. Wonderful as they can be, they're not the only one.<p>This is true, but in my experience they are far and away the most common and easily tooled <i>automatic</i> way. Tests may run automatically, but they must be manually written, and <em>static</em> <em>analysis</em> <em>tools</em> are not (yet?) very widespread.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Seven deadly sins of talking about “types” (2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.cl.cam.ac.uk/~srk31/blog/2014/10/07/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-11T20:03:16.000Z",
      "title": null,
      "url": null,
      "author": "wglb",
      "points": null,
      "story_text": null,
      "comment_text": "What is your take on <a href=\"http://blog.regehr.org/archives/1217\" rel=\"nofollow\">http:&#x2F;&#x2F;blog.regehr.org&#x2F;archives&#x2F;1217</a> and <a href=\"http://blog.regehr.org/archives/1217\" rel=\"nofollow\">http:&#x2F;&#x2F;blog.regehr.org&#x2F;archives&#x2F;1217</a>, who seem to be less than totally excited about the output of static analysis tools in terms of bugs found.",
      "num_comments": null,
      "story_id": 9032956,
      "story_title": "The Need for Open Research in Software Security",
      "story_url": "http://breakingbits.net/2015/02/05/open-research-software-security/",
      "parent_id": 9034146,
      "created_at_i": 1423684996,
      "_tags": [
        "comment",
        "author_wglb",
        "story_9032956"
      ],
      "objectID": "9035345",
      "_highlightResult": {
        "author": {
          "value": "wglb",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "What is your take on <a href=\"http://blog.regehr.org/archives/1217\" rel=\"nofollow\">http://blog.regehr.org/archives/1217</a> and <a href=\"http://blog.regehr.org/archives/1217\" rel=\"nofollow\">http://blog.regehr.org/archives/1217</a>, who seem to be less than totally excited about the output of <em>static</em> <em>analysis</em> <em>tools</em> in terms of bugs found.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Need for Open Research in Software Security",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://breakingbits.net/2015/02/05/open-research-software-security/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-04T05:28:53.000Z",
      "title": null,
      "url": null,
      "author": "quadratini",
      "points": null,
      "story_text": null,
      "comment_text": "It was a rhetorical question. I understand why we need to use a special version of setTimeout or a special HTTP module, but the fundamental problem is that Angular&#x27;s &quot;reactive javascript&quot; abstraction leaks in a way that you&#x27;re forced to do it the Angular way.<p>React&#x27;s abstraction also leaks, which is evident when it doesn&#x27;t automatically know to update itself so you have to call `setState`. But I&#x27;d choose this set of leaky abstractions over Angular&#x27;s. Plus it makes it easy to spot all the places where the UI can change which is a huge plus for debugging. The beauty of React&#x27;s set of abstractions is that it doesn&#x27;t force you to do things a certain way (use $http, use $timeout) or use observables which embraces mutability.<p>Also to further my point that Angular (and any other framework that provides templating) doesn&#x27;t embrace javascript, every time you use `ng-repeat` you&#x27;re not doing javascript. You can&#x27;t put a debugger in the middle of the loop to check the scope. You can&#x27;t use Immutable-js because `ng-repeat` loves arrays. (Ok you can convert the immutable to an array before hand, but then when it changes you&#x27;d have to incur an expensive rerender of the list) You can&#x27;t use static analysis tools.",
      "num_comments": null,
      "story_id": 8991239,
      "story_title": "Ask HN: What's the problem with AngularJS?",
      "story_url": "",
      "parent_id": 8995145,
      "created_at_i": 1423027733,
      "_tags": [
        "comment",
        "author_quadratini",
        "story_8991239"
      ],
      "objectID": "8995467",
      "_highlightResult": {
        "author": {
          "value": "quadratini",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It was a rhetorical question. I understand why we need to use a special version of setTimeout or a special HTTP module, but the fundamental problem is that Angular's &quot;reactive javascript&quot; abstraction leaks in a way that you're forced to do it the Angular way.<p>React's abstraction also leaks, which is evident when it doesn't automatically know to update itself so you have to call `setState`. But I'd choose this set of leaky abstractions over Angular's. Plus it makes it easy to spot all the places where the UI can change which is a huge plus for debugging. The beauty of React's set of abstractions is that it doesn't force you to do things a certain way (use $http, use $timeout) or use observables which embraces mutability.<p>Also to further my point that Angular (and any other framework that provides templating) doesn't embrace javascript, every time you use `ng-repeat` you're not doing javascript. You can't put a debugger in the middle of the loop to check the scope. You can't use Immutable-js because `ng-repeat` loves arrays. (Ok you can convert the immutable to an array before hand, but then when it changes you'd have to incur an expensive rerender of the list) You can't use <em>static</em> <em>analysis</em> <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: What's the problem with AngularJS?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-25T13:34:50.000Z",
      "title": null,
      "url": null,
      "author": "chroma",
      "points": null,
      "story_text": null,
      "comment_text": "(Note: I don&#x27;t mean for this comment to be perceived as bragging or showmanship. It&#x27;s just that... well, you asked about my background.)<p>Computers have fascinated me since before I can remember. I spend most of my waking hours in front of them. I&#x27;ve been honing my craft for over 20 years. I&#x27;ve written and maintained projects in C, C++, C#, Java, JavaScript (both browser and server-side)[1], Perl, PHP (we all make mistakes), Python, Ruby, and a couple Lisps. In my travels, I&#x27;ve discovered and reported bugs in popular software such as Firefox, Chrome, Node.js, Apple&#x27;s XNU kernel, and libxml2.<p>I completely agree that some programmers are like machine guns, firing off vast quantities of poorly-aimed code. I try my best to avoid that. I hate sloppy code. I hate repetitive code. Most of all, I hate re-inventing the wheel. If a decent library exists, I&#x27;ll use it. I have no qualms with something Not Invented Here.<p>I pair sometimes. I do code reviews often. And I use as many profiling, testing, and static analysis tools as I can get my hands on.<p>It sounds like your ordeal made you a better coder. Those sorts of experiences are indispensable, but I&#x27;ve found it takes more to keep improving. It&#x27;s very useful to become an expert <i>on</i> programming, not just an expert <i>at</i> programming. There&#x27;s a growing body of literature to aid anyone interested. McConnell&#x27;s <i>Code Complete</i> is still great. Michael Feathers has a book called <i>Working Effectively with Legacy Code</i>. It contains some great techniques for incrementally improving hard-to-maintain projects. Lastly, browsing <i>It Will Never Work in Theory</i>[2] is a good way to stumble into some academic papers that apply to your own work.<p>1. &quot;JavaScript&quot; is such a nebulous term these days, but I&#x27;ve worked on JS codebases using tools ranging from nothing (vanilla JS) to JQuery to Google Closure to React.<p>2. <a href=\"http://neverworkintheory.org/\" rel=\"nofollow\">http:&#x2F;&#x2F;neverworkintheory.org&#x2F;</a>",
      "num_comments": null,
      "story_id": 8942176,
      "story_title": "The Parable of the Two Programmers (1985)",
      "story_url": "http://www.csd.uwo.ca/staff/magi/personal/humour/Computer_Audience/The%20Parable%20of%20the%20Two%20Programmers.html?",
      "parent_id": 8942715,
      "created_at_i": 1422192890,
      "_tags": [
        "comment",
        "author_chroma",
        "story_8942176"
      ],
      "objectID": "8942882",
      "_highlightResult": {
        "author": {
          "value": "chroma",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "(Note: I don't mean for this comment to be perceived as bragging or showmanship. It's just that... well, you asked about my background.)<p>Computers have fascinated me since before I can remember. I spend most of my waking hours in front of them. I've been honing my craft for over 20 years. I've written and maintained projects in C, C++, C#, Java, JavaScript (both browser and server-side)[1], Perl, PHP (we all make mistakes), Python, Ruby, and a couple Lisps. In my travels, I've discovered and reported bugs in popular software such as Firefox, Chrome, Node.js, Apple's XNU kernel, and libxml2.<p>I completely agree that some programmers are like machine guns, firing off vast quantities of poorly-aimed code. I try my best to avoid that. I hate sloppy code. I hate repetitive code. Most of all, I hate re-inventing the wheel. If a decent library exists, I'll use it. I have no qualms with something Not Invented Here.<p>I pair sometimes. I do code reviews often. And I use as many profiling, testing, and <em>static</em> <em>analysis</em> <em>tools</em> as I can get my hands on.<p>It sounds like your ordeal made you a better coder. Those sorts of experiences are indispensable, but I've found it takes more to keep improving. It's very useful to become an expert <i>on</i> programming, not just an expert <i>at</i> programming. There's a growing body of literature to aid anyone interested. McConnell's <i>Code Complete</i> is still great. Michael Feathers has a book called <i>Working Effectively with Legacy Code</i>. It contains some great techniques for incrementally improving hard-to-maintain projects. Lastly, browsing <i>It Will Never Work in Theory</i>[2] is a good way to stumble into some academic papers that apply to your own work.<p>1. &quot;JavaScript&quot; is such a nebulous term these days, but I've worked on JS codebases using <em>tools</em> ranging from nothing (vanilla JS) to JQuery to Google Closure to React.<p>2. <a href=\"http://neverworkintheory.org/\" rel=\"nofollow\">http://neverworkintheory.org/</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Parable of the Two Programmers (1985)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.csd.uwo.ca/staff/magi/personal/humour/Computer_Audience/The%20Parable%20of%20the%20Two%20Programmers.html?",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-25T11:51:10.000Z",
      "title": null,
      "url": null,
      "author": "asuffield",
      "points": null,
      "story_text": null,
      "comment_text": "The last ruby project that I worked on laughed at static analysis tools before pitching them into halting problems. You have to execute ruby code just to assemble the classes, it&#x27;s quite resistant to static analysis unless you artificially restrict yourself to a subset of the language.<p>If you&#x27;re going to limit yourself to the statically checkable part of the language then you might as well just use a language that was designed for it. The fundamental feature of dynamic languages is variations on the theme of self-modifying code - behaviour is determined at runtime. This feature is not normally considered compatible with static analysis, because you have to execute an unbounded amount of the program to find out what it does.<p>The important thing about static type checking on languages like ocaml is that it can be both &quot;sound&quot; and &quot;complete&quot; - any type error is an error in your program, and a program that type checks cannot go wrong according to the constraints of the type system. In order to make this possible, we have a body of theory on how to design type systems that are constrained just enough to be checkable while still expressing everything you want them to say.",
      "num_comments": null,
      "story_id": 8940866,
      "story_title": "Why the Cool Kids Don't Use Erlang [video]",
      "story_url": "https://www.youtube.com/watch?v=3MvKLOecT1I",
      "parent_id": 8942365,
      "created_at_i": 1422186670,
      "_tags": [
        "comment",
        "author_asuffield",
        "story_8940866"
      ],
      "objectID": "8942702",
      "_highlightResult": {
        "author": {
          "value": "asuffield",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The last ruby project that I worked on laughed at <em>static</em> <em>analysis</em> <em>tools</em> before pitching them into halting problems. You have to execute ruby code just to assemble the classes, it's quite resistant to <em>static</em> <em>analysis</em> unless you artificially restrict yourself to a subset of the language.<p>If you're going to limit yourself to the statically checkable part of the language then you might as well just use a language that was designed for it. The fundamental feature of dynamic languages is variations on the theme of self-modifying code - behaviour is determined at runtime. This feature is not normally considered compatible with <em>static</em> <em>analysis</em>, because you have to execute an unbounded amount of the program to find out what it does.<p>The important thing about <em>static</em> type checking on languages like ocaml is that it can be both &quot;sound&quot; and &quot;complete&quot; - any type error is an error in your program, and a program that type checks cannot go wrong according to the constraints of the type system. In order to make this possible, we have a body of theory on how to design type systems that are constrained just enough to be checkable while still expressing everything you want them to say.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why the Cool Kids Don't Use Erlang [video]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.youtube.com/watch?v=3MvKLOecT1I",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-24T18:29:15.000Z",
      "title": null,
      "url": null,
      "author": "douche",
      "points": null,
      "story_text": null,
      "comment_text": "It&#x27;s going to be difficult, but that goes for nearly any endeavor, in my experience.  That being said, I&#x27;m not sure whether attention to detail is an innate skill, or something that has been honed to a keen edge by repeated failures.  I know that most of the things that I do while programming that could be described as detail-oriented are more the result of the experience of getting burned by a particular edge case than anything else.<p>If a reference can possibly be null, check it before you use it.<p>When comparing things like URLs and URIs that are supposed to be functionally equivalent regardless of case, use a case-insensitive comparison like string.equals(&quot;a&quot;, &quot;A&quot;, StringComparison.InvariantCultureIgnoreCase) or even &quot;a&quot;.ToUpper()==&quot;A&quot;.ToUpper(), rather than the default &quot;a&quot;==&quot;A&quot;.<p>The Javascript === vs == shitshow.<p>Floating point equality without an epsilon value.<p>Remembering to put in the # or . prefix when trying to select an element by id or class in css&#x2F;jQuery selectors.<p>Understanding when database calls are actually triggered using your ORM of choice.<p>Using thread-safe containers when collections can be modified on one thread while they are being iterated over on another.<p>Treating rm -rf with extreme care.<p>After you run into an embarrassing bug that makes you look incompetent because you failed to account properly for these things, you develop a certain amount of OCD about it and internalize the checks.  At least you should, or else you just end up making the same mistakes over and over.  Of course, things can always fail in new and unexpected ways, so you are always adding to your corpus of fail.<p>As a last note, an incredibly help for me has been using static analysis tools that are built into tools like Resharper, Webstorm, IntelliJ, (basically anything made by JetBrains), Javascript linters, etc.  You can offload a lot of the burden of correctness checking for the more trivial errors and gotchas to the machine, and focus on higher-level issues.",
      "num_comments": null,
      "story_id": 8939957,
      "story_title": "Ask HN: Can you be a good programmer if you are not details oriented?",
      "story_url": "",
      "parent_id": 8939957,
      "created_at_i": 1422124155,
      "_tags": [
        "comment",
        "author_douche",
        "story_8939957"
      ],
      "objectID": "8940441",
      "_highlightResult": {
        "author": {
          "value": "douche",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's going to be difficult, but that goes for nearly any endeavor, in my experience.  That being said, I'm not sure whether attention to detail is an innate skill, or something that has been honed to a keen edge by repeated failures.  I know that most of the things that I do while programming that could be described as detail-oriented are more the result of the experience of getting burned by a particular edge case than anything else.<p>If a reference can possibly be null, check it before you use it.<p>When comparing things like URLs and URIs that are supposed to be functionally equivalent regardless of case, use a case-insensitive comparison like string.equals(&quot;a&quot;, &quot;A&quot;, StringComparison.InvariantCultureIgnoreCase) or even &quot;a&quot;.ToUpper()==&quot;A&quot;.ToUpper(), rather than the default &quot;a&quot;==&quot;A&quot;.<p>The Javascript === vs == shitshow.<p>Floating point equality without an epsilon value.<p>Remembering to put in the # or . prefix when trying to select an element by id or class in css/jQuery selectors.<p>Understanding when database calls are actually triggered using your ORM of choice.<p>Using thread-safe containers when collections can be modified on one thread while they are being iterated over on another.<p>Treating rm -rf with extreme care.<p>After you run into an embarrassing bug that makes you look incompetent because you failed to account properly for these things, you develop a certain amount of OCD about it and internalize the checks.  At least you should, or else you just end up making the same mistakes over and over.  Of course, things can always fail in new and unexpected ways, so you are always adding to your corpus of fail.<p>As a last note, an incredibly help for me has been using <em>static</em> <em>analysis</em> <em>tools</em> that are built into <em>tools</em> like Resharper, Webstorm, IntelliJ, (basically anything made by JetBrains), Javascript linters, etc.  You can offload a lot of the burden of correctness checking for the more trivial errors and gotchas to the machine, and focus on higher-level issues.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Can you be a good programmer if you are not details oriented?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-21T14:26:29.000Z",
      "title": null,
      "url": null,
      "author": "rcseacord",
      "points": null,
      "story_text": null,
      "comment_text": "We did actually produce ISO&#x2F;IEC TS 17961:2013 Information technology -- Programming languages, their environments and system software interfaces -- C secure coding rules\n<a href=\"http://www.iso.org/iso/catalogue_detail.htm?csnumber=61134\" rel=\"nofollow\">http:&#x2F;&#x2F;www.iso.org&#x2F;iso&#x2F;catalogue_detail.htm?csnumber=61134</a><p>The rules specified in this Technical Specification apply to analyzers, including static analysis tools and C language compiler vendors that wish to diagnose insecure code beyond the requirements of the language standard. All rules are meant to be enforceable by static analysis.<p>I wrote an article putting all this in some context at:\n<a href=\"http://www.informit.com/articles/article.aspx?p=2088511\" rel=\"nofollow\">http:&#x2F;&#x2F;www.informit.com&#x2F;articles&#x2F;article.aspx?p=2088511</a>",
      "num_comments": null,
      "story_id": 8921297,
      "story_title": "The CERT C Secure Coding Standard",
      "story_url": "https://www.securecoding.cert.org/confluence/display/seccode/CERT+C+Coding+Standard",
      "parent_id": 8922212,
      "created_at_i": 1421850389,
      "_tags": [
        "comment",
        "author_rcseacord",
        "story_8921297"
      ],
      "objectID": "8923180",
      "_highlightResult": {
        "author": {
          "value": "rcseacord",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "We did actually produce ISO/IEC TS 17961:2013 Information technology -- Programming languages, their environments and system software interfaces -- C secure coding rules\n<a href=\"http://www.iso.org/iso/catalogue_detail.htm?csnumber=61134\" rel=\"nofollow\">http://www.iso.org/iso/catalogue_detail.htm?csnumber=61134</a><p>The rules specified in this Technical Specification apply to analyzers, including <em>static</em> <em>analysis</em> <em>tools</em> and C language compiler vendors that wish to diagnose insecure code beyond the requirements of the language standard. All rules are meant to be enforceable by <em>static</em> <em>analysis.</em><p>I wrote an article putting all this in some context at:\n<a href=\"http://www.informit.com/articles/article.aspx?p=2088511\" rel=\"nofollow\">http://www.informit.com/articles/article.aspx?p=2088511</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The CERT C Secure Coding Standard",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.securecoding.cert.org/confluence/display/seccode/CERT+C+Coding+Standard",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-18T15:22:40.000Z",
      "title": null,
      "url": null,
      "author": "EliRivers",
      "points": null,
      "story_text": null,
      "comment_text": "I work with some people in the static analysis industry, and I&#x27;m told that Toyota did have static analysis tools that would have identified a number of these issues; as a  particular example, recursive functions, which are verboten under the MISRA rules they should have been following.<p>I heard to a less reliable degree that the tools <i>had</i> been used, and results ignored.",
      "num_comments": null,
      "story_id": 8905718,
      "story_title": "A Case Study of Toyota Unintended Acceleration and Software Safety",
      "story_url": "http://betterembsw.blogspot.com/2014/09/a-case-study-of-toyota-unintended.html?m=1",
      "parent_id": 8905718,
      "created_at_i": 1421594560,
      "_tags": [
        "comment",
        "author_EliRivers",
        "story_8905718"
      ],
      "objectID": "8907707",
      "_highlightResult": {
        "author": {
          "value": "EliRivers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I work with some people in the <em>static</em> <em>analysis</em> industry, and I'm told that Toyota did have <em>static</em> <em>analysis</em> <em>tools</em> that would have identified a number of these issues; as a  particular example, recursive functions, which are verboten under the MISRA rules they should have been following.<p>I heard to a less reliable degree that the <em>tools</em> <i>had</i> been used, and results ignored.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "A Case Study of Toyota Unintended Acceleration and Software Safety",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://betterembsw.blogspot.com/2014/09/a-case-study-of-toyota-unintended.html?m=1",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-16T13:34:05.000Z",
      "title": null,
      "url": null,
      "author": "dimman",
      "points": null,
      "story_text": null,
      "comment_text": "A bit surprised it doesn&#x27;t mention the use of curly braces. Perhaps they assume their &quot;state of the art&quot; static code analysis tools will find potential issues (like Apple&#x27;s goto fail failure).",
      "num_comments": null,
      "story_id": 8898299,
      "story_title": "NASA's 10 rules for developing mission critical code [pdf]",
      "story_url": "http://pixelscommander.com/wp-content/uploads/2014/12/P10.pdf",
      "parent_id": 8898299,
      "created_at_i": 1421415245,
      "_tags": [
        "comment",
        "author_dimman",
        "story_8898299"
      ],
      "objectID": "8898743",
      "_highlightResult": {
        "author": {
          "value": "dimman",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "A bit surprised it doesn't mention the use of curly braces. Perhaps they assume their &quot;state of the art&quot; <em>static</em> code <em>analysis</em> <em>tools</em> will find potential issues (like Apple's goto fail failure).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "NASA's 10 rules for developing mission critical code [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pixelscommander.com/wp-content/uploads/2014/12/P10.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-11T16:16:01.000Z",
      "title": null,
      "url": null,
      "author": "rquirk",
      "points": null,
      "story_text": null,
      "comment_text": "Heh, that agony description was eerily familiar, and I&#x27;d be the employee! The hard part is not being afraid to make an obviously right change, even if it means spending ages manually testing things and then continuing to follow up weeks later when the non-obvious things you didn&#x27;t think of break :)<p>Even in the face of changing requirements I&#x27;ve found that there are substrates of code that do their job without (showing?) major bugs for years. They never needing fixing. That&#x27;s your good code. If you had unit tests, you&#x27;d never run them anyway because you never touch that code. They are the &quot;select()&quot;s of this world, but specific to whatever you&#x27;re writing.<p>Now if the whole system had to be rewritten, the old tests would be useless anyway. You mention requirements that have changed, so those tests you had would no longer apply. You&#x27;d have to write a new system <i>and</i> new tests ;-)<p>FWIW I&#x27;ve found that peer code review and static analysis tools give you a lot of what unit tests would anyway, without the overhead of having to write the tests and update the dead code when you rewrite the affected part of the system.<p>I mean... what&#x27;s the point of code anyway? Is it to be &quot;perfect&quot;? Or is it to do a job, earn you money, and be more or less maintainable? Constantly refactoring to stay in the same place is worse than copy-pasting code, from a business owner&#x27;s POV. Sometimes it is better to have 2 copy pasted methods that are deployed and the customers are happy, than trying to have 1 perfect method sat in development. If those 2 methods never need updating again, you wasted time refactoring. If you would need a third copied method later on, that&#x27;s the time to refactor.<p>Maybe I&#x27;m being a bit devil&#x27;s advocatey. Unit tests and refactoring are good tools, but they are not &quot;free&quot; (since you have to test the real system anyway at some point) and Uncle Bob is a bit of a snake oil salesman anyway :-P",
      "num_comments": null,
      "story_id": 8869608,
      "story_title": "Lessons learned from the big rewrite",
      "story_url": "http://www.anton-pirker.at/the-big-rewrite-war-story/",
      "parent_id": 8870148,
      "created_at_i": 1420992961,
      "_tags": [
        "comment",
        "author_rquirk",
        "story_8869608"
      ],
      "objectID": "8870294",
      "_highlightResult": {
        "author": {
          "value": "rquirk",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Heh, that agony description was eerily familiar, and I'd be the employee! The hard part is not being afraid to make an obviously right change, even if it means spending ages manually testing things and then continuing to follow up weeks later when the non-obvious things you didn't think of break :)<p>Even in the face of changing requirements I've found that there are substrates of code that do their job without (showing?) major bugs for years. They never needing fixing. That's your good code. If you had unit tests, you'd never run them anyway because you never touch that code. They are the &quot;select()&quot;s of this world, but specific to whatever you're writing.<p>Now if the whole system had to be rewritten, the old tests would be useless anyway. You mention requirements that have changed, so those tests you had would no longer apply. You'd have to write a new system <i>and</i> new tests ;-)<p>FWIW I've found that peer code review and <em>static</em> <em>analysis</em> <em>tools</em> give you a lot of what unit tests would anyway, without the overhead of having to write the tests and update the dead code when you rewrite the affected part of the system.<p>I mean... what's the point of code anyway? Is it to be &quot;perfect&quot;? Or is it to do a job, earn you money, and be more or less maintainable? Constantly refactoring to stay in the same place is worse than copy-pasting code, from a business owner's POV. Sometimes it is better to have 2 copy pasted methods that are deployed and the customers are happy, than trying to have 1 perfect method sat in development. If those 2 methods never need updating again, you wasted time refactoring. If you would need a third copied method later on, that's the time to refactor.<p>Maybe I'm being a bit devil's advocatey. Unit tests and refactoring are good <em>tools</em>, but they are not &quot;free&quot; (since you have to test the real system anyway at some point) and Uncle Bob is a bit of a snake oil salesman anyway :-P",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lessons learned from the big rewrite",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.anton-pirker.at/the-big-rewrite-war-story/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-08T18:04:23.000Z",
      "title": null,
      "url": null,
      "author": "nanolith",
      "points": null,
      "story_text": null,
      "comment_text": "While this particular vulnerability in OpenSSL isn&#x27;t nearly as bad as some of the other recent ones, it drives me crazy that we still have NULL pointer dereferences in something this critical.  The worst part of this library is that the way it is organized makes it difficult to find these problems, or to use tools such as static analyzers to help.  There are some amazing static analysis tools out there for C, but they are rendered useless by some of the hackery used in this library, such as their custom allocators.  I don&#x27;t mean to sound negative -- the OpenSSL team has done a great job making this library available in the first place -- but given how heavily this library is relied upon, better discipline is needed in this code base.<p>LibreSSL is a step in the right direction, and I commend the OpenBSD team for taking on this alternative.  However, it&#x27;s only a starting point.  The entire approach of OpenSSL is dated, and it has not done a good job keeping up with our modern understanding of solid security engineering.  The code base needs to be overhauled from the ground up with modern security and software development practices in mind.  If ever there were a library that should be designed using formal proofs in software, it&#x27;s this one.  Even basic TDD with good code coverage would catch the majority of the bugs that have been discovered in OpenSSL over the past ten years.<p>&lt;&#x2F;rant&gt;",
      "num_comments": null,
      "story_id": 8856717,
      "story_title": "OpenSSL Security Advisory",
      "story_url": "https://www.openssl.org/news/secadv_20150108.txt",
      "parent_id": 8856717,
      "created_at_i": 1420740263,
      "_tags": [
        "comment",
        "author_nanolith",
        "story_8856717"
      ],
      "objectID": "8857763",
      "_highlightResult": {
        "author": {
          "value": "nanolith",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "While this particular vulnerability in OpenSSL isn't nearly as bad as some of the other recent ones, it drives me crazy that we still have NULL pointer dereferences in something this critical.  The worst part of this library is that the way it is organized makes it difficult to find these problems, or to use <em>tools</em> such as <em>static</em> analyzers to help.  There are some amazing <em>static</em> <em>analysis</em> <em>tools</em> out there for C, but they are rendered useless by some of the hackery used in this library, such as their custom allocators.  I don't mean to sound negative -- the OpenSSL team has done a great job making this library available in the first place -- but given how heavily this library is relied upon, better discipline is needed in this code base.<p>LibreSSL is a step in the right direction, and I commend the OpenBSD team for taking on this alternative.  However, it's only a starting point.  The entire approach of OpenSSL is dated, and it has not done a good job keeping up with our modern understanding of solid security engineering.  The code base needs to be overhauled from the ground up with modern security and software development practices in mind.  If ever there were a library that should be designed using formal proofs in software, it's this one.  Even basic TDD with good code coverage would catch the majority of the bugs that have been discovered in OpenSSL over the past ten years.<p>&lt;/rant&gt;",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "OpenSSL Security Advisory",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.openssl.org/news/secadv_20150108.txt",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-07T23:25:46.000Z",
      "title": null,
      "url": null,
      "author": "Ded7xSEoPKYNsDd",
      "points": null,
      "story_text": null,
      "comment_text": "This is certainly impossible on x86 - you can even interleave two different instruction streams (which is mainly used to confuse static analysis tools).",
      "num_comments": null,
      "story_id": 8853026,
      "story_title": "RISC vs. CISC (2000)",
      "story_url": "http://cs.stanford.edu/people/eroberts/courses/soco/projects/risc/risccisc/",
      "parent_id": 8853678,
      "created_at_i": 1420673146,
      "_tags": [
        "comment",
        "author_Ded7xSEoPKYNsDd",
        "story_8853026"
      ],
      "objectID": "8854024",
      "_highlightResult": {
        "author": {
          "value": "Ded7xSEoPKYNsDd",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is certainly impossible on x86 - you can even interleave two different instruction streams (which is mainly used to confuse <em>static</em> <em>analysis</em> <em>tools</em>).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "RISC vs. CISC (2000)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cs.stanford.edu/people/eroberts/courses/soco/projects/risc/risccisc/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-06T16:39:35.000Z",
      "title": null,
      "url": null,
      "author": "oblio",
      "points": null,
      "story_text": null,
      "comment_text": "What&#x27;s so ugly&#x2F;trash about that?<p>It looks quite simple&#x2F;elegant. Plus what they&#x27;re added is meant to be used by static analysis tools and IDEs, not actually for validating things at runtime.",
      "num_comments": null,
      "story_id": 8844927,
      "story_title": "Type hinting for Python",
      "story_url": "http://lwn.net/SubscriberLink/627418/a09d6081e42b3bc0/",
      "parent_id": 8845181,
      "created_at_i": 1420562375,
      "_tags": [
        "comment",
        "author_oblio",
        "story_8844927"
      ],
      "objectID": "8845237",
      "_highlightResult": {
        "author": {
          "value": "oblio",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "What's so ugly/trash about that?<p>It looks quite simple/elegant. Plus what they're added is meant to be used by <em>static</em> <em>analysis</em> <em>tools</em> and IDEs, not actually for validating things at runtime.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Type hinting for Python",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lwn.net/SubscriberLink/627418/a09d6081e42b3bc0/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-05T01:14:33.000Z",
      "title": null,
      "url": null,
      "author": "spion",
      "points": null,
      "story_text": null,
      "comment_text": "C itself is also scary. Most other languages provide at least run-time safety; some provide great compile-time safety. C providing neither <i>and</i> being the most popular language for system software is what is really scary.<p>I guess part of what is scary about C is that it gives you the illusion of a high-level language, but unless you know all UB by heart, you might accidentally start working in assembly.<p>Isn&#x27;t there at least a flag that activates warnings for stuff like this? I tried -Wall in both clang and gcc and they didn&#x27;t say jack shit.<p>What do modern C developers do these days? Arm themselves with expensive advanced static analysis tools to their teeth?",
      "num_comments": null,
      "story_id": 8833965,
      "story_title": "Deconstructing K&R C (2010)",
      "story_url": "http://c.learncodethehardway.org/book/krcritique.html",
      "parent_id": 8836445,
      "created_at_i": 1420420473,
      "_tags": [
        "comment",
        "author_spion",
        "story_8833965"
      ],
      "objectID": "8836639",
      "_highlightResult": {
        "author": {
          "value": "spion",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "C itself is also scary. Most other languages provide at least run-time safety; some provide great compile-time safety. C providing neither <i>and</i> being the most popular language for system software is what is really scary.<p>I guess part of what is scary about C is that it gives you the illusion of a high-level language, but unless you know all UB by heart, you might accidentally start working in assembly.<p>Isn't there at least a flag that activates warnings for stuff like this? I tried -Wall in both clang and gcc and they didn't say jack shit.<p>What do modern C developers do these days? Arm themselves with expensive advanced <em>static</em> <em>analysis</em> <em>tools</em> to their teeth?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Deconstructing K&R C (2010)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://c.learncodethehardway.org/book/krcritique.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-03T13:36:13.000Z",
      "title": null,
      "url": null,
      "author": "nawitus",
      "points": null,
      "story_text": null,
      "comment_text": "&gt;Automating restarts &#x2F; Automatic browser refresh<p>I don&#x27;t think this is very beneficial when your project&#x27;s complexity grows enough to require a non-trivial build. It&#x27;s nice to have for simple projects, of course.<p>&gt; Using control flow modules (such as async)<p>In my experience the async module creates verbose and ugly looking code. In almost all cases promises are a better solution. Of course, even promises are pretty ugly as it&#x27;s a &quot;hack&quot; to solve a problem at the language level. ES7 proposal includes async&#x2F;await, maybe that&#x27;ll finally solve this problem.<p>&gt;Not using static analysis tools<p>I&#x27;d also recommend checking out TypeScript and tslint for complex Node.js applications.",
      "num_comments": null,
      "story_id": 8827525,
      "story_title": "Mistakes Node.js Developers Make",
      "story_url": "https://www.airpair.com/node.js/posts/top-10-mistakes-node-developers-make",
      "parent_id": 8827525,
      "created_at_i": 1420292173,
      "_tags": [
        "comment",
        "author_nawitus",
        "story_8827525"
      ],
      "objectID": "8830703",
      "_highlightResult": {
        "author": {
          "value": "nawitus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;Automating restarts / Automatic browser refresh<p>I don't think this is very beneficial when your project's complexity grows enough to require a non-trivial build. It's nice to have for simple projects, of course.<p>&gt; Using control flow modules (such as async)<p>In my experience the async module creates verbose and ugly looking code. In almost all cases promises are a better solution. Of course, even promises are pretty ugly as it's a &quot;hack&quot; to solve a problem at the language level. ES7 proposal includes async/await, maybe that'll finally solve this problem.<p>&gt;Not using <em>static</em> <em>analysis</em> <em>tools</em><p>I'd also recommend checking out TypeScript and tslint for complex Node.js applications.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mistakes Node.js Developers Make",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.airpair.com/node.js/posts/top-10-mistakes-node-developers-make",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-03T09:41:07.000Z",
      "title": null,
      "url": null,
      "author": "GeneralError",
      "points": null,
      "story_text": null,
      "comment_text": "Why is this post on the front page, what&#x27;s so special about it?<p>Read the TOC:<p>1 Not using development tools<p>2 Blocking the event loop<p>3 Executing a call back multiple times<p>4 The Christmas tree of callbacks (Callback light)<p>5 Creating big monolithic applications<p>6 Poor logging<p>7 No tests<p>8 Not using static analysis tools<p>9 Zero monitoring or profiling<p>10 Debugging with console.log<p>The author talks about trivial or something that has already been written few times.<p>It would be interesting to see if a post with the title &quot;Top 10 Mistakes C # Developers Make&quot; and comparable content would get just drop the same attention and encouragement. Maybe if it was written by Jon Skeet...",
      "num_comments": null,
      "story_id": 8827525,
      "story_title": "Mistakes Node.js Developers Make",
      "story_url": "https://www.airpair.com/node.js/posts/top-10-mistakes-node-developers-make",
      "parent_id": 8827525,
      "created_at_i": 1420278067,
      "_tags": [
        "comment",
        "author_GeneralError",
        "story_8827525"
      ],
      "objectID": "8830357",
      "_highlightResult": {
        "author": {
          "value": "GeneralError",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Why is this post on the front page, what's so special about it?<p>Read the TOC:<p>1 Not using development <em>tools</em><p>2 Blocking the event loop<p>3 Executing a call back multiple times<p>4 The Christmas tree of callbacks (Callback light)<p>5 Creating big monolithic applications<p>6 Poor logging<p>7 No tests<p>8 Not using <em>static</em> <em>analysis</em> <em>tools</em><p>9 Zero monitoring or profiling<p>10 Debugging with console.log<p>The author talks about trivial or something that has already been written few times.<p>It would be interesting to see if a post with the title &quot;Top 10 Mistakes C # Developers Make&quot; and comparable content would get just drop the same attention and encouragement. Maybe if it was written by Jon Skeet...",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mistakes Node.js Developers Make",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.airpair.com/node.js/posts/top-10-mistakes-node-developers-make",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-30T15:24:58.000Z",
      "title": null,
      "url": null,
      "author": "kasey_junk",
      "points": null,
      "story_text": null,
      "comment_text": "Unused import cleanup has been a standard part of all the major Java IDEs for quite some time.  Further, checkstyle and other static analysis tools can easily replicate the check.",
      "num_comments": null,
      "story_id": 8814202,
      "story_title": "Everyday hassles in Go",
      "story_url": "http://crufter.com/2014/12/01/everyday-hassles-in-go/",
      "parent_id": 8814828,
      "created_at_i": 1419953098,
      "_tags": [
        "comment",
        "author_kasey_junk",
        "story_8814202"
      ],
      "objectID": "8814924",
      "_highlightResult": {
        "author": {
          "value": "kasey_junk",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Unused import cleanup has been a standard part of all the major Java IDEs for quite some time.  Further, checkstyle and other <em>static</em> <em>analysis</em> <em>tools</em> can easily replicate the check.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Everyday hassles in Go",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://crufter.com/2014/12/01/everyday-hassles-in-go/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-29T14:38:45.000Z",
      "title": null,
      "url": null,
      "author": "untitaker_",
      "points": null,
      "story_text": null,
      "comment_text": "&gt;Imports shouldn&#x27;t have side-effects (like registering functions with flask).<p>Imports don&#x27;t have side-effects. Using Flask&#x27;s route decorators has.<p>&gt;You shouldn&#x27;t use globals (like the flask app).<p>The Flask app is just as much a global as any other class instance in any OOP language. Whether you make it a module-level object or not is your choice.<p>&gt;Objects (such as the flask app) should be immutable whenever possible.<p>They hardly are. This is a good rule which nobody follows, and I don&#x27;t think you&#x27;d gain enough advantages through this.<p>&gt;You need to make sure that you import every file with a request handler, and those imports often end up unused (only imported for their side-effects), which confuses linters and other static analysis tools.<p>The fact that your app has import side-effects is your fault, this pattern is not at all encouraged by Flask. You probably want to use blueprints.",
      "num_comments": null,
      "story_id": 8808453,
      "story_title": "Things which aren't magic – Flask and app.route",
      "story_url": "http://ains.co/blog/things-which-arent-magic-flask-part-1.html",
      "parent_id": 8808916,
      "created_at_i": 1419863925,
      "_tags": [
        "comment",
        "author_untitaker_",
        "story_8808453"
      ],
      "objectID": "8809914",
      "_highlightResult": {
        "author": {
          "value": "untitaker_",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;Imports shouldn't have side-effects (like registering functions with flask).<p>Imports don't have side-effects. Using Flask's route decorators has.<p>&gt;You shouldn't use globals (like the flask app).<p>The Flask app is just as much a global as any other class instance in any OOP language. Whether you make it a module-level object or not is your choice.<p>&gt;Objects (such as the flask app) should be immutable whenever possible.<p>They hardly are. This is a good rule which nobody follows, and I don't think you'd gain enough advantages through this.<p>&gt;You need to make sure that you import every file with a request handler, and those imports often end up unused (only imported for their side-effects), which confuses linters and other <em>static</em> <em>analysis</em> <em>tools</em>.<p>The fact that your app has import side-effects is your fault, this pattern is not at all encouraged by Flask. You probably want to use blueprints.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Things which aren't magic – Flask and app.route",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ains.co/blog/things-which-arent-magic-flask-part-1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-29T08:11:46.000Z",
      "title": null,
      "url": null,
      "author": "alangpierce",
      "points": null,
      "story_text": null,
      "comment_text": "Flask&#x27;s route decorator gives a nice syntax, but it goes against some ideal best practices:<p>* Imports shouldn&#x27;t have side-effects (like registering functions with flask).<p>* You shouldn&#x27;t use globals (like the flask app).<p>* Objects (such as the flask app) should be immutable whenever possible.<p>None of these are hard-and-fast rules, and Python code has a tendency to give up purity in favor of syntax, so it&#x27;s certainly justified for Flask to be designed this way, but it&#x27;s still a bit unsettling, and can lead to bugs, especially in larger cases when your handlers are split up across many files. Some examples:<p>* You need to make sure that you import every file with a request handler, and those imports often end up unused (only imported for their side-effects), which confuses linters and other static analysis tools.<p>* It&#x27;s also easy to accidentally import a new file through some other import chain, so someone rearranging imports later might accidentally disable part of your app by never importing it.<p>* It can break some &quot;advanced&quot; uses of modules&#x2F;imports, such as the reload function.<p>* Test code and scripts that want access to your request handlers are forced to build a (partial) Flask app, even if they have no use for one.<p>At my job, I recently changed our Flask handlers to be registered with a different approach (but the same API) that avoids most of these issues. Rather than setting things up with side-effects, it makes the route details easy to introspect later. Here&#x27;s what our implementation of @route() looks like now:<p><pre><code>  def route(rule, **options):\n      def route_decorator(func):\n          # Attach the route rule to the request handler.\n          func.func_dict.setdefault(&#x27;_flask_routes&#x27;, []).append((rule, options))\n  \n          # Add the request handler to this module&#x27;s list of handlers.\n          module = sys.modules[func.__module__]\n          if not hasattr(module, &#x27;_FLASK_HANDLERS&#x27;):\n              module. _FLASK_HANDLERS = {}\n          module._FLASK_HANDLERS[func.__name__] = func\n          return func\n  \n      return route_decorator\n</code></pre>\nSo if you have a module called user_routes.py, with 3 Flask request handlers, then user_routes._FLASK_HANDLERS is a list containing those three functions. If one of those handlers is user_routes.create_user, then you can access user_routes.create_user._flask_routes in order to see the names of all of the route strings (usually just one) registered for that request handler.<p>Then, in separate code, there&#x27;s a list of all modules with request handlers, and we import and introspect all of them as part of a function that sets up and returns the Flask app. So outside code never has any way of accessing a partially-registered Flask app, imports of request handler modules are &quot;pure&quot;, and request handlers can often be defined without depending on Flask at all.",
      "num_comments": null,
      "story_id": 8808453,
      "story_title": "Things which aren't magic – Flask and app.route",
      "story_url": "http://ains.co/blog/things-which-arent-magic-flask-part-1.html",
      "parent_id": 8808453,
      "created_at_i": 1419840706,
      "_tags": [
        "comment",
        "author_alangpierce",
        "story_8808453"
      ],
      "objectID": "8808916",
      "_highlightResult": {
        "author": {
          "value": "alangpierce",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Flask's route decorator gives a nice syntax, but it goes against some ideal best practices:<p>* Imports shouldn't have side-effects (like registering functions with flask).<p>* You shouldn't use globals (like the flask app).<p>* Objects (such as the flask app) should be immutable whenever possible.<p>None of these are hard-and-fast rules, and Python code has a tendency to give up purity in favor of syntax, so it's certainly justified for Flask to be designed this way, but it's still a bit unsettling, and can lead to bugs, especially in larger cases when your handlers are split up across many files. Some examples:<p>* You need to make sure that you import every file with a request handler, and those imports often end up unused (only imported for their side-effects), which confuses linters and other <em>static</em> <em>analysis</em> <em>tools</em>.<p>* It's also easy to accidentally import a new file through some other import chain, so someone rearranging imports later might accidentally disable part of your app by never importing it.<p>* It can break some &quot;advanced&quot; uses of modules/imports, such as the reload function.<p>* Test code and scripts that want access to your request handlers are forced to build a (partial) Flask app, even if they have no use for one.<p>At my job, I recently changed our Flask handlers to be registered with a different approach (but the same API) that avoids most of these issues. Rather than setting things up with side-effects, it makes the route details easy to introspect later. Here's what our implementation of @route() looks like now:<p><pre><code>  def route(rule, **options):\n      def route_decorator(func):\n          # Attach the route rule to the request handler.\n          func.func_dict.setdefault('_flask_routes', []).append((rule, options))\n  \n          # Add the request handler to this module's list of handlers.\n          module = sys.modules[func.__module__]\n          if not hasattr(module, '_FLASK_HANDLERS'):\n              module. _FLASK_HANDLERS = {}\n          module._FLASK_HANDLERS[func.__name__] = func\n          return func\n  \n      return route_decorator\n</code></pre>\nSo if you have a module called user_routes.py, with 3 Flask request handlers, then user_routes._FLASK_HANDLERS is a list containing those three functions. If one of those handlers is user_routes.create_user, then you can access user_routes.create_user._flask_routes in order to see the names of all of the route strings (usually just one) registered for that request handler.<p>Then, in separate code, there's a list of all modules with request handlers, and we import and introspect all of them as part of a function that sets up and returns the Flask app. So outside code never has any way of accessing a partially-registered Flask app, imports of request handler modules are &quot;pure&quot;, and request handlers can often be defined without depending on Flask at all.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Things which aren't magic – Flask and app.route",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ains.co/blog/things-which-arent-magic-flask-part-1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-27T21:32:02.000Z",
      "title": null,
      "url": null,
      "author": "_random_",
      "points": null,
      "story_text": null,
      "comment_text": "C#, obviously. It&#x27;s the only modern language that provides ALL of the following:<p>1) Static and dynamic typing<p>2) OOP and functional paradigms<p>3) Multi-platform via single framework: WP, Android, iOS, Mac, PC, Xbox, PS4, Linux etc.<p>4) Two super-powerful IDE-integrated static analysis tools to choose from: ReSharper and Roslyn<p>5) Mature workflows for developing Web, mobile, enterprise apps and games.<p>6) High performance on WP and desktop, reasonable elsewhere.",
      "num_comments": null,
      "story_id": 8803678,
      "story_title": "Programming languages and Frameworks to learn in 2015",
      "story_url": "",
      "parent_id": 8803678,
      "created_at_i": 1419715922,
      "_tags": [
        "comment",
        "author__random_",
        "story_8803678"
      ],
      "objectID": "8804014",
      "_highlightResult": {
        "author": {
          "value": "_random_",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "C#, obviously. It's the only modern language that provides ALL of the following:<p>1) <em>Static</em> and dynamic typing<p>2) OOP and functional paradigms<p>3) Multi-platform via single framework: WP, Android, iOS, Mac, PC, Xbox, PS4, Linux etc.<p>4) Two super-powerful IDE-integrated <em>static</em> <em>analysis</em> <em>tools</em> to choose from: ReSharper and Roslyn<p>5) Mature workflows for developing Web, mobile, enterprise apps and games.<p>6) High performance on WP and desktop, reasonable elsewhere.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Programming languages and Frameworks to learn in 2015",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-16T13:43:27.000Z",
      "title": null,
      "url": null,
      "author": "corbet",
      "points": null,
      "story_text": null,
      "comment_text": "Interesting work, but I wish they had put a date on it.  The fact that they were working with the 2.6.15 kernel suggests that the work is old now.  Certainly you will find few bugs that are fixable in the current kernel by looking at 2.6.15!<p>My suspicion is that this work is abandoned at this point, which is too bad.  The last release tarball is over four years old...  We could really use better static analysis tools, but so much of this stuff never seems to escape academia.",
      "num_comments": null,
      "story_id": 8755989,
      "story_title": "RELAY: Static Race Detection on Millions of Lines of Code",
      "story_url": "http://cseweb.ucsd.edu/~jvoung/race/",
      "parent_id": 8755989,
      "created_at_i": 1418737407,
      "_tags": [
        "comment",
        "author_corbet",
        "story_8755989"
      ],
      "objectID": "8757050",
      "_highlightResult": {
        "author": {
          "value": "corbet",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Interesting work, but I wish they had put a date on it.  The fact that they were working with the 2.6.15 kernel suggests that the work is old now.  Certainly you will find few bugs that are fixable in the current kernel by looking at 2.6.15!<p>My suspicion is that this work is abandoned at this point, which is too bad.  The last release tarball is over four years old...  We could really use better <em>static</em> <em>analysis</em> <em>tools</em>, but so much of this stuff never seems to escape academia.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "RELAY: <em>Static</em> Race Detection on Millions of Lines of Code",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "http://cseweb.ucsd.edu/~jvoung/race/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-11T15:19:53.000Z",
      "title": null,
      "url": null,
      "author": "dragonwriter",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; There will always be people to say that doing things manually is better than having the computer do it<p>Languages that don&#x27;t require a heavy IDE (particularly one including lots of tools for writing and rewriting code -- static analysis tools are a different issue) aren&#x27;t &quot;doing things manually instead of having the computer do it&quot; -- interacting with the language itself is no more &quot;manual&quot; than interacting directly with the IDE. Its just aligning the write-language with the read-language. If I need a separate visual language to use to write code from the language I&#x27;m nominally working in, that both increases the overall mental complexity and indicates that there are weaknesses in the abstractions available in the nominal working language.",
      "num_comments": null,
      "story_id": 8733352,
      "story_title": "Go 1.4 is released",
      "story_url": "https://blog.golang.org/go1.4",
      "parent_id": 8735066,
      "created_at_i": 1418311193,
      "_tags": [
        "comment",
        "author_dragonwriter",
        "story_8733352"
      ],
      "objectID": "8735172",
      "_highlightResult": {
        "author": {
          "value": "dragonwriter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; There will always be people to say that doing things manually is better than having the computer do it<p>Languages that don't require a heavy IDE (particularly one including lots of <em>tools</em> for writing and rewriting code -- <em>static</em> <em>analysis</em> <em>tools</em> are a different issue) aren't &quot;doing things manually instead of having the computer do it&quot; -- interacting with the language itself is no more &quot;manual&quot; than interacting directly with the IDE. Its just aligning the write-language with the read-language. If I need a separate visual language to use to write code from the language I'm nominally working in, that both increases the overall mental complexity and indicates that there are weaknesses in the abstractions available in the nominal working language.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Go 1.4 is released",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://blog.golang.org/go1.4",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-27T20:38:53.000Z",
      "title": null,
      "url": null,
      "author": "ajkjk",
      "points": null,
      "story_text": null,
      "comment_text": "(rant ahead) What do I expect? I would expect engineers to identify how awful this situation is years ago and build a replacement. Finally, in the last few years, there are some serious attempts at doing so (Rust comes to mind). But it&#x27;s taken this long and that astounds me.<p>You&#x27;ll get no argument from me that a language needs direct access to memory. My problem is that the difference between correct code and exploitable code is extreme diligence on the part of the programmer, which fails constantly. [Arguably static analysis type tools can help a lot, but, that&#x27;s just trying to recover from an already bad situation.]<p>For example, in the prequel to the OP&#x27;s article (<a href=\"http://googleprojectzero.blogspot.com/2014/07/pwn4fun-spring-2014-safari-part-i_24.html\" rel=\"nofollow\">http:&#x2F;&#x2F;googleprojectzero.blogspot.com&#x2F;2014&#x2F;07&#x2F;pwn4fun-spring...</a>), the original bug was overflowing an unsigned int. You should be spitting out your coffee! (&#x2F;beverage of choice) How can it be be that a (presumably expert) programmer can write code that silently overflows integers <i>by accident</i>?<p>&quot;It&#x27;s 2014 and this still happens.&quot;\nThat&#x27;s my favorite non-argument. It&#x27;s not constructive but it expresses how I feel. We&#x27;re well past the years where people have had time to reflect on the fact that people have already  struggled with and tried to solve the problem that <i>this should simply not be possible</i>. I don&#x27;t need a fancy type system to enforce &#x27;checked integers&#x27; are the only things that are passed to to my memcpys - but I do have to be willing, at some point, to discard the broken versions of the same thing I&#x27;ve been holding on to for 30 years in favor of something less perilous.<p>Oh, and, if you read the rest of that prequel article, the person who fixed the bug missed something else in doing so. They&#x27;re adding overflow-safe versions of &#x27;size_t&#x27; and &#x27;unsigned int&#x27; together. Again, embarrassing. Not for their error, but because we-as-a-species are still writing code where that mistake can be made, and then not doing anything about it when it inevitably happens.",
      "num_comments": null,
      "story_id": 8664971,
      "story_title": "Escaping the Safari sandbox with a kernel GPU bug",
      "story_url": "http://googleprojectzero.blogspot.com/2014/11/pwn4fun-spring-2014-safari-part-ii.html",
      "parent_id": 8668374,
      "created_at_i": 1417120733,
      "_tags": [
        "comment",
        "author_ajkjk",
        "story_8664971"
      ],
      "objectID": "8668667",
      "_highlightResult": {
        "author": {
          "value": "ajkjk",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "(rant ahead) What do I expect? I would expect engineers to identify how awful this situation is years ago and build a replacement. Finally, in the last few years, there are some serious attempts at doing so (Rust comes to mind). But it's taken this long and that astounds me.<p>You'll get no argument from me that a language needs direct access to memory. My problem is that the difference between correct code and exploitable code is extreme diligence on the part of the programmer, which fails constantly. [Arguably <em>static</em> <em>analysis</em> type <em>tools</em> can help a lot, but, that's just trying to recover from an already bad situation.]<p>For example, in the prequel to the OP's article (<a href=\"http://googleprojectzero.blogspot.com/2014/07/pwn4fun-spring-2014-safari-part-i_24.html\" rel=\"nofollow\">http://googleprojectzero.blogspot.com/2014/07/pwn4fun-spring...</a>), the original bug was overflowing an unsigned int. You should be spitting out your coffee! (/beverage of choice) How can it be be that a (presumably expert) programmer can write code that silently overflows integers <i>by accident</i>?<p>&quot;It's 2014 and this still happens.&quot;\nThat's my favorite non-argument. It's not constructive but it expresses how I feel. We're well past the years where people have had time to reflect on the fact that people have already  struggled with and tried to solve the problem that <i>this should simply not be possible</i>. I don't need a fancy type system to enforce 'checked integers' are the only things that are passed to to my memcpys - but I do have to be willing, at some point, to discard the broken versions of the same thing I've been holding on to for 30 years in favor of something less perilous.<p>Oh, and, if you read the rest of that prequel article, the person who fixed the bug missed something else in doing so. They're adding overflow-safe versions of 'size_t' and 'unsigned int' together. Again, embarrassing. Not for their error, but because we-as-a-species are still writing code where that mistake can be made, and then not doing anything about it when it inevitably happens.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Escaping the Safari sandbox with a kernel GPU bug",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://googleprojectzero.blogspot.com/2014/11/pwn4fun-spring-2014-safari-part-ii.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-27T18:36:52.000Z",
      "title": null,
      "url": null,
      "author": "saryant",
      "points": null,
      "story_text": null,
      "comment_text": "Yeah, pretty sure you could get WartRemover or one of the other static analysis tools to disallow these sort of egregious violations.",
      "num_comments": null,
      "story_id": 8664989,
      "story_title": "Amazon is hiring Clojure devs",
      "story_url": "http://lispjobs.wordpress.com/2014/11/25/clojure-software-development-engineers-amazon-com/",
      "parent_id": 8668005,
      "created_at_i": 1417113412,
      "_tags": [
        "comment",
        "author_saryant",
        "story_8664989"
      ],
      "objectID": "8668376",
      "_highlightResult": {
        "author": {
          "value": "saryant",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Yeah, pretty sure you could get WartRemover or one of the other <em>static</em> <em>analysis</em> <em>tools</em> to disallow these sort of egregious violations.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Amazon is hiring Clojure devs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lispjobs.wordpress.com/2014/11/25/clojure-software-development-engineers-amazon-com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-20T07:06:43.000Z",
      "title": null,
      "url": null,
      "author": "shadowfox",
      "points": null,
      "story_text": null,
      "comment_text": "There is always idea of Gradual Typing [1] which has been implemented with varying degrees of success. There are also a large set of static analysis theories&#x2F;tools which can help here.<p>It is also worth noting that if you dont want (global) type inference, you can get far in a language with permissive casting, type annotations and local inference. The results aren&#x27;t a panacea though.<p>&gt;  Suppose you could catch 99% of type-based errors instead of 100%, and in addition, use a compiler switch to see all the case statements where a class of a type is missing.<p>I am not quite sure what you mean by this. Care to elaborate? (In general, with inference systems, missing type information is hard(ish) to localize. So pointing out where exactly a type error occurred is non-trivial)<p>[1] <a href=\"https://en.wikipedia.org/wiki/Gradual_typing\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Gradual_typing</a>",
      "num_comments": null,
      "story_id": 8480551,
      "story_title": "Haskell Is Exceptionally Unsafe",
      "story_url": "http://existentialtype.wordpress.com/2012/08/14/haskell-is-exceptionally-unsafe/",
      "parent_id": 8480939,
      "created_at_i": 1413788803,
      "_tags": [
        "comment",
        "author_shadowfox",
        "story_8480551"
      ],
      "objectID": "8480975",
      "_highlightResult": {
        "author": {
          "value": "shadowfox",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "There is always idea of Gradual Typing [1] which has been implemented with varying degrees of success. There are also a large set of <em>static</em> <em>analysis</em> theories/<em>tools</em> which can help here.<p>It is also worth noting that if you dont want (global) type inference, you can get far in a language with permissive casting, type annotations and local inference. The results aren't a panacea though.<p>&gt;  Suppose you could catch 99% of type-based errors instead of 100%, and in addition, use a compiler switch to see all the case statements where a class of a type is missing.<p>I am not quite sure what you mean by this. Care to elaborate? (In general, with inference systems, missing type information is hard(ish) to localize. So pointing out where exactly a type error occurred is non-trivial)<p>[1] <a href=\"https://en.wikipedia.org/wiki/Gradual_typing\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Gradual_typing</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Haskell Is Exceptionally Unsafe",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://existentialtype.wordpress.com/2012/08/14/haskell-is-exceptionally-unsafe/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-20T02:59:41.000Z",
      "title": null,
      "url": null,
      "author": "eliteraspberrie",
      "points": null,
      "story_text": null,
      "comment_text": "As well as being the author of the algorithms in NaCl, djb is also a specialist in secure software development, as tptacek mentioned.<p>You can be reasonably sure that his code is bug free, but they went the extra step of proving the absence of certain types of bugs using static analysis tools. One of the project&#x27;s deliverables mentioned they used Frama-C to prove the absence of integer overflows, for example. (I will update this comment when I find the specific report.)<p>Other projects take the traditional approach of trusting that the code looks right until someone proves otherwise.<p>Edit: The report was probably one of these, which I can&#x27;t access anymore:<p><a href=\"http://www.cace-project.eu/downloads/deliverables-y1/CACE_D5.1_Security_Policies_for_Cryptographic_Software.pdf\" rel=\"nofollow\">http:&#x2F;&#x2F;www.cace-project.eu&#x2F;downloads&#x2F;deliverables-y1&#x2F;CACE_D5...</a>\n<a href=\"http://www.cace-project.eu/downloads/deliverables-y1/CACE_M5.2_Machine-assisted_verficiation_and_certification_tool_specification.pdf\" rel=\"nofollow\">http:&#x2F;&#x2F;www.cace-project.eu&#x2F;downloads&#x2F;deliverables-y1&#x2F;CACE_M5...</a>\n<a href=\"http://www.cace-project.eu/downloads/deliverables-y3/31_CACE_D5.3-V1.1.PDF\" rel=\"nofollow\">http:&#x2F;&#x2F;www.cace-project.eu&#x2F;downloads&#x2F;deliverables-y3&#x2F;31_CACE...</a>",
      "num_comments": null,
      "story_id": 8478427,
      "story_title": "Making sure crypto remains insecure [pdf]",
      "story_url": "http://cr.yp.to/talks/2014.10.18/slides-djb-20141018-a4.pdf",
      "parent_id": 8479582,
      "created_at_i": 1413773981,
      "_tags": [
        "comment",
        "author_eliteraspberrie",
        "story_8478427"
      ],
      "objectID": "8480533",
      "_highlightResult": {
        "author": {
          "value": "eliteraspberrie",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "As well as being the author of the algorithms in NaCl, djb is also a specialist in secure software development, as tptacek mentioned.<p>You can be reasonably sure that his code is bug free, but they went the extra step of proving the absence of certain types of bugs using <em>static</em> <em>analysis</em> <em>tools</em>. One of the project's deliverables mentioned they used Frama-C to prove the absence of integer overflows, for example. (I will update this comment when I find the specific report.)<p>Other projects take the traditional approach of trusting that the code looks right until someone proves otherwise.<p>Edit: The report was probably one of these, which I can't access anymore:<p><a href=\"http://www.cace-project.eu/downloads/deliverables-y1/CACE_D5.1_Security_Policies_for_Cryptographic_Software.pdf\" rel=\"nofollow\">http://www.cace-project.eu/downloads/deliverables-y1/CACE_D5...</a>\n<a href=\"http://www.cace-project.eu/downloads/deliverables-y1/CACE_M5.2_Machine-assisted_verficiation_and_certification_tool_specification.pdf\" rel=\"nofollow\">http://www.cace-project.eu/downloads/deliverables-y1/CACE_M5...</a>\n<a href=\"http://www.cace-project.eu/downloads/deliverables-y3/31_CACE_D5.3-V1.1.PDF\" rel=\"nofollow\">http://www.cace-project.eu/downloads/deliverables-y3/31_CACE...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Making sure crypto remains insecure [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cr.yp.to/talks/2014.10.18/slides-djb-20141018-a4.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-05-25T22:25:25.000Z",
      "title": null,
      "url": null,
      "author": "camtarn",
      "points": null,
      "story_text": null,
      "comment_text": "Unfortunately, JSLint objects strongly to using 'new foo()' without assigning the result to anything, which is a pain if you're using Prototype AJAX since firing off an AJAX request is done by calling 'new Ajax.Request(url, options)'. The only way to get around this seems to be to put parentheses around the statement - there's no way to turn most individual checks on or off, unlike other static analysis tools I've used like PMD and FindBugs.<p>I still use it - because that trailing-comma-in-hash-definition issue in IE is really annoying.",
      "num_comments": null,
      "story_id": 624671,
      "story_title": "JSLint, The Javascript Verifier",
      "story_url": "http://www.jslint.com/",
      "parent_id": 624671,
      "created_at_i": 1243290325,
      "_tags": [
        "comment",
        "author_camtarn",
        "story_624671"
      ],
      "objectID": "625968",
      "_highlightResult": {
        "author": {
          "value": "camtarn",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Unfortunately, JSLint objects strongly to using 'new foo()' without assigning the result to anything, which is a pain if you're using Prototype AJAX since firing off an AJAX request is done by calling 'new Ajax.Request(url, options)'. The only way to get around this seems to be to put parentheses around the statement - there's no way to turn most individual checks on or off, unlike other <em>static</em> <em>analysis</em> <em>tools</em> I've used like PMD and FindBugs.<p>I still use it - because that trailing-comma-in-hash-definition issue in IE is really annoying.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "JSLint, The Javascript Verifier",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.jslint.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-04-24T16:10:29.000Z",
      "title": null,
      "url": null,
      "author": "tptacek",
      "points": null,
      "story_text": null,
      "comment_text": "This is old news, obviously. It's worth pointing out that as good as the code appeared to these reviewers in 2004, between then and now, Microsoft underwent a sea change in code-level quality control. Windows is now likely to be the best reviewed, most rigidly compliant code shipping on the market:<p>* Virtually every Microsoft senior developer has been trained on software security<p>* All shipping code is checked in-house, including some homegrown static analysis tools<p>* Most shipping products have had line-by-line source code reviews done by at least two different firms (we did some of this work for Vista).<p>During the Summer of Worms in '03, when Microsoft security lapses were front-page material on CNN, Bill Gates told the press that Microsoft was going to totally overhaul security and code quality. They weren't kidding. Microsoft now outspends everybody on that.<p>Note: I'm a Mac person.",
      "num_comments": null,
      "story_id": 577540,
      "story_title": "We Are Morons: a quick look at the Win2k source (2004)",
      "story_url": "http://www.kuro5hin.org/story/2004/2/15/71552/7795",
      "parent_id": 577540,
      "created_at_i": 1240589429,
      "_tags": [
        "comment",
        "author_tptacek",
        "story_577540"
      ],
      "objectID": "577684",
      "_highlightResult": {
        "author": {
          "value": "tptacek",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is old news, obviously. It's worth pointing out that as good as the code appeared to these reviewers in 2004, between then and now, Microsoft underwent a sea change in code-level quality control. Windows is now likely to be the best reviewed, most rigidly compliant code shipping on the market:<p>* Virtually every Microsoft senior developer has been trained on software security<p>* All shipping code is checked in-house, including some homegrown <em>static</em> <em>analysis</em> <em>tools</em><p>* Most shipping products have had line-by-line source code reviews done by at least two different firms (we did some of this work for Vista).<p>During the Summer of Worms in '03, when Microsoft security lapses were front-page material on CNN, Bill Gates told the press that Microsoft was going to totally overhaul security and code quality. They weren't kidding. Microsoft now outspends everybody on that.<p>Note: I'm a Mac person.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "We Are Morons: a quick look at the Win2k source (2004)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.kuro5hin.org/story/2004/2/15/71552/7795",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-03-28T20:33:24.000Z",
      "title": null,
      "url": null,
      "author": "silentOpen",
      "points": null,
      "story_text": null,
      "comment_text": "Java still has javac. I suppose an IDE could hide this from you. Of course, Java also has lots of static analysis tools written for it so many errors are caught way before compilation.",
      "num_comments": null,
      "story_id": 535878,
      "story_title": "Joel on Solid State Disks",
      "story_url": "http://www.joelonsoftware.com/items/2009/03/27.html",
      "parent_id": 536601,
      "created_at_i": 1238272404,
      "_tags": [
        "comment",
        "author_silentOpen",
        "story_535878"
      ],
      "objectID": "536752",
      "_highlightResult": {
        "author": {
          "value": "silentOpen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Java still has javac. I suppose an IDE could hide this from you. Of course, Java also has lots of <em>static</em> <em>analysis</em> <em>tools</em> written for it so many errors are caught way before compilation.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Joel on Solid State Disks",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.joelonsoftware.com/items/2009/03/27.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-11-29T18:22:12.000Z",
      "title": null,
      "url": null,
      "author": "seanmcdirmid",
      "points": null,
      "story_text": null,
      "comment_text": "I am a firm believer that the best way to fix programming is through better programming languages, which I learned about myself while working at Coverity. Otherwise I think it was a great place to work: lots of very smart people, a very good business plan, great startup stock (back then), but I'm too idealistic!<p>Static analysis tools are very pragmatic in a world where better languages aren't adopted very often.",
      "num_comments": null,
      "story_id": 4848456,
      "story_title": "Eric Lippert is leaving Microsoft",
      "story_url": "http://ericlippert.com/",
      "parent_id": 4849267,
      "created_at_i": 1354213332,
      "_tags": [
        "comment",
        "author_seanmcdirmid",
        "story_4848456"
      ],
      "objectID": "4849358",
      "_highlightResult": {
        "author": {
          "value": "seanmcdirmid",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I am a firm believer that the best way to fix programming is through better programming languages, which I learned about myself while working at Coverity. Otherwise I think it was a great place to work: lots of very smart people, a very good business plan, great startup stock (back then), but I'm too idealistic!<p><em>Static</em> <em>analysis</em> <em>tools</em> are very pragmatic in a world where better languages aren't adopted very often.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Eric Lippert is leaving Microsoft",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ericlippert.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2008-09-16T04:01:04.000Z",
      "title": null,
      "url": null,
      "author": "rcoder",
      "points": null,
      "story_text": null,
      "comment_text": "Where a static analysis tool can help is in flagging those cases where a developer <i>might</i> have made a bad assumption, and forcing them to reconsider that code point. Basically, it's a way to enforce some basic code review practices without requiring one of your senior developers to be able + willing to read over your junior devs' code.<p>The whole point of programming is to automate those tasks that can be automated, right? So, let's automate the first-pass stage of a basic security audit as much as we can.<p>To your specific points:<p>* Parameterized queries are available in some cases, as you said, but don't work when you have to build some portion of the query (sort order, grouping, etc.) at runtime. Static tools can help flag such dynamic values as being tainted or clean, as well as help insure that resulting queries will be well-formed.<p>* All that's necessary to extend your type checking to the database is to enforce the same level of discipline you do for built-in API functions. Just as static analysis tools need a signature for primitive functions provided by the runtime platform (syscalls for C, primitive library functions for PHP, etc.), your static checker could ensure that queries which used stored procedures checked at least the asserted type signature of those procedures. (SQL is pretty type-savvy, and most stored proc authors should be able to trivially provide type sigs for their code.)<p>The advantage to using Haskell for all of this is twofold:<p>* There are excellent existing parsing and graph algorithm libraries maintained by the Haskell community<p>* Working in a strict, pure functional language makes you think in terms of mathematical theories, rather than stateful effects, which in turn tends to result in better, more deterministic code<p>That being said, I think you could use OCaml, Lisp, or any number of other high-level languages to similar effect. The uniquely math-oriented world view of Haskell (and its implementers and users) does tend to lend itself to just the kind of defensible reasoning that you would want from a security-focused static analysis tool, though.",
      "num_comments": null,
      "story_id": 305349,
      "story_title": "Ask YC: if Haskell is the hammer, what should be the nail?",
      "story_url": "",
      "parent_id": 305392,
      "created_at_i": 1221537664,
      "_tags": [
        "comment",
        "author_rcoder",
        "story_305349"
      ],
      "objectID": "305395",
      "_highlightResult": {
        "author": {
          "value": "rcoder",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Where a <em>static</em> <em>analysis</em> tool can help is in flagging those cases where a developer <i>might</i> have made a bad assumption, and forcing them to reconsider that code point. Basically, it's a way to enforce some basic code review practices without requiring one of your senior developers to be able + willing to read over your junior devs' code.<p>The whole point of programming is to automate those tasks that can be automated, right? So, let's automate the first-pass stage of a basic security audit as much as we can.<p>To your specific points:<p>* Parameterized queries are available in some cases, as you said, but don't work when you have to build some portion of the query (sort order, grouping, etc.) at runtime. <em>Static</em> <em>tools</em> can help flag such dynamic values as being tainted or clean, as well as help insure that resulting queries will be well-formed.<p>* All that's necessary to extend your type checking to the database is to enforce the same level of discipline you do for built-in API functions. Just as <em>static</em> <em>analysis</em> <em>tools</em> need a signature for primitive functions provided by the runtime platform (syscalls for C, primitive library functions for PHP, etc.), your <em>static</em> checker could ensure that queries which used stored procedures checked at least the asserted type signature of those procedures. (SQL is pretty type-savvy, and most stored proc authors should be able to trivially provide type sigs for their code.)<p>The advantage to using Haskell for all of this is twofold:<p>* There are excellent existing parsing and graph algorithm libraries maintained by the Haskell community<p>* Working in a strict, pure functional language makes you think in terms of mathematical theories, rather than stateful effects, which in turn tends to result in better, more deterministic code<p>That being said, I think you could use OCaml, Lisp, or any number of other high-level languages to similar effect. The uniquely math-oriented world view of Haskell (and its implementers and users) does tend to lend itself to just the kind of defensible reasoning that you would want from a security-focused <em>static</em> <em>analysis</em> tool, though.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask YC: if Haskell is the hammer, what should be the nail?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2008-08-18T23:58:30.000Z",
      "title": null,
      "url": null,
      "author": "etal",
      "points": null,
      "story_text": null,
      "comment_text": "I agree with SwellJoe, gruseom and gasull: this is a code maintenance issue, and the way to sell it to the customer (and to yourself, so you can get started) is bundling some cleanup with each feature.<p>I ran into some ancient and crufty code at my last job, and learned some things in the process of dealing with it.<p>1. Make sure you're using sane version control -- SVN or a DVCS. If you're on a Unix or have access to cygwin, getting started looks like:<p><pre><code>  cd ~/projects/bigco/thisone\n  git init\n  git add .\n  git commit\n</code></pre>\nThis will give you the courage and safety net to make big changes to your code.<p>2. Look at your build file (Makefile?) and see what it says about the project's organization. You probably have some idea of what's wrong already, but this might point out things like files that are never compiled, the same few files used to build everything else -- even though one or more files really should only do one specific thing.<p>3. Start cutting dependencies. Starting with the file where you're adding the newest feature, look into each of the files/modules included/imported and see if the dependency is really necessary. Maybe you only depend on one function or data definition in that other file, and it would make sense to merge that code with another existing dependency. Also take a hard look at your \"utils\" file/folder (every project has one) and see if some parts can be merged elsewhere, or even eliminated by using existing features of your platform.<p>4. Clean up the configuration file. Are some options irrelevant now? Are the defaults sane? Look at the code that touches it. Are there more defaults hidden in the code, when it should all be in the config file? Are there settings at the top of some files that could be moved to the config file? Don't go overboard, though: you usually don't need a configuration option to tell one piece of code about a choice you made in another piece of code in the same project. Clean that up, delete some if/else branches, and maybe find and clear some obsolete code in the process.<p>Also, we might be able to give more specific tips if you tell us more about the platform you're using. If the project is compiled, static analysis tools are worth a shot. If you're on Unix/Linux, it can be useful to break off pieces of code into standalone scripts, or better, use an existing (but perhaps obscure) command-line utility to replace old code or base a new feature on. Maybe use cron instead of your homespun scheduling system to launch these separate processes. But at least the customer is supporting this effort, right?",
      "num_comments": null,
      "story_id": 279559,
      "story_title": "Ask YC: What do you do when a small project keeps getting larger?",
      "story_url": "",
      "parent_id": 279559,
      "created_at_i": 1219103910,
      "_tags": [
        "comment",
        "author_etal",
        "story_279559"
      ],
      "objectID": "279840",
      "_highlightResult": {
        "author": {
          "value": "etal",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I agree with SwellJoe, gruseom and gasull: this is a code maintenance issue, and the way to sell it to the customer (and to yourself, so you can get started) is bundling some cleanup with each feature.<p>I ran into some ancient and crufty code at my last job, and learned some things in the process of dealing with it.<p>1. Make sure you're using sane version control -- SVN or a DVCS. If you're on a Unix or have access to cygwin, getting started looks like:<p><pre><code>  cd ~/projects/bigco/thisone\n  git init\n  git add .\n  git commit\n</code></pre>\nThis will give you the courage and safety net to make big changes to your code.<p>2. Look at your build file (Makefile?) and see what it says about the project's organization. You probably have some idea of what's wrong already, but this might point out things like files that are never compiled, the same few files used to build everything else -- even though one or more files really should only do one specific thing.<p>3. Start cutting dependencies. Starting with the file where you're adding the newest feature, look into each of the files/modules included/imported and see if the dependency is really necessary. Maybe you only depend on one function or data definition in that other file, and it would make sense to merge that code with another existing dependency. Also take a hard look at your \"utils\" file/folder (every project has one) and see if some parts can be merged elsewhere, or even eliminated by using existing features of your platform.<p>4. Clean up the configuration file. Are some options irrelevant now? Are the defaults sane? Look at the code that touches it. Are there more defaults hidden in the code, when it should all be in the config file? Are there settings at the top of some files that could be moved to the config file? Don't go overboard, though: you usually don't need a configuration option to tell one piece of code about a choice you made in another piece of code in the same project. Clean that up, delete some if/else branches, and maybe find and clear some obsolete code in the process.<p>Also, we might be able to give more specific tips if you tell us more about the platform you're using. If the project is compiled, <em>static</em> <em>analysis</em> <em>tools</em> are worth a shot. If you're on Unix/Linux, it can be useful to break off pieces of code into standalone scripts, or better, use an existing (but perhaps obscure) command-line utility to replace old code or base a new feature on. Maybe use cron instead of your homespun scheduling system to launch these separate processes. But at least the customer is supporting this effort, right?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask YC: What do you do when a small project keeps getting larger?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-03-15T09:38:58.000Z",
      "title": null,
      "url": null,
      "author": "chalst",
      "points": null,
      "story_text": null,
      "comment_text": "Agreed.  Luatex makes the following division of labour practical: work with data structures and manipulate fonts and the backend in Lua, handle moving about text and setting parameters in the macro language.<p>One thing I would like to see is proper static analysis tools for Luatex.  Lua has tools like <a href=\"https://github.com/fab13n/metalua/tree/master/src/samples/metalint\" rel=\"nofollow\">https://github.com/fab13n/metalua/tree/master/src/samples/me...</a> but there's nothing of comparable sophistication for Tex, let alone code combining the two, which makes debugging needlessly hard.",
      "num_comments": null,
      "story_id": 2326545,
      "story_title": "Why is TeX still used? What are some good, modern alternatives?",
      "story_url": "http://tex.stackexchange.com/questions/13370/why-are-there-no-alternatives-to-tex-or-why-is-tex-still-used",
      "parent_id": 2326625,
      "created_at_i": 1300181938,
      "_tags": [
        "comment",
        "author_chalst",
        "story_2326545"
      ],
      "objectID": "2326683",
      "_highlightResult": {
        "author": {
          "value": "chalst",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Agreed.  Luatex makes the following division of labour practical: work with data structures and manipulate fonts and the backend in Lua, handle moving about text and setting parameters in the macro language.<p>One thing I would like to see is proper <em>static</em> <em>analysis</em> <em>tools</em> for Luatex.  Lua has <em>tools</em> like <a href=\"https://github.com/fab13n/metalua/tree/master/src/samples/metalint\" rel=\"nofollow\">https://github.com/fab13n/metalua/tree/master/src/samples/me...</a> but there's nothing of comparable sophistication for Tex, let alone code combining the two, which makes debugging needlessly hard.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why is TeX still used? What are some good, modern alternatives?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://tex.stackexchange.com/questions/13370/why-are-there-no-alternatives-to-tex-or-why-is-tex-still-used",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-12-09T18:16:57.000Z",
      "title": null,
      "url": null,
      "author": "jdp23",
      "points": null,
      "story_text": null,
      "comment_text": "there's always been a lot of debate about whether software engineering is part of computer science or a separate profession.<p>looking at it through my own personal lens ... PREfix and PREfast (the static analysis tools i architected) were primarily software engineering -- we published in the Journal of Empirical Software Engineering.  others working in the same space took more of a computer science approach, developed far more precise models and made breakthroughs in SAT and BDD.  over time the two streams merged, which is a big win all around.<p>on the other hand, some of my other work was very CS-y -- looking at formalizing security algebras, for example, and applying standpoint epistemology to graph theory.  so in the end i consider myself both a computer scientist and a software engineer.",
      "num_comments": null,
      "story_id": 1988239,
      "story_title": "Engineering Is Not Science",
      "story_url": "http://spectrum.ieee.org/at-work/tech-careers/engineering-is-not-science/?utm_source=techalert&utm_medium=email&utm_campaign=101209",
      "parent_id": 1988334,
      "created_at_i": 1291918617,
      "_tags": [
        "comment",
        "author_jdp23",
        "story_1988239"
      ],
      "objectID": "1988426",
      "_highlightResult": {
        "author": {
          "value": "jdp23",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "there's always been a lot of debate about whether software engineering is part of computer science or a separate profession.<p>looking at it through my own personal lens ... PREfix and PREfast (the <em>static</em> <em>analysis</em> <em>tools</em> i architected) were primarily software engineering -- we published in the Journal of Empirical Software Engineering.  others working in the same space took more of a computer science approach, developed far more precise models and made breakthroughs in SAT and BDD.  over time the two streams merged, which is a big win all around.<p>on the other hand, some of my other work was very CS-y -- looking at formalizing security algebras, for example, and applying standpoint epistemology to graph theory.  so in the end i consider myself both a computer scientist and a software engineer.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Engineering Is Not Science",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://spectrum.ieee.org/at-work/tech-careers/engineering-is-not-science/?utm_source=techalert&utm_medium=email&utm_campaign=101209",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-11-28T16:42:09.000Z",
      "title": null,
      "url": null,
      "author": "wahnfrieden",
      "points": null,
      "story_text": null,
      "comment_text": "Found this article to be mostly uninformed fluff, unfortunately.<p>One point: although \"Ruby and Javascript\" don't have compilers to yell at you, there are static analysis tools which accomplish that to various degrees.",
      "num_comments": null,
      "story_id": 1944551,
      "story_title": "The Biology of Sloppy Code",
      "story_url": "http://journal.stuffwithstuff.com/2010/11/26/the-biology-of-sloppy-code/",
      "parent_id": 1944551,
      "created_at_i": 1290962529,
      "_tags": [
        "comment",
        "author_wahnfrieden",
        "story_1944551"
      ],
      "objectID": "1947585",
      "_highlightResult": {
        "author": {
          "value": "wahnfrieden",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Found this article to be mostly uninformed fluff, unfortunately.<p>One point: although \"Ruby and Javascript\" don't have compilers to yell at you, there are <em>static</em> <em>analysis</em> <em>tools</em> which accomplish that to various degrees.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Biology of Sloppy Code",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://journal.stuffwithstuff.com/2010/11/26/the-biology-of-sloppy-code/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-09-30T18:48:38.000Z",
      "title": null,
      "url": null,
      "author": "gmcquillan",
      "points": null,
      "story_text": null,
      "comment_text": "In an ideal world this is true. But in reality we don't always have control over the codebase from birth until deprecation. Often, you find yourself a newcomer to code, and being able to reason your way though it can be time consuming, and scary.<p>I think this article's approach is a good one. Take precautions, use things like continuous builds, static analysis tools to boost your confidence, but DO make the necessary changes. Better sooner than later.",
      "num_comments": null,
      "story_id": 1743777,
      "story_title": "You Have to Break It.",
      "story_url": "http://blog.paradoxica.net/post/1214142321/you-have-to-break-it",
      "parent_id": 1743887,
      "created_at_i": 1285872518,
      "_tags": [
        "comment",
        "author_gmcquillan",
        "story_1743777"
      ],
      "objectID": "1744360",
      "_highlightResult": {
        "author": {
          "value": "gmcquillan",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In an ideal world this is true. But in reality we don't always have control over the codebase from birth until deprecation. Often, you find yourself a newcomer to code, and being able to reason your way though it can be time consuming, and scary.<p>I think this article's approach is a good one. Take precautions, use things like continuous builds, <em>static</em> <em>analysis</em> <em>tools</em> to boost your confidence, but DO make the necessary changes. Better sooner than later.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "You Have to Break It.",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.paradoxica.net/post/1214142321/you-have-to-break-it",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-09-28T10:12:50.000Z",
      "title": null,
      "url": null,
      "author": "Robin_Message",
      "points": null,
      "story_text": null,
      "comment_text": "Thanks for the clarification. Given the way this cycle is bound to repeat, do you see any mileage in attempts to use typed assembly languages or other static analysis tools on things like the kernel? I've never seen them as worthwhile for application software, but they could definitely prevent this kind of bug, and if current techniques aren't stopping these bugs, then would it be worth the investment?",
      "num_comments": null,
      "story_id": 1731425,
      "story_title": "Detailed explanation of a recent privilege escalation bug in Linux",
      "story_url": "http://timetobleed.com/detailed-explanation-of-a-recent-privilege-escalation-bug-in-linux-cve-2010-3301/",
      "parent_id": 1733151,
      "created_at_i": 1285668770,
      "_tags": [
        "comment",
        "author_Robin_Message",
        "story_1731425"
      ],
      "objectID": "1735164",
      "_highlightResult": {
        "author": {
          "value": "Robin_Message",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Thanks for the clarification. Given the way this cycle is bound to repeat, do you see any mileage in attempts to use typed assembly languages or other <em>static</em> <em>analysis</em> <em>tools</em> on things like the kernel? I've never seen them as worthwhile for application software, but they could definitely prevent this kind of bug, and if current techniques aren't stopping these bugs, then would it be worth the investment?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Detailed explanation of a recent privilege escalation bug in Linux",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://timetobleed.com/detailed-explanation-of-a-recent-privilege-escalation-bug-in-linux-cve-2010-3301/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-07-29T23:41:30.000Z",
      "title": null,
      "url": null,
      "author": "silentbicycle",
      "points": null,
      "story_text": null,
      "comment_text": "Also, I agree that trying to refactor (say) C++ with awk would be hopelessly quixotic. I'm not an idiot. (I have written parsing and static analysis tools for an in-house language, though, just not one as screwed up as C++.) I was explaining the historical reason for vi lacking such features - grammatically ambiguous, overloading-heavy languages that combine static typing with OOP hadn't been invented yet.<p>I think it's bad design to have refactoring tools be a part of the editor, proper, rather than as a standalone tool the editor calls. It's more a matter of static analysis (or runtime introspection) issue than editing per se.",
      "num_comments": null,
      "story_id": 1556835,
      "story_title": "Everyone Who Tried to Convince Me to Use Vim Was Wrong",
      "story_url": "http://yehudakatz.com/2010/07/29/everyone-who-tried-to-convince-me-to-use-vim-was-wrong",
      "parent_id": 1559654,
      "created_at_i": 1280446890,
      "_tags": [
        "comment",
        "author_silentbicycle",
        "story_1556835"
      ],
      "objectID": "1559733",
      "_highlightResult": {
        "author": {
          "value": "silentbicycle",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Also, I agree that trying to refactor (say) C++ with awk would be hopelessly quixotic. I'm not an idiot. (I have written parsing and <em>static</em> <em>analysis</em> <em>tools</em> for an in-house language, though, just not one as screwed up as C++.) I was explaining the historical reason for vi lacking such features - grammatically ambiguous, overloading-heavy languages that combine <em>static</em> typing with OOP hadn't been invented yet.<p>I think it's bad design to have refactoring <em>tools</em> be a part of the editor, proper, rather than as a standalone tool the editor calls. It's more a matter of <em>static</em> <em>analysis</em> (or runtime introspection) issue than editing per se.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Everyone Who Tried to Convince Me to Use Vim Was Wrong",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://yehudakatz.com/2010/07/29/everyone-who-tried-to-convince-me-to-use-vim-was-wrong",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-07-26T18:02:53.000Z",
      "title": null,
      "url": null,
      "author": "pascal_cuoq",
      "points": null,
      "story_text": null,
      "comment_text": "It saddens me to see the linked article taken seriously and its political agenda repeated as if the existence of an article advocating Open Source in an Open Source conference gave credence to the idea of mandatory Open Source for life-critical software.<p>The article \"Killed by Code: Software Transparency in Implantable Medical Devices\" is weak. It mixes safety and security, which are subtly different beasts. Specifically, it justifies the idea of mandatory Open Source for safety-critical software with security examples. Unfortunately, while there are independent security researchers, I have yet to meet my first independent safety researcher, who looks for flaws in life-critical equipment for fame or money or ego…<p>The article also completely ignores the fact that DO-178B certified code, as found embedded in civil aircrafts, has a perfect safety track record (although some incidents have, no loss of human life has yet been attributed to software malfunction in a civil aircraft).<p>I work on static analysis tools for critical software. In this domain, the unavailability of examples is a big pain in the neck. My colleagues and I would love to see more examples of critical embedded code available to try our tools on. But in spite of this, I have to say that I find this article highly unscientific and so tainted by politics that it becomes distasteful.<p>(oh, and our analysis framework is Open Source. By choice, not by constraints based on unsound reasoning)<p>NOTE: I merely claim that the article is unscientific, not that it makes a particular unscientific claim such \"that opening up software will solve all of it problems\". But since apparently I need to be more specific, here is a paragraph straight from the article:<p>Other public sector agencies, such as the U.S. Navy, the Federal Aviation Administration, the U.S. Census Bureau and the U.S. Patent and Trademark Office have been identified as recognizing the security benefits of publicly auditable source code.20<p>There is only one reference for the four sources. Let's take a look at that reference:<p>20 FAQs, Open Source for America, <a href=\"http://opensourceforamerica.org/faq\" rel=\"nofollow\">http://opensourceforamerica.org/faq</a> (last visited July 16, 2010).<p>How does that page justify the above paragraph? You tell me if you find it. This is not how references are supposed to work in a scientific article. The last time I saw this kind of \"he said she said\" reference, it was in a text trying to justify homeopathic claims.",
      "num_comments": null,
      "story_id": 1547900,
      "story_title": "Why Free Software is a Matter of Life and Death ",
      "story_url": "http://www.computerworlduk.com/community/blogs/index.cfm?blogid=14&entryid=3090&utm_source=ycombinator&utm_medium=sb&utm_content=anguyen&utm_campaign=sb",
      "parent_id": 1547900,
      "created_at_i": 1280167373,
      "_tags": [
        "comment",
        "author_pascal_cuoq",
        "story_1547900"
      ],
      "objectID": "1548738",
      "_highlightResult": {
        "author": {
          "value": "pascal_cuoq",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It saddens me to see the linked article taken seriously and its political agenda repeated as if the existence of an article advocating Open Source in an Open Source conference gave credence to the idea of mandatory Open Source for life-critical software.<p>The article \"Killed by Code: Software Transparency in Implantable Medical Devices\" is weak. It mixes safety and security, which are subtly different beasts. Specifically, it justifies the idea of mandatory Open Source for safety-critical software with security examples. Unfortunately, while there are independent security researchers, I have yet to meet my first independent safety researcher, who looks for flaws in life-critical equipment for fame or money or ego…<p>The article also completely ignores the fact that DO-178B certified code, as found embedded in civil aircrafts, has a perfect safety track record (although some incidents have, no loss of human life has yet been attributed to software malfunction in a civil aircraft).<p>I work on <em>static</em> <em>analysis</em> <em>tools</em> for critical software. In this domain, the unavailability of examples is a big pain in the neck. My colleagues and I would love to see more examples of critical embedded code available to try our <em>tools</em> on. But in spite of this, I have to say that I find this article highly unscientific and so tainted by politics that it becomes distasteful.<p>(oh, and our <em>analysis</em> framework is Open Source. By choice, not by constraints based on unsound reasoning)<p>NOTE: I merely claim that the article is unscientific, not that it makes a particular unscientific claim such \"that opening up software will solve all of it problems\". But since apparently I need to be more specific, here is a paragraph straight from the article:<p>Other public sector agencies, such as the U.S. Navy, the Federal Aviation Administration, the U.S. Census Bureau and the U.S. Patent and Trademark Office have been identified as recognizing the security benefits of publicly auditable source code.20<p>There is only one reference for the four sources. Let's take a look at that reference:<p>20 FAQs, Open Source for America, <a href=\"http://opensourceforamerica.org/faq\" rel=\"nofollow\">http://opensourceforamerica.org/faq</a> (last visited July 16, 2010).<p>How does that page justify the above paragraph? You tell me if you find it. This is not how references are supposed to work in a scientific article. The last time I saw this kind of \"he said she said\" reference, it was in a text trying to justify homeopathic claims.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Free Software is a Matter of Life and Death ",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.computerworlduk.com/community/blogs/index.cfm?blogid=14&entryid=3090&utm_source=ycombinator&utm_medium=sb&utm_content=anguyen&utm_campaign=sb",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-06-25T11:39:42.000Z",
      "title": null,
      "url": null,
      "author": "fourneau",
      "points": null,
      "story_text": null,
      "comment_text": "That's both hilarious and frightening all at once.  Luckily static analysis tools catch that kind of stuff very easily now...",
      "num_comments": null,
      "story_id": 1460087,
      "story_title": "\"A sleep(1) is put into all SSL_read() and SSL_write() calls...\"",
      "story_url": "http://bugs.python.org/issue9075",
      "parent_id": 1460274,
      "created_at_i": 1277465982,
      "_tags": [
        "comment",
        "author_fourneau",
        "story_1460087"
      ],
      "objectID": "1460480",
      "_highlightResult": {
        "author": {
          "value": "fourneau",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's both hilarious and frightening all at once.  Luckily <em>static</em> <em>analysis</em> <em>tools</em> catch that kind of stuff very easily now...",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "\"A sleep(1) is put into all SSL_read() and SSL_write() calls...\"",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://bugs.python.org/issue9075",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-06-23T23:15:45.000Z",
      "title": null,
      "url": null,
      "author": "adelevie",
      "points": null,
      "story_text": null,
      "comment_text": "I would think that the number could greatly fluctuate. Perhaps there are better ways to measure complexity of code such as <a href=\"http://thinksimple.pl/entries/88-Ruby-static-code-analysis\" rel=\"nofollow\">http://thinksimple.pl/entries/88-Ruby-static-code-analysis</a>.<p>These tools could be used to turn code smells, duplication, and poorly written tests into a total \"score\" for well-written code. Although this should hardly be the way code is evaluated.<p>Also, complex code that isn't written \"the best way\" isn't so bad. It incurs technical debts. Like financial debt, technical debt can be very good if used properly--or end with disastrous results if used irresponsibly. So let some component of a code base bloat if you need to hit a deadline so long as you're going to refactor later.",
      "num_comments": null,
      "story_id": 1456662,
      "story_title": "How many lines of code per developer?",
      "story_url": "",
      "parent_id": 1456662,
      "created_at_i": 1277334945,
      "_tags": [
        "comment",
        "author_adelevie",
        "story_1456662"
      ],
      "objectID": "1456768",
      "_highlightResult": {
        "author": {
          "value": "adelevie",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I would think that the number could greatly fluctuate. Perhaps there are better ways to measure complexity of code such as <a href=\"http://thinksimple.pl/entries/88-Ruby-static-code-analysis\" rel=\"nofollow\">http://thinksimple.pl/entries/88-Ruby-<em>static</em>-code-<em>analysis</em></a>.<p>These <em>tools</em> could be used to turn code smells, duplication, and poorly written tests into a total \"score\" for well-written code. Although this should hardly be the way code is evaluated.<p>Also, complex code that isn't written \"the best way\" isn't so bad. It incurs technical debts. Like financial debt, technical debt can be very good if used properly--or end with disastrous results if used irresponsibly. So let some component of a code base bloat if you need to hit a deadline so long as you're going to refactor later.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How many lines of code per developer?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-06-18T10:09:08.000Z",
      "title": null,
      "url": null,
      "author": "strlen",
      "points": null,
      "story_text": null,
      "comment_text": "This is a fairly interesting discussion. I'm not a Haskelite (if I had to pick a favourite language it would be OCaml, with Common Lisp and plain-old-C being close seconds), but I can understand where he's coming from. I'd imagine most people on this site at in the same boat: we don't get to have full freedom to choose our tools (in some cases even if we're running our own companies: there are many interesting projects where our favourite tools are the <i>wrong</i> tools for the job). That doesn't mean we should lose passion for those tools, nor does it mean that we can't find meaning and enjoyment in our work.<p>Oddly enough, I've found this sort of inspiration when I was reading \"Programming Pearls\". The author managed to maintain an very upbeat and enthusiastic tone, pointing out clever hacks, even when he talked about programming in Cobol and BASIC. That helped me regain the sight of the fact that as a professional programmer <i>and</i> a (for lack of a better word) computer nerd, I was lucky enough to be in a place where I could make a profession out of my passion. Most people aren't that lucky. The fact that I don't always get to choose my tools shouldn't let me get in the way of enjoying programming: I love to program, when I drive in to the office, I'm going to be programming.<p>Ultimately, though, the advice I would give is:<p>* Look for interesting and non-trivial work, irrespective of what language is used (that criteria does generally disqualify some of the most frustrating and boring \"niche\" languages e.g., SAP, ASP, Coldfusion, PHP, Visual Basic).<p>A common pattern I've noticed when interesting languages are used for mundane problems in start-ups is that as soon as the initial generation of developers leaves (and the start-up becomes a modestly profitable midsize company: most stay that way, rather than become \"the next Google\") management pressure grows to switch to blub.<p>* Consider non-blub languages that on .NET and JVM: F# (being worked on by Peyton-Jones!), Scala (surprisingly many Haskell hackers are involved in it, despite Scala being far closer to OCaml), Clojure (borrows several ML family concepts in a <i>very</i> interesting way -- that alone would actually make it interesting even if it didn't run on the JVM)<p>* Additionally, consider a full time job rather than projects and free lancing. If technology is a company's core competency, they're going to be very reluctant to outsource its development (typically exceptions are only made for exceptional individuals who are unwilling to sign on full time  and even then it's often difficult to do).<p>Almost axiomatically, some of the most interesting software  work is generally done by companies where software is the core competency (the big exception being things like computational finance and scientific/medical computing or highly innovative enterprises such as Amazon [pre-AWS -- AWS made them a genuine tech company] or PayPal). Thus, if you only choose to work on a freelance/project basis you're likely locking yourself out of very interesting jobs. Of course, this doesn't apply if you're in an area where most of the full-time jobs are in the outsourcing industry (either in offshoring firms or in off-shore offices of foreign firms).<p>* Use Haskell (or whatever else you like) as your secret weapon. Build prototypes in it and then once you have a clear mental picture implement them in another language. Write tools in it to automate away the drudgery (code analysis, debugging, verification: things Haskell is great at).<p>I should add that C and C++ shops tend to be slightly more open to this use of Haskell, OCaml, Scheme and other uncommon languages: C/C++ are not very scalable languages when it comes to \"scaling down\" to scripting and automation work. Nonetheless I also know of people prototyping Java and Scala code in Haskell as well.<p>* Don't forget that Haskell, Common Lisp etc... jobs are out there. They're just rare. They also typically look for individuals with specific skills rather than individuals skilled at specific languages e.g., you're more likely to find a Haskell job if you've written static analysis tools in Java than if you've written web apps in Haskell. ITA software very specifically stated that they don't require new hires to know Lisp, they want smart people whom they're willing to invest in and educate. \"I really want to program in X language and you're one of the few places that uses it\", unfortunately, won't persuade them if you can't pass their technical interview (unless they're specifically looking for an evangelist rather than a developer).<p>If you can manage to provide a more or less stable situation for yourself which lets you develop new skills, you can always switch when tgw opportunity comes. Technology job market is usually fluid. If you're not constantly thinking \"how will I get the next contract, what money will I live on\" you don't have to keep taking jobs you don't like (only to discover a posting for a \"perfect job\" a week after you begin a new six month contract).<p>Finally, remember that there are people who hate Haskell, Lisp etc.. too <i>when they are forced to use it</i>. There's no better example than university students. I was unfortunate enough to be exempt (as a CS major in School of Arts and Sciences vs. a CSE student in the School of Engineering) from taking a specific undergrad course (the equiv of 6.001 or CS68a) that was taught in Haskell. I couldn't enroll in the course, as the priority went to students from whom it was required. I was green with envy, but most students absolutely <i>hated</i> it. I volunteered to help out my Berkeley friends with CS68a (their SICP class), but they endlessly complained of not knowing what the point of the course was (especially the non-CS students who had no prior or following programming experience).",
      "num_comments": null,
      "story_id": 1441434,
      "story_title": "How does one get off Haskell?",
      "story_url": "http://www.haskell.org/pipermail/haskell-cafe/2010-June/079044.html",
      "parent_id": 1441434,
      "created_at_i": 1276855748,
      "_tags": [
        "comment",
        "author_strlen",
        "story_1441434"
      ],
      "objectID": "1441798",
      "_highlightResult": {
        "author": {
          "value": "strlen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is a fairly interesting discussion. I'm not a Haskelite (if I had to pick a favourite language it would be OCaml, with Common Lisp and plain-old-C being close seconds), but I can understand where he's coming from. I'd imagine most people on this site at in the same boat: we don't get to have full freedom to choose our <em>tools</em> (in some cases even if we're running our own companies: there are many interesting projects where our favourite <em>tools</em> are the <i>wrong</i> <em>tools</em> for the job). That doesn't mean we should lose passion for those <em>tools</em>, nor does it mean that we can't find meaning and enjoyment in our work.<p>Oddly enough, I've found this sort of inspiration when I was reading \"Programming Pearls\". The author managed to maintain an very upbeat and enthusiastic tone, pointing out clever hacks, even when he talked about programming in Cobol and BASIC. That helped me regain the sight of the fact that as a professional programmer <i>and</i> a (for lack of a better word) computer nerd, I was lucky enough to be in a place where I could make a profession out of my passion. Most people aren't that lucky. The fact that I don't always get to choose my <em>tools</em> shouldn't let me get in the way of enjoying programming: I love to program, when I drive in to the office, I'm going to be programming.<p>Ultimately, though, the advice I would give is:<p>* Look for interesting and non-trivial work, irrespective of what language is used (that criteria does generally disqualify some of the most frustrating and boring \"niche\" languages e.g., SAP, ASP, Coldfusion, PHP, Visual Basic).<p>A common pattern I've noticed when interesting languages are used for mundane problems in start-ups is that as soon as the initial generation of developers leaves (and the start-up becomes a modestly profitable midsize company: most stay that way, rather than become \"the next Google\") management pressure grows to switch to blub.<p>* Consider non-blub languages that on .NET and JVM: F# (being worked on by Peyton-Jones!), Scala (surprisingly many Haskell hackers are involved in it, despite Scala being far closer to OCaml), Clojure (borrows several ML family concepts in a <i>very</i> interesting way -- that alone would actually make it interesting even if it didn't run on the JVM)<p>* Additionally, consider a full time job rather than projects and free lancing. If technology is a company's core competency, they're going to be very reluctant to outsource its development (typically exceptions are only made for exceptional individuals who are unwilling to sign on full time  and even then it's often difficult to do).<p>Almost axiomatically, some of the most interesting software  work is generally done by companies where software is the core competency (the big exception being things like computational finance and scientific/medical computing or highly innovative enterprises such as Amazon [pre-AWS -- AWS made them a genuine tech company] or PayPal). Thus, if you only choose to work on a freelance/project basis you're likely locking yourself out of very interesting jobs. Of course, this doesn't apply if you're in an area where most of the full-time jobs are in the outsourcing industry (either in offshoring firms or in off-shore offices of foreign firms).<p>* Use Haskell (or whatever else you like) as your secret weapon. Build prototypes in it and then once you have a clear mental picture implement them in another language. Write <em>tools</em> in it to automate away the drudgery (code <em>analysis</em>, debugging, verification: things Haskell is great at).<p>I should add that C and C++ shops tend to be slightly more open to this use of Haskell, OCaml, Scheme and other uncommon languages: C/C++ are not very scalable languages when it comes to \"scaling down\" to scripting and automation work. Nonetheless I also know of people prototyping Java and Scala code in Haskell as well.<p>* Don't forget that Haskell, Common Lisp etc... jobs are out there. They're just rare. They also typically look for individuals with specific skills rather than individuals skilled at specific languages e.g., you're more likely to find a Haskell job if you've written <em>static</em> <em>analysis</em> <em>tools</em> in Java than if you've written web apps in Haskell. ITA software very specifically stated that they don't require new hires to know Lisp, they want smart people whom they're willing to invest in and educate. \"I really want to program in X language and you're one of the few places that uses it\", unfortunately, won't persuade them if you can't pass their technical interview (unless they're specifically looking for an evangelist rather than a developer).<p>If you can manage to provide a more or less stable situation for yourself which lets you develop new skills, you can always switch when tgw opportunity comes. Technology job market is usually fluid. If you're not constantly thinking \"how will I get the next contract, what money will I live on\" you don't have to keep taking jobs you don't like (only to discover a posting for a \"perfect job\" a week after you begin a new six month contract).<p>Finally, remember that there are people who hate Haskell, Lisp etc.. too <i>when they are forced to use it</i>. There's no better example than university students. I was unfortunate enough to be exempt (as a CS major in School of Arts and Sciences vs. a CSE student in the School of Engineering) from taking a specific undergrad course (the equiv of 6.001 or CS68a) that was taught in Haskell. I couldn't enroll in the course, as the priority went to students from whom it was required. I was green with envy, but most students absolutely <i>hated</i> it. I volunteered to help out my Berkeley friends with CS68a (their SICP class), but they endlessly complained of not knowing what the point of the course was (especially the non-CS students who had no prior or following programming experience).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How does one get off Haskell?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.haskell.org/pipermail/haskell-cafe/2010-June/079044.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2008-03-20T19:14:28.000Z",
      "title": null,
      "url": null,
      "author": "nradov",
      "points": null,
      "story_text": null,
      "comment_text": "We have coding standards. The developers are good about following them, and some coding standards problems can even by caught automatically by static analysis tools.<p>But coding standards don't prevent logic errors, or requirements misunderstandings. Even the best developers make those kinds of mistakes and we catch a significant fraction of them during code reviews.<p>The other major benefit of consistently doing code reviews is learning. The attendees often pick up useful new techniques. And you spread knowledge of the code base around the team, which reduces the organization's dependence on any one developer and also brings out opportunities for code reuse.",
      "num_comments": null,
      "story_id": 141679,
      "story_title": "Design/code reviews in a startup",
      "story_url": "",
      "parent_id": 141763,
      "created_at_i": 1206040468,
      "_tags": [
        "comment",
        "author_nradov",
        "story_141679"
      ],
      "objectID": "141849",
      "_highlightResult": {
        "author": {
          "value": "nradov",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "We have coding standards. The developers are good about following them, and some coding standards problems can even by caught automatically by <em>static</em> <em>analysis</em> <em>tools</em>.<p>But coding standards don't prevent logic errors, or requirements misunderstandings. Even the best developers make those kinds of mistakes and we catch a significant fraction of them during code reviews.<p>The other major benefit of consistently doing code reviews is learning. The attendees often pick up useful new techniques. And you spread knowledge of the code base around the team, which reduces the organization's dependence on any one developer and also brings out opportunities for code reuse.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Design/code reviews in a startup",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-06-01T15:07:29.000Z",
      "title": null,
      "url": null,
      "author": "tptacek",
      "points": null,
      "story_text": null,
      "comment_text": "The source code to Windows, while not public, is some of the best studied in the world both inside and out of Microsoft. Even though MSFT doesn't publish it, they do release complete debug symbols for most of the operating system; there isn't a pro vulnerability researcher on the Internet that can't navigate Windows with a copy of IDA Pro and a couple of PDBs. The openness of the Windows source code is a red herring.<p>Meanwhile, most bugs aren't discovered in careful source code review or by static analysis tools. Instead, we write programs to exercise the code, either by sending random dumb buffers to the target or by working out the expected format and varying messages until we cover every basic block in the target. You can do this with or without any source code.<p>I think you would have a hard time finding a professional to say that they trust Mac OS X dramatically more than they trust WinAPI in 2010, and I say this as a full-time Mac user.",
      "num_comments": null,
      "story_id": 1393768,
      "story_title": "Google ditches Windows on security concerns",
      "story_url": "http://www.ft.com/cms/s/2/d2f3f04e-6ccf-11df-91c8-00144feab49a.html",
      "parent_id": 1394172,
      "created_at_i": 1275404849,
      "_tags": [
        "comment",
        "author_tptacek",
        "story_1393768"
      ],
      "objectID": "1395200",
      "_highlightResult": {
        "author": {
          "value": "tptacek",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The source code to Windows, while not public, is some of the best studied in the world both inside and out of Microsoft. Even though MSFT doesn't publish it, they do release complete debug symbols for most of the operating system; there isn't a pro vulnerability researcher on the Internet that can't navigate Windows with a copy of IDA Pro and a couple of PDBs. The openness of the Windows source code is a red herring.<p>Meanwhile, most bugs aren't discovered in careful source code review or by <em>static</em> <em>analysis</em> <em>tools</em>. Instead, we write programs to exercise the code, either by sending random dumb buffers to the target or by working out the expected format and varying messages until we cover every basic block in the target. You can do this with or without any source code.<p>I think you would have a hard time finding a professional to say that they trust Mac OS X dramatically more than they trust WinAPI in 2010, and I say this as a full-time Mac user.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Google ditches Windows on security concerns",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.ft.com/cms/s/2/d2f3f04e-6ccf-11df-91c8-00144feab49a.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-05-26T00:38:37.000Z",
      "title": null,
      "url": null,
      "author": "klodolph",
      "points": null,
      "story_text": null,
      "comment_text": "\"Pretty severe\" lack of professionalism?  It's not unprofessional not to turn the warnings all the way up and sift through each and every one.  Some of us work code inherited from other people with different coding guidelines, and some of the warnings will generate loads of messages for code that is not only technically correct but stylistically correct as well.  The unused parameter warning is one of the biggest offenders in this area.  And if you have a hundred warnings for unused parameters, which ones do you pay attention to?<p>Another potential issue is that the code in the patch might almost never be called in the first place.  Most libc implementations (three that I know of, where I've examined the \"memset\" source) have a \"memset\" like that as a fallback only for platforms without an assembly version.<p>I'd say the problem is that there are several different ways this error could have been detected sooner: warnings, test, static analysis tools, and review, but none of them worked.  But again, it's also possible that the code is never called because assembly versions are always available.",
      "num_comments": null,
      "story_id": 1378912,
      "story_title": "Android Project Changeset 4f8b683: libc/memset.c",
      "story_url": "https://review.source.android.com/#patch,sidebyside,14699,1,libc/memset.c",
      "parent_id": 1379063,
      "created_at_i": 1274834317,
      "_tags": [
        "comment",
        "author_klodolph",
        "story_1378912"
      ],
      "objectID": "1379151",
      "_highlightResult": {
        "author": {
          "value": "klodolph",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "\"Pretty severe\" lack of professionalism?  It's not unprofessional not to turn the warnings all the way up and sift through each and every one.  Some of us work code inherited from other people with different coding guidelines, and some of the warnings will generate loads of messages for code that is not only technically correct but stylistically correct as well.  The unused parameter warning is one of the biggest offenders in this area.  And if you have a hundred warnings for unused parameters, which ones do you pay attention to?<p>Another potential issue is that the code in the patch might almost never be called in the first place.  Most libc implementations (three that I know of, where I've examined the \"memset\" source) have a \"memset\" like that as a fallback only for platforms without an assembly version.<p>I'd say the problem is that there are several different ways this error could have been detected sooner: warnings, test, <em>static</em> <em>analysis</em> <em>tools</em>, and review, but none of them worked.  But again, it's also possible that the code is never called because assembly versions are always available.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Android Project Changeset 4f8b683: libc/memset.c",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://review.source.android.com/#patch,sidebyside,14699,1,libc/memset.c",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-02-20T20:29:14.000Z",
      "title": null,
      "url": null,
      "author": "sparky",
      "points": null,
      "story_text": null,
      "comment_text": "I don't see how the fact that other developers aren't complaining is proof that hardware acceleration is not useful.  There is a full spectrum of how much access you allow browser plugins and client-side code to features of the underlying OS and hardware.  Apple has chosen a relatively conservative point along that spectrum, Microsoft chose a more aggressive one (ActiveX).  There is an obvious tradeoff between capabilities/performance and security.  Google, with its Native Client sandbox, static analysis tools, etc. is attempting to get the performance of ActiveX with the security of more stringent sandboxes.  This is an extraordinarily difficult problem, and Apple is justified in not wanting to deal with it.  However, they are not justified in saying they're not leaving performance on the table.<p>Adobe should be able to improve H.264 decode performance without HW acceleration, but it is unclear what the upper bound is on performance when running inside the browser sandbox.  Certainly it can do no better than a native app.<p>EDIT: wmf is probably right; though there is no browser-specific sandbox that prevents third-party browsers from allowing plugins access to underlying OS APIs, such an API for HW-accelerated video decoding doesn't exist. It's unclear to me if acceleration is just not supported by the driver at all, or if the capability is only exposed via a private API, reserving it for first-party apps like Quicktime. Certainly many of the GPUs included in Apple products support hardware acceleration, so it seems to be primarily a software issue.",
      "num_comments": null,
      "story_id": 1139393,
      "story_title": "About Adobe's Flash Player Not Having Access to H.264 HW Acceleration on OSX",
      "story_url": "http://daringfireball.net/2010/02/flash_hardware_acceleration",
      "parent_id": 1139393,
      "created_at_i": 1266697754,
      "_tags": [
        "comment",
        "author_sparky",
        "story_1139393"
      ],
      "objectID": "1139423",
      "_highlightResult": {
        "author": {
          "value": "sparky",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't see how the fact that other developers aren't complaining is proof that hardware acceleration is not useful.  There is a full spectrum of how much access you allow browser plugins and client-side code to features of the underlying OS and hardware.  Apple has chosen a relatively conservative point along that spectrum, Microsoft chose a more aggressive one (ActiveX).  There is an obvious tradeoff between capabilities/performance and security.  Google, with its Native Client sandbox, <em>static</em> <em>analysis</em> <em>tools</em>, etc. is attempting to get the performance of ActiveX with the security of more stringent sandboxes.  This is an extraordinarily difficult problem, and Apple is justified in not wanting to deal with it.  However, they are not justified in saying they're not leaving performance on the table.<p>Adobe should be able to improve H.264 decode performance without HW acceleration, but it is unclear what the upper bound is on performance when running inside the browser sandbox.  Certainly it can do no better than a native app.<p>EDIT: wmf is probably right; though there is no browser-specific sandbox that prevents third-party browsers from allowing plugins access to underlying OS APIs, such an API for HW-accelerated video decoding doesn't exist. It's unclear to me if acceleration is just not supported by the driver at all, or if the capability is only exposed via a private API, reserving it for first-party apps like Quicktime. Certainly many of the GPUs included in Apple products support hardware acceleration, so it seems to be primarily a software issue.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "About Adobe's Flash Player Not Having Access to H.264 HW Acceleration on OSX",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://daringfireball.net/2010/02/flash_hardware_acceleration",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-02-05T12:55:42.000Z",
      "title": null,
      "url": null,
      "author": "wtallis",
      "points": null,
      "story_text": null,
      "comment_text": "LLVM is designed to be more than just a compiler. It's different stages can be used separately by other code, making it well suited for building things like static analysis tools. Apple (sponsor and de facto leader of LLVM) has been taking advantage of this to integrate clang-based static analysis into XCode, the proprietary IDE that ships with Mac OS X. Even if GCC had a clean enough architecture to be used this way, the licensing restrictions would force all of XCode to be open-sourced.",
      "num_comments": null,
      "story_id": 1102753,
      "story_title": "LLVM's Clang Successfully Self-Hosts",
      "story_url": "http://blog.llvm.org/2010/02/clang-successfully-self-hosts.html",
      "parent_id": 1103277,
      "created_at_i": 1265374542,
      "_tags": [
        "comment",
        "author_wtallis",
        "story_1102753"
      ],
      "objectID": "1103422",
      "_highlightResult": {
        "author": {
          "value": "wtallis",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "LLVM is designed to be more than just a compiler. It's different stages can be used separately by other code, making it well suited for building things like <em>static</em> <em>analysis</em> <em>tools</em>. Apple (sponsor and de facto leader of LLVM) has been taking advantage of this to integrate clang-based <em>static</em> <em>analysis</em> into XCode, the proprietary IDE that ships with Mac OS X. Even if GCC had a clean enough architecture to be used this way, the licensing restrictions would force all of XCode to be open-sourced.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "LLVM's Clang Successfully Self-Hosts",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.llvm.org/2010/02/clang-successfully-self-hosts.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-01-18T23:29:32.000Z",
      "title": null,
      "url": null,
      "author": "white_eskimo",
      "points": null,
      "story_text": null,
      "comment_text": "@jpluscplusm thanks for the feedback and good questions. Regarding the \"what state is the codebase in\" question, I can't imagine them telling me its \"poor\". What questions do you think would help me to gauge the quality of the code base? Obviously there is no formula, but it would be interesting to see what factors impact a codebase's quality. I guess there are static analysis tools to help out though :)",
      "num_comments": null,
      "story_id": 1060910,
      "story_title": "Ask HN: What key question would you ask a software engineering hiring manager?",
      "story_url": "",
      "parent_id": 1061008,
      "created_at_i": 1263857372,
      "_tags": [
        "comment",
        "author_white_eskimo",
        "story_1060910"
      ],
      "objectID": "1061068",
      "_highlightResult": {
        "author": {
          "value": "white_eskimo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "@jpluscplusm thanks for the feedback and good questions. Regarding the \"what state is the codebase in\" question, I can't imagine them telling me its \"poor\". What questions do you think would help me to gauge the quality of the code base? Obviously there is no formula, but it would be interesting to see what factors impact a codebase's quality. I guess there are <em>static</em> <em>analysis</em> <em>tools</em> to help out though :)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: What key question would you ask a software engineering hiring manager?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-16T18:55:24.000Z",
      "title": null,
      "url": null,
      "author": "hythloday",
      "points": 40,
      "story_text": null,
      "comment_text": "From Theo de Raadt, on-thread:<p><pre><code>  On a regular basis, we find real and serious bugs which affect all\\n  platforms, but they are incidentally made visible on one of the\\n  platforms we run, following that they are fixed.  It is a harsh\\n  reality which static and dynamic analysis tools have not yet resolved.</code></pre>",
      "num_comments": null,
      "story_id": 7069889,
      "story_title": "OpenBSD will shut down if we do not have the funding to keep the lights on",
      "story_url": "http://marc.info/?l=openbsd-misc&m=138972987203440&w=2",
      "parent_id": 7071114,
      "created_at_i": 1389898524,
      "_tags": [
        "comment",
        "author_hythloday",
        "story_7069889"
      ],
      "objectID": "7071624",
      "_highlightResult": {
        "author": {
          "value": "hythloday",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "From Theo de Raadt, on-thread:<p><pre><code>  On a regular basis, we find real and serious bugs which affect all\\n  platforms, but they are incidentally made visible on one of the\\n  platforms we run, following that they are fixed.  It is a harsh\\n  reality which <em>static</em> and dynamic <em>analysis</em> <em>tools</em> have not yet resolved.</code></pre>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "OpenBSD will shut down if we do not have the funding to keep the lights on",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://marc.info/?l=openbsd-misc&m=138972987203440&w=2",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-15T20:04:34.000Z",
      "title": null,
      "url": null,
      "author": "U2EF1",
      "points": 27,
      "story_text": null,
      "comment_text": "C has some of the best static analysis and debugging tools of any language, but all of that&#x27;s worthless if you don&#x27;t use them. Doubly so if you specifically handicap those tools and write your own obfuscated allocation scheme. Heartbleed was less an indictment against C and more an indictment against shitty code.",
      "num_comments": null,
      "story_id": 8182713,
      "story_title": "Quality Software Costs Money – Heartbleed Was Free",
      "story_url": "http://queue.acm.org/detail.cfm?id=2636165",
      "parent_id": 8183618,
      "created_at_i": 1408133074,
      "_tags": [
        "comment",
        "author_U2EF1",
        "story_8182713"
      ],
      "objectID": "8183887",
      "_highlightResult": {
        "author": {
          "value": "U2EF1",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "C has some of the best <em>static</em> <em>analysis</em> and debugging <em>tools</em> of any language, but all of that's worthless if you don't use them. Doubly so if you specifically handicap those <em>tools</em> and write your own obfuscated allocation scheme. Heartbleed was less an indictment against C and more an indictment against shitty code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Quality Software Costs Money – Heartbleed Was Free",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://queue.acm.org/detail.cfm?id=2636165",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-16T17:28:06.000Z",
      "title": null,
      "url": null,
      "author": "hhw",
      "points": 21,
      "story_text": null,
      "comment_text": "From Theo&#x27;s comments on the mailing list:<p>&quot;On a regular basis, we find real and serious bugs which affect all platforms, but they are incidentally made visible on one of the platforms we run, following that they are fixed.  It is a harsh reality which static and dynamic analysis tools have not yet resolved.\\n&quot;<p>&quot;Regarding shutting them down, there other social problems.<p>Yes, we remove about 10 of the architectures.  We&#x27;d slowly lose the developers who like to work on those areas.  They also work in other areas, but ... I suspect they would another BSD that supports them.&quot;",
      "num_comments": null,
      "story_id": 7069889,
      "story_title": "OpenBSD will shut down if we do not have the funding to keep the lights on",
      "story_url": "http://marc.info/?l=openbsd-misc&m=138972987203440&w=2",
      "parent_id": 7070733,
      "created_at_i": 1389893286,
      "_tags": [
        "comment",
        "author_hhw",
        "story_7069889"
      ],
      "objectID": "7070841",
      "_highlightResult": {
        "author": {
          "value": "hhw",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "From Theo's comments on the mailing list:<p>&quot;On a regular basis, we find real and serious bugs which affect all platforms, but they are incidentally made visible on one of the platforms we run, following that they are fixed.  It is a harsh reality which <em>static</em> and dynamic <em>analysis</em> <em>tools</em> have not yet resolved.\\n&quot;<p>&quot;Regarding shutting them down, there other social problems.<p>Yes, we remove about 10 of the architectures.  We'd slowly lose the developers who like to work on those areas.  They also work in other areas, but ... I suspect they would another BSD that supports them.&quot;",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "OpenBSD will shut down if we do not have the funding to keep the lights on",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://marc.info/?l=openbsd-misc&m=138972987203440&w=2",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-06-04T10:22:18.000Z",
      "title": "",
      "url": "",
      "author": "hamidpalo",
      "points": 21,
      "story_text": null,
      "comment_text": "It's about the type system.<p>Dynamic, weak typing makes writing static analysis/refactoring/etc tools extremely hard, but more importantly makes nearly any compile-time guarantees impossible. Having your app crash because of a small typo of a member name is impossible in C++/C#/Java. It happens to me almost once a day with Node/JS.",
      "num_comments": null,
      "story_id": 4063203,
      "story_title": "Anders Hejlsberg: You Can't Maintain Large Programs in JavaScript.",
      "story_url": "http://css.dzone.com/articles/you-can-write-large-programs",
      "parent_id": 4063290,
      "created_at_i": 1338805338,
      "_tags": [
        "comment",
        "author_hamidpalo",
        "story_4063203"
      ],
      "objectID": "4063338",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "hamidpalo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's about the type system.<p>Dynamic, weak typing makes writing <em>static</em> <em>analysis</em>/refactoring/etc <em>tools</em> extremely hard, but more importantly makes nearly any compile-time guarantees impossible. Having your app crash because of a small typo of a member name is impossible in C++/C#/Java. It happens to me almost once a day with Node/JS.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Anders Hejlsberg: You Can't Maintain Large Programs in JavaScript.",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://css.dzone.com/articles/you-can-write-large-programs",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-20T23:40:23.000Z",
      "title": "",
      "url": "",
      "author": "pacaro",
      "points": 9,
      "story_text": null,
      "comment_text": "This caught my eye \"Program analyzers that warn about these problems are likely to lose users.\"<p>For me, this is perhaps the biggest issue raised in this article, as static and dynamic analysis tools become more ubiquitous we should be learning to fix the issues that they raise, not ignore them.<p>I remember a while ago (2004 or 5) interviewing a college-hire candidate, I had asked about working with others and we had gotten to talking about code review - the candidate was passionate about how code review had helped with a group project he worked on, but every single example he gave of a a bug found by code review was something that -Wall would have found...<p>The same applies to static analysis - let the machines do the work that they can do, that leaves the humans to get on with the work that the machines can't do (yet!)",
      "num_comments": null,
      "story_id": 5088586,
      "story_title": "C and C++ Aren't Future Proof",
      "story_url": "http://blog.regehr.org/archives/880",
      "parent_id": 5088586,
      "created_at_i": 1358725223,
      "_tags": [
        "comment",
        "author_pacaro",
        "story_5088586"
      ],
      "objectID": "5088795",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pacaro",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This caught my eye \"Program analyzers that warn about these problems are likely to lose users.\"<p>For me, this is perhaps the biggest issue raised in this article, as <em>static</em> and dynamic <em>analysis</em> <em>tools</em> become more ubiquitous we should be learning to fix the issues that they raise, not ignore them.<p>I remember a while ago (2004 or 5) interviewing a college-hire candidate, I had asked about working with others and we had gotten to talking about code review - the candidate was passionate about how code review had helped with a group project he worked on, but every single example he gave of a a bug found by code review was something that -Wall would have found...<p>The same applies to <em>static</em> <em>analysis</em> - let the machines do the work that they can do, that leaves the humans to get on with the work that the machines can't do (yet!)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "C and C++ Aren't Future Proof",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.regehr.org/archives/880",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-29T17:13:09.000Z",
      "title": null,
      "url": null,
      "author": "Sajmani",
      "points": 7,
      "story_text": null,
      "comment_text": "In Google, we use two approaches:<p>1) add an explicit Context parameter to each function that needs one; typically this is the first parameter and is named &quot;ctx&quot;.  This makes it obvious how to cancel that function and pass stuff through it, but it&#x27;s a lot of work.  We are developing static analysis and refactoring tools to help automate tasks like this.<p>2) use a package to map http.Requests to Contexts.  This requires that whatever server handler you&#x27;re using register a Context in a map for each http.Request and remove it when the request completes.  You could do this using the gorilla context package, for example.<p>My personal preference is the explicit ctx parameter, since then libraries are agnostic to the framework being used.  Different frameworks can provide their own Context implementations; middleware should not care.",
      "num_comments": null,
      "story_id": 8103128,
      "story_title": "Go Concurrency Patterns: Context",
      "story_url": "http://blog.golang.org/context",
      "parent_id": 8103283,
      "created_at_i": 1406653989,
      "_tags": [
        "comment",
        "author_Sajmani",
        "story_8103128"
      ],
      "objectID": "8103381",
      "_highlightResult": {
        "author": {
          "value": "Sajmani",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In Google, we use two approaches:<p>1) add an explicit Context parameter to each function that needs one; typically this is the first parameter and is named &quot;ctx&quot;.  This makes it obvious how to cancel that function and pass stuff through it, but it's a lot of work.  We are developing <em>static</em> <em>analysis</em> and refactoring <em>tools</em> to help automate tasks like this.<p>2) use a package to map http.Requests to Contexts.  This requires that whatever server handler you're using register a Context in a map for each http.Request and remove it when the request completes.  You could do this using the gorilla context package, for example.<p>My personal preference is the explicit ctx parameter, since then libraries are agnostic to the framework being used.  Different frameworks can provide their own Context implementations; middleware should not care.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Go Concurrency Patterns: Context",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.golang.org/context",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-20T11:18:44.000Z",
      "title": null,
      "url": null,
      "author": "eksith",
      "points": 4,
      "story_text": null,
      "comment_text": "You may have missed the discussion from last time in which Theo explains the benefit of having older hardware. The dissatisfaction with OpenBSD seems to eerily mirror the incredibly short-sighted criticism of NASA funding : &quot;Why do we spend all this money to send junk into space?&quot; Which conveniently side-steps the innumerable benefits it produces.<p><a href=\"http://marc.info/?l=openbsd-tech&amp;m=138973312304511&amp;w=2\" rel=\"nofollow\">http:&#x2F;&#x2F;marc.info&#x2F;?l=openbsd-tech&amp;m=138973312304511&amp;w=2</a><p><pre><code>  The answer to that is not news.\\n  \\n  On a regular basis, we find real and serious bugs which affect all\\n  platforms, but they are incidentally made visible on one of the\\n  platforms we run, following that they are fixed.  It is a harsh\\n  reality which static and dynamic analysis tools have not yet resolved.\\n  \\n  Now, If you don&#x27;t realize this is the reason we try to run on the\\n  older platforms, I am sorry but you have really not tried to stay in\\n  the loop of what makes OpenBSD a vibrant ecosystem.  If you aren&#x27;t in\\n  the loop regarding this, then your mail comes off pretty darn preachy.\\n  \\n  &gt; The recent discussion of a need for a replacement\\n  &gt; Vax for package-building illustrates that.\\n  \\n  The vaxes being asked for draw almost no power, but it supplies the\\n  same benefits as the other architectures.\\n  \\n  Regarding shutting them down, there other social problems.\\n  \\n  Yes, we remove about 10 of the architectures.  We&#x27;d slowly lose the\\n  developers who like to work on those areas.  They also work in other\\n  areas, but ... I suspect they would another BSD that supports them.</code></pre>",
      "num_comments": null,
      "story_id": 7087800,
      "story_title": "Romanian saves OpenBSD?",
      "story_url": "http://www.thedrinkingrecord.com/2014/01/19/romanian-billionaire-saves-openbsd/",
      "parent_id": 7088055,
      "created_at_i": 1390216724,
      "_tags": [
        "comment",
        "author_eksith",
        "story_7087800"
      ],
      "objectID": "7088899",
      "_highlightResult": {
        "author": {
          "value": "eksith",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You may have missed the discussion from last time in which Theo explains the benefit of having older hardware. The dissatisfaction with OpenBSD seems to eerily mirror the incredibly short-sighted criticism of NASA funding : &quot;Why do we spend all this money to send junk into space?&quot; Which conveniently side-steps the innumerable benefits it produces.<p><a href=\"http://marc.info/?l=openbsd-tech&amp;m=138973312304511&amp;w=2\" rel=\"nofollow\">http://marc.info/?l=openbsd-tech&amp;m=138973312304511&amp;w=2</a><p><pre><code>  The answer to that is not news.\\n  \\n  On a regular basis, we find real and serious bugs which affect all\\n  platforms, but they are incidentally made visible on one of the\\n  platforms we run, following that they are fixed.  It is a harsh\\n  reality which <em>static</em> and dynamic <em>analysis</em> <em>tools</em> have not yet resolved.\\n  \\n  Now, If you don't realize this is the reason we try to run on the\\n  older platforms, I am sorry but you have really not tried to stay in\\n  the loop of what makes OpenBSD a vibrant ecosystem.  If you aren't in\\n  the loop regarding this, then your mail comes off pretty darn preachy.\\n  \\n  &gt; The recent discussion of a need for a replacement\\n  &gt; Vax for package-building illustrates that.\\n  \\n  The vaxes being asked for draw almost no power, but it supplies the\\n  same benefits as the other architectures.\\n  \\n  Regarding shutting them down, there other social problems.\\n  \\n  Yes, we remove about 10 of the architectures.  We'd slowly lose the\\n  developers who like to work on those areas.  They also work in other\\n  areas, but ... I suspect they would another BSD that supports them.</code></pre>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Romanian saves OpenBSD?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.thedrinkingrecord.com/2014/01/19/romanian-billionaire-saves-openbsd/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-10-24T13:58:26.000Z",
      "title": null,
      "url": null,
      "author": "mynegation",
      "points": 4,
      "story_text": null,
      "comment_text": "Automotive producers in general have pretty high standard of the source code creation and maintenance. However - the set of guidelines that govern the code - MISRA (Motor Industry Software Reliability Association), while better than nothing, are pretty poor. Most of MISRA rules look like they were designed to be easily checked by automated tools - not to check for real defects. That situation may have been acceptable 15 years ago, but modern static and dynamic analysis tools are capable of much more than that.",
      "num_comments": null,
      "story_id": 3148831,
      "story_title": "Jaguar recalls 18,000 cars over major software fault",
      "story_url": "http://www.computerworlduk.com/news/applications/3312860/jaguar-recalls-18000-cars-over-cruise-control-software-fault/",
      "parent_id": 3148831,
      "created_at_i": 1319464706,
      "_tags": [
        "comment",
        "author_mynegation",
        "story_3148831"
      ],
      "objectID": "3149590",
      "_highlightResult": {
        "author": {
          "value": "mynegation",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Automotive producers in general have pretty high standard of the source code creation and maintenance. However - the set of guidelines that govern the code - MISRA (Motor Industry Software Reliability Association), while better than nothing, are pretty poor. Most of MISRA rules look like they were designed to be easily checked by automated <em>tools</em> - not to check for real defects. That situation may have been acceptable 15 years ago, but modern <em>static</em> and dynamic <em>analysis</em> <em>tools</em> are capable of much more than that.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Jaguar recalls 18,000 cars over major software fault",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.computerworlduk.com/news/applications/3312860/jaguar-recalls-18000-cars-over-cruise-control-software-fault/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-05-31T13:38:11.000Z",
      "title": null,
      "url": null,
      "author": "gnuvince",
      "points": 2,
      "story_text": null,
      "comment_text": "I don&#x27;t think that C has any safety features; there are tools to help you find where you are being unsafe (e.g. static and dynamic analysis) and tools to mitigate the effects of the unsafe code (e.g. memory randomization, canaries, etc.).",
      "num_comments": null,
      "story_id": 7825524,
      "story_title": "Pointers Gone Wild",
      "story_url": "http://goto.ucsd.edu/~rjhala/liquid/haskell/blog/blog/2014/05/28/pointers-gone-wild.lhs/",
      "parent_id": 7825713,
      "created_at_i": 1401543491,
      "_tags": [
        "comment",
        "author_gnuvince",
        "story_7825524"
      ],
      "objectID": "7825976",
      "_highlightResult": {
        "author": {
          "value": "gnuvince",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't think that C has any safety features; there are <em>tools</em> to help you find where you are being unsafe (e.g. <em>static</em> and dynamic <em>analysis</em>) and <em>tools</em> to mitigate the effects of the unsafe code (e.g. memory randomization, canaries, etc.).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Pointers Gone Wild",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://goto.ucsd.edu/~rjhala/liquid/haskell/blog/blog/2014/05/28/pointers-gone-wild.lhs/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-06-04T01:42:22.000Z",
      "title": "",
      "url": "",
      "author": "peripetylabs",
      "points": 2,
      "story_text": null,
      "comment_text": "There exist proof and verification tools for C, like ACSL and Frama-C, [1] or LCL and Splint. [2,3] Not to mention the myriad of static and dynamic analysis tools. You can <i>prove</i> that a piece of C code does or doesn't contain certain bugs -- this is not the case for higher-level languages (except perhaps Haskell and ML). That is why C is used for highly sensitive projects like avionics.<p>I would say: learn C <i>and high-level languages</i>.<p>[1] <a href=\"http://frama-c.com/acsl.html\" rel=\"nofollow\">http://frama-c.com/acsl.html</a><p>[2] www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-74.pdf<p>[3] <a href=\"http://splint.org/\" rel=\"nofollow\">http://splint.org/</a>",
      "num_comments": null,
      "story_id": 5809012,
      "story_title": "Learn C",
      "story_url": "https://medium.com/tech-talk/afcfa2920c17",
      "parent_id": 5809012,
      "created_at_i": 1370310142,
      "_tags": [
        "comment",
        "author_peripetylabs",
        "story_5809012"
      ],
      "objectID": "5817213",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "peripetylabs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "There exist proof and verification <em>tools</em> for C, like ACSL and Frama-C, [1] or LCL and Splint. [2,3] Not to mention the myriad of <em>static</em> and dynamic <em>analysis</em> <em>tools</em>. You can <i>prove</i> that a piece of C code does or doesn't contain certain bugs -- this is not the case for higher-level languages (except perhaps Haskell and ML). That is why C is used for highly sensitive projects like avionics.<p>I would say: learn C <i>and high-level languages</i>.<p>[1] <a href=\"http://frama-c.com/acsl.html\" rel=\"nofollow\">http://frama-c.com/acsl.html</a><p>[2] www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-74.pdf<p>[3] <a href=\"http://splint.org/\" rel=\"nofollow\">http://splint.org/</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Learn C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://medium.com/tech-talk/afcfa2920c17",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-17T15:05:17.000Z",
      "title": "",
      "url": "",
      "author": "kibwen",
      "points": 2,
      "story_text": null,
      "comment_text": "Maybe, I'm still juggling the options in my head. But when I say enterprise I mean <i>enterprise</i>, with all the pejorative connotations thereof. We are not a nimble startup, we are an enormous, established, <i>very</i> conservative company; I'm just the guy who knows all those newfangled languages. This means that, unless someone can convince me otherwise (and if you can, please, please convince me otherwise), Java seems to possess the correct combination of features: mature platform, wide adoption, familiar syntax, readily-available developers, maintainability by those other than the original authors (Java isn't necessarily great at this, but better than many), and a quality that I'll describe only as <i>hard to really fuck things up too badly</i>. If it wasn't for that last requirement, I'd already be trying to sell Python to my boss; as it stands, if I can't find some really awesome static analysis and verification tools for Python, Java is simply the only choice that my conscience allows me to make.<p>(Corollary: what about .NET? Mostly I'm incredibly wary of recommending a language with only one \"blessed\" platform, and a proprietary one at that. My bosses are wary of this too: as a result of historical decisions we're currently locked into IBM hardware, writing million-line codebases in RPG-LE. If someone can allay my fears of vendor lock-in (at the hands of no less than Microsoft), perhaps I'll consider it.)",
      "num_comments": null,
      "story_id": 3986540,
      "story_title": "Jython 2.7 alpha1 released",
      "story_url": "http://fwierzbicki.blogspot.com/2012/05/jython-27-alpha1-released.html",
      "parent_id": 3987092,
      "created_at_i": 1337267117,
      "_tags": [
        "comment",
        "author_kibwen",
        "story_3986540"
      ],
      "objectID": "3987282",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "kibwen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Maybe, I'm still juggling the options in my head. But when I say enterprise I mean <i>enterprise</i>, with all the pejorative connotations thereof. We are not a nimble startup, we are an enormous, established, <i>very</i> conservative company; I'm just the guy who knows all those newfangled languages. This means that, unless someone can convince me otherwise (and if you can, please, please convince me otherwise), Java seems to possess the correct combination of features: mature platform, wide adoption, familiar syntax, readily-available developers, maintainability by those other than the original authors (Java isn't necessarily great at this, but better than many), and a quality that I'll describe only as <i>hard to really fuck things up too badly</i>. If it wasn't for that last requirement, I'd already be trying to sell Python to my boss; as it stands, if I can't find some really awesome <em>static</em> <em>analysis</em> and verification <em>tools</em> for Python, Java is simply the only choice that my conscience allows me to make.<p>(Corollary: what about .NET? Mostly I'm incredibly wary of recommending a language with only one \"blessed\" platform, and a proprietary one at that. My bosses are wary of this too: as a result of historical decisions we're currently locked into IBM hardware, writing million-line codebases in RPG-LE. If someone can allay my fears of vendor lock-in (at the hands of no less than Microsoft), perhaps I'll consider it.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Jython 2.7 alpha1 released",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://fwierzbicki.blogspot.com/2012/05/jython-27-alpha1-released.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T03:38:43.000Z",
      "title": null,
      "url": null,
      "author": "gtani",
      "points": 2,
      "story_text": null,
      "comment_text": "Hmm, tough question to google but: I was going to blog about but: didn't get around toit. Look at static code analysis and runtime tools (debuggers) there's SO tags for that, python+code-analysis.<p><a href=\"http://stackoverflow.com/questions/3883484/using-python-code-coverage-tool-for-understanding-and-pruning-back-source-code-o\" rel=\"nofollow\">http://stackoverflow.com/questions/3883484/using-python-code...</a><p>Python has a very rich toolset, including inspect module,<p><a href=\"http://stackoverflow.com/questions/1568544/given-a-python-class-how-can-i-inspect-and-find-the-place-in-my-code-where-it-i\" rel=\"nofollow\">http://stackoverflow.com/questions/1568544/given-a-python-cl...</a><p><a href=\"http://code.activestate.com/recipes/213898-drawing-inheritance-diagrams-with-dot/?in=user-1122360\" rel=\"nofollow\">http://code.activestate.com/recipes/213898-drawing-inheritan...</a><p>Also (this thread)[<a href=\"http://stackoverflow.com/questions/334009/how-to-read-source-code-learn-how-to-use-large-system\" rel=\"nofollow\">http://stackoverflow.com/questions/334009/how-to-read-source...</a>] mentions ctags, doxygen, tools like that.  Reading test suites (and running code coverage) is where a lot of people start with new to them codebases.  And python specific emacs and vim plugins, and python-specific IDE's, komodo and pycharm, at the tools they provide for folding code, showing module dependencies/call graphs, stuff like that<p>---------<p>My python's a little rusty, but could generate stacktraces, or use an IDE's stepper/debugger to show where you are at some point in execution of django code<p>-----------<p>Finally [a book](<a href=\"http://www.amazon.com/Code-Reading-Open-Source-Perspective/dp/0201799405/\" rel=\"nofollow\">http://www.amazon.com/Code-Reading-Open-Source-Perspective/d...</a>)",
      "num_comments": null,
      "story_id": 3387812,
      "story_title": "Ask HN: Advice on Reading Source Code",
      "story_url": "",
      "parent_id": 3387812,
      "created_at_i": 1324697923,
      "_tags": [
        "comment",
        "author_gtani",
        "story_3387812"
      ],
      "objectID": "3388096",
      "_highlightResult": {
        "author": {
          "value": "gtani",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Hmm, tough question to google but: I was going to blog about but: didn't get around toit. Look at <em>static</em> code <em>analysis</em> and runtime <em>tools</em> (debuggers) there's SO tags for that, python+code-<em>analysis.</em><p><a href=\"http://stackoverflow.com/questions/3883484/using-python-code-coverage-tool-for-understanding-and-pruning-back-source-code-o\" rel=\"nofollow\">http://stackoverflow.com/questions/3883484/using-python-code...</a><p>Python has a very rich <em>tools</em>et, including inspect module,<p><a href=\"http://stackoverflow.com/questions/1568544/given-a-python-class-how-can-i-inspect-and-find-the-place-in-my-code-where-it-i\" rel=\"nofollow\">http://stackoverflow.com/questions/1568544/given-a-python-cl...</a><p><a href=\"http://code.activestate.com/recipes/213898-drawing-inheritance-diagrams-with-dot/?in=user-1122360\" rel=\"nofollow\">http://code.activestate.com/recipes/213898-drawing-inheritan...</a><p>Also (this thread)[<a href=\"http://stackoverflow.com/questions/334009/how-to-read-source-code-learn-how-to-use-large-system\" rel=\"nofollow\">http://stackoverflow.com/questions/334009/how-to-read-source...</a>] mentions ctags, doxygen, <em>tools</em> like that.  Reading test suites (and running code coverage) is where a lot of people start with new to them codebases.  And python specific emacs and vim plugins, and python-specific IDE's, komodo and pycharm, at the <em>tools</em> they provide for folding code, showing module dependencies/call graphs, stuff like that<p>---------<p>My python's a little rusty, but could generate stacktraces, or use an IDE's stepper/debugger to show where you are at some point in execution of django code<p>-----------<p>Finally [a book](<a href=\"http://www.amazon.com/Code-Reading-Open-Source-Perspective/dp/0201799405/\" rel=\"nofollow\">http://www.amazon.com/Code-Reading-Open-Source-Perspective/d...</a>)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Advice on Reading Source Code",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-22T04:57:04.000Z",
      "title": "",
      "url": "",
      "author": "dietrichepp",
      "points": 1,
      "story_text": null,
      "comment_text": "When I started seriously working with JavaScript, I decided to try to conform to community standards by using JSLint.  I was shocked by how terrible JSLint was.  It offered corrections for very straightforward constructs such as:<p><pre><code>    var count = 0;\n    for (var i = 0; i &#60; arr.length; i++) {\n        if (some_func(i)) {\n            count++;\n        }\n    }\n</code></pre>\nI have no idea why JSLint would tell me that I should move the definition of \"i\" to the top of the function (am I supposed to pretend I'm writing ANSI C for obsolete compilers?) and its insistence that \"++\" is evil in both uses above is equally ridiculous.<p>I love static analysis, I like tools that automatically format source code (indent, go fmt, emacs), but JSLint is just annoying.",
      "num_comments": null,
      "story_id": 5747961,
      "story_title": "Dart Is Not the Language You Think It Is",
      "story_url": "http://programming.oreilly.com/2013/05/dart-is-not-the-language-you-think-it-is.html",
      "parent_id": 5748784,
      "created_at_i": 1369198624,
      "_tags": [
        "comment",
        "author_dietrichepp",
        "story_5747961"
      ],
      "objectID": "5748963",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dietrichepp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "When I started seriously working with JavaScript, I decided to try to conform to community standards by using JSLint.  I was shocked by how terrible JSLint was.  It offered corrections for very straightforward constructs such as:<p><pre><code>    var count = 0;\n    for (var i = 0; i < arr.length; i++) {\n        if (some_func(i)) {\n            count++;\n        }\n    }\n</code></pre>\nI have no idea why JSLint would tell me that I should move the definition of \"i\" to the top of the function (am I supposed to pretend I'm writing ANSI C for obsolete compilers?) and its insistence that \"++\" is evil in both uses above is equally ridiculous.<p>I love <em>static</em> <em>analysis</em>, I like <em>tools</em> that automatically format source code (indent, go fmt, emacs), but JSLint is just annoying.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dart Is Not the Language You Think It Is",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://programming.oreilly.com/2013/05/dart-is-not-the-language-you-think-it-is.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-02T14:05:16.000Z",
      "title": "",
      "url": "",
      "author": "ruediger",
      "points": 1,
      "story_text": null,
      "comment_text": "I guess the reason for Google to start contributing to Clang and using it for their tools is the availability of the frontend. As far as I know the GCC developers made it extra hard to separate the frontend from the compiler because they feared that people would use it on proprietary backends. But this really left us in a situation were for decades people couldn't work on creating amazing static analysis, autocompletion, refactoring tools for C and C++. In the end this decision probably did more damage to the free software movement. GCC now comes with a plugin interface and with the Clang frontend available I hope that this will change quickly.",
      "num_comments": null,
      "story_id": 3654081,
      "story_title": "GCC 4.6.3 Released",
      "story_url": "http://gcc.gnu.org/ml/gcc/2012-03/msg00006.html",
      "parent_id": 3655385,
      "created_at_i": 1330697116,
      "_tags": [
        "comment",
        "author_ruediger",
        "story_3654081"
      ],
      "objectID": "3656589",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "ruediger",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I guess the reason for Google to start contributing to Clang and using it for their <em>tools</em> is the availability of the frontend. As far as I know the GCC developers made it extra hard to separate the frontend from the compiler because they feared that people would use it on proprietary backends. But this really left us in a situation were for decades people couldn't work on creating amazing <em>static</em> <em>analysis</em>, autocompletion, refactoring <em>tools</em> for C and C++. In the end this decision probably did more damage to the free software movement. GCC now comes with a plugin interface and with the Clang frontend available I hope that this will change quickly.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "GCC 4.6.3 Released",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://gcc.gnu.org/ml/gcc/2012-03/msg00006.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-08-31T13:12:31.000Z",
      "title": "",
      "url": "",
      "author": "dagw",
      "points": 1,
      "story_text": null,
      "comment_text": "Debuggers, profilers, static and dynamic analysis tools...",
      "num_comments": null,
      "story_id": 2945064,
      "story_title": "What are the best C++ development tools in Linux?",
      "story_url": "http://www.typemock.com/blog/2011/07/04/what-are-the-best-c-development-tools-in-linux-2/",
      "parent_id": 2945338,
      "created_at_i": 1314796351,
      "_tags": [
        "comment",
        "author_dagw",
        "story_2945064"
      ],
      "objectID": "2945367",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dagw",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Debuggers, profilers, <em>static</em> and dynamic <em>analysis</em> <em>tools</em>...",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What are the best C++ development <em>tools</em> in Linux?",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "http://www.typemock.com/blog/2011/07/04/what-are-the-best-c-development-<em>tools</em>-in-linux-2/",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        }
      }
    },
    {
      "created_at": "2011-08-13T23:19:39.000Z",
      "title": "",
      "url": "",
      "author": "tincholio",
      "points": 1,
      "story_text": null,
      "comment_text": "&#62; Sure, for my project, I'm typing in code in Visual Basic .NET. For writing code today, all things considered for my context, that is about the best option.<p>Maybe you should try something other than VB.NET, then. There are ways of constructing correct code, if you're patient enough, that is. If you're using the CLR, why not use F# instead of VB? That'd be a big step towards being able to prove some things about your code. Or if you really want to take out the big guns, go for Coq, Isabelle, Agda, Epigram, etc.<p>&#62; Can some software go over it, report properties, do some transformations with known, useful properties?<p>Yes, in many cases. There's a whole lot of work in static code analysis, and refactoring tools. It's not perfect (the halting problem being non-decidable and all that) but there have been _significant_ improvements since the Algol60 days, and that's not counting functional languages and type-theoretic approaches.<p>&#62; Or, return to most of the rest of engineering<p>That goes a bit off topic, but at the stage we are in, for most practical purposes, \"software engineering\" is not really engineering. Except maybe when done by NASA, but then again, that's not a practical approach either.<p>&#62; Also for another of your points, I'm not talking about anything like branch prediction or deep pipelining. That's basically what to do with with the hardware to execute an existing instruction set.<p>Oh, but you were talking about compilers. Modern optimizing compilers have to take those things into account, among many other things.<p>&#62; Clearly compiling and executing a program are necessarily mathematically something, understood or not, powerful or not. For progress, we need to understand the subject mathematically.<p>(from your previous post)\nMy point was that very significant progress has been made in many fields, even if not necessarily formalized.<p>&#62; Also the point is not math or not.<p>Sorry, but when you state that CS should be a footnote in a math book, you are kinda making the point that everything in CS (even in those sub-domains that are eminently practical) should be math-based to do anything meaningful. This is demonstrably not true.<p>&#62; The point is progress.<p>And I've agreed with you on this. More and better maths can help advance CS. But we knew that already.<p>&#62; Your point that there's a lot of good CS to do without 'mathematizing' the field is not promising for research or significant progress.<p>I contend that there has been significant progress in many CS areas without 'mathematizing' them. That is a fact. I also stated, in my previous post, that I agree that maths could help improve this progress. I think my problem with your position is that you're talking in absolutes in topics where those absolutes clearly don't hold.",
      "num_comments": null,
      "story_id": 2877563,
      "story_title": "Milestone for MIT Presss bestseller, \"Introduction to Algorithms\"",
      "story_url": "http://web.mit.edu/newsoffice/2011/introduction-to-algorithms-500k-0810.html",
      "parent_id": 2882071,
      "created_at_i": 1313277579,
      "_tags": [
        "comment",
        "author_tincholio",
        "story_2877563"
      ],
      "objectID": "2882267",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "tincholio",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> Sure, for my project, I'm typing in code in Visual Basic .NET. For writing code today, all things considered for my context, that is about the best option.<p>Maybe you should try something other than VB.NET, then. There are ways of constructing correct code, if you're patient enough, that is. If you're using the CLR, why not use F# instead of VB? That'd be a big step towards being able to prove some things about your code. Or if you really want to take out the big guns, go for Coq, Isabelle, Agda, Epigram, etc.<p>> Can some software go over it, report properties, do some transformations with known, useful properties?<p>Yes, in many cases. There's a whole lot of work in <em>static</em> code <em>analysis</em>, and refactoring <em>tools</em>. It's not perfect (the halting problem being non-decidable and all that) but there have been _significant_ improvements since the Algol60 days, and that's not counting functional languages and type-theoretic approaches.<p>> Or, return to most of the rest of engineering<p>That goes a bit off topic, but at the stage we are in, for most practical purposes, \"software engineering\" is not really engineering. Except maybe when done by NASA, but then again, that's not a practical approach either.<p>> Also for another of your points, I'm not talking about anything like branch prediction or deep pipelining. That's basically what to do with with the hardware to execute an existing instruction set.<p>Oh, but you were talking about compilers. Modern optimizing compilers have to take those things into account, among many other things.<p>> Clearly compiling and executing a program are necessarily mathematically something, understood or not, powerful or not. For progress, we need to understand the subject mathematically.<p>(from your previous post)\nMy point was that very significant progress has been made in many fields, even if not necessarily formalized.<p>> Also the point is not math or not.<p>Sorry, but when you state that CS should be a footnote in a math book, you are kinda making the point that everything in CS (even in those sub-domains that are eminently practical) should be math-based to do anything meaningful. This is demonstrably not true.<p>> The point is progress.<p>And I've agreed with you on this. More and better maths can help advance CS. But we knew that already.<p>> Your point that there's a lot of good CS to do without 'mathematizing' the field is not promising for research or significant progress.<p>I contend that there has been significant progress in many CS areas without 'mathematizing' them. That is a fact. I also stated, in my previous post, that I agree that maths could help improve this progress. I think my problem with your position is that you're talking in absolutes in topics where those absolutes clearly don't hold.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Milestone for MIT Presss bestseller, \"Introduction to Algorithms\"",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://web.mit.edu/newsoffice/2011/introduction-to-algorithms-500k-0810.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-29T16:05:43.000Z",
      "title": null,
      "url": null,
      "author": "geofft",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; No, because none of them contain the static analysis and developer tools one comes to expect from a competent IDE.<p>So nobody uses emacs or vi without static analysis plugins either?",
      "num_comments": null,
      "story_id": 9457973,
      "story_title": "Ask HN: Is anyone using a web IDE for most of their development work?",
      "story_url": "",
      "parent_id": 9458567,
      "created_at_i": 1430323543,
      "_tags": [
        "comment",
        "author_geofft",
        "story_9457973"
      ],
      "objectID": "9459254",
      "_highlightResult": {
        "author": {
          "value": "geofft",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; No, because none of them contain the <em>static</em> <em>analysis</em> and developer <em>tools</em> one comes to expect from a competent IDE.<p>So nobody uses emacs or vi without <em>static</em> <em>analysis</em> plugins either?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Is anyone using a web IDE for most of their development work?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-29T14:40:37.000Z",
      "title": null,
      "url": null,
      "author": "task_queue",
      "points": null,
      "story_text": null,
      "comment_text": "No, because none of them contain the static analysis and developer tools one comes to expect from a competent IDE.<p>Also coding in the browser has been a miserable experience.",
      "num_comments": null,
      "story_id": 9457973,
      "story_title": "Ask HN: Is anyone using a web IDE for most of their development work?",
      "story_url": "",
      "parent_id": 9457973,
      "created_at_i": 1430318437,
      "_tags": [
        "comment",
        "author_task_queue",
        "story_9457973"
      ],
      "objectID": "9458567",
      "_highlightResult": {
        "author": {
          "value": "task_queue",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "No, because none of them contain the <em>static</em> <em>analysis</em> and developer <em>tools</em> one comes to expect from a competent IDE.<p>Also coding in the browser has been a miserable experience.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Is anyone using a web IDE for most of their development work?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-20T17:58:50.000Z",
      "title": null,
      "url": null,
      "author": "bch",
      "points": null,
      "story_text": null,
      "comment_text": "History says that security is a process, not a product (or artifact). I <i>get</i> it that C can be difficult. Pointers allow NULL dereferencing and use-after-free, strings are open to poor handling, etc. That said: we have OpenBSD w&#x2F; their re-written string&#x2F;memory management and static and dynamic analysis tools with decades of development behind them.<p>I&#x27;m more hesitant to crucify C than I feel others are... are we throwing out the baby with the bathwater ?<p>To your comment -- that a  C program is probably not secure -- <i>most</i> code written (regardless of language) is probably junk, with different classes of errors. Its tough.",
      "num_comments": null,
      "story_id": 8916379,
      "story_title": "Go Static or Go Home",
      "story_url": "http://queue.acm.org/detail.cfm?id=2721993",
      "parent_id": 8918122,
      "created_at_i": 1421776730,
      "_tags": [
        "comment",
        "author_bch",
        "story_8916379"
      ],
      "objectID": "8918287",
      "_highlightResult": {
        "author": {
          "value": "bch",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "History says that security is a process, not a product (or artifact). I <i>get</i> it that C can be difficult. Pointers allow NULL dereferencing and use-after-free, strings are open to poor handling, etc. That said: we have OpenBSD w/ their re-written string/memory management and <em>static</em> and dynamic <em>analysis</em> <em>tools</em> with decades of development behind them.<p>I'm more hesitant to crucify C than I feel others are... are we throwing out the baby with the bathwater ?<p>To your comment -- that a  C program is probably not secure -- <i>most</i> code written (regardless of language) is probably junk, with different classes of errors. Its tough.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Go <em>Static</em> or Go Home",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "http://queue.acm.org/detail.cfm?id=2721993",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-16T22:41:16.000Z",
      "title": null,
      "url": null,
      "author": "mikestew",
      "points": null,
      "story_text": null,
      "comment_text": "Having worked on and off in software testing for the last fifteen years or so, I&#x27;m becoming increasingly convinced that there&#x27;s a correlation between the recent trend of calling software test teams &quot;Quality Assurance&quot; and general purpose software that seems to get less stable as time goes on. Bear with me on my admittedly whacky theory that I haven&#x27;t completely fleshed out yet.<p>What is called &quot;quality assurance&quot; is really &quot;quality control&quot; in the places I&#x27;ve observed. The difference is subtle. For example, at my last position I carried the title &quot;Director of QA&quot;. That was a made-up title that didn&#x27;t mean anything. It didn&#x27;t mean anything because if I were truly a manager of QA, then when dev throws something over the wall that has no code reviews and no unit tests, I&#x27;m empowered to say, &quot;no, we&#x27;re not shipping this&quot;. But as we all know, that&#x27;s not how it turns out. Instead my team is &quot;quality control&quot; because we&#x27;re just testing the output and have no empowerment over the creation process. In other words, we&#x27;re a test team, so quit with the &quot;QA&quot; crap just because it has the word &quot;quality&quot; in it. As the saying goes, you can&#x27;t test in quality.<p>With that, I see two trends. One, which has been going on for a while what with TDD and the like, is an increase of the testing burden on dev. This is, generally speaking, a good thing IMO, especially if dev can be backed by a dedicated test team. Where it goes off the rails is what I hear from my Microsoft friends: there is no more test, &quot;devs&quot; (many of whom might be converted testers that may or may not be qualified &quot;devs&quot;) are responsible for testing, too. Don&#x27;t ever rely on your own testing if you&#x27;re a dev. You&#x27;ll test it the way it was written, and you&#x27;ll not only miss edge cases but likely scenarios as well.<p>Could this explain the steaming pile that was the Xbox One (the only MSFT product I have in the house, or use, these days) in its early days? Could it explain the unbelievably buggy, nearly unusable, _Halo: The Master Chief Collection_ we got from a Microsoft studio? Dunno, could be coincidence, but it conveniently fits my theory; might want to grab some tin foil.<p>Trend #2 is a regression bug: throw shit over the wall and hope test finds the bugs. Call &#x27;em &quot;QA&quot; so that when the quality isn&#x27;t there we have someone to blame. That&#x27;s what we used to do 20 years ago, then we as an industry got a clue and put some quality onus on dev while test got brought into the process earlier. Maybe it&#x27;s just my corner of the world, but many seem to be going back to just that (I left my last position mainly because of that reason, after they bait-and-switched me between the interview and the actual work.)<p>Could be that tools that help with quality haven&#x27;t kept pace with the increasing complexity of software systems. Could be, but I&#x27;m not sure I buy that. We&#x27;ve got tools I could only dream of 20 years ago (Xcode&#x27;s point-and-click profiling tools, code coverage tools, static analysis). Test modeling tools need some work, but at least they exist.<p>I think an overly simplistic answer is that the industry doesn&#x27;t know what to do with software test. We know we need some, but damn does it cost money. So how can we minimize that cost without appearing to just throw up our hands? After all, most of us are not building the guidance control for space probes, so who cares if Angry Confectionary Squashing Avians crashes once in a while? Instead we throw an understaffed and unempowered team of victims at the problem, then scream &quot;why didn&#x27;t test (pardon me: &quot;QA&quot;) find this?!&quot;<p>That&#x27;s my take on it, anyway. I&#x27;m astounded at the poor quality of most software I encounter, but I think the general user population is used to thinking that it&#x27;s either something they&#x27;re doing wrong, or that&#x27;s just the way software is. There are no late night pitchfork parties along Microsoft Way or One Infinite Loop, and people keeping paying, so there&#x27;s not always a huge incentive to do otherwise. Many of us have said we&#x27;d pay for an upgrade that included nothing but bug fixes. Companies think otherwise (and they&#x27;re probably right). Apple had their Snow Leopard, which they had to give away, but I can&#x27;t think of any other examples.<p>Solutions? Oh, I&#x27;ve got a few but this is getting long-winded and rambling, so I&#x27;ll spare those of you that stuck with me this long.",
      "num_comments": null,
      "story_id": 8758496,
      "story_title": "Microsoft has been making quality assurance mistakes lately",
      "story_url": "http://www.computerworld.com/article/2859902/at-microsoft-quality-seems-to-be-job-none.html#linkedin",
      "parent_id": 8758696,
      "created_at_i": 1418769676,
      "_tags": [
        "comment",
        "author_mikestew",
        "story_8758496"
      ],
      "objectID": "8760048",
      "_highlightResult": {
        "author": {
          "value": "mikestew",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Having worked on and off in software testing for the last fifteen years or so, I'm becoming increasingly convinced that there's a correlation between the recent trend of calling software test teams &quot;Quality Assurance&quot; and general purpose software that seems to get less stable as time goes on. Bear with me on my admittedly whacky theory that I haven't completely fleshed out yet.<p>What is called &quot;quality assurance&quot; is really &quot;quality control&quot; in the places I've observed. The difference is subtle. For example, at my last position I carried the title &quot;Director of QA&quot;. That was a made-up title that didn't mean anything. It didn't mean anything because if I were truly a manager of QA, then when dev throws something over the wall that has no code reviews and no unit tests, I'm empowered to say, &quot;no, we're not shipping this&quot;. But as we all know, that's not how it turns out. Instead my team is &quot;quality control&quot; because we're just testing the output and have no empowerment over the creation process. In other words, we're a test team, so quit with the &quot;QA&quot; crap just because it has the word &quot;quality&quot; in it. As the saying goes, you can't test in quality.<p>With that, I see two trends. One, which has been going on for a while what with TDD and the like, is an increase of the testing burden on dev. This is, generally speaking, a good thing IMO, especially if dev can be backed by a dedicated test team. Where it goes off the rails is what I hear from my Microsoft friends: there is no more test, &quot;devs&quot; (many of whom might be converted testers that may or may not be qualified &quot;devs&quot;) are responsible for testing, too. Don't ever rely on your own testing if you're a dev. You'll test it the way it was written, and you'll not only miss edge cases but likely scenarios as well.<p>Could this explain the steaming pile that was the Xbox One (the only MSFT product I have in the house, or use, these days) in its early days? Could it explain the unbelievably buggy, nearly unusable, _Halo: The Master Chief Collection_ we got from a Microsoft studio? Dunno, could be coincidence, but it conveniently fits my theory; might want to grab some tin foil.<p>Trend #2 is a regression bug: throw shit over the wall and hope test finds the bugs. Call 'em &quot;QA&quot; so that when the quality isn't there we have someone to blame. That's what we used to do 20 years ago, then we as an industry got a clue and put some quality onus on dev while test got brought into the process earlier. Maybe it's just my corner of the world, but many seem to be going back to just that (I left my last position mainly because of that reason, after they bait-and-switched me between the interview and the actual work.)<p>Could be that <em>tools</em> that help with quality haven't kept pace with the increasing complexity of software systems. Could be, but I'm not sure I buy that. We've got <em>tools</em> I could only dream of 20 years ago (Xcode's point-and-click profiling <em>tools</em>, code coverage <em>tools</em>, <em>static</em> <em>analysis</em>). Test modeling <em>tools</em> need some work, but at least they exist.<p>I think an overly simplistic answer is that the industry doesn't know what to do with software test. We know we need some, but damn does it cost money. So how can we minimize that cost without appearing to just throw up our hands? After all, most of us are not building the guidance control for space probes, so who cares if Angry Confectionary Squashing Avians crashes once in a while? Instead we throw an understaffed and unempowered team of victims at the problem, then scream &quot;why didn't test (pardon me: &quot;QA&quot;) find this?!&quot;<p>That's my take on it, anyway. I'm astounded at the poor quality of most software I encounter, but I think the general user population is used to thinking that it's either something they're doing wrong, or that's just the way software is. There are no late night pitchfork parties along Microsoft Way or One Infinite Loop, and people keeping paying, so there's not always a huge incentive to do otherwise. Many of us have said we'd pay for an upgrade that included nothing but bug fixes. Companies think otherwise (and they're probably right). Apple had their Snow Leopard, which they had to give away, but I can't think of any other examples.<p>Solutions? Oh, I've got a few but this is getting long-winded and rambling, so I'll spare those of you that stuck with me this long.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Microsoft has been making quality assurance mistakes lately",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.computerworld.com/article/2859902/at-microsoft-quality-seems-to-be-job-none.html#linkedin",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-08-31T22:08:45.000Z",
      "title": null,
      "url": null,
      "author": "stonemetal",
      "points": null,
      "story_text": null,
      "comment_text": "The free edition is just the base IDE(code editor, debugger, gui designer).  Come on this is MS, there are 5 versions of the pay IDE.\nThings you need to pay for:<p>using more than one language(you can download multiple free versions but that means having multiple installs of VS laying around),<p>3rd party plugins,<p>profiler,<p>code test coverage tool,<p>static analysis tool,<p>Database tools,<p>Integration with their team foundation server(source control, bug tracker, project management stuff )",
      "num_comments": null,
      "story_id": 796681,
      "story_title": "Making money from programming language design",
      "story_url": "http://www.plsadventures.com/2009/08/making-money-from-programming-language.html",
      "parent_id": 796798,
      "created_at_i": 1251756525,
      "_tags": [
        "comment",
        "author_stonemetal",
        "story_796681"
      ],
      "objectID": "796832",
      "_highlightResult": {
        "author": {
          "value": "stonemetal",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The free edition is just the base IDE(code editor, debugger, gui designer).  Come on this is MS, there are 5 versions of the pay IDE.\nThings you need to pay for:<p>using more than one language(you can download multiple free versions but that means having multiple installs of VS laying around),<p>3rd party plugins,<p>profiler,<p>code test coverage tool,<p><em>static</em> <em>analysis</em> tool,<p>Database <em>tools</em>,<p>Integration with their team foundation server(source control, bug tracker, project management stuff )",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Making money from programming language design",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.plsadventures.com/2009/08/making-money-from-programming-language.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-12-21T14:18:32.000Z",
      "title": null,
      "url": null,
      "author": "achew22",
      "points": null,
      "story_text": null,
      "comment_text": "I don't know specifically about the `crashme` tool but I can say that fuzzing is not a technique that has gone out of vogue. In fact it is standard security practice for finding ill defined behavior in programs for buffer overflows and other nasties. When you read the exacerbated cries of the security researchers who have been sitting on a critical IE/Firefox/Whatever bug they almost always scream something to the effect of \"Why didn't they just use a fuzzer, it's easy to find these problems that way -- that's how I did it.\" I would like to give props to Google, their security teams have been diligent in running static analysis and fuzzing tools against their code (white box[1][2]/black box testing[3])<p>As always, Wikipedia is a great source for information on this one[4] and I can personally testify to OWASP's fuzzer if you're going after webpages (my last local OWASP that I went to was on fuzzing and was REALLY interesting)<p>[1] <a href=\"http://en.wikipedia.org/wiki/White-box_testing\" rel=\"nofollow\">http://en.wikipedia.org/wiki/White-box_testing</a><p>[2] <a href=\"http://en.wikipedia.org/wiki/Static_code_analysis\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Static_code_analysis</a><p>[3] <a href=\"http://en.wikipedia.org/wiki/Black-box_testing\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Black-box_testing</a><p>[4] <a href=\"http://en.wikipedia.org/wiki/Fuzz_testing\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Fuzz_testing</a><p>EDIT: Fixing formatting",
      "num_comments": null,
      "story_id": 2027603,
      "story_title": "Hardening LLVM With Random Testing [PDF Slides]",
      "story_url": "http://www.llvm.org/devmtg/2010-11/Yang-HardenLLVM.pdf",
      "parent_id": 2027740,
      "created_at_i": 1292941112,
      "_tags": [
        "comment",
        "author_achew22",
        "story_2027603"
      ],
      "objectID": "2027769",
      "_highlightResult": {
        "author": {
          "value": "achew22",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't know specifically about the `crashme` tool but I can say that fuzzing is not a technique that has gone out of vogue. In fact it is standard security practice for finding ill defined behavior in programs for buffer overflows and other nasties. When you read the exacerbated cries of the security researchers who have been sitting on a critical IE/Firefox/Whatever bug they almost always scream something to the effect of \"Why didn't they just use a fuzzer, it's easy to find these problems that way -- that's how I did it.\" I would like to give props to Google, their security teams have been diligent in running <em>static</em> <em>analysis</em> and fuzzing <em>tools</em> against their code (white box[1][2]/black box testing[3])<p>As always, Wikipedia is a great source for information on this one[4] and I can personally testify to OWASP's fuzzer if you're going after webpages (my last local OWASP that I went to was on fuzzing and was REALLY interesting)<p>[1] <a href=\"http://en.wikipedia.org/wiki/White-box_testing\" rel=\"nofollow\">http://en.wikipedia.org/wiki/White-box_testing</a><p>[2] <a href=\"http://en.wikipedia.org/wiki/Static_code_analysis\" rel=\"nofollow\">http://en.wikipedia.org/wiki/<em>Static</em>_code_<em>analysis</em></a><p>[3] <a href=\"http://en.wikipedia.org/wiki/Black-box_testing\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Black-box_testing</a><p>[4] <a href=\"http://en.wikipedia.org/wiki/Fuzz_testing\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Fuzz_testing</a><p>EDIT: Fixing formatting",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Hardening LLVM With Random Testing [PDF Slides]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.llvm.org/devmtg/2010-11/Yang-HardenLLVM.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-04-17T20:13:50.000Z",
      "title": null,
      "url": null,
      "author": "gnosis",
      "points": 14,
      "story_text": null,
      "comment_text": "Believe it or not, I do.<p>I really enjoy using various tools like static analysis programs and memory checkers to ferret out the offending bits of code, figuring out why they're broken, and fixing them.<p>It gives me a certain sense of satisfaction to finally conquer a bug.  Particularly when it's a really tricky bug I've been bashing my head against for days.<p>Then again, when I've been after a given bug for days it can get really frustrating, and I don't enjoy the frustration.<p>And it's not like my dream job is doing nothing but fixing bugs.  I also enjoy architecting new systems, learning new concepts, and applying them during the quest to complete a project.<p>I suppose a healthy mix of tasks, from architecture, to writing new code, to fixing bugs is ideal.<p>But what I really hate is writing documentation.  I know it's necessary.  And my (non-throwaway) code has quite a lot of comments in it because I know it's necessary and good practice.  But it can get quite tedious.<p>I'd much rather bugfix than write documentation.",
      "num_comments": null,
      "story_id": 2456379,
      "story_title": "Some Developers Just Can't Develop",
      "story_url": "http://www.richard-banks.org/2009/08/some-developers-just-cant-develop.html",
      "parent_id": 2456869,
      "created_at_i": 1303071230,
      "_tags": [
        "comment",
        "author_gnosis",
        "story_2456379"
      ],
      "objectID": "2456889",
      "_highlightResult": {
        "author": {
          "value": "gnosis",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Believe it or not, I do.<p>I really enjoy using various <em>tools</em> like <em>static</em> <em>analysis</em> programs and memory checkers to ferret out the offending bits of code, figuring out why they're broken, and fixing them.<p>It gives me a certain sense of satisfaction to finally conquer a bug.  Particularly when it's a really tricky bug I've been bashing my head against for days.<p>Then again, when I've been after a given bug for days it can get really frustrating, and I don't enjoy the frustration.<p>And it's not like my dream job is doing nothing but fixing bugs.  I also enjoy architecting new systems, learning new concepts, and applying them during the quest to complete a project.<p>I suppose a healthy mix of tasks, from architecture, to writing new code, to fixing bugs is ideal.<p>But what I really hate is writing documentation.  I know it's necessary.  And my (non-throwaway) code has quite a lot of comments in it because I know it's necessary and good practice.  But it can get quite tedious.<p>I'd much rather bugfix than write documentation.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Some Developers Just Can't Develop",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.richard-banks.org/2009/08/some-developers-just-cant-develop.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-11T08:06:20.000Z",
      "title": null,
      "url": null,
      "author": "fit2rule",
      "points": 11,
      "story_text": null,
      "comment_text": "Code coverage and static analysis are such valuable tools, I can&#x27;t believe they are not used more and more frequently .. it really seems that a lot of open source projects would benefit from a coverage&#x2F;analysis phase on checkin.",
      "num_comments": null,
      "story_id": 8162259,
      "story_title": "Can We Trust the Libraries We Use?",
      "story_url": "http://www.viva64.com/en/b/0271/",
      "parent_id": 8162259,
      "created_at_i": 1407744380,
      "_tags": [
        "comment",
        "author_fit2rule",
        "story_8162259"
      ],
      "objectID": "8162389",
      "_highlightResult": {
        "author": {
          "value": "fit2rule",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Code coverage and <em>static</em> <em>analysis</em> are such valuable <em>tools</em>, I can't believe they are not used more and more frequently .. it really seems that a lot of open source projects would benefit from a coverage/<em>analysis</em> phase on checkin.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Can We Trust the Libraries We Use?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0271/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-26T20:18:24.000Z",
      "title": "",
      "url": "",
      "author": "bad_user",
      "points": 11,
      "story_text": null,
      "comment_text": "If you&#x27;ll go read his opinions, you&#x27;ll see that he has been a strong advocate for static analysis. His position is very understandable since he spent a lot of time working on complex pieces of C&#x2F;C++ code, encountering a lot of subtle accidental errors that could have been avoided with better tools for static analysis or with a better language. He also worked mostly on client side software, where the fail fast &#x2F; fail hard strategy of projects built in dynamic languages doesn&#x27;t work so well.<p>Lisp vs ML vs others is a very subjective issue since languages involve different kinds of trade-offs, so optimal choices depend on the project or on personal style.<p>Also, this is John Carmack. For me he was a God 10 years ago and he&#x27;s still one of the best and most practical developers we have today. Seeing him talk about Haskell is amazing.<p>BTW, I&#x27;ve been a big fan of Scala lately, and I don&#x27;t see myself using much Haskell precisely because its tools for modularity seem limited. In Scala you can use OOP to build abstract modules, with the much hyped Cake pattern being based on that. Dynamic languages are naturally more modular, however I still prefer static languages.",
      "num_comments": null,
      "story_id": 6278047,
      "story_title": "John Carmack: Thoughts on Haskell [video]",
      "story_url": "http://functionaltalks.org/2013/08/26/john-carmack-thoughts-on-haskell/",
      "parent_id": 6279215,
      "created_at_i": 1377548304,
      "_tags": [
        "comment",
        "author_bad_user",
        "story_6278047"
      ],
      "objectID": "6279610",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "bad_user",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "If you'll go read his opinions, you'll see that he has been a strong advocate for <em>static</em> <em>analysis.</em> His position is very understandable since he spent a lot of time working on complex pieces of C/C++ code, encountering a lot of subtle accidental errors that could have been avoided with better <em>tools</em> for <em>static</em> <em>analysis</em> or with a better language. He also worked mostly on client side software, where the fail fast / fail hard strategy of projects built in dynamic languages doesn't work so well.<p>Lisp vs ML vs others is a very subjective issue since languages involve different kinds of trade-offs, so optimal choices depend on the project or on personal style.<p>Also, this is John Carmack. For me he was a God 10 years ago and he's still one of the best and most practical developers we have today. Seeing him talk about Haskell is amazing.<p>BTW, I've been a big fan of Scala lately, and I don't see myself using much Haskell precisely because its <em>tools</em> for modularity seem limited. In Scala you can use OOP to build abstract modules, with the much hyped Cake pattern being based on that. Dynamic languages are naturally more modular, however I still prefer <em>static</em> languages.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack: Thoughts on Haskell [video]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://functionaltalks.org/2013/08/26/john-carmack-thoughts-on-haskell/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-23T17:03:58.000Z",
      "title": null,
      "url": null,
      "author": "aaronblohowiak",
      "points": 4,
      "story_text": null,
      "comment_text": "Which warts?<p>For this discussion, let&#x27;s ignore the current state of Rust&#x27;s maturity and ecosystem on faith that they will at least rival Go&#x27;s.<p>They are both compelling offerings that can (in capable hands) deliver performance that you cannot get out of a Ruby&#x2F;Python&#x2F;JS for CPU-bound tasks. They also both offer strategies for parallelism and concurrency that embrace modern hardware. Neither offers a Erlang&#x2F;OTP-level distributed fault-tolerance. They both have closures and the ability to decouple interface from implementation. They both offer signed&#x2F;unsigned ints&#x2F;floats of multiple sizes. They both have fixed and variable sized vector implementations.<p>I suggest that you pick the language that matches your philosophy.<p>Go is simple on purpose, and comes with a robust and opinionated standard library. Rust is sophisticated and has many options for developers.<p>Go is very much like a garbage-collected memory-safe C with type inference, lightweight threads and a thread-safe message queue datatype built in. Rust is more like if someone took modern C++, baked support for advanced pointer types into the syntax of the language, and made the compiler aware of their implications.<p>Go leaves thread safety to the user and does not have a robust notion of const or immutability. Conceptually, everything in Go is garbage collected (the compiler is smart about stack vs heap allocation through static escape analysis and there are tools that help you to identify when things actually get heap allocated if you need to avoid that for performance reasons.) Rust has a type system where immutability is a first-class concept and has rules about how a parent object&#x27;s im&#x2F;mutability transfers to its sub-objects. In rust, there are a few different choices for lifecycle management including linear typing (unique pointers,) reference counted and garbage collected. In rust, refcounted and gc&#x27;d variables may not be shared across threads.  <a href=\"http://cosmic.mearie.org/2014/01/periodic-table-of-rust-types/\" rel=\"nofollow\">http:&#x2F;&#x2F;cosmic.mearie.org&#x2F;2014&#x2F;01&#x2F;periodic-table-of-rust-type...</a><p>Go does not have a destructor, per se (there is a thing you can do that can run when something is gc&#x27;d, but you shouldn&#x27;t do this in most cases). Rust has destructors. Neither have constructors.<p>Go has &quot;duck typing&quot; interfaces -- if an object implements all the methods in an interface, then it <i>implicitly</i> implements that interface. Rust has generics and parameterized types. Implementing interfaces in Rust is explicit.<p>This is an abbreviated and hopefully mostly-accurate overview of the differences in the languages that reflect the differences in the language philosophies. Go is simple, Rust is sophisticated. If you think having type-parameterized interfaces is an important thing for a language to have, you&#x27;ll probably prefer Rust. If you think generics are more trouble than they are worth as long as you have interfaces, you&#x27;ll probably prefer Go.<p>I presently write production systems in Go and Ruby, and will probably look more into rust when they stop making breaking changes to the language.",
      "num_comments": null,
      "story_id": 7632969,
      "story_title": "Introducing Teepee: the next step for rust-http",
      "story_url": "http://chrismorgan.info/blog/introducing-teepee.html",
      "parent_id": 7634876,
      "created_at_i": 1398272638,
      "_tags": [
        "comment",
        "author_aaronblohowiak",
        "story_7632969"
      ],
      "objectID": "7635299",
      "_highlightResult": {
        "author": {
          "value": "aaronblohowiak",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Which warts?<p>For this discussion, let's ignore the current state of Rust's maturity and ecosystem on faith that they will at least rival Go's.<p>They are both compelling offerings that can (in capable hands) deliver performance that you cannot get out of a Ruby/Python/JS for CPU-bound tasks. They also both offer strategies for parallelism and concurrency that embrace modern hardware. Neither offers a Erlang/OTP-level distributed fault-tolerance. They both have closures and the ability to decouple interface from implementation. They both offer signed/unsigned ints/floats of multiple sizes. They both have fixed and variable sized vector implementations.<p>I suggest that you pick the language that matches your philosophy.<p>Go is simple on purpose, and comes with a robust and opinionated standard library. Rust is sophisticated and has many options for developers.<p>Go is very much like a garbage-collected memory-safe C with type inference, lightweight threads and a thread-safe message queue datatype built in. Rust is more like if someone took modern C++, baked support for advanced pointer types into the syntax of the language, and made the compiler aware of their implications.<p>Go leaves thread safety to the user and does not have a robust notion of const or immutability. Conceptually, everything in Go is garbage collected (the compiler is smart about stack vs heap allocation through <em>static</em> escape <em>analysis</em> and there are <em>tools</em> that help you to identify when things actually get heap allocated if you need to avoid that for performance reasons.) Rust has a type system where immutability is a first-class concept and has rules about how a parent object's im/mutability transfers to its sub-objects. In rust, there are a few different choices for lifecycle management including linear typing (unique pointers,) reference counted and garbage collected. In rust, refcounted and gc'd variables may not be shared across threads.  <a href=\"http://cosmic.mearie.org/2014/01/periodic-table-of-rust-types/\" rel=\"nofollow\">http://cosmic.mearie.org/2014/01/periodic-table-of-rust-type...</a><p>Go does not have a destructor, per se (there is a thing you can do that can run when something is gc'd, but you shouldn't do this in most cases). Rust has destructors. Neither have constructors.<p>Go has &quot;duck typing&quot; interfaces -- if an object implements all the methods in an interface, then it <i>implicitly</i> implements that interface. Rust has generics and parameterized types. Implementing interfaces in Rust is explicit.<p>This is an abbreviated and hopefully mostly-accurate overview of the differences in the languages that reflect the differences in the language philosophies. Go is simple, Rust is sophisticated. If you think having type-parameterized interfaces is an important thing for a language to have, you'll probably prefer Rust. If you think generics are more trouble than they are worth as long as you have interfaces, you'll probably prefer Go.<p>I presently write production systems in Go and Ruby, and will probably look more into rust when they stop making breaking changes to the language.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Introducing Teepee: the next step for rust-http",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://chrismorgan.info/blog/introducing-teepee.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-11-29T22:29:08.000Z",
      "title": null,
      "url": null,
      "author": "ghostdiver",
      "points": 4,
      "story_text": null,
      "comment_text": "Fun stuff, but again, doesn&#x27;t come with any tools. Microsoft Typescript is much better on that matter.<p>What javascript universe needs right now is not some more of syntactic sugar clusterfuck followed by debugging nightmare, but real tools, static code analysis. I don&#x27;t want to waste my precious time dealing with closure compiler+scala something combo. \\nIt&#x27;s fun from programmers POV, but still it won&#x27;t make me pay my bills!<p>reality check, please",
      "num_comments": null,
      "story_id": 6821145,
      "story_title": "Announcing Scala.js v0.1",
      "story_url": "http://www.scala-lang.org/news/2013/11/29/announcing-scala-js-v0.1.html",
      "parent_id": 6821145,
      "created_at_i": 1385764148,
      "_tags": [
        "comment",
        "author_ghostdiver",
        "story_6821145"
      ],
      "objectID": "6821289",
      "_highlightResult": {
        "author": {
          "value": "ghostdiver",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Fun stuff, but again, doesn't come with any <em>tools</em>. Microsoft Typescript is much better on that matter.<p>What javascript universe needs right now is not some more of syntactic sugar clusterfuck followed by debugging nightmare, but real <em>tools</em>, <em>static</em> code <em>analysis.</em> I don't want to waste my precious time dealing with closure compiler+scala something combo. \\nIt's fun from programmers POV, but still it won't make me pay my bills!<p>reality check, please",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Announcing Scala.js v0.1",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.scala-lang.org/news/2013/11/29/announcing-scala-js-v0.1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-19T03:49:32.000Z",
      "title": "",
      "url": "",
      "author": "edwinnathaniel",
      "points": 4,
      "story_text": null,
      "comment_text": "Not only excellent library support, but also a large array of productivity tools ranging from superb IDE, static code analysis, build+dependency tools, great Continuous Integration, etc.",
      "num_comments": null,
      "story_id": 3721989,
      "story_title": "Go is amazing, period.",
      "story_url": "http://poincare101.blogspot.com/2012/03/experiences-in-go-ing.html",
      "parent_id": 3722108,
      "created_at_i": 1332128972,
      "_tags": [
        "comment",
        "author_edwinnathaniel",
        "story_3721989"
      ],
      "objectID": "3722184",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "edwinnathaniel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Not only excellent library support, but also a large array of productivity <em>tools</em> ranging from superb IDE, <em>static</em> code <em>analysis</em>, build+dependency <em>tools</em>, great Continuous Integration, etc.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Go is amazing, period.",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://poincare101.blogspot.com/2012/03/experiences-in-go-ing.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-08T15:44:56.000Z",
      "title": "",
      "url": "",
      "author": "hershel",
      "points": 3,
      "story_text": null,
      "comment_text": "Safety verification tools - like static analysis&#x2F;timing analysis - is different from full formal verification. Those tool run on their own and don&#x27;t need complex definition of what to verify , and they verify just small amount of bugs.",
      "num_comments": null,
      "story_id": 6348532,
      "story_title": "Quark: A secure Web Browser with a Formally Verified Kernel",
      "story_url": "http://goto.ucsd.edu/quark/",
      "parent_id": 6349048,
      "created_at_i": 1378655096,
      "_tags": [
        "comment",
        "author_hershel",
        "story_6348532"
      ],
      "objectID": "6349074",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "hershel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Safety verification <em>tools</em> - like <em>static</em> <em>analysis</em>/timing <em>analysis</em> - is different from full formal verification. Those tool run on their own and don't need complex definition of what to verify , and they verify just small amount of bugs.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Quark: A secure Web Browser with a Formally Verified Kernel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://goto.ucsd.edu/quark/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-11-29T18:59:58.000Z",
      "title": "",
      "url": "",
      "author": "Someone",
      "points": 3,
      "story_text": null,
      "comment_text": "Do you think better languages will make static analysis useless? I would think the combination to be better than better languages alone. Or are you arguing that static analysis by compilers should be improved (1) so far that separate tools for static analysis aren't useful anymore?<p>(1) almost all compiled language systems do _some_ static analysis. For example, many compilers and linkers do dead code elimination, and Java and C# must, by spec, do static analyisis to prove that variables won't be used before set.",
      "num_comments": null,
      "story_id": 4848456,
      "story_title": "Eric Lippert is leaving Microsoft",
      "story_url": "http://ericlippert.com/",
      "parent_id": 4849358,
      "created_at_i": 1354215598,
      "_tags": [
        "comment",
        "author_Someone",
        "story_4848456"
      ],
      "objectID": "4849597",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Someone",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Do you think better languages will make <em>static</em> <em>analysis</em> useless? I would think the combination to be better than better languages alone. Or are you arguing that <em>static</em> <em>analysis</em> by compilers should be improved (1) so far that separate <em>tools</em> for <em>static</em> <em>analysis</em> aren't useful anymore?<p>(1) almost all compiled language systems do _some_ <em>static</em> <em>analysis.</em> For example, many compilers and linkers do dead code elimination, and Java and C# must, by spec, do <em>static</em> analyisis to prove that variables won't be used before set.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Eric Lippert is leaving Microsoft",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ericlippert.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-05-17T23:10:52.000Z",
      "title": null,
      "url": null,
      "author": "platz",
      "points": 2,
      "story_text": null,
      "comment_text": "To me it seems the only way to smarter tools is static analysis, but there&#x27;s only so much one can do in a dynamic language.<p>There seems to be this dissonance between dynamic languages, which tend to be popular with new programmers for a variety of reasons, and better tools enabled by static analysis of (usually) static langues.<p>The static languages seem to present this &quot;hump&quot; that a lot of people are averse to, and if we really want these smarter tools, we&#x27;re going to have to find a way to get programmers to use more static techniques; we need to get them over that &quot;hump&quot;, possibly then these smarter tools would ease things in the long run, but doesn&#x27;t have quite the same immediate-gratification aspect of dynamic languages due to the up-front effort.",
      "num_comments": null,
      "story_id": 7760790,
      "story_title": "Pain we forgot",
      "story_url": "http://www.lighttable.com/2014/05/16/pain-we-forgot/",
      "parent_id": 7761046,
      "created_at_i": 1400368252,
      "_tags": [
        "comment",
        "author_platz",
        "story_7760790"
      ],
      "objectID": "7761436",
      "_highlightResult": {
        "author": {
          "value": "platz",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "To me it seems the only way to smarter <em>tools</em> is <em>static</em> <em>analysis</em>, but there's only so much one can do in a dynamic language.<p>There seems to be this dissonance between dynamic languages, which tend to be popular with new programmers for a variety of reasons, and better <em>tools</em> enabled by <em>static</em> <em>analysis</em> of (usually) <em>static</em> langues.<p>The <em>static</em> languages seem to present this &quot;hump&quot; that a lot of people are averse to, and if we really want these smarter <em>tools</em>, we're going to have to find a way to get programmers to use more <em>static</em> techniques; we need to get them over that &quot;hump&quot;, possibly then these smarter <em>tools</em> would ease things in the long run, but doesn't have quite the same immediate-gratification aspect of dynamic languages due to the up-front effort.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Pain we forgot",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.lighttable.com/2014/05/16/pain-we-forgot/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-12-17T11:31:32.000Z",
      "title": "",
      "url": "",
      "author": "AndreyKarpov",
      "points": 2,
      "story_text": null,
      "comment_text": "A good reason to use the right tools of static analysis, rather than look manually. ;)",
      "num_comments": null,
      "story_id": 4931740,
      "story_title": "On checking OpenSSL",
      "story_url": "http://www.viva64.com/en/b/0183/",
      "parent_id": 4931809,
      "created_at_i": 1355743892,
      "_tags": [
        "comment",
        "author_AndreyKarpov",
        "story_4931740"
      ],
      "objectID": "4931869",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "AndreyKarpov",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "A good reason to use the right <em>tools</em> of <em>static</em> <em>analysis</em>, rather than look manually. ;)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "On checking OpenSSL",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0183/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-29T17:57:29.000Z",
      "title": null,
      "url": null,
      "author": "Sajmani",
      "points": 1,
      "story_text": null,
      "comment_text": "Yes, we are working on static analysis and automated refactoring tools.  We will make them available publicly when they are ready, but that won&#x27;t be very soon.  We wanted to publicize Context now to encourage people to start using it and incorporating it into new code and frameworks.",
      "num_comments": null,
      "story_id": 8103128,
      "story_title": "Go Concurrency Patterns: Context",
      "story_url": "http://blog.golang.org/context",
      "parent_id": 8103464,
      "created_at_i": 1406656649,
      "_tags": [
        "comment",
        "author_Sajmani",
        "story_8103128"
      ],
      "objectID": "8103711",
      "_highlightResult": {
        "author": {
          "value": "Sajmani",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Yes, we are working on <em>static</em> <em>analysis</em> and automated refactoring <em>tools</em>.  We will make them available publicly when they are ready, but that won't be very soon.  We wanted to publicize Context now to encourage people to start using it and incorporating it into new code and frameworks.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Go Concurrency Patterns: Context",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.golang.org/context",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-21T19:02:36.000Z",
      "title": null,
      "url": null,
      "author": "Jtsummers",
      "points": 1,
      "story_text": null,
      "comment_text": "Re 3: A nit, it&#x27;s not weakly typed, it&#x27;s dynamically typed. The type of a variable X may be an integer or a list. But you can&#x27;t ask for the head of an integer or multiply a list by 3. That said, I half-agree with you. I find static typing or tools which can perform static analysis to be a great benefit in working with larger projects or other coding with other people. Tools for static analysis exist for erlang and come with the standard install, dialyzer.",
      "num_comments": null,
      "story_id": 7277797,
      "story_title": "Ask HN: Why isn't Erlang more popular?",
      "story_url": "",
      "parent_id": 7278135,
      "created_at_i": 1393009356,
      "_tags": [
        "comment",
        "author_Jtsummers",
        "story_7277797"
      ],
      "objectID": "7278700",
      "_highlightResult": {
        "author": {
          "value": "Jtsummers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Re 3: A nit, it's not weakly typed, it's dynamically typed. The type of a variable X may be an integer or a list. But you can't ask for the head of an integer or multiply a list by 3. That said, I half-agree with you. I find <em>static</em> typing or <em>tools</em> which can perform <em>static</em> <em>analysis</em> to be a great benefit in working with larger projects or other coding with other people. <em>Tools</em> for <em>static</em> <em>analysis</em> exist for erlang and come with the standard install, dialyzer.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Why isn't Erlang more popular?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-07-18T20:33:45.000Z",
      "title": "",
      "url": "",
      "author": "woobles",
      "points": 1,
      "story_text": null,
      "comment_text": "I'm going to assume you mean \"What tools can a web entrepreneur use to check if his site can be hacked by script-kiddies\".\nThere are a multitude of static analysis and penetration testing tools out there, free and licensed. Fortify (Static analysis), HP Web Inspect and IBM AppScan (penetration testing) are just a couple easy(ish) to use tools. On the free side of things, BackTrack comes with a plethora of security tools one can use to assess your site.",
      "num_comments": null,
      "story_id": 4260602,
      "story_title": "Web App Security Best Practices",
      "story_url": "http://coffeeonthekeyboard.com/best-basic-security-practices-especially-with-django-697/",
      "parent_id": 4262714,
      "created_at_i": 1342643625,
      "_tags": [
        "comment",
        "author_woobles",
        "story_4260602"
      ],
      "objectID": "4262795",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "woobles",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm going to assume you mean \"What <em>tools</em> can a web entrepreneur use to check if his site can be hacked by script-kiddies\".\nThere are a multitude of <em>static</em> <em>analysis</em> and penetration testing <em>tools</em> out there, free and licensed. Fortify (<em>Static</em> <em>analysis</em>), HP Web Inspect and IBM AppScan (penetration testing) are just a couple easy(ish) to use <em>tools</em>. On the free side of things, BackTrack comes with a plethora of security <em>tools</em> one can use to assess your site.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Web App Security Best Practices",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://coffeeonthekeyboard.com/best-basic-security-practices-especially-with-django-697/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-07-11T23:40:11.000Z",
      "title": "",
      "url": "",
      "author": "kitsaws",
      "points": 1,
      "story_text": null,
      "comment_text": "+1 for this comment\nFor all static (heck, even runtime) analysis tools, I would rather have more rules than less - and disable the ones I don't like/want/agree with. I wrote the code, I set the standard for rules, it's that simple.",
      "num_comments": null,
      "story_id": 2750100,
      "story_title": "CSS Lint is harmful",
      "story_url": "http://mattwilcox.net/archive/entry/id/1054/",
      "parent_id": 2751861,
      "created_at_i": 1310427611,
      "_tags": [
        "comment",
        "author_kitsaws",
        "story_2750100"
      ],
      "objectID": "2752939",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "kitsaws",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "+1 for this comment\nFor all <em>static</em> (heck, even runtime) <em>analysis</em> <em>tools</em>, I would rather have more rules than less - and disable the ones I don't like/want/agree with. I wrote the code, I set the standard for rules, it's that simple.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "CSS Lint is harmful",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://mattwilcox.net/archive/entry/id/1054/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-13T23:39:42.000Z",
      "title": null,
      "url": null,
      "author": "MetaCosm",
      "points": null,
      "story_text": null,
      "comment_text": "I have been slowly (last 4 or so years) moving away from microservices towards the &quot;cookie cutter&quot; (<a href=\"http:&#x2F;&#x2F;paulhammant.com&#x2F;2011&#x2F;11&#x2F;29&#x2F;cookie-cutter-scaling&#x2F;\" rel=\"nofollow\">http:&#x2F;&#x2F;paulhammant.com&#x2F;2011&#x2F;11&#x2F;29&#x2F;cookie-cutter-scaling&#x2F;</a>) model (we didn&#x27;t use that term of art) and been very delighted with the change.  I had completely drank the koolaid on microservices, but after having to maintain them in production for a few years, changed my tune.<p>In my experience that &quot;iterate and change the system easily and quickly&quot; simply doesn&#x27;t end up being true.  That is the bait, but then comes the switch.  Once you have a real system, heavily interdependent, the cost of changing things starts to go up greatly, and your ability to cleanly describe a working system becomes challenging.  Answering simple management questions like &quot;OK, so if we change X, what could break?&quot;... &quot;We should send out an email to all the teams to ask!&quot; (ugh)<p>The problem is that for most significant changes to a component -- there are changes to the interface to that component. So you have &#x27;the choice&#x27; -- (1) Maintain this interface forever or (2) Ensure all the teams transition off it by X date, via a deprecation system.  Both work, and most companies seem to use a mix of both, they strive for (1) until it gets insane, then they do (2) and force everyone to upgrade to X version by Y date.. rinse and repeat.<p>We are currently doing the &quot;fat binary&quot; cookie cutter system.  Our deploy is a single binary that does &quot;all the things&quot;.  There is a lot to like about this system.  Easy to manage and role back.  Compile time checking, including additional tools for static analysis, etc.  No network overhead on making local calls.  You know and can clearly describe &#x27;the system&#x27;, it isn&#x27;t in some continuous flux state.  Due to compiling time checking and static analysis you can maintain &#x27;one truth&#x27; and when you upgrade a component, you can go into all the callers and update them, so you don&#x27;t have to maintain that old interface.  You can scale decently vertically not just horizontally, which at times is a far more efficient way to scale.  Overall, it has made us able to move much faster because it gives us a lot of confidence in what we are shipping, and a sense of safety in that we can quickly go back to what we had.",
      "num_comments": null,
      "story_id": 9538945,
      "story_title": "MicroservicePremium",
      "story_url": "http://martinfowler.com/bliki/MicroservicePremium.html",
      "parent_id": 9540197,
      "created_at_i": 1431560382,
      "_tags": [
        "comment",
        "author_MetaCosm",
        "story_9538945"
      ],
      "objectID": "9542696",
      "_highlightResult": {
        "author": {
          "value": "MetaCosm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I have been slowly (last 4 or so years) moving away from microservices towards the &quot;cookie cutter&quot; (<a href=\"http://paulhammant.com/2011/11/29/cookie-cutter-scaling/\" rel=\"nofollow\">http://paulhammant.com/2011/11/29/cookie-cutter-scaling/</a>) model (we didn't use that term of art) and been very delighted with the change.  I had completely drank the koolaid on microservices, but after having to maintain them in production for a few years, changed my tune.<p>In my experience that &quot;iterate and change the system easily and quickly&quot; simply doesn't end up being true.  That is the bait, but then comes the switch.  Once you have a real system, heavily interdependent, the cost of changing things starts to go up greatly, and your ability to cleanly describe a working system becomes challenging.  Answering simple management questions like &quot;OK, so if we change X, what could break?&quot;... &quot;We should send out an email to all the teams to ask!&quot; (ugh)<p>The problem is that for most significant changes to a component -- there are changes to the interface to that component. So you have 'the choice' -- (1) Maintain this interface forever or (2) Ensure all the teams transition off it by X date, via a deprecation system.  Both work, and most companies seem to use a mix of both, they strive for (1) until it gets insane, then they do (2) and force everyone to upgrade to X version by Y date.. rinse and repeat.<p>We are currently doing the &quot;fat binary&quot; cookie cutter system.  Our deploy is a single binary that does &quot;all the things&quot;.  There is a lot to like about this system.  Easy to manage and role back.  Compile time checking, including additional <em>tools</em> for <em>static</em> <em>analysis</em>, etc.  No network overhead on making local calls.  You know and can clearly describe 'the system', it isn't in some continuous flux state.  Due to compiling time checking and <em>static</em> <em>analysis</em> you can maintain 'one truth' and when you upgrade a component, you can go into all the callers and update them, so you don't have to maintain that old interface.  You can scale decently vertically not just horizontally, which at times is a far more efficient way to scale.  Overall, it has made us able to move much faster because it gives us a lot of confidence in what we are shipping, and a sense of safety in that we can quickly go back to what we had.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "MicroservicePremium",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://martinfowler.com/bliki/MicroservicePremium.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-18T22:12:33.000Z",
      "title": null,
      "url": null,
      "author": "cwills",
      "points": null,
      "story_text": null,
      "comment_text": "Is there any reason we cannot use both TypeScript and Flow.<p>Besides perhaps the extra &#x27;compile&#x27; time added to do both translation with TypeScript and then static analysis with Flow. Both tools have their advantages and disadvantages.<p>May as well throw in a linting tool as well..",
      "num_comments": null,
      "story_id": 8625222,
      "story_title": "Facebook Launches Flow, Static Type Checker for JavaScript",
      "story_url": "https://code.prod.facebook.com/posts/1505962329687926/flow-a-new-static-type-checker-for-javascript/",
      "parent_id": 8625469,
      "created_at_i": 1416348753,
      "_tags": [
        "comment",
        "author_cwills",
        "story_8625222"
      ],
      "objectID": "8626717",
      "_highlightResult": {
        "author": {
          "value": "cwills",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Is there any reason we cannot use both TypeScript and Flow.<p>Besides perhaps the extra 'compile' time added to do both translation with TypeScript and then <em>static</em> <em>analysis</em> with Flow. Both <em>tools</em> have their advantages and disadvantages.<p>May as well throw in a linting tool as well..",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Facebook Launches Flow, <em>Static</em> Type Checker for JavaScript",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "https://code.prod.facebook.com/posts/1505962329687926/flow-a-new-<em>static</em>-type-checker-for-javascript/",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        }
      }
    },
    {
      "created_at": "2014-11-18T19:37:15.000Z",
      "title": null,
      "url": null,
      "author": "inglor",
      "points": null,
      "story_text": null,
      "comment_text": "Well, here are some things that it does that other tools don&#x27;t:<p>- It type checks JSX\n - It supports some ES6 features others don&#x27;t (like destructuring) as the build step\n - It has union types (TS will get those soon, already in master)\n - It does a lot more inference and a lot more assumptions. It assumes you won&#x27;t multiply a string by a number for example (although technically &#x27;10&#x27; * 5 is legal in JS). So it&#x27;s opinionated in that it enforces checks that rule out code that is legal but not likely intended in JS (an opinin I agree with).<p>Yes - it is possible to write tests and get good coverage and not use those tools - however static analysis can be very valuable in finding errors early. While I&#x27;m not sure I&#x27;d bother with explicit typing in this in smaller projects from the examples and unit tests it looks like it could find errors people would not easily notice otherwise. (Think JSHint, on steroids).<p>That said, only time will tell how good the implementation will really get in understanding your code.",
      "num_comments": null,
      "story_id": 8625222,
      "story_title": "Facebook Launches Flow, Static Type Checker for JavaScript",
      "story_url": "https://code.prod.facebook.com/posts/1505962329687926/flow-a-new-static-type-checker-for-javascript/",
      "parent_id": 8625783,
      "created_at_i": 1416339435,
      "_tags": [
        "comment",
        "author_inglor",
        "story_8625222"
      ],
      "objectID": "8625836",
      "_highlightResult": {
        "author": {
          "value": "inglor",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Well, here are some things that it does that other <em>tools</em> don't:<p>- It type checks JSX\n - It supports some ES6 features others don't (like destructuring) as the build step\n - It has union types (TS will get those soon, already in master)\n - It does a lot more inference and a lot more assumptions. It assumes you won't multiply a string by a number for example (although technically '10' * 5 is legal in JS). So it's opinionated in that it enforces checks that rule out code that is legal but not likely intended in JS (an opinin I agree with).<p>Yes - it is possible to write tests and get good coverage and not use those <em>tools</em> - however <em>static</em> <em>analysis</em> can be very valuable in finding errors early. While I'm not sure I'd bother with explicit typing in this in smaller projects from the examples and unit tests it looks like it could find errors people would not easily notice otherwise. (Think JSHint, on steroids).<p>That said, only time will tell how good the implementation will really get in understanding your code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Facebook Launches Flow, <em>Static</em> Type Checker for JavaScript",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "https://code.prod.facebook.com/posts/1505962329687926/flow-a-new-<em>static</em>-type-checker-for-javascript/",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        }
      }
    },
    {
      "created_at": "2014-10-18T20:03:41.000Z",
      "title": null,
      "url": null,
      "author": "MaxGabriel",
      "points": null,
      "story_text": null,
      "comment_text": "I don&#x27;t think the author&#x27;s tool is in opposition to IDE&#x2F;plugin based static analysis. For one thing, tools like python-mode for vim (<a href=\"https://github.com/klen/python-mode\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;klen&#x2F;python-mode</a>) call out to libraries like pylint to implement their functionality. Prospector also supports machine readable outputs that IDEs&#x2F;plugins can use to determine how to display linting issues.<p>Even if you prefer not to use a command-line based linter, a non-GUI option is essential if you want to do linting with CI. If you run an open source Python project, you can&#x27;t assume that everyone will use a linter to check for warnings before submitting a PR (and even then, can&#x27;t assume their linter settings match yours)—but you can check easily lint all PRs using Travis CI or the author&#x27;s company Landscape.",
      "num_comments": null,
      "story_id": 8475991,
      "story_title": "Prospector: Python Static Analysis for Humans",
      "story_url": "http://blog.landscape.io/prospector-python-static-analysis-for-humans.html",
      "parent_id": 8476094,
      "created_at_i": 1413662621,
      "_tags": [
        "comment",
        "author_MaxGabriel",
        "story_8475991"
      ],
      "objectID": "8476140",
      "_highlightResult": {
        "author": {
          "value": "MaxGabriel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't think the author's tool is in opposition to IDE/plugin based <em>static</em> <em>analysis.</em> For one thing, <em>tools</em> like python-mode for vim (<a href=\"https://github.com/klen/python-mode\" rel=\"nofollow\">https://github.com/klen/python-mode</a>) call out to libraries like pylint to implement their functionality. Prospector also supports machine readable outputs that IDEs/plugins can use to determine how to display linting issues.<p>Even if you prefer not to use a command-line based linter, a non-GUI option is essential if you want to do linting with CI. If you run an open source Python project, you can't assume that everyone will use a linter to check for warnings before submitting a PR (and even then, can't assume their linter settings match yours)—but you can check easily lint all PRs using Travis CI or the author's company Landscape.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Prospector: Python <em>Static</em> <em>Analysis</em> for Humans",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://blog.landscape.io/prospector-python-<em>static</em>-<em>analysis</em>-for-humans.html",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2010-06-25T12:08:21.000Z",
      "title": null,
      "url": null,
      "author": "travem",
      "points": null,
      "story_text": null,
      "comment_text": "Do we really want to heed advice when it's comes with obviously wrong advice like \"Only people can detect and solve software bugs, not tools.\"<p>Static bug analysis is definitely not the be all and end all of software quality but definitely has a place. We automatically run FindBugs (along with unit test etc) on our code base every time new code is pushed by a developer and it definitely helps pick up quirky little errors much more cheaply than code reviews.",
      "num_comments": null,
      "story_id": 1460135,
      "story_title": "Semicolons in JavaScript are optional",
      "story_url": "http://mislav.uniqpath.com/2010/05/semicolons/",
      "parent_id": 1460135,
      "created_at_i": 1277467701,
      "_tags": [
        "comment",
        "author_travem",
        "story_1460135"
      ],
      "objectID": "1460517",
      "_highlightResult": {
        "author": {
          "value": "travem",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Do we really want to heed advice when it's comes with obviously wrong advice like \"Only people can detect and solve software bugs, not <em>tools</em>.\"<p><em>Static</em> bug <em>analysis</em> is definitely not the be all and end all of software quality but definitely has a place. We automatically run FindBugs (along with unit test etc) on our code base every time new code is pushed by a developer and it definitely helps pick up quirky little errors much more cheaply than code reviews.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Semicolons in JavaScript are optional",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://mislav.uniqpath.com/2010/05/semicolons/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-10-02T15:19:59.000Z",
      "title": "",
      "url": "",
      "author": "oinksoft",
      "points": 20,
      "story_text": null,
      "comment_text": "Types <i>are not</i> classes! Why do people feel the need to constantly drag out this scarecrow? Having tools to perform static analysis is nothing but a good thing, and you need type data to do a great deal of this. Perhaps your project requirements are such that you never require type checking for your JS, but I can say that it's saved my ass a number of times when working on very large code-bases, and definitely has sped up my development cycle when working on hairy code.<p>This is a type, not a class, taken from a Closure Compiler docs annotation example:<p><pre><code>  /**\n   * Enum for tri-state values.\n   * @enum {number}\n   */\n  project.TriState = {\n    TRUE: 1,\n    FALSE: -1,\n    MAYBE: 0\n  };\n</code></pre>\nNow I can require this type in my code with standard JSDoc, which is what the compiler uses anyway for type-checking. It makes my code self-documenting (the Closure Linter, should you use it, will complain if you omit descriptions and the like too, if you find yourself getting lazy):<p><pre><code>  /**\n   * Do something...\n   * \n   * @param state {project.TriState} The state ...\n   */\n  function doSomething(state) {\n</code></pre>\nIf you are documenting your code, you already do this. And now you have static analysis out-of-the-box ... not bad!",
      "num_comments": null,
      "story_id": 4601654,
      "story_title": "Why does TypeScript have be the answer to anything?",
      "story_url": "http://www.hanselman.com/blog/WhyDoesTypeScriptHaveBeTheAnswerToAnything.aspx",
      "parent_id": 4602321,
      "created_at_i": 1349191199,
      "_tags": [
        "comment",
        "author_oinksoft",
        "story_4601654"
      ],
      "objectID": "4602414",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "oinksoft",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Types <i>are not</i> classes! Why do people feel the need to constantly drag out this scarecrow? Having <em>tools</em> to perform <em>static</em> <em>analysis</em> is nothing but a good thing, and you need type data to do a great deal of this. Perhaps your project requirements are such that you never require type checking for your JS, but I can say that it's saved my ass a number of times when working on very large code-bases, and definitely has sped up my development cycle when working on hairy code.<p>This is a type, not a class, taken from a Closure Compiler docs annotation example:<p><pre><code>  /**\n   * Enum for tri-state values.\n   * @enum {number}\n   */\n  project.TriState = {\n    TRUE: 1,\n    FALSE: -1,\n    MAYBE: 0\n  };\n</code></pre>\nNow I can require this type in my code with standard JSDoc, which is what the compiler uses anyway for type-checking. It makes my code self-documenting (the Closure Linter, should you use it, will complain if you omit descriptions and the like too, if you find yourself getting lazy):<p><pre><code>  /**\n   * Do something...\n   * \n   * @param state {project.TriState} The state ...\n   */\n  function doSomething(state) {\n</code></pre>\nIf you are documenting your code, you already do this. And now you have <em>static</em> <em>analysis</em> out-of-the-box ... not bad!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why does TypeScript have be the answer to anything?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.hanselman.com/blog/WhyDoesTypeScriptHaveBeTheAnswerToAnything.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-02T14:36:29.000Z",
      "title": null,
      "url": null,
      "author": "jerven",
      "points": 5,
      "story_text": null,
      "comment_text": "Don&#x27;t try to figure out how the code does what does yet. \\nFigure out what systems exists inside it:<p><pre><code>  1.  What kind of modules?\\n  2.  Which servers&#x2F;hardware?\\n  3.  Which databases&#x2F;datastores?\\n  4.  What systems talk to what?\\n  5.  What test systems exist or existed?\\n  6.  Which api&#x2F;frameworks where used?\\n  7.  Who is currently working on them&#x2F;maintaining it?\\n  8.  Is anyone left who used to?\\n  9.  Why is a rewrite on the table?\\n  10. Is there any way you can work on smaller pieces at a time?\\n  11. What are the pain points of the current users (will tell you what area to focus on)?\\n  12. Can you document what comes in and out?\\n</code></pre>\\nIn my experience with such large code bases, there is never one way to do things. i.e. I once worked on a smaller system with 4 ways to talk to the same database. On one with 100 million lines I would expect even more ways to rome ;)<p>If you do want to go down the static analysis path, start with existing tools before trying to build your own. If needed get external help for this.<p>A 100 Million lines of code is not so bizarre. The project I work on is currently about 300,000 lines and a project some 300 times larger is quite imaginable for me.",
      "num_comments": null,
      "story_id": 8257327,
      "story_title": "Ask HN: I have to analyze 100M lines of Java – where do I start?",
      "story_url": "",
      "parent_id": 8257527,
      "created_at_i": 1409668589,
      "_tags": [
        "comment",
        "author_jerven",
        "story_8257327"
      ],
      "objectID": "8257802",
      "_highlightResult": {
        "author": {
          "value": "jerven",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Don't try to figure out how the code does what does yet. \\nFigure out what systems exists inside it:<p><pre><code>  1.  What kind of modules?\\n  2.  Which servers/hardware?\\n  3.  Which databases/datastores?\\n  4.  What systems talk to what?\\n  5.  What test systems exist or existed?\\n  6.  Which api/frameworks where used?\\n  7.  Who is currently working on them/maintaining it?\\n  8.  Is anyone left who used to?\\n  9.  Why is a rewrite on the table?\\n  10. Is there any way you can work on smaller pieces at a time?\\n  11. What are the pain points of the current users (will tell you what area to focus on)?\\n  12. Can you document what comes in and out?\\n</code></pre>\\nIn my experience with such large code bases, there is never one way to do things. i.e. I once worked on a smaller system with 4 ways to talk to the same database. On one with 100 million lines I would expect even more ways to rome ;)<p>If you do want to go down the <em>static</em> <em>analysis</em> path, start with existing <em>tools</em> before trying to build your own. If needed get external help for this.<p>A 100 Million lines of code is not so bizarre. The project I work on is currently about 300,000 lines and a project some 300 times larger is quite imaginable for me.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: I have to analyze 100M lines of Java – where do I start?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-10-23T13:51:44.000Z",
      "title": "",
      "url": "",
      "author": "benihana",
      "points": 5,
      "story_text": null,
      "comment_text": "Code reviews are about psychology. When you know your teammates are going to be reviewing your code, you write it differently than you do when you know no one but you will ever look at it.<p>Static analysis and regression tests are tools to make sure the code isn&#x27;t broken.",
      "num_comments": null,
      "story_id": 6598509,
      "story_title": "We dont have time for code reviews",
      "story_url": "http://blog.8thcolor.com/2013/10/we-dont-have-time-for-code-reviews/",
      "parent_id": 6598658,
      "created_at_i": 1382536304,
      "_tags": [
        "comment",
        "author_benihana",
        "story_6598509"
      ],
      "objectID": "6598688",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "benihana",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Code reviews are about psychology. When you know your teammates are going to be reviewing your code, you write it differently than you do when you know no one but you will ever look at it.<p><em>Static</em> <em>analysis</em> and regression tests are <em>tools</em> to make sure the code isn't broken.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "We dont have time for code reviews",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.8thcolor.com/2013/10/we-dont-have-time-for-code-reviews/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-29T01:37:15.000Z",
      "title": "",
      "url": "",
      "author": "encoderer",
      "points": 4,
      "story_text": null,
      "comment_text": "This is a complicated problem, and one that I'm excited to think could be improved in the coming years as Github et al have the time and resources to invest in it.<p>I have a few thoughts on the topic and on your comments:<p>1. I actually DO think that the quality of pull requests varies widely from project to project. You dismiss this in your first sentence but I don't think you should. I think there are a lot of reasons for this, but many can be reduced to: Some projects attract more inexperienced developers than others.<p>2. I don't think you can simply indict the project maintainers for not optimally leveraging the talent pool of volunteer contributors. While Open Source has been validated a million times over as a truly successful movement/concept/etc, nobody has ever accused it of being efficient. Specifically, most pull request submitters act on their own, without coordination between submitters or with project maintainers. It's not just an issue of coding standards, it's also things like the maintainers having a roadmap that includes bug fixes, refactoring, new features, etc, and that may conflict with Joe in Idaho and his pull request that he did to scratch his own specific itch.<p>In many ways community submitted pull requests are a \"million monkeys at a million typewriters.\"<p>3. The most successful way of getting a pull request accepted, I think, is to first raise a discussion on the issue on the projects mailing list or issues forum. Link to your in-progress patch, say \"I have this fix here for problem X, can anybody take a look and tell me if I'm on the wrong track with this?\" So many of us are code-first, conversation-later types and that  constantly conflicts with the social nature of our job.<p>I guess my takeaway here is that there is a lot of room for interesting technology solutions to this problem, in the areas of:<p>1. Tools that help maintainers cultivate the submitters talent pool on their project.<p>2. Tools and workflows that help submitters through coordination. Totally a half baked idea but suppose if I'm fixing a bug in a function somewhere, Github can help me discover what is happening to that function elsewhere. Maybe it's been radically changed in a feature branch owned by the project maintainers, maybe it's already been fixed nearly the same way by another submitter who has an open pull request, maybe it was already submitted by somebody and rejected.<p>3. Static analysis that can power those tools and more. Would love a meaningful quantative quality score on the pull request submission page. Like an additional tab beside the \"Commits\" and \"Diff\" tabs. Maybe it could run various analysis on the code and show formatting issues, known vulnerabilities, known bugs, etc. Obviously the abilities here vary from language to language.",
      "num_comments": null,
      "story_id": 5783616,
      "story_title": "Probability of acceptance of pull requests",
      "story_url": "http://paulmillr.com/posts/github-pull-request-stats/",
      "parent_id": 5783922,
      "created_at_i": 1369791435,
      "_tags": [
        "comment",
        "author_encoderer",
        "story_5783616"
      ],
      "objectID": "5784078",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "encoderer",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is a complicated problem, and one that I'm excited to think could be improved in the coming years as Github et al have the time and resources to invest in it.<p>I have a few thoughts on the topic and on your comments:<p>1. I actually DO think that the quality of pull requests varies widely from project to project. You dismiss this in your first sentence but I don't think you should. I think there are a lot of reasons for this, but many can be reduced to: Some projects attract more inexperienced developers than others.<p>2. I don't think you can simply indict the project maintainers for not optimally leveraging the talent pool of volunteer contributors. While Open Source has been validated a million times over as a truly successful movement/concept/etc, nobody has ever accused it of being efficient. Specifically, most pull request submitters act on their own, without coordination between submitters or with project maintainers. It's not just an issue of coding standards, it's also things like the maintainers having a roadmap that includes bug fixes, refactoring, new features, etc, and that may conflict with Joe in Idaho and his pull request that he did to scratch his own specific itch.<p>In many ways community submitted pull requests are a \"million monkeys at a million typewriters.\"<p>3. The most successful way of getting a pull request accepted, I think, is to first raise a discussion on the issue on the projects mailing list or issues forum. Link to your in-progress patch, say \"I have this fix here for problem X, can anybody take a look and tell me if I'm on the wrong track with this?\" So many of us are code-first, conversation-later types and that  constantly conflicts with the social nature of our job.<p>I guess my takeaway here is that there is a lot of room for interesting technology solutions to this problem, in the areas of:<p>1. <em>Tools</em> that help maintainers cultivate the submitters talent pool on their project.<p>2. <em>Tools</em> and workflows that help submitters through coordination. Totally a half baked idea but suppose if I'm fixing a bug in a function somewhere, Github can help me discover what is happening to that function elsewhere. Maybe it's been radically changed in a feature branch owned by the project maintainers, maybe it's already been fixed nearly the same way by another submitter who has an open pull request, maybe it was already submitted by somebody and rejected.<p>3. <em>Static</em> <em>analysis</em> that can power those <em>tools</em> and more. Would love a meaningful quantative quality score on the pull request submission page. Like an additional tab beside the \"Commits\" and \"Diff\" tabs. Maybe it could run various <em>analysis</em> on the code and show formatting issues, known vulnerabilities, known bugs, etc. Obviously the abilities here vary from language to language.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Probability of acceptance of pull requests",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://paulmillr.com/posts/github-pull-request-stats/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-03T15:34:39.000Z",
      "title": "",
      "url": "",
      "author": "tree_of_item",
      "points": 4,
      "story_text": null,
      "comment_text": "That's if you prefer tools like Visual Studio to tools like Squeak.<p>That is, if you prefer your tools to perform static analysis as opposed to allowing you to inspect and modify your system while it's running.",
      "num_comments": null,
      "story_id": 3923974,
      "story_title": "The Essence of Dynamic Typing",
      "story_url": "http://daniel.yokomizo.org/2012/05/essence-of-dynamic-typing.html",
      "parent_id": 3924167,
      "created_at_i": 1336059279,
      "_tags": [
        "comment",
        "author_tree_of_item",
        "story_3923974"
      ],
      "objectID": "3924259",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "tree_of_item",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's if you prefer <em>tools</em> like Visual Studio to <em>tools</em> like Squeak.<p>That is, if you prefer your <em>tools</em> to perform <em>static</em> <em>analysis</em> as opposed to allowing you to inspect and modify your system while it's running.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Essence of Dynamic Typing",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://daniel.yokomizo.org/2012/05/essence-of-dynamic-typing.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-28T14:09:05.000Z",
      "title": null,
      "url": null,
      "author": "forgottenpass",
      "points": 2,
      "story_text": null,
      "comment_text": "<i>then created some search thing that found similar programmin style in other tools - especially if they also found interesting bugs.</i><p>It&#x27;s called static analysis and (judging by the tools we use) probably already ship with rules that would bark loudly at this code.",
      "num_comments": null,
      "story_id": 8379310,
      "story_title": "The shockingly obsolete code of bash",
      "story_url": "http://blog.erratasec.com/2014/09/the-shockingly-bad-code-of-bash.html",
      "parent_id": 8379646,
      "created_at_i": 1411913345,
      "_tags": [
        "comment",
        "author_forgottenpass",
        "story_8379310"
      ],
      "objectID": "8379751",
      "_highlightResult": {
        "author": {
          "value": "forgottenpass",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>then created some search thing that found similar programmin style in other <em>tools</em> - especially if they also found interesting bugs.</i><p>It's called <em>static</em> <em>analysis</em> and (judging by the <em>tools</em> we use) probably already ship with rules that would bark loudly at this code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The shockingly obsolete code of bash",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.erratasec.com/2014/09/the-shockingly-bad-code-of-bash.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-11-17T15:37:01.000Z",
      "title": "",
      "url": "",
      "author": "Too",
      "points": 2,
      "story_text": null,
      "comment_text": "C is deceivingly simple, I wonder how many people know about strict aliasing rules for example. To verify a C-program you should really 1. Do static analysis, preferable using many different tools, 2. Test on different optimization levels, 3. Test on different compilers.",
      "num_comments": null,
      "story_id": 6748514,
      "story_title": "Towards Optimization-Safe Systems: Analyzing the Impact of Undefined Behavior",
      "story_url": "http://pdos.csail.mit.edu/~xi/papers/stack-sosp13.pdf",
      "parent_id": 6748514,
      "created_at_i": 1384702621,
      "_tags": [
        "comment",
        "author_Too",
        "story_6748514"
      ],
      "objectID": "6749312",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Too",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "C is deceivingly simple, I wonder how many people know about strict aliasing rules for example. To verify a C-program you should really 1. Do <em>static</em> <em>analysis</em>, preferable using many different <em>tools</em>, 2. Test on different optimization levels, 3. Test on different compilers.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Towards Optimization-Safe Systems: Analyzing the Impact of Undefined Behavior",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pdos.csail.mit.edu/~xi/papers/stack-sosp13.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-19T18:26:37.000Z",
      "title": "",
      "url": "",
      "author": "DanBC",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt; wouldn&#x27;t have any semi-capable static analysis tool caught this?<p>Using tools to find &quot;errors&quot; can be problematic.  see, for example, the Debian random number bug.  (<a href=\"https://www.schneier.com/blog/archives/2008/05/random_number_b.html\" rel=\"nofollow\">https:&#x2F;&#x2F;www.schneier.com&#x2F;blog&#x2F;archives&#x2F;2008&#x2F;05&#x2F;random_number...</a>)<p>&gt; <i>These lines were removed because they caused the Valgrind and Purify tools to produce warnings about the use of uninitialized data in any code that was linked to OpenSSL.</i>",
      "num_comments": null,
      "story_id": 6410779,
      "story_title": "Thwarted Linux backdoor hints at smarter hacks (2003)",
      "story_url": "http://www.securityfocus.com/news/7388",
      "parent_id": 6411030,
      "created_at_i": 1379615197,
      "_tags": [
        "comment",
        "author_DanBC",
        "story_6410779"
      ],
      "objectID": "6413319",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "DanBC",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; wouldn't have any semi-capable <em>static</em> <em>analysis</em> tool caught this?<p>Using <em>tools</em> to find &quot;errors&quot; can be problematic.  see, for example, the Debian random number bug.  (<a href=\"https://www.schneier.com/blog/archives/2008/05/random_number_b.html\" rel=\"nofollow\">https://www.schneier.com/blog/archives/2008/05/random_number...</a>)<p>&gt; <i>These lines were removed because they caused the Valgrind and Purify <em>tools</em> to produce warnings about the use of uninitialized data in any code that was linked to OpenSSL.</i>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Thwarted Linux backdoor hints at smarter hacks (2003)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.securityfocus.com/news/7388",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-10-28T13:20:47.000Z",
      "title": "",
      "url": "",
      "author": "67726e",
      "points": 1,
      "story_text": null,
      "comment_text": "As a part of the build system at my work, we run various passes over the code aside from just \"does this compile\". I'm sure these MOOCs could find software to:<p>1. Check style of a language<p>2. Run a comprehensive suite of unit tests<p>3. Static analysis of the code<p>These tools together can catch most problems of bad formatting, fragile code (cannot handle edge cases, errors, etc.), and structural errors. Additionally you could take into account some kind of performance of the code - does this solve this problem in a reasonable amount of time?<p>By using standard industry tools, one could do a good grading system that is entirely automated.",
      "num_comments": null,
      "story_id": 4708697,
      "story_title": "Automatic Grading of Code Submissions Isn't Perfect Either",
      "story_url": "http://gregorulm.com/automatic-grading-of-code-submissions-in-moocs-isnt-perfect-either/",
      "parent_id": 4708697,
      "created_at_i": 1351430447,
      "_tags": [
        "comment",
        "author_67726e",
        "story_4708697"
      ],
      "objectID": "4708859",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "67726e",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "As a part of the build system at my work, we run various passes over the code aside from just \"does this compile\". I'm sure these MOOCs could find software to:<p>1. Check style of a language<p>2. Run a comprehensive suite of unit tests<p>3. <em>Static</em> <em>analysis</em> of the code<p>These <em>tools</em> together can catch most problems of bad formatting, fragile code (cannot handle edge cases, errors, etc.), and structural errors. Additionally you could take into account some kind of performance of the code - does this solve this problem in a reasonable amount of time?<p>By using standard industry <em>tools</em>, one could do a good grading system that is entirely automated.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Automatic Grading of Code Submissions Isn't Perfect Either",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://gregorulm.com/automatic-grading-of-code-submissions-in-moocs-isnt-perfect-either/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-20T23:49:32.000Z",
      "title": null,
      "url": null,
      "author": "pbiggar",
      "points": null,
      "story_text": null,
      "comment_text": "Definitely don&#x27;t trying writing new types of compilers hoping that people will want them! You could conceivably get lucky, but you won&#x27;t.<p>You should be fine writing new frameworks (meteor), or working in closely related areas like static analysis (coverity, fortify), CI&#x2F;CD tools (CircleCI), or even things like DB optimizers. I just wouldn&#x27;t write a straightforward compiler.",
      "num_comments": null,
      "story_id": 9237137,
      "story_title": "HippyVM goes to Y Combinator and fails",
      "story_url": "http://lostinjit.blogspot.com/2015/03/hippyvm-goes-to-y-combinator-and-fails.html",
      "parent_id": 9241024,
      "created_at_i": 1426895372,
      "_tags": [
        "comment",
        "author_pbiggar",
        "story_9237137"
      ],
      "objectID": "9241342",
      "_highlightResult": {
        "author": {
          "value": "pbiggar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Definitely don't trying writing new types of compilers hoping that people will want them! You could conceivably get lucky, but you won't.<p>You should be fine writing new frameworks (meteor), or working in closely related areas like <em>static</em> <em>analysis</em> (coverity, fortify), CI/CD <em>tools</em> (CircleCI), or even things like DB optimizers. I just wouldn't write a straightforward compiler.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "HippyVM goes to Y Combinator and fails",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lostinjit.blogspot.com/2015/03/hippyvm-goes-to-y-combinator-and-fails.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-02-05T02:53:17.000Z",
      "title": null,
      "url": null,
      "author": "eneveu",
      "points": null,
      "story_text": null,
      "comment_text": "I did not know about KeYmeara. Looks great!<p>While I'm not sure if we may count those as \"programmation by contract\", some Java tools provide (some) static analysis:<p>- Findbugs<p>- IntelliJ IDEA does some nullness analysis : <a href=\"http://www.jetbrains.com/idea/documentation/howto.html\" rel=\"nofollow\">http://www.jetbrains.com/idea/documentation/howto.html</a><p>- JSR 305 (Annotations for Software Defect Detection in Java) attempted to standardize on a set of annotations. We use it in our project, mainly the @Nonnull at the moment... I believe Findbugs considers these annotations.<p>- CodePro Analytix, also recently open sourced by Google, might also do some static analysis: <a href=\"http://code.google.com/javadevtools/codepro/doc/index.html\" rel=\"nofollow\">http://code.google.com/javadevtools/codepro/doc/index.html</a><p>- Eclipse might too (any expert Eclipse user knows?)<p>I think there is still a lot to do in this space. \"Contracts for Java\" is a step in the right direction :)",
      "num_comments": null,
      "story_id": 2182127,
      "story_title": "Google open sources \"Contracts for Java\"",
      "story_url": "http://google-opensource.blogspot.com/2011/02/contracts-for-java.html",
      "parent_id": 2182258,
      "created_at_i": 1296874397,
      "_tags": [
        "comment",
        "author_eneveu",
        "story_2182127"
      ],
      "objectID": "2182291",
      "_highlightResult": {
        "author": {
          "value": "eneveu",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I did not know about KeYmeara. Looks great!<p>While I'm not sure if we may count those as \"programmation by contract\", some Java <em>tools</em> provide (some) <em>static</em> <em>analysis</em>:<p>- Findbugs<p>- IntelliJ IDEA does some nullness <em>analysis</em> : <a href=\"http://www.jetbrains.com/idea/documentation/howto.html\" rel=\"nofollow\">http://www.jetbrains.com/idea/documentation/howto.html</a><p>- JSR 305 (Annotations for Software Defect Detection in Java) attempted to standardize on a set of annotations. We use it in our project, mainly the @Nonnull at the moment... I believe Findbugs considers these annotations.<p>- CodePro Analytix, also recently open sourced by Google, might also do some <em>static</em> <em>analysis</em>: <a href=\"http://code.google.com/javadevtools/codepro/doc/index.html\" rel=\"nofollow\">http://code.google.com/javadevtools/codepro/doc/index.html</a><p>- Eclipse might too (any expert Eclipse user knows?)<p>I think there is still a lot to do in this space. \"Contracts for Java\" is a step in the right direction :)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Google open sources \"Contracts for Java\"",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://google-opensource.blogspot.com/2011/02/contracts-for-java.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-07-29T05:13:18.000Z",
      "title": "",
      "url": "",
      "author": "dherman",
      "points": 4,
      "story_text": null,
      "comment_text": "It's not so much a reduced subset as a kernel language: the full ECMAScript Edition 5 language can be translated down to the kernel language, so in principle they can actually model the behavior of any program that the language defined by the standard admits.<p>There have been a few attempts to formalize the semantics of JS, but the lambdaJS approach is the most practical: by factoring out the incidental details (the \"syntactic sugar\") as a translation (\"desugaring\") to a kernel language, any work you do on the formal semantics of the language only has to focus on the smaller kernel.<p>This is also a really practical way to approach building tools for JS, like static analysis: if you design a single desugaring pass as a translation, then you can build a whole bunch of tools on the kernel language. Same idea roughly as the standard compilers approach of translating to an IR.",
      "num_comments": null,
      "story_id": 4307070,
      "story_title": "Mechanized LambdaJS",
      "story_url": "http://brownplt.github.com/2012/06/04/lambdajs-coq.html#posts-content",
      "parent_id": 4307588,
      "created_at_i": 1343538798,
      "_tags": [
        "comment",
        "author_dherman",
        "story_4307070"
      ],
      "objectID": "4307627",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dherman",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's not so much a reduced subset as a kernel language: the full ECMAScript Edition 5 language can be translated down to the kernel language, so in principle they can actually model the behavior of any program that the language defined by the standard admits.<p>There have been a few attempts to formalize the semantics of JS, but the lambdaJS approach is the most practical: by factoring out the incidental details (the \"syntactic sugar\") as a translation (\"desugaring\") to a kernel language, any work you do on the formal semantics of the language only has to focus on the smaller kernel.<p>This is also a really practical way to approach building <em>tools</em> for JS, like <em>static</em> <em>analysis</em>: if you design a single desugaring pass as a translation, then you can build a whole bunch of <em>tools</em> on the kernel language. Same idea roughly as the standard compilers approach of translating to an IR.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mechanized LambdaJS",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://brownplt.github.com/2012/06/04/lambdajs-coq.html#posts-content",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-10-09T09:17:10.000Z",
      "title": "",
      "url": "",
      "author": "gizzlon",
      "points": 3,
      "story_text": null,
      "comment_text": "<p><pre><code>    I Advanced UNIX Programming with Linux\n    \n    1 Getting Started\n    2 Writing Good GNU/Linux Software\n    3 Processes\n    4 Threads\n    5 Interprocess Communication\n    \n    \n    II Mastering Linux\n    \n    6 Devices\n    7 The /proc File System\n    8 Linux System Calls\n    9 Inline Assembly Code\n    10 Security\n    11 A Sample GNU/Linux\n    \n    \n    III Appendixes\n    \n    A Other Development Tools\n        A.1 Static Program Analysis 259\n        A.2 Finding Dynamic Memory Errors 261\n        A.3 Profiling 269\n    \n    B Low-Level I/O\n        Reading and Writing Data 282\n        stat 291\n        Vector Reads and Writes 293\n        Relation to Standard C Library I/O\n        Functions 295\n        B.5 Other File Operations 296\n        B.6 Reading Directory Contents 296\n    \n    C Table of Signals</code></pre>",
      "num_comments": null,
      "story_id": 4629161,
      "story_title": "Advanced Linux Programming",
      "story_url": "http://www.advancedlinuxprogramming.com/alp-folder/",
      "parent_id": 4629161,
      "created_at_i": 1349774230,
      "_tags": [
        "comment",
        "author_gizzlon",
        "story_4629161"
      ],
      "objectID": "4630647",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "gizzlon",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<p><pre><code>    I Advanced UNIX Programming with Linux\n    \n    1 Getting Started\n    2 Writing Good GNU/Linux Software\n    3 Processes\n    4 Threads\n    5 Interprocess Communication\n    \n    \n    II Mastering Linux\n    \n    6 Devices\n    7 The /proc File System\n    8 Linux System Calls\n    9 Inline Assembly Code\n    10 Security\n    11 A Sample GNU/Linux\n    \n    \n    III Appendixes\n    \n    A Other Development <em>Tools</em>\n        A.1 <em>Static</em> Program <em>Analysis</em> 259\n        A.2 Finding Dynamic Memory Errors 261\n        A.3 Profiling 269\n    \n    B Low-Level I/O\n        Reading and Writing Data 282\n        stat 291\n        Vector Reads and Writes 293\n        Relation to Standard C Library I/O\n        Functions 295\n        B.5 Other File Operations 296\n        B.6 Reading Directory Contents 296\n    \n    C Table of Signals</code></pre>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Advanced Linux Programming",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.advancedlinuxprogramming.com/alp-folder/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-12T19:19:17.000Z",
      "title": null,
      "url": null,
      "author": "pkroll",
      "points": 2,
      "story_text": null,
      "comment_text": "In what way is asking someone, somewhere, to move a project to another, unnamed language, going to be more effective than actually starting a project and putting code into it? Sure, &quot;go do it yourself&quot; is not a pleasant response, but &quot;go take the tens of thousands of lines of code that mostly works, and spend person-years rewriting it in another language so that a certain set of bugs aren&#x27;t an issue anymore, instead of fixing the mostly working code&quot; is in no way a reasonable request. &quot;What can be done to help reduce the bug count, by a casual user?&quot; might be. Contacting Coverity or another static analysis company that occasionally runs their tools on open source programs to help the world (and get the free press out of it...), might result in a huge list of subtle (and hideously obvious) bugs getting squashed.",
      "num_comments": null,
      "story_id": 7038033,
      "story_title": "FFmpeg and a thousand fixes",
      "story_url": "http://googleonlinesecurity.blogspot.com/2014/01/ffmpeg-and-thousand-fixes.html",
      "parent_id": 7041040,
      "created_at_i": 1389554357,
      "_tags": [
        "comment",
        "author_pkroll",
        "story_7038033"
      ],
      "objectID": "7047055",
      "_highlightResult": {
        "author": {
          "value": "pkroll",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In what way is asking someone, somewhere, to move a project to another, unnamed language, going to be more effective than actually starting a project and putting code into it? Sure, &quot;go do it yourself&quot; is not a pleasant response, but &quot;go take the tens of thousands of lines of code that mostly works, and spend person-years rewriting it in another language so that a certain set of bugs aren't an issue anymore, instead of fixing the mostly working code&quot; is in no way a reasonable request. &quot;What can be done to help reduce the bug count, by a casual user?&quot; might be. Contacting Coverity or another <em>static</em> <em>analysis</em> company that occasionally runs their <em>tools</em> on open source programs to help the world (and get the free press out of it...), might result in a huge list of subtle (and hideously obvious) bugs getting squashed.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "FFmpeg and a thousand fixes",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://googleonlinesecurity.blogspot.com/2014/01/ffmpeg-and-thousand-fixes.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-16T18:44:58.000Z",
      "title": null,
      "url": null,
      "author": "tlarkworthy",
      "points": 1,
      "story_text": null,
      "comment_text": "I am doing serious transpiler stuff at the moment and I think its easier to do in JS than any other language.<p>It look me about 2 hours to design and write this little utility for finding and removing redundant braces in expressions using node-falafel:- \\n<a href=\"http://edinburghhacklab.com/2014/02/remove-redundant-brackets-from-expressions-with-falafel/\" rel=\"nofollow\">http:&#x2F;&#x2F;edinburghhacklab.com&#x2F;2014&#x2F;02&#x2F;remove-redundant-bracket...</a><p>The larger problem I am doing is static code analysis for Firebase and the JS tools for doing such stuff are delightful compared to yacc and lex and javacc etc.<p>Functional programming really shines in this domain. You can populate your symbol table with functions that get &quot;called&quot; when &quot;CallExpressions&quot; are encountered during parsing, or functions that expand to function declarations on &quot;MemberExpression&quot; are encounter during parsing (the &lt;dot&gt; operator). Its very easy to mirror the true structure of JS using JS if that makes sense.",
      "num_comments": null,
      "story_id": 7248362,
      "story_title": "Building JavaScript Tools You Didn't Think Were Possible",
      "story_url": "http://gregfranko.com/building-javascript-tools-talk/",
      "parent_id": 7248362,
      "created_at_i": 1392576298,
      "_tags": [
        "comment",
        "author_tlarkworthy",
        "story_7248362"
      ],
      "objectID": "7248653",
      "_highlightResult": {
        "author": {
          "value": "tlarkworthy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I am doing serious transpiler stuff at the moment and I think its easier to do in JS than any other language.<p>It look me about 2 hours to design and write this little utility for finding and removing redundant braces in expressions using node-falafel:- \\n<a href=\"http://edinburghhacklab.com/2014/02/remove-redundant-brackets-from-expressions-with-falafel/\" rel=\"nofollow\">http://edinburghhacklab.com/2014/02/remove-redundant-bracket...</a><p>The larger problem I am doing is <em>static</em> code <em>analysis</em> for Firebase and the JS <em>tools</em> for doing such stuff are delightful compared to yacc and lex and javacc etc.<p>Functional programming really shines in this domain. You can populate your symbol table with functions that get &quot;called&quot; when &quot;CallExpressions&quot; are encountered during parsing, or functions that expand to function declarations on &quot;MemberExpression&quot; are encounter during parsing (the &lt;dot&gt; operator). Its very easy to mirror the true structure of JS using JS if that makes sense.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Building JavaScript <em>Tools</em> You Didn't Think Were Possible",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "http://gregfranko.com/building-javascript-<em>tools</em>-talk/",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        }
      }
    },
    {
      "created_at": "2012-02-24T19:53:29.000Z",
      "title": "",
      "url": "",
      "author": "tobiasSoftware",
      "points": -1,
      "story_text": null,
      "comment_text": "Mine are:\n1. Python - mixed with C extensions used in a functional way\n2. Java   - when I need better compile time tools and analysis such as static typing\n3. AutoIt - Windows scripting<p>I have also dabbled in C++, C#, Ruby, and Perl, you need to experiment occasionally",
      "num_comments": null,
      "story_id": 3628942,
      "story_title": "Your favourite programming language is not good enough",
      "story_url": "http://blaag.haard.se/Your-favourite-programming-language-is-not-good-enough/",
      "parent_id": 3628997,
      "created_at_i": 1330113209,
      "_tags": [
        "comment",
        "author_tobiasSoftware",
        "story_3628942"
      ],
      "objectID": "3630707",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "tobiasSoftware",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Mine are:\n1. Python - mixed with C extensions used in a functional way\n2. Java   - when I need better compile time <em>tools</em> and <em>analysis</em> such as <em>static</em> typing\n3. AutoIt - Windows scripting<p>I have also dabbled in C++, C#, Ruby, and Perl, you need to experiment occasionally",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Your favourite programming language is not good enough",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blaag.haard.se/Your-favourite-programming-language-is-not-good-enough/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-07T18:09:22.000Z",
      "title": null,
      "url": null,
      "author": "ZeroGravitas",
      "points": null,
      "story_text": null,
      "comment_text": "I&#x27;ve always thought PSNR gets a bad rap. It&#x27;s not that PSNR isn&#x27;t a very blunt tool, it&#x27;s just that every other tool in it&#x27;s class is pretty blunt too.<p>I mean it compares a video codec by treating it as a series of independent still images. That right there is crazy, but the same basic methodology applies to most of the alternatives, even the crazy obscure ones that no-one really uses because they&#x27;re too new or processor intensive.<p>The Mozilla&#x2F;Daala team have written a lot about these topics in regards to their work on a) Daala, b) netvc (new IETF codec project just getting started), c) evaluating improvements to JPEG for MozJPEG, d) evaluating WebP<p><a href=\"https:&#x2F;&#x2F;tools.ietf.org&#x2F;html&#x2F;draft-daede-netvc-testing-00#section-3\" rel=\"nofollow\">https:&#x2F;&#x2F;tools.ietf.org&#x2F;html&#x2F;draft-daede-netvc-testing-00#sec...</a><p><a href=\"https:&#x2F;&#x2F;arewecompressedyet.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;arewecompressedyet.com&#x2F;</a><p><a href=\"http:&#x2F;&#x2F;people.mozilla.org&#x2F;~josh&#x2F;lossy_compressed_image_study_october_2013&#x2F;\" rel=\"nofollow\">http:&#x2F;&#x2F;people.mozilla.org&#x2F;~josh&#x2F;lossy_compressed_image_study...</a><p>In the end, like unit tests, performance benchmarks, static analysis or various other software development tools, they&#x27;re useful if you use them wisely and know their limitations, and dangerous if you abuse them or treat them as if they are magical.<p>But crappy tools that can be easily automated fill an important part of the toolbox and I feel PSNR has it&#x27;s place. I&#x27;m deeply suspicious of anyone who looks down their nose at PSNR because they&#x27;ve just discovered SSIM for example, which seems to be a common sentiment. They&#x27;re both just crappy tools that can be used for good or ill if you know what you&#x27;re doing, running them both (and others too) might help catch more bugs than either alone and if you&#x27;re automating then why the heck not?",
      "num_comments": null,
      "story_id": 9328921,
      "story_title": "VP9: Faster, better, buffer-free YouTube videos",
      "story_url": "http://youtube-eng.blogspot.com/2015/04/vp9-faster-better-buffer-free-youtube.html",
      "parent_id": 9335492,
      "created_at_i": 1428430162,
      "_tags": [
        "comment",
        "author_ZeroGravitas",
        "story_9328921"
      ],
      "objectID": "9335888",
      "_highlightResult": {
        "author": {
          "value": "ZeroGravitas",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I've always thought PSNR gets a bad rap. It's not that PSNR isn't a very blunt tool, it's just that every other tool in it's class is pretty blunt too.<p>I mean it compares a video codec by treating it as a series of independent still images. That right there is crazy, but the same basic methodology applies to most of the alternatives, even the crazy obscure ones that no-one really uses because they're too new or processor intensive.<p>The Mozilla/Daala team have written a lot about these topics in regards to their work on a) Daala, b) netvc (new IETF codec project just getting started), c) evaluating improvements to JPEG for MozJPEG, d) evaluating WebP<p><a href=\"https://tools.ietf.org/html/draft-daede-netvc-testing-00#section-3\" rel=\"nofollow\">https://<em>tools</em>.ietf.org/html/draft-daede-netvc-testing-00#sec...</a><p><a href=\"https://arewecompressedyet.com/\" rel=\"nofollow\">https://arewecompressedyet.com/</a><p><a href=\"http://people.mozilla.org/~josh/lossy_compressed_image_study_october_2013/\" rel=\"nofollow\">http://people.mozilla.org/~josh/lossy_compressed_image_study...</a><p>In the end, like unit tests, performance benchmarks, <em>static</em> <em>analysis</em> or various other software development <em>tools</em>, they're useful if you use them wisely and know their limitations, and dangerous if you abuse them or treat them as if they are magical.<p>But crappy <em>tools</em> that can be easily automated fill an important part of the toolbox and I feel PSNR has it's place. I'm deeply suspicious of anyone who looks down their nose at PSNR because they've just discovered SSIM for example, which seems to be a common sentiment. They're both just crappy <em>tools</em> that can be used for good or ill if you know what you're doing, running them both (and others too) might help catch more bugs than either alone and if you're automating then why the heck not?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "VP9: Faster, better, buffer-free YouTube videos",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://youtube-eng.blogspot.com/2015/04/vp9-faster-better-buffer-free-youtube.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-06T18:07:29.000Z",
      "title": null,
      "url": null,
      "author": "hampsterx",
      "points": null,
      "story_text": null,
      "comment_text": "I presume you played with SonarQube? If not take a look, was very Java focused but is branching out, supports over 30 languages using an array of standard tools to do static code analysis.<p>Pretty much SonarQube is the only tool I have found and it&#x27;s somewhat annoying as a few plugins are commercial and very expensive. As you say, a plugin architecture would be great.<p>I personally feel that in a few years time Code Analysis&#x2F;Technical Debt tools will become standard as CI servers have.<p>And for the doubters, of course no tool is going to tell you very precisely the true Technical Debt of a project but knowing how the code base is changing over time in terms of code count&#x2F;complexity&#x2F;todo count, etc I think is something every development team (+ management) should be pay attention to.",
      "num_comments": null,
      "story_id": 8562196,
      "story_title": "Show HN: Debt Ceiling – Tech Debt Quantification/visibility/CI Tool",
      "story_url": "https://github.com/bglusman/debt_ceiling",
      "parent_id": 8562580,
      "created_at_i": 1415297249,
      "_tags": [
        "comment",
        "author_hampsterx",
        "story_8562196"
      ],
      "objectID": "8568574",
      "_highlightResult": {
        "author": {
          "value": "hampsterx",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I presume you played with SonarQube? If not take a look, was very Java focused but is branching out, supports over 30 languages using an array of standard <em>tools</em> to do <em>static</em> code <em>analysis.</em><p>Pretty much SonarQube is the only tool I have found and it's somewhat annoying as a few plugins are commercial and very expensive. As you say, a plugin architecture would be great.<p>I personally feel that in a few years time Code <em>Analysis</em>/Technical Debt <em>tools</em> will become standard as CI servers have.<p>And for the doubters, of course no tool is going to tell you very precisely the true Technical Debt of a project but knowing how the code base is changing over time in terms of code count/complexity/todo count, etc I think is something every development team (+ management) should be pay attention to.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Show HN: Debt Ceiling – Tech Debt Quantification/visibility/CI Tool",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/bglusman/debt_ceiling",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-10-19T22:21:44.000Z",
      "title": null,
      "url": null,
      "author": "vilya",
      "points": null,
      "story_text": null,
      "comment_text": "&#62; Given that IDEs are the primary tools of programmers, and unlike Photoshop users our primary skill is to build software itself, why are IDEs not the most advanced pieces of software that exist?<p>I guess it depends what you call advanced. There's some pretty impressive work that goes into the static and dynamic analysis, refactoring, profiling etc. tools that you see in modern IDEs. Is that more or less advanced than software that can identify faces in an image? Who's to say?<p>BTW I think you're being a bit unfair to Eclipse. I agree about its performance, but picking on the download size seems a bit disingenuous: looking at the download page right now the largest package is less than 250 Mb, no more than a few minutes even on a slow broadband connection. Both svn and cvs are well supported within the IDE too. I've just decided to switch away from Eclipse primarily because of its performance, but it deserves justified criticism at least. :-)",
      "num_comments": null,
      "story_id": 1806844,
      "story_title": "IDE WTF",
      "story_url": "http://lukepalmer.wordpress.com/2010/10/18/idewtf/",
      "parent_id": 1807691,
      "created_at_i": 1287526904,
      "_tags": [
        "comment",
        "author_vilya",
        "story_1806844"
      ],
      "objectID": "1809048",
      "_highlightResult": {
        "author": {
          "value": "vilya",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> Given that IDEs are the primary <em>tools</em> of programmers, and unlike Photoshop users our primary skill is to build software itself, why are IDEs not the most advanced pieces of software that exist?<p>I guess it depends what you call advanced. There's some pretty impressive work that goes into the <em>static</em> and dynamic <em>analysis</em>, refactoring, profiling etc. <em>tools</em> that you see in modern IDEs. Is that more or less advanced than software that can identify faces in an image? Who's to say?<p>BTW I think you're being a bit unfair to Eclipse. I agree about its performance, but picking on the download size seems a bit disingenuous: looking at the download page right now the largest package is less than 250 Mb, no more than a few minutes even on a slow broadband connection. Both svn and cvs are well supported within the IDE too. I've just decided to switch away from Eclipse primarily because of its performance, but it deserves justified criticism at least. :-)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "IDE WTF",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lukepalmer.wordpress.com/2010/10/18/idewtf/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-10-18T00:20:43.000Z",
      "title": "",
      "url": "",
      "author": "pnathan",
      "points": 27,
      "story_text": null,
      "comment_text": "I've been spending time learning Haskell lately, as part of an investigation into tools which are amenable to static analysis at work.<p>To learn about the situation, I've put together similar programs in Lisp, OCaml, and Haskell, as well as installed compilers for Haskell &#38; Ocaml on the PPC.<p>Well -<p>I've coded for over a decade, and I've never encountered such a difficult to use language and jargony community &#38; documentation (including AWK &#38; SED). The only reasons I have been able to do anything are Real World Haskell, Learn You A Haskell, and Stack Overflow.<p>I'm not going to say Haskell is useless, or has no libraries, etc.  Those aren't true. It's also not a bad language because it's weirder than my Blub (Common Lisp). It's a really sweet language, and I think in the hands of an expert, Haskell can <i>dance</i>.<p>But, I'm going to say Haskell is nearly impossible for an experienced procedural programmer to pick up and go with on the fly. There are a few reasons for my opinion:<p>* Special operators out the wazzoo. &#62;&#62;= ` ++ :: etc. The wrong 'dialect' of Haskell leads you to believe it's Perl and APL's love child. It's just not clear what something does until you find a reference book. Google doesn't help here - I don't even know the verbal names for some of them. :)<p>* Monads &#38; in particular, the IO Monad. The number of tutorials and explanations (and the number of new ones) suggest that this is not the most obvious concept in the land. It seems to be very simple if you know what you're doing (and what operators to use), though.<p>* The REPL is not identical to the compiler. This means that you can't <i>trust</i> the REPL. Coming from Python and Lisp, that is a pain.<p>* Type messages that are quite unclear, and probably require referring to the Haskell98 report to fully understand.<p><i>Regardless</i>, the above are surmountable problems and reasonable when moving to a new paradigm (very frustrating, though).<p>However, there are two key issues that are close to deal-breakers, with a third more minor one.<p>* Time to put a small program together. Easily 3x-10x my time working on Ocaml, a language which I am less experienced in (in both languages, I am amazingly inexperienced).<p>* Building the compiler on PPC (business reasons why I would need to do this).  Ocaml builds with the traditional ./configure &#38;&#38; make. Very straightforward. GHC requires a cross compile with some funky source tweaks, or <i>possibly</i> a binary package (but the bin package dependency tree required replacing libc++, at which point I stopped).  This is a dealbreaker unless I can straightforwardly guarantee my boss a good ROI with Haskell vs. (OCaml or other statically typed language).<p>* Human costs for my code. It's not professional to have a codebase only I can use in a team. Yes, the team could learn Haskell, but would it be a good ROI? If OCaml gets us there faster...<p>So Haskell is probably not going to work for me at work. :-(  We'll see though.",
      "num_comments": null,
      "story_id": 3122725,
      "story_title": "Why Not Haskell?",
      "story_url": "http://neugierig.org/software/blog/2011/10/why-not-haskell.html",
      "parent_id": 3122725,
      "created_at_i": 1318897243,
      "_tags": [
        "comment",
        "author_pnathan",
        "story_3122725"
      ],
      "objectID": "3123138",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pnathan",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I've been spending time learning Haskell lately, as part of an investigation into <em>tools</em> which are amenable to <em>static</em> <em>analysis</em> at work.<p>To learn about the situation, I've put together similar programs in Lisp, OCaml, and Haskell, as well as installed compilers for Haskell & Ocaml on the PPC.<p>Well -<p>I've coded for over a decade, and I've never encountered such a difficult to use language and jargony community & documentation (including AWK & SED). The only reasons I have been able to do anything are Real World Haskell, Learn You A Haskell, and Stack Overflow.<p>I'm not going to say Haskell is useless, or has no libraries, etc.  Those aren't true. It's also not a bad language because it's weirder than my Blub (Common Lisp). It's a really sweet language, and I think in the hands of an expert, Haskell can <i>dance</i>.<p>But, I'm going to say Haskell is nearly impossible for an experienced procedural programmer to pick up and go with on the fly. There are a few reasons for my opinion:<p>* Special operators out the wazzoo. >>= ` ++ :: etc. The wrong 'dialect' of Haskell leads you to believe it's Perl and APL's love child. It's just not clear what something does until you find a reference book. Google doesn't help here - I don't even know the verbal names for some of them. :)<p>* Monads & in particular, the IO Monad. The number of tutorials and explanations (and the number of new ones) suggest that this is not the most obvious concept in the land. It seems to be very simple if you know what you're doing (and what operators to use), though.<p>* The REPL is not identical to the compiler. This means that you can't <i>trust</i> the REPL. Coming from Python and Lisp, that is a pain.<p>* Type messages that are quite unclear, and probably require referring to the Haskell98 report to fully understand.<p><i>Regardless</i>, the above are surmountable problems and reasonable when moving to a new paradigm (very frustrating, though).<p>However, there are two key issues that are close to deal-breakers, with a third more minor one.<p>* Time to put a small program together. Easily 3x-10x my time working on Ocaml, a language which I am less experienced in (in both languages, I am amazingly inexperienced).<p>* Building the compiler on PPC (business reasons why I would need to do this).  Ocaml builds with the traditional ./configure && make. Very straightforward. GHC requires a cross compile with some funky source tweaks, or <i>possibly</i> a binary package (but the bin package dependency tree required replacing libc++, at which point I stopped).  This is a dealbreaker unless I can straightforwardly guarantee my boss a good ROI with Haskell vs. (OCaml or other statically typed language).<p>* Human costs for my code. It's not professional to have a codebase only I can use in a team. Yes, the team could learn Haskell, but would it be a good ROI? If OCaml gets us there faster...<p>So Haskell is probably not going to work for me at work. :-(  We'll see though.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Not Haskell?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://neugierig.org/software/blog/2011/10/why-not-haskell.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T08:32:49.000Z",
      "title": null,
      "url": null,
      "author": "asb",
      "points": 14,
      "story_text": null,
      "comment_text": "D. Richard Hipp and the SQLite project have not had such a positive experience with static code analysis. They already use a <i>massive</i> amount of testing though. There's also no mention of commercial tools like Coverity.<p>See the \"Static Analysis\" section:\\n<a href=\"http://www.sqlite.org/testing.html\" rel=\"nofollow\">http://www.sqlite.org/testing.html</a>",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388290,
      "created_at_i": 1324715569,
      "_tags": [
        "comment",
        "author_asb",
        "story_3388290"
      ],
      "objectID": "3388542",
      "_highlightResult": {
        "author": {
          "value": "asb",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "D. Richard Hipp and the SQLite project have not had such a positive experience with <em>static</em> code <em>analysis.</em> They already use a <i>massive</i> amount of testing though. There's also no mention of commercial <em>tools</em> like Coverity.<p>See the \"<em>Static</em> <em>Analysis</em>\" section:\\n<a href=\"http://www.sqlite.org/testing.html\" rel=\"nofollow\">http://www.sqlite.org/testing.html</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2011-12-04T15:33:21.000Z",
      "title": "",
      "url": "",
      "author": "hello_moto",
      "points": 10,
      "story_text": null,
      "comment_text": "My experienced as an unofficial team lead of a few programmers with various experience (which I conclude that they were Jr. Programmers with a few years of lack of mentorship) was to do the following:<p>1) Define structure<p>Set some rules. Coding styles, check-in etiquette<p>2) Find tools to limit mistakes<p>Static code analysis, automate build that breaks when #1 fails.<p>3) Always on alert<p>Do a lot of code reviews. A lot. Argue and fight over little things (variable naming convention, missing documentations, unclear code).<p>Now this might not sit well with others so get ready:<p>4) Become a \"drill\" sergeant<p>I find that becoming the \"bulldog\" sometime works. You've got to become some sort of \"drill\" sergeant. People may dislike you at first but if the project is successful, they can hate you all the way to the exit door all they like.<p>That was my experience. I made a concious decision to put the success of the project as the top priority. Even if it means breaking some bridges with other programmers. I hope they learn why I did those things in the future. If they don't, I won't quarrel or regret my action.<p>5) Be nice on other occasions<p>I may be the biggest jerk during code-review and check-in commits but when my co-workers stuck, I'll be gladly help them even if it means I have to sit with them and do my overtime. This can gain you some respect after confrontation/intense debate/being a jerk.<p>I always try to be friendly during office/release party. Give credit to the team, etc.",
      "num_comments": null,
      "story_id": 3310355,
      "story_title": "Half Life of a Tech Worker: 15 Years - Slashdot",
      "story_url": "http://tech.slashdot.org/story/11/12/03/1435217/half-life-of-a-tech-worker-15-years?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+Slashdot%2Fslashdot+%28Slashdot%29",
      "parent_id": 3310790,
      "created_at_i": 1323012801,
      "_tags": [
        "comment",
        "author_hello_moto",
        "story_3310355"
      ],
      "objectID": "3310837",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "hello_moto",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "My experienced as an unofficial team lead of a few programmers with various experience (which I conclude that they were Jr. Programmers with a few years of lack of mentorship) was to do the following:<p>1) Define structure<p>Set some rules. Coding styles, check-in etiquette<p>2) Find <em>tools</em> to limit mistakes<p><em>Static</em> code <em>analysis</em>, automate build that breaks when #1 fails.<p>3) Always on alert<p>Do a lot of code reviews. A lot. Argue and fight over little things (variable naming convention, missing documentations, unclear code).<p>Now this might not sit well with others so get ready:<p>4) Become a \"drill\" sergeant<p>I find that becoming the \"bulldog\" sometime works. You've got to become some sort of \"drill\" sergeant. People may dislike you at first but if the project is successful, they can hate you all the way to the exit door all they like.<p>That was my experience. I made a concious decision to put the success of the project as the top priority. Even if it means breaking some bridges with other programmers. I hope they learn why I did those things in the future. If they don't, I won't quarrel or regret my action.<p>5) Be nice on other occasions<p>I may be the biggest jerk during code-review and check-in commits but when my co-workers stuck, I'll be gladly help them even if it means I have to sit with them and do my overtime. This can gain you some respect after confrontation/intense debate/being a jerk.<p>I always try to be friendly during office/release party. Give credit to the team, etc.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Half Life of a Tech Worker: 15 Years - Slashdot",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://tech.slashdot.org/story/11/12/03/1435217/half-life-of-a-tech-worker-15-years?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+Slashdot%2Fslashdot+%28Slashdot%29",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-24T02:59:54.000Z",
      "title": "",
      "url": "",
      "author": "tikhonj",
      "points": 8,
      "story_text": null,
      "comment_text": "Maybe it's just me, but I was under the impression that working on internal tools was one of the best places to be, at least at primarily software-based companies.  You're insulated from whatever invariably boring domain your company happens to serve, you have far more range to innovate and try new technologies, you don't have to deal with customers who aren't also developers...<p>A disproportionate amount of interesting projects I've read about and seen were internal tools of various sorts: compilers, static analysis, testing, verification, building. If I was going to work at a big company like Google or Facebook, I would definitely prefer to be on a tools team.<p>Also, I think working at a financial company like Jane Street would be great, and that is also an internal sort of job. Really, the company doesn't have any external customers at all. Yet I'd go there over virtually any other standard software engineering sort of job.",
      "num_comments": null,
      "story_id": 5106728,
      "story_title": "Key points to look for in your next job if you are a developer",
      "story_url": "http://blog.davidtate.org/2010/08/key-points-to-look-for-in-your-next-job-if-you-are-a-developer/",
      "parent_id": 5106728,
      "created_at_i": 1358996394,
      "_tags": [
        "comment",
        "author_tikhonj",
        "story_5106728"
      ],
      "objectID": "5106880",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "tikhonj",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Maybe it's just me, but I was under the impression that working on internal <em>tools</em> was one of the best places to be, at least at primarily software-based companies.  You're insulated from whatever invariably boring domain your company happens to serve, you have far more range to innovate and try new technologies, you don't have to deal with customers who aren't also developers...<p>A disproportionate amount of interesting projects I've read about and seen were internal <em>tools</em> of various sorts: compilers, <em>static</em> <em>analysis</em>, testing, verification, building. If I was going to work at a big company like Google or Facebook, I would definitely prefer to be on a <em>tools</em> team.<p>Also, I think working at a financial company like Jane Street would be great, and that is also an internal sort of job. Really, the company doesn't have any external customers at all. Yet I'd go there over virtually any other standard software engineering sort of job.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Key points to look for in your next job if you are a developer",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.davidtate.org/2010/08/key-points-to-look-for-in-your-next-job-if-you-are-a-developer/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-22T14:56:07.000Z",
      "title": null,
      "url": null,
      "author": "mike_hearn",
      "points": 6,
      "story_text": null,
      "comment_text": "It&#x27;s hard for someone who was not the author to dive in to the middle of the code and understand it, debug it or upgrade it, due to the lack of explicit types.<p>Additionally there static analysis was limited to lint and refactoring tools didn&#x27;t exist, or at least nobody seemed to use them (I never used PyCharm but I heard it can do some cool stuff).<p>Also for whatever reason these codebases often weren&#x27;t very well structured and there was a common tendency to define configuration files that were themselves Python, resulting in the codebase spilling out into things that were theoretically just static data, complicating unit testing.",
      "num_comments": null,
      "story_id": 8067834,
      "story_title": "Java Developers",
      "story_url": "http://nsainsbury.svbtle.com/java-developers",
      "parent_id": 8068572,
      "created_at_i": 1406040967,
      "_tags": [
        "comment",
        "author_mike_hearn",
        "story_8067834"
      ],
      "objectID": "8069295",
      "_highlightResult": {
        "author": {
          "value": "mike_hearn",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's hard for someone who was not the author to dive in to the middle of the code and understand it, debug it or upgrade it, due to the lack of explicit types.<p>Additionally there <em>static</em> <em>analysis</em> was limited to lint and refactoring <em>tools</em> didn't exist, or at least nobody seemed to use them (I never used PyCharm but I heard it can do some cool stuff).<p>Also for whatever reason these codebases often weren't very well structured and there was a common tendency to define configuration files that were themselves Python, resulting in the codebase spilling out into things that were theoretically just <em>static</em> data, complicating unit testing.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Java Developers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://nsainsbury.svbtle.com/java-developers",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-05-30T13:47:42.000Z",
      "title": null,
      "url": null,
      "author": "smoyer",
      "points": 6,
      "story_text": null,
      "comment_text": "I still prefer using JSR-305 annotations&#x2F;tools (like Findbugs) to do static analysis.  Reification should help Optional&lt;?&gt; become more useful, but why would you ask for run-time checking when in most cases compile-time checking identifies the problems?",
      "num_comments": null,
      "story_id": 7821120,
      "story_title": "Java 8 Features",
      "story_url": "http://www.infoq.com/articles/Java-8-Quiet-Features?utm_source=hackernews&utm_medium=link&utm_campaign=8java_article",
      "parent_id": 7821373,
      "created_at_i": 1401457662,
      "_tags": [
        "comment",
        "author_smoyer",
        "story_7821120"
      ],
      "objectID": "7821723",
      "_highlightResult": {
        "author": {
          "value": "smoyer",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I still prefer using JSR-305 annotations/<em>tools</em> (like Findbugs) to do <em>static</em> <em>analysis.</em>  Reification should help Optional&lt;?&gt; become more useful, but why would you ask for run-time checking when in most cases compile-time checking identifies the problems?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Java 8 Features",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.infoq.com/articles/Java-8-Quiet-Features?utm_source=hackernews&utm_medium=link&utm_campaign=8java_article",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-22T15:28:58.000Z",
      "title": null,
      "url": null,
      "author": "apaprocki",
      "points": 4,
      "story_text": null,
      "comment_text": "My personal observation is that while compilers continually get better at identifying straightforward mistakes, they don&#x27;t have the same capability as a static analysis tool that works across compilation units. That is the real selling point of these tools. Definitely -Weverything&#x2F;-Wexta plus static analysis for baseline checking.<p>My other beef is that compilers always add new warnings as options or behind new &quot;catch all&quot; flags like -Weverything that no one knows about. As long as each new warning can be individually disabled, there isn&#x27;t a huge cost to pay by making much more of them enabled by default. Upgrading to a new compiler version usually requires a tiny bit of work, so adding a few -Wno-* rules for new things you want to disable until the code is clean (or forever) is a small price to pay for all new code getting the checks by default.",
      "num_comments": null,
      "story_id": 7282005,
      "story_title": "Apple's SSL/TLS bug",
      "story_url": "https://www.imperialviolet.org/2014/02/22/applebug.html",
      "parent_id": 7282277,
      "created_at_i": 1393082938,
      "_tags": [
        "comment",
        "author_apaprocki",
        "story_7282005"
      ],
      "objectID": "7282309",
      "_highlightResult": {
        "author": {
          "value": "apaprocki",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "My personal observation is that while compilers continually get better at identifying straightforward mistakes, they don't have the same capability as a <em>static</em> <em>analysis</em> tool that works across compilation units. That is the real selling point of these <em>tools</em>. Definitely -Weverything/-Wexta plus <em>static</em> <em>analysis</em> for baseline checking.<p>My other beef is that compilers always add new warnings as options or behind new &quot;catch all&quot; flags like -Weverything that no one knows about. As long as each new warning can be individually disabled, there isn't a huge cost to pay by making much more of them enabled by default. Upgrading to a new compiler version usually requires a tiny bit of work, so adding a few -Wno-* rules for new things you want to disable until the code is clean (or forever) is a small price to pay for all new code getting the checks by default.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Apple's SSL/TLS bug",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.imperialviolet.org/2014/02/22/applebug.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T18:11:09.000Z",
      "title": "",
      "url": "",
      "author": "_delirium",
      "points": 3,
      "story_text": null,
      "comment_text": "That's true, but I think a different class of tools: theorem-provers that depend on extensive domain-specific annotations (e.g. about SQL semantics) to prove correctness aren't usually applied in the same situations as tools like Coverity that do static analysis of raw C/C++ code to find likely bugs; though there's some convergence in the past 10 years.",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388796,
      "created_at_i": 1324750269,
      "_tags": [
        "comment",
        "author__delirium",
        "story_3388290"
      ],
      "objectID": "3389318",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "_delirium",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's true, but I think a different class of <em>tools</em>: theorem-provers that depend on extensive domain-specific annotations (e.g. about SQL semantics) to prove correctness aren't usually applied in the same situations as <em>tools</em> like Coverity that do <em>static</em> <em>analysis</em> of raw C/C++ code to find likely bugs; though there's some convergence in the past 10 years.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2013-09-01T18:19:55.000Z",
      "title": "",
      "url": "",
      "author": "jeffdavis",
      "points": 2,
      "story_text": null,
      "comment_text": "I think there is reasonable consensus about some software engineering best practices:<p>1. Avoid action-at-a-distance and side-effects that are hard to reason about.<p>2. Use immutable objects and values rather than references and pointers.<p>3. Avoid intricate control flow with many branches.<p>4. Greater isolation of processes&#x2F;threads (actor model).<p>5. Use systems and platforms with simple and strong guarantees (e.g. ACID) that are easy to reason about. Special cases and nuances to the underlying platform should be avoided.<p>6. Use tools with good support for static analysis (e.g. a good type system with a compiler that can understand it).<p>Exceptions seem to violate #1, #3, and #6.<p>These rules only apply to software engineering; that is, the reliability, robustness, long-term maintainability, and total project development cost (including maintenance and support).<p>Of course, there are other considerations, such as: performance, the time to achieve the minimum viable product, how much developers like the tools, how &quot;hackable&quot; it is, or utility for research purposes. These other concerns may be a good reason to violate the above rules.",
      "num_comments": null,
      "story_id": 6310555,
      "story_title": "Exceptions (2003)",
      "story_url": "http://www.joelonsoftware.com/items/2003/10/13.html",
      "parent_id": 6310555,
      "created_at_i": 1378059595,
      "_tags": [
        "comment",
        "author_jeffdavis",
        "story_6310555"
      ],
      "objectID": "6311432",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jeffdavis",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I think there is reasonable consensus about some software engineering best practices:<p>1. Avoid action-at-a-distance and side-effects that are hard to reason about.<p>2. Use immutable objects and values rather than references and pointers.<p>3. Avoid intricate control flow with many branches.<p>4. Greater isolation of processes/threads (actor model).<p>5. Use systems and platforms with simple and strong guarantees (e.g. ACID) that are easy to reason about. Special cases and nuances to the underlying platform should be avoided.<p>6. Use <em>tools</em> with good support for <em>static</em> <em>analysis</em> (e.g. a good type system with a compiler that can understand it).<p>Exceptions seem to violate #1, #3, and #6.<p>These rules only apply to software engineering; that is, the reliability, robustness, long-term maintainability, and total project development cost (including maintenance and support).<p>Of course, there are other considerations, such as: performance, the time to achieve the minimum viable product, how much developers like the <em>tools</em>, how &quot;hackable&quot; it is, or utility for research purposes. These other concerns may be a good reason to violate the above rules.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Exceptions (2003)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.joelonsoftware.com/items/2003/10/13.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-06-28T05:59:02.000Z",
      "title": "",
      "url": "",
      "author": "willvarfar",
      "points": 2,
      "story_text": null,
      "comment_text": "All this is discoverable in static code analysis.  It is entirely possible to make tools that check the docs cover all these cases.  There are probably tools they can buy to do it.<p>Google should check it all, every release.",
      "num_comments": null,
      "story_id": 2703377,
      "story_title": "Android's Log.wtf Method",
      "story_url": "http://developer.android.com/reference/android/util/Log.html#wtf(java.lang.String, java.lang.Throwable)",
      "parent_id": 2704200,
      "created_at_i": 1309240742,
      "_tags": [
        "comment",
        "author_willvarfar",
        "story_2703377"
      ],
      "objectID": "2704241",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "willvarfar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "All this is discoverable in <em>static</em> code <em>analysis.</em>  It is entirely possible to make <em>tools</em> that check the docs cover all these cases.  There are probably <em>tools</em> they can buy to do it.<p>Google should check it all, every release.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Android's Log.wtf Method",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://developer.android.com/reference/android/util/Log.html#wtf(java.lang.String, java.lang.Throwable)",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-14T11:32:28.000Z",
      "title": null,
      "url": null,
      "author": "SparklingCotton",
      "points": 1,
      "story_text": null,
      "comment_text": "What are the efficient ways of preventing this kind of bug, if not type systems?<p>The parent had a good point and you should really try to look at Haskell before you say that kind of nonsense.<p>All the tools that are available for static analysis are basically extra type systems bolted on top of existing languages.<p>If you try to detect buffer overflows using static analysis of the linux kernel what you need to do is to is go through the source code and define invariants.  Those invariants are TYPES in languages powerful enough to express them.<p>For example the invariant that memory, or any resource allocated must be freed can be expressed in Haskell.<p>In C++ it cannot be expressed.  There are workarounds like RAII, but that does not give any guarantees.<p>If you do not think type systems and thus languages make any differences, you also cannot believe that formal verification makes any difference, because type systems are a weak form of formal verification.  How &quot;weak&quot; depends on the language.<p>You should also read up on the Curry-Howard correspondence to learn something about the deep connections between types, programs, and proofs.<p><a href=\"http://en.wikipedia.org/wiki/Curry-Howard_correspondence\" rel=\"nofollow\">http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Curry-Howard_correspondence</a>",
      "num_comments": null,
      "story_id": 7548991,
      "story_title": "The Heartbleed Bug",
      "story_url": "http://heartbleed.com/",
      "parent_id": 7564977,
      "created_at_i": 1397475148,
      "_tags": [
        "comment",
        "author_SparklingCotton",
        "story_7548991"
      ],
      "objectID": "7585553",
      "_highlightResult": {
        "author": {
          "value": "SparklingCotton",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "What are the efficient ways of preventing this kind of bug, if not type systems?<p>The parent had a good point and you should really try to look at Haskell before you say that kind of nonsense.<p>All the <em>tools</em> that are available for <em>static</em> <em>analysis</em> are basically extra type systems bolted on top of existing languages.<p>If you try to detect buffer overflows using <em>static</em> <em>analysis</em> of the linux kernel what you need to do is to is go through the source code and define invariants.  Those invariants are TYPES in languages powerful enough to express them.<p>For example the invariant that memory, or any resource allocated must be freed can be expressed in Haskell.<p>In C++ it cannot be expressed.  There are workarounds like RAII, but that does not give any guarantees.<p>If you do not think type systems and thus languages make any differences, you also cannot believe that formal verification makes any difference, because type systems are a weak form of formal verification.  How &quot;weak&quot; depends on the language.<p>You should also read up on the Curry-Howard correspondence to learn something about the deep connections between types, programs, and proofs.<p><a href=\"http://en.wikipedia.org/wiki/Curry-Howard_correspondence\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Curry-Howard_correspondence</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Heartbleed Bug",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://heartbleed.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-20T16:48:33.000Z",
      "title": "",
      "url": "",
      "author": "JulianMorrison",
      "points": 1,
      "story_text": null,
      "comment_text": "That surprises me - when I am talking about tools, I mean things like static analysis, theorem provers, and coding standards like MISRA C.<p>I guess they figure if they simulate it enough, they can test out the bugs rather than being very careful about putting them in.",
      "num_comments": null,
      "story_id": 3722341,
      "story_title": "SpaceX Prepares For April 30 Launch To Space Station",
      "story_url": "http://www.wired.com/autopia/2012/03/spacex-prepares-for-april-30-launch-to-space-station/",
      "parent_id": 3726047,
      "created_at_i": 1332262113,
      "_tags": [
        "comment",
        "author_JulianMorrison",
        "story_3722341"
      ],
      "objectID": "3730229",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "JulianMorrison",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That surprises me - when I am talking about <em>tools</em>, I mean things like <em>static</em> <em>analysis</em>, theorem provers, and coding standards like MISRA C.<p>I guess they figure if they simulate it enough, they can test out the bugs rather than being very careful about putting them in.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "SpaceX Prepares For April 30 Launch To Space Station",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.wired.com/autopia/2012/03/spacex-prepares-for-april-30-launch-to-space-station/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-11T11:09:32.000Z",
      "title": "",
      "url": "",
      "author": "wink",
      "points": 0,
      "story_text": null,
      "comment_text": "Yes, because you can be swamped in false positives so much that it's easier on time, money and nerves to just not use the tool.\nAnd this is a general problem in static source code analysis, not just the \"bad tools\".<p>I had this awesome example in one book about metrics where the static analysis on some 100k LOC project produced output with the same line length as \"War and Peace\". Good luck sifting through those.<p>But I'm absolutely not saying you shouldn't use them, but as some commenters in the original post pointed out, you need to check if they produce sensible output for your project or if they can catch some really nasty bugs, if it's worth the additional work.",
      "num_comments": null,
      "story_id": 3689676,
      "story_title": "Big discussion: Do Static Source Code Analysis Tools Really Work? ",
      "story_url": "http://developers.slashdot.org/story/08/05/19/1510245/do-static-source-code-analysis-tools-really-work",
      "parent_id": 3689747,
      "created_at_i": 1331464172,
      "_tags": [
        "comment",
        "author_wink",
        "story_3689676"
      ],
      "objectID": "3690149",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "wink",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Yes, because you can be swamped in false positives so much that it's easier on time, money and nerves to just not use the tool.\nAnd this is a general problem in <em>static</em> source code <em>analysis</em>, not just the \"bad <em>tools</em>\".<p>I had this awesome example in one book about metrics where the <em>static</em> <em>analysis</em> on some 100k LOC project produced output with the same line length as \"War and Peace\". Good luck sifting through those.<p>But I'm absolutely not saying you shouldn't use them, but as some commenters in the original post pointed out, you need to check if they produce sensible output for your project or if they can catch some really nasty bugs, if it's worth the additional work.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Big discussion: Do <em>Static</em> Source Code <em>Analysis</em> <em>Tools</em> Really Work? ",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_url": {
          "value": "http://developers.slashdot.org/story/08/05/19/1510245/do-<em>static</em>-source-code-<em>analysis</em>-<em>tools</em>-really-work",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        }
      }
    },
    {
      "created_at": "2015-01-15T17:15:54.000Z",
      "title": null,
      "url": null,
      "author": "davmre",
      "points": null,
      "story_text": null,
      "comment_text": "You can donate to keep software bug-free by funding research into safer programming languages (e.g., Rust), tools for formal verification and static analysis, testing frameworks, software engineering methodology, etc. Sure, someone could always ignore all the research advances and just write unsafe, untested C code. But for the most part, people <i>want</i> to eliminate bugs, so as the techniques for doing so mature, they will tend to become adopted in practice and certain types of bugs will become much less frequent.<p>Similarly, there are technical research questions related to how to design an intelligent agent that is &quot;controllable&quot;, in that it acts to achieve its given goals but not to such an extent that it would resist being switched off or reprogrammed with new goals. Making progress on answering these questions doesn&#x27;t <i>guarantee</i> that any given developer will use whatever techniques are discovered. But insofar as pretty much everyone, even evil masterminds, wants to maintain control over their AIs, the availability of techniques for &#x27;safe&#x27; AI will at least decrease the likelihood that a powerful AI is built without any safeguards.",
      "num_comments": null,
      "story_id": 8892839,
      "story_title": "Elon Musk donates $10M to keep AI beneficial",
      "story_url": "http://futureoflife.org/misc/AI",
      "parent_id": 8893639,
      "created_at_i": 1421342154,
      "_tags": [
        "comment",
        "author_davmre",
        "story_8892839"
      ],
      "objectID": "8893751",
      "_highlightResult": {
        "author": {
          "value": "davmre",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You can donate to keep software bug-free by funding research into safer programming languages (e.g., Rust), <em>tools</em> for formal verification and <em>static</em> <em>analysis</em>, testing frameworks, software engineering methodology, etc. Sure, someone could always ignore all the research advances and just write unsafe, untested C code. But for the most part, people <i>want</i> to eliminate bugs, so as the techniques for doing so mature, they will tend to become adopted in practice and certain types of bugs will become much less frequent.<p>Similarly, there are technical research questions related to how to design an intelligent agent that is &quot;controllable&quot;, in that it acts to achieve its given goals but not to such an extent that it would resist being switched off or reprogrammed with new goals. Making progress on answering these questions doesn't <i>guarantee</i> that any given developer will use whatever techniques are discovered. But insofar as pretty much everyone, even evil masterminds, wants to maintain control over their AIs, the availability of techniques for 'safe' AI will at least decrease the likelihood that a powerful AI is built without any safeguards.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Elon Musk donates $10M to keep AI beneficial",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://futureoflife.org/misc/AI",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-06-02T12:51:38.000Z",
      "title": "",
      "url": "",
      "author": "jcr",
      "points": 56,
      "story_text": null,
      "comment_text": "I wouldn't venture to say this doesn't belong on HN since it really is\ninteresting (if it was actually done correctly), but the files available\nfor download are most likely illegal, were most likely created with\npirated tools (IDA Pro/Hex-Rays, and yes, as a customer of theirs for over a\ndozen years I've reported it), and of course, the usual vilification of\nreverse engineering.<p>If you're reading this on a desktop or laptop system (rather than a\nphone), then you are most likely using an \"IBM PC <i>Compatible</i>\" even if\nyou're using an Intel based Apple, and hence, you're using the fruits of\ncompletely legal reverse engineering.<p>The way to do reverse engineering legally is to have one team reverse\nengineer the target and completely document how it works. Once it's\ndocumented, another <i>disconnected</i> team writes a new implementation from\nthe documentation. This process is how you're using an IBM PC\n<i>Compatible</i> today, so yes, reverse engineering for compatibility is\nperfectly legal.<p>If there is a patented algorithm required, it's not a sure thing. There\nare most likely compatible ways around the patent, but there's also the\nfact that the patent is only valid in the US. With open source hosted in\nsome other country, who are you going to sue?  The users in the US?\n--Nope, users are the ones paying for skype.<p>You might say, \"But we forbid reverse engineering in our license!!!\"<p>Contract clauses forbidding reverse engineering are invalid in many\ncountries and jurisdictions, and of course, you also have to prove the\nother party agreed to the contract/license. With this said, it's very\neasy to create a international jurisdictional nightmare to render any\nsuch contract clause tactically impossible to enforce.<p>The easiest way to think about this is security research. The folks\nfinding and reporting exploitable flaws in software are obviously\nreverse engineering it. Occasionally companies have tried to legally go\nafter people who have published security research on their products, but\nusually this ends very badly for the company. Additionally, doing\nsecurity research is protected use in some countries and jurisdictions.<p>In short, competition is good for markets, and competing by studying and\nmimicking the competition is both normal and legal.<p>For the \"rights\" advocates out there, there are legal problems with the\nthree file downloads available:<p>1.) According to the first file name, the original binaries are being\nredistributed which may be (and usually is) against the license terms\nand default rights granted by copyrights.<p>2.) The IDA Pro database (most likely) contains the entire target\nbinary, so you do have (illegal) redistribution of a copyrighted work.\nYou can load only parts of a target binary into IDA, but that doesn't\nmatter since it is still a portion of the original work. As for whether\nor not said portion could fall under fair use is debatable (i.e.\nlawsuit). In general usage, the entire binary is loaded, since without\nit, you're limited to static analysis (i.e. no debugging).<p>3.) Decompilation, and to a lesser degree disassembly, are equivalent to\n\"machine translation\" in the sense of copyright. Creating a translation\nis considered creating a \"derivative work\" and unless you have been\ngiven rights to create derivative works, then you're in trouble. One of\nthe comments here on HN claims the \"source code\" file is the output of\nthe Hex-Rays Decompiler.<p>I've never used skype and I've never read their license so I don't know\nif they specifically allow redistribution.<p>I have no love for skype or microsoft, but if this had been done\n<i>CORRECTLY</i> by releasing written documentation so an entirely new\nimplementation could be written, then I'd have no problem with it.\nThere are right ways and wrong ways to legally create compatible (open\nsource) software through reverse engineering, and this is a perfect\nexample of the wrong way.",
      "num_comments": null,
      "story_id": 2611299,
      "story_title": "Skype protocol reverse engineered, source available",
      "story_url": "http://skype-open-source.blogspot.com/",
      "parent_id": 2611299,
      "created_at_i": 1307019098,
      "_tags": [
        "comment",
        "author_jcr",
        "story_2611299"
      ],
      "objectID": "2611728",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jcr",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I wouldn't venture to say this doesn't belong on HN since it really is\ninteresting (if it was actually done correctly), but the files available\nfor download are most likely illegal, were most likely created with\npirated <em>tools</em> (IDA Pro/Hex-Rays, and yes, as a customer of theirs for over a\ndozen years I've reported it), and of course, the usual vilification of\nreverse engineering.<p>If you're reading this on a desktop or laptop system (rather than a\nphone), then you are most likely using an \"IBM PC <i>Compatible</i>\" even if\nyou're using an Intel based Apple, and hence, you're using the fruits of\ncompletely legal reverse engineering.<p>The way to do reverse engineering legally is to have one team reverse\nengineer the target and completely document how it works. Once it's\ndocumented, another <i>disconnected</i> team writes a new implementation from\nthe documentation. This process is how you're using an IBM PC\n<i>Compatible</i> today, so yes, reverse engineering for compatibility is\nperfectly legal.<p>If there is a patented algorithm required, it's not a sure thing. There\nare most likely compatible ways around the patent, but there's also the\nfact that the patent is only valid in the US. With open source hosted in\nsome other country, who are you going to sue?  The users in the US?\n--Nope, users are the ones paying for skype.<p>You might say, \"But we forbid reverse engineering in our license!!!\"<p>Contract clauses forbidding reverse engineering are invalid in many\ncountries and jurisdictions, and of course, you also have to prove the\nother party agreed to the contract/license. With this said, it's very\neasy to create a international jurisdictional nightmare to render any\nsuch contract clause tactically impossible to enforce.<p>The easiest way to think about this is security research. The folks\nfinding and reporting exploitable flaws in software are obviously\nreverse engineering it. Occasionally companies have tried to legally go\nafter people who have published security research on their products, but\nusually this ends very badly for the company. Additionally, doing\nsecurity research is protected use in some countries and jurisdictions.<p>In short, competition is good for markets, and competing by studying and\nmimicking the competition is both normal and legal.<p>For the \"rights\" advocates out there, there are legal problems with the\nthree file downloads available:<p>1.) According to the first file name, the original binaries are being\nredistributed which may be (and usually is) against the license terms\nand default rights granted by copyrights.<p>2.) The IDA Pro database (most likely) contains the entire target\nbinary, so you do have (illegal) redistribution of a copyrighted work.\nYou can load only parts of a target binary into IDA, but that doesn't\nmatter since it is still a portion of the original work. As for whether\nor not said portion could fall under fair use is debatable (i.e.\nlawsuit). In general usage, the entire binary is loaded, since without\nit, you're limited to <em>static</em> <em>analysis</em> (i.e. no debugging).<p>3.) Decompilation, and to a lesser degree disassembly, are equivalent to\n\"machine translation\" in the sense of copyright. Creating a translation\nis considered creating a \"derivative work\" and unless you have been\ngiven rights to create derivative works, then you're in trouble. One of\nthe comments here on HN claims the \"source code\" file is the output of\nthe Hex-Rays Decompiler.<p>I've never used skype and I've never read their license so I don't know\nif they specifically allow redistribution.<p>I have no love for skype or microsoft, but if this had been done\n<i>CORRECTLY</i> by releasing written documentation so an entirely new\nimplementation could be written, then I'd have no problem with it.\nThere are right ways and wrong ways to legally create compatible (open\nsource) software through reverse engineering, and this is a perfect\nexample of the wrong way.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Skype protocol reverse engineered, source available",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://skype-open-source.blogspot.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-06T02:02:21.000Z",
      "title": "",
      "url": "",
      "author": "zaphar",
      "points": 49,
      "story_text": null,
      "comment_text": "My day job involves working with Java and C++ on 10+ year old systems. All of my hobby or side projects are in Go these days with occasional diversions into haskell, ML or various Lisps.<p>So I'll try to impart some understanding of why I would switch to Go from Java or C++.<p>First lets get some things out of the way. Go is fast enough and getting faster very quickly and it definitely has a smaller memory footprint. So when compared to java and C++ in those dimensions it holds up just fine but that might not be enough to sway someone over to the Go camp.<p>It's about what else Go has:<p>* Go is a batteries included language. The stdlib has almost everything you need to get started much like python does.<p>* Go is fast for development. I mean really fast. I mean like using Lisp in a REPL fast (almost). I really can't express how fast it's development speed is adequately just trust me its really really fast. This is not just about how fast it compiles although that's part of it. (I've literally been able to write, compile, and run a go \"script\" faster than an equivalent python script.)<p>* Go makes concurrency easy to get right. I haven't seen any other language get this so right since Erlang.<p>* Go is concise. There is no wasted typing. It's easy to read and it's easy to write. Every feature of the language is orthoganal. And it tells you quickly when you've done it wrong.<p>* Go does OO right. Code reuse through composition not inheritance. Polymorphism through interfaces not inheritance. I never have to worry about it with Go. C++ or java? yeah I've got some inheritance related war stories there.<p>All of these things exist in other languages but Go is the only language where they all exist together. This is reason enough to switch to Go but there's more.<p>Go's future is bright. I don't say this because it has celebrity tech people behind it. I say this because the foundation they are laying demonstrates the core team knows what they are doing. Here's some examples.<p>* Go comes with all the tools you need to programmatically understand Go code. Parser, Type checking, Static analysis is all available via the stdlib. As a result GoCode which adds IDE functionality to the EDITOR of your choice came on the scene very quickly. Java doesn't have this. C++ doesn't have this. Go made it possible to create an IDE as a service with minimal effort. Besides Gocode you also have gofmt. Never worry about code formatting again. gofmt will reformat it for you and it will <i>never</i> break your code. It's 100% safe. I am aware of no other language excepting lisp with this functionality.<p>Lastly I want to address your \"a lot less powerful\" comment. I think it's false. In now way is Go less powerful than Java. It's fast enough to be in the same league as java. It has a lower memory footprint than java. It compiles faster than java. And the language itself is if anything more powerful and expressive than java. It has closures, It has interfaces that are just as typesafe and yet easier to use than java.<p>In fact I'll sum it up in one word: Go is <i>relaxing</i>.",
      "num_comments": null,
      "story_id": 5013596,
      "story_title": "Why I Program in Go",
      "story_url": "http://tech.t9i.in/2013/01/why-program-in-go/",
      "parent_id": 5014829,
      "created_at_i": 1357437741,
      "_tags": [
        "comment",
        "author_zaphar",
        "story_5013596"
      ],
      "objectID": "5014942",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "zaphar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "My day job involves working with Java and C++ on 10+ year old systems. All of my hobby or side projects are in Go these days with occasional diversions into haskell, ML or various Lisps.<p>So I'll try to impart some understanding of why I would switch to Go from Java or C++.<p>First lets get some things out of the way. Go is fast enough and getting faster very quickly and it definitely has a smaller memory footprint. So when compared to java and C++ in those dimensions it holds up just fine but that might not be enough to sway someone over to the Go camp.<p>It's about what else Go has:<p>* Go is a batteries included language. The stdlib has almost everything you need to get started much like python does.<p>* Go is fast for development. I mean really fast. I mean like using Lisp in a REPL fast (almost). I really can't express how fast it's development speed is adequately just trust me its really really fast. This is not just about how fast it compiles although that's part of it. (I've literally been able to write, compile, and run a go \"script\" faster than an equivalent python script.)<p>* Go makes concurrency easy to get right. I haven't seen any other language get this so right since Erlang.<p>* Go is concise. There is no wasted typing. It's easy to read and it's easy to write. Every feature of the language is orthoganal. And it tells you quickly when you've done it wrong.<p>* Go does OO right. Code reuse through composition not inheritance. Polymorphism through interfaces not inheritance. I never have to worry about it with Go. C++ or java? yeah I've got some inheritance related war stories there.<p>All of these things exist in other languages but Go is the only language where they all exist together. This is reason enough to switch to Go but there's more.<p>Go's future is bright. I don't say this because it has celebrity tech people behind it. I say this because the foundation they are laying demonstrates the core team knows what they are doing. Here's some examples.<p>* Go comes with all the <em>tools</em> you need to programmatically understand Go code. Parser, Type checking, <em>Static</em> <em>analysis</em> is all available via the stdlib. As a result GoCode which adds IDE functionality to the EDITOR of your choice came on the scene very quickly. Java doesn't have this. C++ doesn't have this. Go made it possible to create an IDE as a service with minimal effort. Besides Gocode you also have gofmt. Never worry about code formatting again. gofmt will reformat it for you and it will <i>never</i> break your code. It's 100% safe. I am aware of no other language excepting lisp with this functionality.<p>Lastly I want to address your \"a lot less powerful\" comment. I think it's false. In now way is Go less powerful than Java. It's fast enough to be in the same league as java. It has a lower memory footprint than java. It compiles faster than java. And the language itself is if anything more powerful and expressive than java. It has closures, It has interfaces that are just as typesafe and yet easier to use than java.<p>In fact I'll sum it up in one word: Go is <i>relaxing</i>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why I Program in Go",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://tech.t9i.in/2013/01/why-program-in-go/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-08-05T02:03:30.000Z",
      "title": "",
      "url": "",
      "author": "mvanveen",
      "points": 37,
      "story_text": null,
      "comment_text": "A few summers ago I was an intern at JPL working on a static analysis suite for this exact standard.<p>Writing code checkers for these sorts of rules is a really interesting exercise and it helped me grow a lot as a programmer!  I went from having no exposure to formal languages, parsing, and grammars to actively playing around with these concepts to try and help build more reliable software.  It was a humbling, challenging, and incredibly rewarding experience.<p>Sometimes, a rule is extremely simple to implement.  For example, checking a rule that requires that  an assert is raised after every so many lines within a given scope is just a matter of picking the right sed expression.  Other times, you really need an AST to be able to do anything at all.<p>A rule like \"In compound expressions with multiple sub-expressions the intended \norder of evaluation  shall be made explicit with parentheses\" is particularly challenging.  I spent a few weeks on this rule!  I was banging my head, trying to learn the fundamentals of parsing languages, spending my hours diving into wikipedia articles and learning lex and yacc.  The grad students at LaRS were always extremely helpful and were always willing to help tutor me and teach me what I needed to learn (hi mihai and cheng if you're reading!).  After consulting them and scratching our heads for a while, we figured we might be able to do it with a shift-reduce parser when a shift or reduce ambiguity is introduced during the course of parsing a source code file.  This proved beyond the scope of what I'd be able to do within an internship, but it helped me appreciate the nuance and complexity hidden within even seemingly simple statements about language properties.<p>Automated analysis of these rules gives you a really good appreciation of the Chomsky language hierarchy because the goal is always to create the simplest possible checker you can reliably show is able to accurately cover all the possible cases.  Sometimes that is simple as a regular language, but the next rule might require you to have a parser for the language.<p>For what it's worth, this is only one of the ways the guys at LaRS (<a href=\"http://lars-lab.jpl.nasa.gov/\" rel=\"nofollow\">http://lars-lab.jpl.nasa.gov/</a>) help try to improve software reliability on-lab.  Most of the members are world-class experts in formal verification analysis and try to integrate their knowledge with missions as effectively as possible.  Sometimes, this means riding the dual responsibility of functioning as a researcher and a embedded flight software engineer, working alongside the rest of the team.<p>If anyone's interested in trying out static analysis of C on your own, I highly reccomend checking out Eli Bendersky's awesome C parser for Python (<a href=\"http://code.google.com/p/pycparser/\" rel=\"nofollow\">http://code.google.com/p/pycparser/</a>).  I found it leaps and bounds better than the existing closed-source toolsets we had licenses for, like Coverity Extend.  At the time, it had the extremely horrible limitation of only parsing ANSI 89, but Eli has since improved the parser to have ANSI 99 compliance.  Analyzing C in Python is a dream.",
      "num_comments": null,
      "story_id": 4339999,
      "story_title": "NASA JPL C Coding Standard [pdf]",
      "story_url": "http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf",
      "parent_id": 4339999,
      "created_at_i": 1344132210,
      "_tags": [
        "comment",
        "author_mvanveen",
        "story_4339999"
      ],
      "objectID": "4340331",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "mvanveen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "A few summers ago I was an intern at JPL working on a <em>static</em> <em>analysis</em> suite for this exact standard.<p>Writing code checkers for these sorts of rules is a really interesting exercise and it helped me grow a lot as a programmer!  I went from having no exposure to formal languages, parsing, and grammars to actively playing around with these concepts to try and help build more reliable software.  It was a humbling, challenging, and incredibly rewarding experience.<p>Sometimes, a rule is extremely simple to implement.  For example, checking a rule that requires that  an assert is raised after every so many lines within a given scope is just a matter of picking the right sed expression.  Other times, you really need an AST to be able to do anything at all.<p>A rule like \"In compound expressions with multiple sub-expressions the intended \norder of evaluation  shall be made explicit with parentheses\" is particularly challenging.  I spent a few weeks on this rule!  I was banging my head, trying to learn the fundamentals of parsing languages, spending my hours diving into wikipedia articles and learning lex and yacc.  The grad students at LaRS were always extremely helpful and were always willing to help tutor me and teach me what I needed to learn (hi mihai and cheng if you're reading!).  After consulting them and scratching our heads for a while, we figured we might be able to do it with a shift-reduce parser when a shift or reduce ambiguity is introduced during the course of parsing a source code file.  This proved beyond the scope of what I'd be able to do within an internship, but it helped me appreciate the nuance and complexity hidden within even seemingly simple statements about language properties.<p>Automated <em>analysis</em> of these rules gives you a really good appreciation of the Chomsky language hierarchy because the goal is always to create the simplest possible checker you can reliably show is able to accurately cover all the possible cases.  Sometimes that is simple as a regular language, but the next rule might require you to have a parser for the language.<p>For what it's worth, this is only one of the ways the guys at LaRS (<a href=\"http://lars-lab.jpl.nasa.gov/\" rel=\"nofollow\">http://lars-lab.jpl.nasa.gov/</a>) help try to improve software reliability on-lab.  Most of the members are world-class experts in formal verification <em>analysis</em> and try to integrate their knowledge with missions as effectively as possible.  Sometimes, this means riding the dual responsibility of functioning as a researcher and a embedded flight software engineer, working alongside the rest of the team.<p>If anyone's interested in trying out <em>static</em> <em>analysis</em> of C on your own, I highly reccomend checking out Eli Bendersky's awesome C parser for Python (<a href=\"http://code.google.com/p/pycparser/\" rel=\"nofollow\">http://code.google.com/p/pycparser/</a>).  I found it leaps and bounds better than the existing closed-source <em>tools</em>ets we had licenses for, like Coverity Extend.  At the time, it had the extremely horrible limitation of only parsing ANSI 89, but Eli has since improved the parser to have ANSI 99 compliance.  Analyzing C in Python is a dream.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "NASA JPL C Coding Standard [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-10-15T00:06:49.000Z",
      "title": null,
      "url": null,
      "author": "tytso",
      "points": 32,
      "story_text": null,
      "comment_text": "Yes, I&#x27;m aware of the concept of forward secrecy, and the formalism around it.   Without intending to sound snippy myself, I think there is a tendency for academicians (whose promotion&#x2F;tenure prospects are directly related being able to generate papers that get published in high impact journals) to be biased in favor of those things for which formal models can be created.  We saw that for example in the academic focus on formal proof of correctness of programs, which at this point is recognized as a blind alley, as opposed to a more engineering approach of using tools like valgrind and lint and static program analysis.   So I am a bit unpersuaded regarding the academic focus on forward secrecy.  It&#x27;s something that if we can add to a design, I&#x27;ll certainly do it --- and indeed there is a Yarrow-style &quot;catastrophic reseeding&quot; in the &#x2F;dev&#x2F;random design.<p>We have been moving away from using entropy estimators in &#x2F;dev&#x2F;random, actually.  We still use it for certain entropy sources, most notably for the keyboard and mouse inputs, where it is useful for filtering out event timings caused by the user leaning on the key and triggering autorepeat.   But these days we have a &quot;fast mix pool&quot; (which is per-CPU) where we sample on every single interrupt, and then down-mix from there to much larger entropy pool, and the bulk of the entropy, especially on servers, comes from the fast mix pool.<p>I tend to focus much more on engineering&#x2F;social aspects; for example, the fundamental cause of the failure found by the Mining Your P&#x27;s and Q&#x27;s paper (as opposed to the hypothetical failures of things like the forward secrecy papers), was  people disabling the entropy collection in many&#x2F;most device drivers because they thought it was too slow for high speed devices, in particular network devices.   They made arguments that it was because an adversary could monitor the packet arrival times on the Ethernet (which is not true in a switched fabric anyway, and if the attacker is sitting at Fort Meade, or even at AT&amp;T&#x27;s data center, they won&#x27;t know about your local area network), but that was just an excuse; the main reason was engineers who were worried about performance.<p>So using a fancy &quot;approved by academics&quot; design which uses crypto hashing to mix entropy into the mixing pools may be pointless, if downstream kernel hackers disable the entropy collection &quot;because it&#x27;s too slow&quot;.   We now have something hard-wired into the main interrupt code path (it&#x27;s now no longer optional, so it can&#x27;t be configured on or off on an individual device driver basis), and I&#x27;ve gone through a lot of work to make it be extremely fast, including using per-CPU pools, worrying about cache effects, etc.   These are concerns that I&#x27;m sure would never help a professor achieve tenure, but as a practicing engineer, I&#x27;ve been painfully aware about how important these sorts of concerns really are.<p>Don&#x27;t get me wrong; I do read the papers from those academics who try to analyze &#x2F;dev&#x2F;random, and I appreciate their attention.  But I do come from a someone different perspective than they do, and over the years I&#x27;ve learned that it&#x27;s not wise to blindly take the advice of every single bug report that you get (and I consider papers to be simply formal bug reports :-) since sometimes you can&#x27;t satisfy every single user and every single bug report.",
      "num_comments": null,
      "story_id": 6548893,
      "story_title": "Insecurities in the Linux /dev/random",
      "story_url": "https://www.schneier.com/blog/archives/2013/10/insecurities_in.html",
      "parent_id": 6550433,
      "created_at_i": 1381795609,
      "_tags": [
        "comment",
        "author_tytso",
        "story_6548893"
      ],
      "objectID": "6550514",
      "_highlightResult": {
        "author": {
          "value": "tytso",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Yes, I'm aware of the concept of forward secrecy, and the formalism around it.   Without intending to sound snippy myself, I think there is a tendency for academicians (whose promotion/tenure prospects are directly related being able to generate papers that get published in high impact journals) to be biased in favor of those things for which formal models can be created.  We saw that for example in the academic focus on formal proof of correctness of programs, which at this point is recognized as a blind alley, as opposed to a more engineering approach of using <em>tools</em> like valgrind and lint and <em>static</em> program <em>analysis.</em>   So I am a bit unpersuaded regarding the academic focus on forward secrecy.  It's something that if we can add to a design, I'll certainly do it --- and indeed there is a Yarrow-style &quot;catastrophic reseeding&quot; in the /dev/random design.<p>We have been moving away from using entropy estimators in /dev/random, actually.  We still use it for certain entropy sources, most notably for the keyboard and mouse inputs, where it is useful for filtering out event timings caused by the user leaning on the key and triggering autorepeat.   But these days we have a &quot;fast mix pool&quot; (which is per-CPU) where we sample on every single interrupt, and then down-mix from there to much larger entropy pool, and the bulk of the entropy, especially on servers, comes from the fast mix pool.<p>I tend to focus much more on engineering/social aspects; for example, the fundamental cause of the failure found by the Mining Your P's and Q's paper (as opposed to the hypothetical failures of things like the forward secrecy papers), was  people disabling the entropy collection in many/most device drivers because they thought it was too slow for high speed devices, in particular network devices.   They made arguments that it was because an adversary could monitor the packet arrival times on the Ethernet (which is not true in a switched fabric anyway, and if the attacker is sitting at Fort Meade, or even at AT&amp;T's data center, they won't know about your local area network), but that was just an excuse; the main reason was engineers who were worried about performance.<p>So using a fancy &quot;approved by academics&quot; design which uses crypto hashing to mix entropy into the mixing pools may be pointless, if downstream kernel hackers disable the entropy collection &quot;because it's too slow&quot;.   We now have something hard-wired into the main interrupt code path (it's now no longer optional, so it can't be configured on or off on an individual device driver basis), and I've gone through a lot of work to make it be extremely fast, including using per-CPU pools, worrying about cache effects, etc.   These are concerns that I'm sure would never help a professor achieve tenure, but as a practicing engineer, I've been painfully aware about how important these sorts of concerns really are.<p>Don't get me wrong; I do read the papers from those academics who try to analyze /dev/random, and I appreciate their attention.  But I do come from a someone different perspective than they do, and over the years I've learned that it's not wise to blindly take the advice of every single bug report that you get (and I consider papers to be simply formal bug reports :-) since sometimes you can't satisfy every single user and every single bug report.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Insecurities in the Linux /dev/random",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.schneier.com/blog/archives/2013/10/insecurities_in.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-07-09T19:30:47.000Z",
      "title": "",
      "url": "",
      "author": "weland",
      "points": 28,
      "story_text": null,
      "comment_text": "This is actually a very interesting post, and the first one of this level of documentation I&#x27;ve seen in a while. I also actually agree with most of the author&#x27;s points.<p>That being said, I think there&#x27;s a big elephant in the room: the additional layers of complexity. Much of the younger generation in the web development community seems very far removed from the principles of computer engineering, to the point that there&#x27;s a bunch of things you can hint at simply by common sense, yet they are opaque to them. For instance:<p>1. Performance hits aren&#x27;t only due to slower &quot;raw&quot; data processing, they can also occur due to data representation -- think about cache hits, for instance. Your average mobile application&#x27;s processing is more IO-bound than processor-bound. Unless you can guarantee that your data is being efficiently represented, you get a hit from that.<p>2. Since the applications are sandboxed, the amount of memory your runtime occupies is directly subtracted from the amount of memory your application gets. The more layers your runtime piles up that cannot be shared between applications -- the more memory you consume without actually offering any functionality.<p>3. Every additional layer needs some processing time. Writing into a buffer that gets efficiently transfered into video memory is always going to be slower than JIT-ing instructions that write something into a buffer that gets efficiently transfered into video memory -- <i>at the very least</i> the first time around.<p>I&#x27;m not sure if someone is actually trying to say or (futilely) prove that a web application is going to be as fast as a native one (assuming, of course, the native environment is worth a fsck) -- that&#x27;s something people would be able to predict easily. This isn&#x27;t rocket science, as long as you leave the jQuery ivory tower every once in a while.<p>The question of whether it&#x27;s fast <i>enough</i>, on the other hand, is different, but I think it&#x27;s eschewing the wider picture of where &quot;fast&quot; is in the &quot;efficiency&quot; forest.<p>I honestly consider web applications that don&#x27;t actually depend on widely, remotely accessible data for their function to be an inferior technical solution; a music player that is written as a web application but doesn&#x27;t stream data from the Internet and doesn&#x27;t even issue a single HTTP request to a remote server is, IMO, a badly engineered system, due to the additional technical complexity it involves (even if some of it is hidden). That being said, if I had to write a mobile application that should work on more than one platform (or if that platform were Android...), I&#x27;d do it as a web application for other reasons:<p>1. The fragmentation of mobile platforms is incredible. One can <i>barely</i> handle the fragmentation of the Android platform alone, where at least all you need to do is design a handful of UI versions of your app. Due to the closed nature of most of the mobile platforms, web applications are really the only (if inferior, shaggy and poorly-performing) way to write (mostly) portable applications instead of as many applications as platforms.<p>2. Some of the platforms are themselves economically untractable for smaller teams. Android is a prime example of that; even if we skip over the overengineering of the native API, the documentation is simply useless. The odds of having a hundred monkeys produce something on the same level of coherence and legibility as the Android API documentation by typing random letters on a hundred keyboards are so high, Google should consider hiring their local zoo for tech writing consultance. When you have deadlines to meet and limited funding to use (read: you&#x27;re outside your parents&#x27; basement) for a mobile project, you can&#x27;t always afford that kind of stuff.<p>Technically superior, even when measurable in performance, isn&#x27;t always &quot;superior&quot; in the real life. Sure, the fact that a programming environment with bare debugging capabilities, almost no profiling and static analysis capabilities to speak of and limited optimization options at best is the best you can get for mobile applications is sad, but I do hope it&#x27;s just the difficult beginning of an otherwise productive application platform.<p>I also don&#x27;t think the fight is ever going to be resolved. Practical experience shows users&#x27; performance demands are endless: we&#x27;re nearly thirty years from the first Macintosh, and yet modern computers boot slower and applications load slower than they did then. If thirty years haven&#x27;t filled the users&#x27; thirst for good looks and performance, chances are another thirty years won&#x27;t, either, so thirty years from now we&#x27;ll still have people frustrated that web applications (or whatever cancerous growth we&#x27;ll have then) aren&#x27;t fast enough.<p>Edit: there&#x27;s also another point that I wanted to make, but I forgot about it while ranting the things above. It&#x27;s related to this:<p>&gt; Whether or not this works out kind of hinges on your faith in Moores Law in the face of trying to power a chip on a 3-ounce battery.  I am not a hardware engineer, but I once worked for a major semiconductor company, and the people there tell me that these days performance is mostly a function of your process (e.g., the thing they measure in nanometers).   The iPhone 5s impressive performance is due in no small part to a process shrink from 45nm to 32nm  a reduction of about a third.  But to do it again, Apple would have to shrink to a 22nm process.<p>The point the author is trying to make is valid IMHO -- Intel&#x27;s processors do benefit from having a superior fabrication technology, but just like in the case above, &quot;raw&quot; performance is really just one of the trees in the &quot;performance&quot; view.<p>First off, a really advanced, difficult manufacturing process isn&#x27;t nice when you want massive production. ARM isn&#x27;t even on 28 nm yet, which means that the production lines are cheaper; the process is also more reliable, and being able to keep the same manufacturing line in production for a longer time also means the whole thing costs less on a long term. It also works better when you have an economic model like ARM&#x27;s -- you license your chips, rather than producing them. When you have a bunch of vendors competing for the same implementation of a standard, with many of them being able to afford the production tools they need, chances are you&#x27;re going to see lower cost just from the competition effect. There&#x27;s also the matter of power consumption, which isn&#x27;t negligible at all, especially due to batteries being such nasty, difficult beasts (unfortunately, we suck at storing electrical energy).<p>Overall, I think that within a year or two, once the amount of money shoved into mobile systems will reach its peak, we&#x27;ll see a fairly slower rate of performance improvement on mobile platforms, at least in terms of raw processing power. Improvements will start coming from other areas.",
      "num_comments": null,
      "story_id": 6013784,
      "story_title": "Why mobile web apps are slow",
      "story_url": "http://sealedabstract.com/rants/why-mobile-web-apps-are-slow/",
      "parent_id": 6013784,
      "created_at_i": 1373398247,
      "_tags": [
        "comment",
        "author_weland",
        "story_6013784"
      ],
      "objectID": "6014769",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "weland",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is actually a very interesting post, and the first one of this level of documentation I've seen in a while. I also actually agree with most of the author's points.<p>That being said, I think there's a big elephant in the room: the additional layers of complexity. Much of the younger generation in the web development community seems very far removed from the principles of computer engineering, to the point that there's a bunch of things you can hint at simply by common sense, yet they are opaque to them. For instance:<p>1. Performance hits aren't only due to slower &quot;raw&quot; data processing, they can also occur due to data representation -- think about cache hits, for instance. Your average mobile application's processing is more IO-bound than processor-bound. Unless you can guarantee that your data is being efficiently represented, you get a hit from that.<p>2. Since the applications are sandboxed, the amount of memory your runtime occupies is directly subtracted from the amount of memory your application gets. The more layers your runtime piles up that cannot be shared between applications -- the more memory you consume without actually offering any functionality.<p>3. Every additional layer needs some processing time. Writing into a buffer that gets efficiently transfered into video memory is always going to be slower than JIT-ing instructions that write something into a buffer that gets efficiently transfered into video memory -- <i>at the very least</i> the first time around.<p>I'm not sure if someone is actually trying to say or (futilely) prove that a web application is going to be as fast as a native one (assuming, of course, the native environment is worth a fsck) -- that's something people would be able to predict easily. This isn't rocket science, as long as you leave the jQuery ivory tower every once in a while.<p>The question of whether it's fast <i>enough</i>, on the other hand, is different, but I think it's eschewing the wider picture of where &quot;fast&quot; is in the &quot;efficiency&quot; forest.<p>I honestly consider web applications that don't actually depend on widely, remotely accessible data for their function to be an inferior technical solution; a music player that is written as a web application but doesn't stream data from the Internet and doesn't even issue a single HTTP request to a remote server is, IMO, a badly engineered system, due to the additional technical complexity it involves (even if some of it is hidden). That being said, if I had to write a mobile application that should work on more than one platform (or if that platform were Android...), I'd do it as a web application for other reasons:<p>1. The fragmentation of mobile platforms is incredible. One can <i>barely</i> handle the fragmentation of the Android platform alone, where at least all you need to do is design a handful of UI versions of your app. Due to the closed nature of most of the mobile platforms, web applications are really the only (if inferior, shaggy and poorly-performing) way to write (mostly) portable applications instead of as many applications as platforms.<p>2. Some of the platforms are themselves economically untractable for smaller teams. Android is a prime example of that; even if we skip over the overengineering of the native API, the documentation is simply useless. The odds of having a hundred monkeys produce something on the same level of coherence and legibility as the Android API documentation by typing random letters on a hundred keyboards are so high, Google should consider hiring their local zoo for tech writing consultance. When you have deadlines to meet and limited funding to use (read: you're outside your parents' basement) for a mobile project, you can't always afford that kind of stuff.<p>Technically superior, even when measurable in performance, isn't always &quot;superior&quot; in the real life. Sure, the fact that a programming environment with bare debugging capabilities, almost no profiling and <em>static</em> <em>analysis</em> capabilities to speak of and limited optimization options at best is the best you can get for mobile applications is sad, but I do hope it's just the difficult beginning of an otherwise productive application platform.<p>I also don't think the fight is ever going to be resolved. Practical experience shows users' performance demands are endless: we're nearly thirty years from the first Macintosh, and yet modern computers boot slower and applications load slower than they did then. If thirty years haven't filled the users' thirst for good looks and performance, chances are another thirty years won't, either, so thirty years from now we'll still have people frustrated that web applications (or whatever cancerous growth we'll have then) aren't fast enough.<p>Edit: there's also another point that I wanted to make, but I forgot about it while ranting the things above. It's related to this:<p>&gt; Whether or not this works out kind of hinges on your faith in Moores Law in the face of trying to power a chip on a 3-ounce battery.  I am not a hardware engineer, but I once worked for a major semiconductor company, and the people there tell me that these days performance is mostly a function of your process (e.g., the thing they measure in nanometers).   The iPhone 5s impressive performance is due in no small part to a process shrink from 45nm to 32nm  a reduction of about a third.  But to do it again, Apple would have to shrink to a 22nm process.<p>The point the author is trying to make is valid IMHO -- Intel's processors do benefit from having a superior fabrication technology, but just like in the case above, &quot;raw&quot; performance is really just one of the trees in the &quot;performance&quot; view.<p>First off, a really advanced, difficult manufacturing process isn't nice when you want massive production. ARM isn't even on 28 nm yet, which means that the production lines are cheaper; the process is also more reliable, and being able to keep the same manufacturing line in production for a longer time also means the whole thing costs less on a long term. It also works better when you have an economic model like ARM's -- you license your chips, rather than producing them. When you have a bunch of vendors competing for the same implementation of a standard, with many of them being able to afford the production <em>tools</em> they need, chances are you're going to see lower cost just from the competition effect. There's also the matter of power consumption, which isn't negligible at all, especially due to batteries being such nasty, difficult beasts (unfortunately, we suck at storing electrical energy).<p>Overall, I think that within a year or two, once the amount of money shoved into mobile systems will reach its peak, we'll see a fairly slower rate of performance improvement on mobile platforms, at least in terms of raw processing power. Improvements will start coming from other areas.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why mobile web apps are slow",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://sealedabstract.com/rants/why-mobile-web-apps-are-slow/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-28T09:49:29.000Z",
      "title": "",
      "url": "",
      "author": "Wintamute",
      "points": 26,
      "story_text": null,
      "comment_text": "Up until a few years ago I was a full time Flash developer, working in ActionScript3 which is a strictly typed, fully OO language which conforms completely with the 4th edition of ECMAScript. I used a great IDE (FlashBuilder) that had full code introspection, static analysis, amazing auto-complete and all sorts of great features built in. Unit testing was not uncommon, as was continuous integration, automated build processes and version control. I, and many others, were doing \"real\" programming on the Flash platform and felt totally understood as a developer by Adobe.<p>I'm not going to defend Flash's continued relevance on the web because like most people I think it's had its day but from about 2003 to 2010 the Flash developer community was massive and thriving, people were doing serious programming and Adobe was doing a pretty good job of understanding them and supporting them. It's this wealth of experience that I hope Adobe brings to bear on its HTML5 developer tools.<p>I feel like the relevance of Flash (and Adobe) is really quite poorly understood. A lot of the expertise and good practises from the more serious elements of the Flash community flooded into the JavaScript community and I feel this is one of the reasons JavaScript has developed so quickly. What's more, a lot of the \"web2.0\" style dynamic and interactive elements of websites that we take for granted now are watered down (and much better) versions of ideas that were conceived during those frenzied years of UI experimentation in the Flash community.<p>Granted those years of Flash threw up some UI abominations, but it was also a melting pot of ideas and creativity, the like of which we don't really see anymore, which is a shame in a way. Even though Flash was my livelihood I was happy to move on because I could see it was for the best, but if you ignore Flash your understanding of the last 10 years and the current context of web development is impoverished.",
      "num_comments": null,
      "story_id": 4584625,
      "story_title": "Does Adobe finally understand developers?",
      "story_url": "http://designshack.net/articles/software/adobe-edge-does-adobe-finally-understand-developers/",
      "parent_id": 4584735,
      "created_at_i": 1348825769,
      "_tags": [
        "comment",
        "author_Wintamute",
        "story_4584625"
      ],
      "objectID": "4584845",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Wintamute",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Up until a few years ago I was a full time Flash developer, working in ActionScript3 which is a strictly typed, fully OO language which conforms completely with the 4th edition of ECMAScript. I used a great IDE (FlashBuilder) that had full code introspection, <em>static</em> <em>analysis</em>, amazing auto-complete and all sorts of great features built in. Unit testing was not uncommon, as was continuous integration, automated build processes and version control. I, and many others, were doing \"real\" programming on the Flash platform and felt totally understood as a developer by Adobe.<p>I'm not going to defend Flash's continued relevance on the web because like most people I think it's had its day but from about 2003 to 2010 the Flash developer community was massive and thriving, people were doing serious programming and Adobe was doing a pretty good job of understanding them and supporting them. It's this wealth of experience that I hope Adobe brings to bear on its HTML5 developer <em>tools</em>.<p>I feel like the relevance of Flash (and Adobe) is really quite poorly understood. A lot of the expertise and good practises from the more serious elements of the Flash community flooded into the JavaScript community and I feel this is one of the reasons JavaScript has developed so quickly. What's more, a lot of the \"web2.0\" style dynamic and interactive elements of websites that we take for granted now are watered down (and much better) versions of ideas that were conceived during those frenzied years of UI experimentation in the Flash community.<p>Granted those years of Flash threw up some UI abominations, but it was also a melting pot of ideas and creativity, the like of which we don't really see anymore, which is a shame in a way. Even though Flash was my livelihood I was happy to move on because I could see it was for the best, but if you ignore Flash your understanding of the last 10 years and the current context of web development is impoverished.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Does Adobe finally understand developers?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://designshack.net/articles/software/adobe-edge-does-adobe-finally-understand-developers/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-09-16T09:50:50.000Z",
      "title": "",
      "url": "",
      "author": "natch",
      "points": 22,
      "story_text": null,
      "comment_text": "I love composability as much as the author, but his opinion is, to put it kindly, not well informed. iOS has a myriad of mechanisms for sharing content within and between apps, bot from the same developer and from different developers, with and without prior agreement, and for composing workflows and experiences that are greater than the sum of the parts.<p>Some of these mechanisms are new, and the possibilities have not yet been fully plumbed. Some have been around for a while.<p>But iOS is just getting started. People said the iPad was a \"read-only\" or \"consumption-only\" device, but, over time, we have seen tools come out that are great authoring tools for various types of content. The same thing will happen (and already has happened, but is growing over time) with cross-app workflows.<p>As far as the title, \"anti-Unix and anti-programmer,\" taking the first part, well yes it doesn't provide a built in command line for programmers, if that's what he means, although it does happen to be built on UNIX, and it benefits from the maturity of UNIX (and gives back, with OSS tools like LLVM).<p>On the second part, the tools it does provide for programmers are truly wonderful - the Objective-C language, the frameworks, an amazing compiler with static analysis (if you don't know what this gives you, the answer is pure joy), the development environment (though Xcode 4 had a rocky rollout, it has proven itself to be a sweet update), the patterns that are used and encouraged, and the architectural choices, are all very well thought out.<p>Programmers coming from other mobile platforms have told me that they left behind a lot of pain, and found a lot of power on iOS.<p>\"Anti-programmer\" is a very odd way to describe a platform that makes programmers who get into it happy with their coding experience, makes them money, and gives users a great experience while keeping their private information secure from abuses by ill-intentioned programmers.<p>I can't help but be baffled by where he is coming from. I love UNIX, the command line, and composing commands, but then I love cooking in the kitchen too. Different environments come with different tools.<p>If we want to compare just mobile development environments, iOS is one that has clearly been developed with a careful deliberative process intended to preserve good battery life, protect user data, and avoid painting itself into any architectural corners. There are constraints. There always are.<p>But iOS is growing, with very exciting (for programmers) features with every update, including deep stuff that goes down to the core architectural level of how your data flows in your program, in ways that promise a very, very happy life for iOS programmers on multiple core devices. The future is very bright for iOS programming.<p>The \"anti-freedom\" charges, the locking out of certain features, you get the same stuff on any platform. Just try to publish an app that abuses the Android logo in any Android market. Not that you would want to, but then, I wouldn't want to publish an app that steals user data, and that's exactly the kind of thing iOS does not give me the \"freedom\" to do... and that's a <i>good</i> thing. All the mechanisms for preventing abuse could have been done in a much more heavy-handed way, such as by being tied to a central email account that you use to authenticate to dozens of critical services you depend on in your life, that can be yanked and shut down at any time, with a very tenuous appeal process. As developers we are lucky to have a platform that has done things in such sensible ways.",
      "num_comments": null,
      "story_id": 3003470,
      "story_title": "iOS is anti-Unix and anti-programmer",
      "story_url": "http://blog.dbpatterson.com/post/10244529137",
      "parent_id": 3003470,
      "created_at_i": 1316166650,
      "_tags": [
        "comment",
        "author_natch",
        "story_3003470"
      ],
      "objectID": "3003831",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "natch",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I love composability as much as the author, but his opinion is, to put it kindly, not well informed. iOS has a myriad of mechanisms for sharing content within and between apps, bot from the same developer and from different developers, with and without prior agreement, and for composing workflows and experiences that are greater than the sum of the parts.<p>Some of these mechanisms are new, and the possibilities have not yet been fully plumbed. Some have been around for a while.<p>But iOS is just getting started. People said the iPad was a \"read-only\" or \"consumption-only\" device, but, over time, we have seen <em>tools</em> come out that are great authoring <em>tools</em> for various types of content. The same thing will happen (and already has happened, but is growing over time) with cross-app workflows.<p>As far as the title, \"anti-Unix and anti-programmer,\" taking the first part, well yes it doesn't provide a built in command line for programmers, if that's what he means, although it does happen to be built on UNIX, and it benefits from the maturity of UNIX (and gives back, with OSS <em>tools</em> like LLVM).<p>On the second part, the <em>tools</em> it does provide for programmers are truly wonderful - the Objective-C language, the frameworks, an amazing compiler with <em>static</em> <em>analysis</em> (if you don't know what this gives you, the answer is pure joy), the development environment (though Xcode 4 had a rocky rollout, it has proven itself to be a sweet update), the patterns that are used and encouraged, and the architectural choices, are all very well thought out.<p>Programmers coming from other mobile platforms have told me that they left behind a lot of pain, and found a lot of power on iOS.<p>\"Anti-programmer\" is a very odd way to describe a platform that makes programmers who get into it happy with their coding experience, makes them money, and gives users a great experience while keeping their private information secure from abuses by ill-intentioned programmers.<p>I can't help but be baffled by where he is coming from. I love UNIX, the command line, and composing commands, but then I love cooking in the kitchen too. Different environments come with different <em>tools</em>.<p>If we want to compare just mobile development environments, iOS is one that has clearly been developed with a careful deliberative process intended to preserve good battery life, protect user data, and avoid painting itself into any architectural corners. There are constraints. There always are.<p>But iOS is growing, with very exciting (for programmers) features with every update, including deep stuff that goes down to the core architectural level of how your data flows in your program, in ways that promise a very, very happy life for iOS programmers on multiple core devices. The future is very bright for iOS programming.<p>The \"anti-freedom\" charges, the locking out of certain features, you get the same stuff on any platform. Just try to publish an app that abuses the Android logo in any Android market. Not that you would want to, but then, I wouldn't want to publish an app that steals user data, and that's exactly the kind of thing iOS does not give me the \"freedom\" to do... and that's a <i>good</i> thing. All the mechanisms for preventing abuse could have been done in a much more heavy-handed way, such as by being tied to a central email account that you use to authenticate to dozens of critical services you depend on in your life, that can be yanked and shut down at any time, with a very tenuous appeal process. As developers we are lucky to have a platform that has done things in such sensible ways.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "iOS is anti-Unix and anti-programmer",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.dbpatterson.com/post/10244529137",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-11-03T21:19:46.000Z",
      "title": "",
      "url": "",
      "author": "sparky",
      "points": 21,
      "story_text": null,
      "comment_text": "This page is a good high-level summary: <a href=\"http://code.google.com/p/address-sanitizer/wiki/ComparisonOfMemoryTools\" rel=\"nofollow\">http://code.google.com/p/address-sanitizer/wiki/ComparisonOf...</a> .<p>I've used most of the tools on that page, including Valgrind.  Valgrind <i>interprets</i> your program, and hooks loads, stores, malloc/free, etc. to track memory usage.  ASan is a compiler pass that inserts extra instructions around loads and stores to drive per-address state machines that live in a shadow area of memory.<p>Valgrind is slow (20x-50x for serial programs, more for parallel programs because Valgrind only executes one thread at a time), but can detect reads from uninitialized memory because your program is essentially executing in a VM.  ASan is much faster, especially if the compiler pass can avoid instrumenting some loads/stores based on static analysis, and cannot detect reads from uninitialized memory, but can detect most other kinds of memory areas.<p>They're both thread-safe, so you can use them to debug parallel programs.  As mentioned above, Valgrind is much slower at this, and until recently [1] you would never see most race conditions in multithreaded programs because Valgrind's schedule would run each thread until it yielded voluntarily, rather than pre-empting and time-multiplexing between threads.  In contrast, with ASan all threads are running close to at-speed and simultaneously, so in my case performance was &#62;100x better <i>and</i> I actually saw the race conditions I cared about.<p>Valgrind supports more platforms than ASan (see [2] vs. [3]), and does not require compiler support (so you can use it to debug code from any compiler), but does tend to lag behind new platform features a bit.  For example, until recently it borked if you used the new x86_64 RDTSCP instruction.<p>Mudflap seems similar in concept, but there appear to be issues with the implementation (see \"Known Shortcomings\" at [4])<p>[1] 3.8.0 and on have the --fair-sched=yes option <a href=\"http://valgrind.org/docs/manual/manual-core.html#manual-core.pthreads_perf_sched\" rel=\"nofollow\">http://valgrind.org/docs/manual/manual-core.html#manual-core...</a>\n[2] <a href=\"http://valgrind.org/info/platforms.html\" rel=\"nofollow\">http://valgrind.org/info/platforms.html</a>\n[3] <a href=\"http://llvm.org/releases/3.1/tools/clang/docs/AddressSanitizer.html\" rel=\"nofollow\">http://llvm.org/releases/3.1/tools/clang/docs/AddressSanitiz...</a>\n[4] <a href=\"http://gcc.gnu.org/wiki/Mudflap_Pointer_Debugging\" rel=\"nofollow\">http://gcc.gnu.org/wiki/Mudflap_Pointer_Debugging</a>",
      "num_comments": null,
      "story_id": 4737423,
      "story_title": "Google Address Sanitizer (\"compile-time valgrind\") to be part of GCC 4.8",
      "story_url": "http://gcc.gnu.org/ml/gcc-patches/2012-11/msg00088.html",
      "parent_id": 4737647,
      "created_at_i": 1351977586,
      "_tags": [
        "comment",
        "author_sparky",
        "story_4737423"
      ],
      "objectID": "4737946",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "sparky",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This page is a good high-level summary: <a href=\"http://code.google.com/p/address-sanitizer/wiki/ComparisonOfMemoryTools\" rel=\"nofollow\">http://code.google.com/p/address-sanitizer/wiki/ComparisonOf...</a> .<p>I've used most of the <em>tools</em> on that page, including Valgrind.  Valgrind <i>interprets</i> your program, and hooks loads, stores, malloc/free, etc. to track memory usage.  ASan is a compiler pass that inserts extra instructions around loads and stores to drive per-address state machines that live in a shadow area of memory.<p>Valgrind is slow (20x-50x for serial programs, more for parallel programs because Valgrind only executes one thread at a time), but can detect reads from uninitialized memory because your program is essentially executing in a VM.  ASan is much faster, especially if the compiler pass can avoid instrumenting some loads/stores based on <em>static</em> <em>analysis</em>, and cannot detect reads from uninitialized memory, but can detect most other kinds of memory areas.<p>They're both thread-safe, so you can use them to debug parallel programs.  As mentioned above, Valgrind is much slower at this, and until recently [1] you would never see most race conditions in multithreaded programs because Valgrind's schedule would run each thread until it yielded voluntarily, rather than pre-empting and time-multiplexing between threads.  In contrast, with ASan all threads are running close to at-speed and simultaneously, so in my case performance was >100x better <i>and</i> I actually saw the race conditions I cared about.<p>Valgrind supports more platforms than ASan (see [2] vs. [3]), and does not require compiler support (so you can use it to debug code from any compiler), but does tend to lag behind new platform features a bit.  For example, until recently it borked if you used the new x86_64 RDTSCP instruction.<p>Mudflap seems similar in concept, but there appear to be issues with the implementation (see \"Known Shortcomings\" at [4])<p>[1] 3.8.0 and on have the --fair-sched=yes option <a href=\"http://valgrind.org/docs/manual/manual-core.html#manual-core.pthreads_perf_sched\" rel=\"nofollow\">http://valgrind.org/docs/manual/manual-core.html#manual-core...</a>\n[2] <a href=\"http://valgrind.org/info/platforms.html\" rel=\"nofollow\">http://valgrind.org/info/platforms.html</a>\n[3] <a href=\"http://llvm.org/releases/3.1/tools/clang/docs/AddressSanitizer.html\" rel=\"nofollow\">http://llvm.org/releases/3.1/<em>tools</em>/clang/docs/AddressSanitiz...</a>\n[4] <a href=\"http://gcc.gnu.org/wiki/Mudflap_Pointer_Debugging\" rel=\"nofollow\">http://gcc.gnu.org/wiki/Mudflap_Pointer_Debugging</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Google Address Sanitizer (\"compile-time valgrind\") to be part of GCC 4.8",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://gcc.gnu.org/ml/gcc-patches/2012-11/msg00088.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-08-23T19:19:22.000Z",
      "title": "",
      "url": "",
      "author": "Arjuna",
      "points": 20,
      "story_text": null,
      "comment_text": "Interesting comments on Mac and Linux platforms [1]:<p><i>\"Other interesting sort of PC-ish platforms, we have... the Mac still remains a viable platform for us. The Mac has never required any charity from id, all of those ports have carried their own weight there; they've been viable business platforms.<p>I actually think that the Mac is going to become a little bit more important for us. Interestingly, we have a ton of people that use, like Macbooks at the office, but we don't have any really rabid, OS X fanboys at the company that drive us to go ahead and get the native ports out early.<p>But, one of my pushes on the greater use of static analysis and verification technologies, is I pretty strongly suspect that the Clang LLVM sort of ecosystem that's living on OS X is going to be, I hope, fertile ground for a whole lot of analysis tools and we'll wind up benefiting by moving more of our platform continuously onto OS X just for that ability to take advantage of additional tools there.<p>Linux is an issue that's taken a lot more currency with Valve announcing Steam for Linux, and that does change, factor, you know, changes things a bit, but we've made two forays into the Linux commercial market, most recently with Quake Live client, and, you know, that platform just hasn't carried its weight compared to the Mac on there. It's great that people are enthusiastic about it, but there's just not nearly as many people that are interested in paying for a game on the platform, and that just seems to be the reality. Valve will probably pull a bunch more people there. I know absolutely nothing about any Valve plans for console, Steam-box stuff on there; I can speculate without violating anything.<p>One thing that also speaks to the favor of Linux and potential open source things is that the integrated graphics cards are getting better and better, and they really are good enough now. Intel's latest integrated graphics cards are good. The drivers still have issues. They're still certainly not going to blow away somebody's top of the line SLI system, but they are completely competent parts that are delivering pretty good performance.<p>And one of the wonderful things is that Intel has been completely supportive of open source driver efforts, that they have chipset docs out there, and they work openly with community to develop that, and that's pretty wonderful. I mean, anybody that's a graphics guy, if you program to a graphics API, use D3D or OpenGL, you owe it to yourself at some point to go download the Intel chipset docs. There's hundreds of pages of them, but you really should read through and see what happens at the hardware level. It's not the same architecture that Invida and AMD have on there, but there's a lot of commonalities there. You'll grow as a graphics developer to know what happens down at the bit level.<p>Another one of those things, if I had more time, if I could go ahead and clone myself a few times, I would love to be involved in working on optimizing the Intel open source drivers there.<p>So, it's enticing, the thought there that you might have a well-supported, completely open platform that you could deliver content through the Steam ecosystem there. It's a tough sell on there, but Valve gets huge kudos for having the vision for what they did with Steam, sticking through all of it. It's funny talking about Doom 3, where we can remember back in the days when they're like, 'Well, should you ship Doom 3 on Steam, go out there, make a splash?' ... I'm like, 'You're kidding, right?' That made no sense at all at that time, but you know Valve stuck with it and they're in a really enviable position from all of that now.<p>It still seems, probably crazy to me that they would be doing anything like that, you know, but, it's something that's not technically impossible, but would be really difficult from a market, sort of ecosystems standpoint.\"</i><p>[1] <a href=\"https://www.youtube.com/watch?v=wt-iVFxgFWk#t=44m28s\" rel=\"nofollow\">https://www.youtube.com/watch?v=wt-iVFxgFWk#t=44m28s</a>",
      "num_comments": null,
      "story_id": 4423031,
      "story_title": "John Carmack discusses the art and science of software engineering",
      "story_url": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
      "parent_id": 4423031,
      "created_at_i": 1345749562,
      "_tags": [
        "comment",
        "author_Arjuna",
        "story_4423031"
      ],
      "objectID": "4424334",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Arjuna",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Interesting comments on Mac and Linux platforms [1]:<p><i>\"Other interesting sort of PC-ish platforms, we have... the Mac still remains a viable platform for us. The Mac has never required any charity from id, all of those ports have carried their own weight there; they've been viable business platforms.<p>I actually think that the Mac is going to become a little bit more important for us. Interestingly, we have a ton of people that use, like Macbooks at the office, but we don't have any really rabid, OS X fanboys at the company that drive us to go ahead and get the native ports out early.<p>But, one of my pushes on the greater use of <em>static</em> <em>analysis</em> and verification technologies, is I pretty strongly suspect that the Clang LLVM sort of ecosystem that's living on OS X is going to be, I hope, fertile ground for a whole lot of <em>analysis</em> <em>tools</em> and we'll wind up benefiting by moving more of our platform continuously onto OS X just for that ability to take advantage of additional <em>tools</em> there.<p>Linux is an issue that's taken a lot more currency with Valve announcing Steam for Linux, and that does change, factor, you know, changes things a bit, but we've made two forays into the Linux commercial market, most recently with Quake Live client, and, you know, that platform just hasn't carried its weight compared to the Mac on there. It's great that people are enthusiastic about it, but there's just not nearly as many people that are interested in paying for a game on the platform, and that just seems to be the reality. Valve will probably pull a bunch more people there. I know absolutely nothing about any Valve plans for console, Steam-box stuff on there; I can speculate without violating anything.<p>One thing that also speaks to the favor of Linux and potential open source things is that the integrated graphics cards are getting better and better, and they really are good enough now. Intel's latest integrated graphics cards are good. The drivers still have issues. They're still certainly not going to blow away somebody's top of the line SLI system, but they are completely competent parts that are delivering pretty good performance.<p>And one of the wonderful things is that Intel has been completely supportive of open source driver efforts, that they have chipset docs out there, and they work openly with community to develop that, and that's pretty wonderful. I mean, anybody that's a graphics guy, if you program to a graphics API, use D3D or OpenGL, you owe it to yourself at some point to go download the Intel chipset docs. There's hundreds of pages of them, but you really should read through and see what happens at the hardware level. It's not the same architecture that Invida and AMD have on there, but there's a lot of commonalities there. You'll grow as a graphics developer to know what happens down at the bit level.<p>Another one of those things, if I had more time, if I could go ahead and clone myself a few times, I would love to be involved in working on optimizing the Intel open source drivers there.<p>So, it's enticing, the thought there that you might have a well-supported, completely open platform that you could deliver content through the Steam ecosystem there. It's a tough sell on there, but Valve gets huge kudos for having the vision for what they did with Steam, sticking through all of it. It's funny talking about Doom 3, where we can remember back in the days when they're like, 'Well, should you ship Doom 3 on Steam, go out there, make a splash?' ... I'm like, 'You're kidding, right?' That made no sense at all at that time, but you know Valve stuck with it and they're in a really enviable position from all of that now.<p>It still seems, probably crazy to me that they would be doing anything like that, you know, but, it's something that's not technically impossible, but would be really difficult from a market, sort of ecosystems standpoint.\"</i><p>[1] <a href=\"https://www.youtube.com/watch?v=wt-iVFxgFWk#t=44m28s\" rel=\"nofollow\">https://www.youtube.com/watch?v=wt-iVFxgFWk#t=44m28s</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack discusses the art and science of software engineering",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-19T20:43:31.000Z",
      "title": null,
      "url": null,
      "author": "6cxs2hd6",
      "points": 16,
      "story_text": null,
      "comment_text": "&gt; <i>How can a static analysis tool keep up with a language that’s being arbitrarily extended at runtime? The prospect is daunting.</i><p>I don&#x27;t really understand that point. In Racket, for example, programs macro-expand down to a very small set of primitives, such as `let-values` and `lambda`. This makes it easier to do analysis, not harder. For example, this is how something like Typed Racket can support every idiom in untyped Racket programs -- because they all expand down to a fairly manageable core set of forms. (Or if you need to analyze something no-so-primtive, you can stop expansion on whatever that is.)<p>Racket is descended from Scheme. I don&#x27;t know if CL or Clojure expand down to quite such a small primitive core, but I imagine the story is roughly similar?<p>Anyway, writing such tools is not what the average programmer would do on a putative large project.<p>Any large project needs technical and social norms, mentoring, and leadership -- regardless of language. I think the language is the smallest part of it. Perhaps like how in security it&#x27;s social not technical engineering that usually turns out to be the weakest link.",
      "num_comments": null,
      "story_id": 7085682,
      "story_title": "Lisp: More is less",
      "story_url": "http://jameso.be/2014/01/19/lisp.html",
      "parent_id": 7085682,
      "created_at_i": 1390164211,
      "_tags": [
        "comment",
        "author_6cxs2hd6",
        "story_7085682"
      ],
      "objectID": "7085911",
      "_highlightResult": {
        "author": {
          "value": "6cxs2hd6",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; <i>How can a <em>static</em> <em>analysis</em> tool keep up with a language that’s being arbitrarily extended at runtime? The prospect is daunting.</i><p>I don't really understand that point. In Racket, for example, programs macro-expand down to a very small set of primitives, such as `let-values` and `lambda`. This makes it easier to do <em>analysis</em>, not harder. For example, this is how something like Typed Racket can support every idiom in untyped Racket programs -- because they all expand down to a fairly manageable core set of forms. (Or if you need to analyze something no-so-primtive, you can stop expansion on whatever that is.)<p>Racket is descended from Scheme. I don't know if CL or Clojure expand down to quite such a small primitive core, but I imagine the story is roughly similar?<p>Anyway, writing such <em>tools</em> is not what the average programmer would do on a putative large project.<p>Any large project needs technical and social norms, mentoring, and leadership -- regardless of language. I think the language is the smallest part of it. Perhaps like how in security it's social not technical engineering that usually turns out to be the weakest link.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lisp: More is less",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://jameso.be/2014/01/19/lisp.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-08T14:02:41.000Z",
      "title": null,
      "url": null,
      "author": "pjmlp",
      "points": 15,
      "story_text": null,
      "comment_text": "&gt; IDE&#x27;s miss the point.<p>No, because IDE are more than just coding.<p>They offer an integration of services that one usually requires in large scale projects.<p>I want:<p>- semantic refactoring<p>- background compilation as I type<p>- static analysis<p>- integration with bug tracking software and source control<p>- visual debugging of data structures, threads<p>- ability to change code during debbuging sessions<p>- navigation of binary artifacts<p>- debugging unit tests<p>- semantic code navigation<p>- GUI designers<p>- XML build tools<p>- visual navigation of databases<p>- UML dual way generation<p>- ...<p>And above all, avoid trying to make Emacs or VIM do half of these features, every time I install them.",
      "num_comments": null,
      "story_id": 8283992,
      "story_title": "CLion, the new C/C++ IDE from JetBrains",
      "story_url": "http://www.jetbrains.com/clion/",
      "parent_id": 8284619,
      "created_at_i": 1410184961,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_8283992"
      ],
      "objectID": "8284733",
      "_highlightResult": {
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; IDE's miss the point.<p>No, because IDE are more than just coding.<p>They offer an integration of services that one usually requires in large scale projects.<p>I want:<p>- semantic refactoring<p>- background compilation as I type<p>- <em>static</em> <em>analysis</em><p>- integration with bug tracking software and source control<p>- visual debugging of data structures, threads<p>- ability to change code during debbuging sessions<p>- navigation of binary artifacts<p>- debugging unit tests<p>- semantic code navigation<p>- GUI designers<p>- XML build <em>tools</em><p>- visual navigation of databases<p>- UML dual way generation<p>- ...<p>And above all, avoid trying to make Emacs or VIM do half of these features, every time I install them.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "CLion, the new C/C++ IDE from JetBrains",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.jetbrains.com/clion/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-14T00:01:10.000Z",
      "title": null,
      "url": null,
      "author": "tikhonj",
      "points": 13,
      "story_text": null,
      "comment_text": "Pandoc is a wonderful tool and by extension a wonderful library. It takes a simple idea--convert between different document formats--and executes it very well. It then turns out that this simple idea is extremely handy.<p>This article about the API shows how it uses a great design: the actual tool is written as a frontend to a generic library. This way, the actual logic is not tied to the frontend at all; the dependency flows from the logic to the interface. Since it&#x27;s designed as a library first, the API is a first-class citizen. Using it never feels like scripting an app, because it isn&#x27;t.<p>I really like this way of separating concerns. It makes the &quot;meat&quot; of the program so much more useful and reusable. Moreover, there is no reason not to use this approach for GUI apps as well, but I see it all too rarely.<p>It would be particularly nice for IDEs. There&#x27;s no reason why all the great refactoring and analysis tools need to be tied to a given frontend. I&#x27;d rather have the two clearly split to make the backend much easier to reuse and repurpose.<p>This sort of design is implicitly encouraged by Haskell (as in the case of Pandoc). The language naturally pushes you to carefully split the logic and the interface, partly through managing IO explicitly. Even the build tool pushes you in this direction, making it very easy to build both a library and an executable at the same time. Of course, this is also very easy to do in other languages, although I&#x27;ve found it a bit easier to mix concerns in an OOP setting. It&#x27;s just too easy to add a render method to your Document class instead of maintaining a strict separation; this is especially true if Document contains extensive private state.<p>I really hope future tools will continue with this sort of split design so that building new things on top of them continues to be easy. I&#x27;ve already benefited from this with Pandoc: the static site generator I use is built on top of Pandoc, giving it some very nice capabilities. Since it uses Pandoc as a library, it&#x27;s more powerful than just passing files through the tool--the configuration can also use and depend on variables in the Pandoc templates, for example, which is very useful and requires  programmatic access to Pandoc&#x27;s internals.",
      "num_comments": null,
      "story_id": 6903223,
      "story_title": "24 Days of Hackage: pandoc",
      "story_url": "http://ocharles.org.uk/blog/guest-posts/2013-12-12-24-days-of-hackage-pandoc.html",
      "parent_id": 6903223,
      "created_at_i": 1386979270,
      "_tags": [
        "comment",
        "author_tikhonj",
        "story_6903223"
      ],
      "objectID": "6903650",
      "_highlightResult": {
        "author": {
          "value": "tikhonj",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Pandoc is a wonderful tool and by extension a wonderful library. It takes a simple idea--convert between different document formats--and executes it very well. It then turns out that this simple idea is extremely handy.<p>This article about the API shows how it uses a great design: the actual tool is written as a frontend to a generic library. This way, the actual logic is not tied to the frontend at all; the dependency flows from the logic to the interface. Since it's designed as a library first, the API is a first-class citizen. Using it never feels like scripting an app, because it isn't.<p>I really like this way of separating concerns. It makes the &quot;meat&quot; of the program so much more useful and reusable. Moreover, there is no reason not to use this approach for GUI apps as well, but I see it all too rarely.<p>It would be particularly nice for IDEs. There's no reason why all the great refactoring and <em>analysis</em> <em>tools</em> need to be tied to a given frontend. I'd rather have the two clearly split to make the backend much easier to reuse and repurpose.<p>This sort of design is implicitly encouraged by Haskell (as in the case of Pandoc). The language naturally pushes you to carefully split the logic and the interface, partly through managing IO explicitly. Even the build tool pushes you in this direction, making it very easy to build both a library and an executable at the same time. Of course, this is also very easy to do in other languages, although I've found it a bit easier to mix concerns in an OOP setting. It's just too easy to add a render method to your Document class instead of maintaining a strict separation; this is especially true if Document contains extensive private state.<p>I really hope future <em>tools</em> will continue with this sort of split design so that building new things on top of them continues to be easy. I've already benefited from this with Pandoc: the <em>static</em> site generator I use is built on top of Pandoc, giving it some very nice capabilities. Since it uses Pandoc as a library, it's more powerful than just passing files through the tool--the configuration can also use and depend on variables in the Pandoc templates, for example, which is very useful and requires  programmatic access to Pandoc's internals.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "24 Days of Hackage: pandoc",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ocharles.org.uk/blog/guest-posts/2013-12-12-24-days-of-hackage-pandoc.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T14:50:39.000Z",
      "title": null,
      "url": null,
      "author": "notacoward",
      "points": 12,
      "story_text": null,
      "comment_text": "Maybe the silver lining here is that it puts the final nail in the coffin for &quot;many eyes make all bugs shallow&quot; - which was always total BS from the day it was uttered.  There&#x27;s so much code out there, much of it highly specialized and even project-specific, that there are very few eyes looking at any particular piece of code, and not all eyes are connected to the greatest of brains.<p>Most static code analyzers could have caught this particular bug, as it requires only a fairly simple kind of reasoning about allocated vs. used length. In fact I believe it probably <i>was</i> found by static analysis before being reported by a human, which is a shame because it misses an opportunity to highlight the value of such tools.  Maybe next time people will spend a little less time designing a logo and a little more time doing things that actually help (though that&#x27;s a wish and what I <i>expect</i> is the exact opposite).<p>The real lesson here is that we should apply as many different tools and processes as we can at improving code quality for critical infrastructure.  Code reviews are nice.  Static analysis is nice.  Detailed tests are nice.  However, <i>none</i> of these alone is sufficient even when pursued with fanatical devotion.",
      "num_comments": null,
      "story_id": 7565764,
      "story_title": "'Heartbleed' contributor denies he inserted it deliberately",
      "story_url": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
      "parent_id": 7565764,
      "created_at_i": 1397141439,
      "_tags": [
        "comment",
        "author_notacoward",
        "story_7565764"
      ],
      "objectID": "7566590",
      "_highlightResult": {
        "author": {
          "value": "notacoward",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Maybe the silver lining here is that it puts the final nail in the coffin for &quot;many eyes make all bugs shallow&quot; - which was always total BS from the day it was uttered.  There's so much code out there, much of it highly specialized and even project-specific, that there are very few eyes looking at any particular piece of code, and not all eyes are connected to the greatest of brains.<p>Most <em>static</em> code analyzers could have caught this particular bug, as it requires only a fairly simple kind of reasoning about allocated vs. used length. In fact I believe it probably <i>was</i> found by <em>static</em> <em>analysis</em> before being reported by a human, which is a shame because it misses an opportunity to highlight the value of such <em>tools</em>.  Maybe next time people will spend a little less time designing a logo and a little more time doing things that actually help (though that's a wish and what I <i>expect</i> is the exact opposite).<p>The real lesson here is that we should apply as many different <em>tools</em> and processes as we can at improving code quality for critical infrastructure.  Code reviews are nice.  <em>Static</em> <em>analysis</em> is nice.  Detailed tests are nice.  However, <i>none</i> of these alone is sufficient even when pursued with fanatical devotion.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "'Heartbleed' contributor denies he inserted it deliberately",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-23T01:38:32.000Z",
      "title": null,
      "url": null,
      "author": "spiralpolitik",
      "points": 12,
      "story_text": null,
      "comment_text": "The vp of engineering should have invested in a good static analysis tool which would have spotted this section in about five seconds. Failing that turning on a sensible set of defaults in the compiler (warning about unreachable code) would have also drawn attention to it.<p>There are many many ways this should have been caught before it even left the building by numerous automated tools. Heck most modern IDEs will flag unreachable code in the editor so there is no real excuse for this. (Adding -Wunreachable-code to a sample project in Xcode immediately flags the next line).<p>The programmer is human which is why automated verification tools exist.<p>(AppCode&#x27;s default inspections will also flag the issue providing you run them)",
      "num_comments": null,
      "story_id": 7284099,
      "story_title": "On the Timing of iOS’s SSL Vulnerability and Apple’s ‘Addition’ to NSA’s PRISM",
      "story_url": "http://daringfireball.net/2014/02/apple_prism",
      "parent_id": 7284546,
      "created_at_i": 1393119512,
      "_tags": [
        "comment",
        "author_spiralpolitik",
        "story_7284099"
      ],
      "objectID": "7284574",
      "_highlightResult": {
        "author": {
          "value": "spiralpolitik",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The vp of engineering should have invested in a good <em>static</em> <em>analysis</em> tool which would have spotted this section in about five seconds. Failing that turning on a sensible set of defaults in the compiler (warning about unreachable code) would have also drawn attention to it.<p>There are many many ways this should have been caught before it even left the building by numerous automated <em>tools</em>. Heck most modern IDEs will flag unreachable code in the editor so there is no real excuse for this. (Adding -Wunreachable-code to a sample project in Xcode immediately flags the next line).<p>The programmer is human which is why automated verification <em>tools</em> exist.<p>(AppCode's default inspections will also flag the issue providing you run them)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "On the Timing of iOS’s SSL Vulnerability and Apple’s ‘Addition’ to NSA’s PRISM",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://daringfireball.net/2014/02/apple_prism",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-24T20:24:16.000Z",
      "title": "",
      "url": "",
      "author": "masklinn",
      "points": 12,
      "story_text": null,
      "comment_text": "&gt; I&#x27;m under the impression that Python is not compiled generally.<p>The direct ancestor to today&#x27;s IDEs are Smalltalk environments. Smalltalk is about as un-compiled as you can get. This and that are completely orthogonal concerns.<p>&gt; In what ways could it be helpful?<p>Navigation across projects (via structural searches or hyperlinking), static analysis (including library- or framework-specific e.g. PyCharm knows some strings have specific meaning in django projects and can check that there&#x27;s no mismatch), refactorings, documentation, visual debugging, ...<p>Some of it can be replicated with extensively customized editor and a multitude of external tools, others not really.",
      "num_comments": null,
      "story_id": 6439431,
      "story_title": "JetBrains releases open-source Python IDE",
      "story_url": "http://www.jetbrains.com/pycharm/",
      "parent_id": 6440465,
      "created_at_i": 1380054256,
      "_tags": [
        "comment",
        "author_masklinn",
        "story_6439431"
      ],
      "objectID": "6440517",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "masklinn",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; I'm under the impression that Python is not compiled generally.<p>The direct ancestor to today's IDEs are Smalltalk environments. Smalltalk is about as un-compiled as you can get. This and that are completely orthogonal concerns.<p>&gt; In what ways could it be helpful?<p>Navigation across projects (via structural searches or hyperlinking), <em>static</em> <em>analysis</em> (including library- or framework-specific e.g. PyCharm knows some strings have specific meaning in django projects and can check that there's no mismatch), refactorings, documentation, visual debugging, ...<p>Some of it can be replicated with extensively customized editor and a multitude of external <em>tools</em>, others not really.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "JetBrains releases open-source Python IDE",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.jetbrains.com/pycharm/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-12-21T18:04:56.000Z",
      "title": "",
      "url": "",
      "author": "Arjuna",
      "points": 12,
      "story_text": null,
      "comment_text": "For those that follow game development, John Carmack had this to say at QuakeCon 2012:<p><i>\"But, one of my pushes on the greater use of static analysis and verification technologies, is I pretty strongly suspect that the Clang LLVM sort of ecosystem that's living on OS X is going to be, I hope, fertile ground for a whole lot of analysis tools and we'll wind up benefiting by moving more of our platform continuously onto OS X just for that ability to take advantage of additional tools there.\"</i> [1]<p>[1] <a href=\"https://www.youtube.com/watch?v=wt-iVFxgFWk#t=45m4s\" rel=\"nofollow\">https://www.youtube.com/watch?v=wt-iVFxgFWk#t=45m4s</a>",
      "num_comments": null,
      "story_id": 4952734,
      "story_title": "LLVM and Clang 3.2 released",
      "story_url": "http://llvm.org/docs/ReleaseNotes.html",
      "parent_id": 4952734,
      "created_at_i": 1356113096,
      "_tags": [
        "comment",
        "author_Arjuna",
        "story_4952734"
      ],
      "objectID": "4953745",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Arjuna",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "For those that follow game development, John Carmack had this to say at QuakeCon 2012:<p><i>\"But, one of my pushes on the greater use of <em>static</em> <em>analysis</em> and verification technologies, is I pretty strongly suspect that the Clang LLVM sort of ecosystem that's living on OS X is going to be, I hope, fertile ground for a whole lot of <em>analysis</em> <em>tools</em> and we'll wind up benefiting by moving more of our platform continuously onto OS X just for that ability to take advantage of additional <em>tools</em> there.\"</i> [1]<p>[1] <a href=\"https://www.youtube.com/watch?v=wt-iVFxgFWk#t=45m4s\" rel=\"nofollow\">https://www.youtube.com/watch?v=wt-iVFxgFWk#t=45m4s</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "LLVM and Clang 3.2 released",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://llvm.org/docs/ReleaseNotes.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-31T14:42:13.000Z",
      "title": null,
      "url": null,
      "author": "nitrogen",
      "points": 11,
      "story_text": null,
      "comment_text": "Saying C is &quot;very hard&quot; is useful to dissuade the unprepared from writing buggy, vulnerable software, but for the experienced developer with modern tools, C is at worst &quot;tedious&quot;.  Some simple habits, like always writing your malloc() and free() calls at the same time in balanced pairs, can make C quite managable.  Add valgrind, unit tests, and static analysis, and I&#x27;d have much more confidence in a good C program than an average program in a weakly typed language.",
      "num_comments": null,
      "story_id": 7156405,
      "story_title": "Printable True Bugs Wait Posters",
      "story_url": "http://natashenka.ca/posters/",
      "parent_id": 7156544,
      "created_at_i": 1391179333,
      "_tags": [
        "comment",
        "author_nitrogen",
        "story_7156405"
      ],
      "objectID": "7156824",
      "_highlightResult": {
        "author": {
          "value": "nitrogen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Saying C is &quot;very hard&quot; is useful to dissuade the unprepared from writing buggy, vulnerable software, but for the experienced developer with modern <em>tools</em>, C is at worst &quot;tedious&quot;.  Some simple habits, like always writing your malloc() and free() calls at the same time in balanced pairs, can make C quite managable.  Add valgrind, unit tests, and <em>static</em> <em>analysis</em>, and I'd have much more confidence in a good C program than an average program in a weakly typed language.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Printable True Bugs Wait Posters",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://natashenka.ca/posters/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-10-03T20:15:31.000Z",
      "title": "",
      "url": "",
      "author": "jrockway",
      "points": 11,
      "story_text": null,
      "comment_text": "I would say that after a little more experience, space leaks are the only thing that <i>really</i> worries me in Haskell.  It's one of those things that I have to think about a little too much to really feel \"safe\" about.  (The other worry is expressions that evaluate to  at runtime, but it's been shown that static analysis can solve that problem.  I don't actually use those tools, though, so I guess I'm a tiny bit afraid of those cases.  Like with other languages, write tests.)<p>Your other concerns don't seem too worrisome to me.  Type hell doesn't happen very much, though there are some libraries that really like their typeclass-based APIs (hello, Text.Regex.Base) which can be nearly impossible to decipher without some documentation with respect to what the author was thinking (``I wanted to be able to write let (foo, bar) = \"foobar\" =~ \"(foo)(bar)\" in ...'').<p>The data type stuff can be confusing for people used to other languages, where the standard library is \"good enough\" for most everything people want.  A good example is Perl, which uses \"scalar\" for numbers, strings, unicode strings, byte vectors, and so on.  This approach simply doesn't work for Haskell, because Haskell programmers want speed and compile-time correctness checks.  That means that ByteString and Text and String are three different concepts: ByteString supports efficient immutable byte vectors, Lazy Bytestrings add fast appends, Text adds support for Unicode, and String is a <i>lazy list</i> of Haskell characters.<p>All of those types have their use cases; for a web application, data is read from the network in terms of ByteStrings (since traditional BSD-style networking stacks only know about bytes) and is then converted to Text, if the data is in fact text and not binary.  Your text-processing application then works in terms of Text.  At the end of the request cycle, you have some text that you want to write to the network.  In order to do that, you need to convert the Unicode character stream to a stream of octets for the network, and you do that with character encoding.  The type system makes this explicit, unlike in other languages where you are allowed to write internal strings to the network.  (It usually works since whatever's on the other end of the network auto-detects your program's internal representation and displays it correctly.  This is why I've argued for representing Unicode as inverse-UTF-8 in-memory; when you dump that to a terminal or browser, it will look like the garbage it is.  But I digress.)<p>I understand that people don't want to think about character encoding issues (since most applications I use are never Unicode-clean), but what's nice about this is that Haskell can force you to do it right.  You may not understand character sets and character encodings, but when the compiler says \"Expected Data.ByteString, not Data.Text\", you find that ByteString -&#62; Text function called \"encodeUTF8\" and it all works!  You have a correct program!<p>With respect to purity; purity is a guarantee that the compiler tries to make for you.  When you load a random C function from a shared library, GHC can't make any assumptions about what it does.  As a result, it puts it in IO and then treats those computations as \"must not be optimized with respect to evaluation order\", because that's the only safe thing it can do.  When you are writing an FFI binding, though, you may be able to <i>prove</i> that a certain operation is pure.  In that case, you annotate the operation as such (\"unsafePerformIO\"), and then the compiler and you are back on the same page.  Ultimately, our computers are a big block of RAM with an instruction pointer, and the lower you go, the more the computer looks like that.  In order to bridge the gap between stuff-that-haskell-knows-about and stuff-that-haskell-deson't-know-about, you have to think logically and teach the runtime as much about that thing as you know.  It's hard, but the idea is that libraries should be hard to write if they'll make applications easier to write.  If everyone was afraid to make purity annotations, then everything you ever did would be in IO, and all Haskell would be is a very nice C frontend.<p><i>For a lot of code you end up using monads plus 'do' notation, making your programs look practically imperative, but an oddball variation of it.</i><p>That's really just an opinion, rather than any objective fact about the language.  I find that do-notation saves typing from time to time, so I use it.  Sometimes it clouds what's going on, so I don't use it.  That's what programming is; using the available language constructs to generate a program that's easy for both computers and humans to understand.  Haskell isn't going to save you from having to do that.<p><i>Using functions with worse time or space complexity, to maintain purity.</i><p>ST can largely save you from this.  A good example is Data.Vector.  Sometimes you want an immutable vector somewhere in your application (for purity), but you can't easily build the vector functionally with good performance.  So, you do a ST computation where the vector is mutable inside the ST monad and immutable outside.  ST guarantees that all your mutable operations are done before anything that expects an immutable vector sees it, and thus that your program is pure.  Purity is important on a big-scale level, but it's not as important in a \"one-lexical-scope\" level.  Haskell let's you be mostly-pure without much effort; other languages punt on this by saying \"nothing can ever be pure, so fuck you\".  I think it's a good compromise.<p><i>I/O looks simple, but for predictable and safe I/O you'd usually end up using a library for enumerators. Writing enumerators, enumeratees, and iteratees is unintuitive and weird, especially compared to (less powerful) iterators/generators in other languages.</i><p>IO is hard in any language.  Consider a construct like Python's \"with\":<p><pre><code>    with open('file') as file:\n        return file\n</code></pre>\nThat construct is meaningless, since the file is closed before the caller ever sees the descriptor object.  But Python lets you write it, and guaranteeing correctness is up to you.  In Haskell, that's not acceptable, and so IO works a little differently.   Ultimately, some things in Haskell are a compromise before simplicity of concepts and safety guarantees at compile time.  You can write lazy-list-based IO in Haskell, but you can run out of file descriptors very quickly.  Or, you can use a library like iteratees, and have guarantees about the composability of IO operations and how long file descriptors are used for.  It's up to you; you can do it the easy way and not have to learn anything, or you can do some learning and get a safer program.  And that's the same as any other programming language.",
      "num_comments": null,
      "story_id": 3065672,
      "story_title": "Is Haskell the Cure?",
      "story_url": "http://mathias-biilmann.net/posts/2011/10/is-haskell-the-cure",
      "parent_id": 3065985,
      "created_at_i": 1317672931,
      "_tags": [
        "comment",
        "author_jrockway",
        "story_3065672"
      ],
      "objectID": "3067838",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jrockway",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I would say that after a little more experience, space leaks are the only thing that <i>really</i> worries me in Haskell.  It's one of those things that I have to think about a little too much to really feel \"safe\" about.  (The other worry is expressions that evaluate to  at runtime, but it's been shown that <em>static</em> <em>analysis</em> can solve that problem.  I don't actually use those <em>tools</em>, though, so I guess I'm a tiny bit afraid of those cases.  Like with other languages, write tests.)<p>Your other concerns don't seem too worrisome to me.  Type hell doesn't happen very much, though there are some libraries that really like their typeclass-based APIs (hello, Text.Regex.Base) which can be nearly impossible to decipher without some documentation with respect to what the author was thinking (``I wanted to be able to write let (foo, bar) = \"foobar\" =~ \"(foo)(bar)\" in ...'').<p>The data type stuff can be confusing for people used to other languages, where the standard library is \"good enough\" for most everything people want.  A good example is Perl, which uses \"scalar\" for numbers, strings, unicode strings, byte vectors, and so on.  This approach simply doesn't work for Haskell, because Haskell programmers want speed and compile-time correctness checks.  That means that ByteString and Text and String are three different concepts: ByteString supports efficient immutable byte vectors, Lazy Bytestrings add fast appends, Text adds support for Unicode, and String is a <i>lazy list</i> of Haskell characters.<p>All of those types have their use cases; for a web application, data is read from the network in terms of ByteStrings (since traditional BSD-style networking stacks only know about bytes) and is then converted to Text, if the data is in fact text and not binary.  Your text-processing application then works in terms of Text.  At the end of the request cycle, you have some text that you want to write to the network.  In order to do that, you need to convert the Unicode character stream to a stream of octets for the network, and you do that with character encoding.  The type system makes this explicit, unlike in other languages where you are allowed to write internal strings to the network.  (It usually works since whatever's on the other end of the network auto-detects your program's internal representation and displays it correctly.  This is why I've argued for representing Unicode as inverse-UTF-8 in-memory; when you dump that to a terminal or browser, it will look like the garbage it is.  But I digress.)<p>I understand that people don't want to think about character encoding issues (since most applications I use are never Unicode-clean), but what's nice about this is that Haskell can force you to do it right.  You may not understand character sets and character encodings, but when the compiler says \"Expected Data.ByteString, not Data.Text\", you find that ByteString -> Text function called \"encodeUTF8\" and it all works!  You have a correct program!<p>With respect to purity; purity is a guarantee that the compiler tries to make for you.  When you load a random C function from a shared library, GHC can't make any assumptions about what it does.  As a result, it puts it in IO and then treats those computations as \"must not be optimized with respect to evaluation order\", because that's the only safe thing it can do.  When you are writing an FFI binding, though, you may be able to <i>prove</i> that a certain operation is pure.  In that case, you annotate the operation as such (\"unsafePerformIO\"), and then the compiler and you are back on the same page.  Ultimately, our computers are a big block of RAM with an instruction pointer, and the lower you go, the more the computer looks like that.  In order to bridge the gap between stuff-that-haskell-knows-about and stuff-that-haskell-deson't-know-about, you have to think logically and teach the runtime as much about that thing as you know.  It's hard, but the idea is that libraries should be hard to write if they'll make applications easier to write.  If everyone was afraid to make purity annotations, then everything you ever did would be in IO, and all Haskell would be is a very nice C frontend.<p><i>For a lot of code you end up using monads plus 'do' notation, making your programs look practically imperative, but an oddball variation of it.</i><p>That's really just an opinion, rather than any objective fact about the language.  I find that do-notation saves typing from time to time, so I use it.  Sometimes it clouds what's going on, so I don't use it.  That's what programming is; using the available language constructs to generate a program that's easy for both computers and humans to understand.  Haskell isn't going to save you from having to do that.<p><i>Using functions with worse time or space complexity, to maintain purity.</i><p>ST can largely save you from this.  A good example is Data.Vector.  Sometimes you want an immutable vector somewhere in your application (for purity), but you can't easily build the vector functionally with good performance.  So, you do a ST computation where the vector is mutable inside the ST monad and immutable outside.  ST guarantees that all your mutable operations are done before anything that expects an immutable vector sees it, and thus that your program is pure.  Purity is important on a big-scale level, but it's not as important in a \"one-lexical-scope\" level.  Haskell let's you be mostly-pure without much effort; other languages punt on this by saying \"nothing can ever be pure, so fuck you\".  I think it's a good compromise.<p><i>I/O looks simple, but for predictable and safe I/O you'd usually end up using a library for enumerators. Writing enumerators, enumeratees, and iteratees is unintuitive and weird, especially compared to (less powerful) iterators/generators in other languages.</i><p>IO is hard in any language.  Consider a construct like Python's \"with\":<p><pre><code>    with open('file') as file:\n        return file\n</code></pre>\nThat construct is meaningless, since the file is closed before the caller ever sees the descriptor object.  But Python lets you write it, and guaranteeing correctness is up to you.  In Haskell, that's not acceptable, and so IO works a little differently.   Ultimately, some things in Haskell are a compromise before simplicity of concepts and safety guarantees at compile time.  You can write lazy-list-based IO in Haskell, but you can run out of file descriptors very quickly.  Or, you can use a library like iteratees, and have guarantees about the composability of IO operations and how long file descriptors are used for.  It's up to you; you can do it the easy way and not have to learn anything, or you can do some learning and get a safer program.  And that's the same as any other programming language.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Is Haskell the Cure?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://mathias-biilmann.net/posts/2011/10/is-haskell-the-cure",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-11T23:58:02.000Z",
      "title": null,
      "url": null,
      "author": "nullc",
      "points": 9,
      "story_text": null,
      "comment_text": "I like Frama-C a lot in theory, though in practice I found it hard to use except on very small code segments.<p>When its unable to prove a range the feedback you get from the solvers is inscrutable enough that its very hard to figure out what additional data it would need to satisfy the analysis. (Sort of like parsing C++ compiler template related errors)<p>I&#x27;d hoped that language features like the typestate stuff that used to be in Rust would someday make the work required to use sound analysis tools in production code smaller. I&#x27;m not sure if much thought has been given to what kinds of accommodations languages could give to ease static analysis while still being programmer friendly.<p>It seems that newer languages have actually moved away from analysis friendliness in some respects, however. E.g. in C a signed overflow is always a bug so if analysis can prove one is possible you have something to fix. Several modern languages have defined signed operations to wrap and so that obvious safety test is no longer available. (You could define in your own code that it should never wrap, effectively writing in a subset of the language, but as soon as you call into third party code you never know if an overflow was intended and safe or not— not without extensive analysis)",
      "num_comments": null,
      "story_id": 7575191,
      "story_title": "Frama-C is a suite of tools dedicated to the analysis of software written in C",
      "story_url": "http://frama-c.com/what_is.html",
      "parent_id": 7575191,
      "created_at_i": 1397260682,
      "_tags": [
        "comment",
        "author_nullc",
        "story_7575191"
      ],
      "objectID": "7576264",
      "_highlightResult": {
        "author": {
          "value": "nullc",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I like Frama-C a lot in theory, though in practice I found it hard to use except on very small code segments.<p>When its unable to prove a range the feedback you get from the solvers is inscrutable enough that its very hard to figure out what additional data it would need to satisfy the <em>analysis.</em> (Sort of like parsing C++ compiler template related errors)<p>I'd hoped that language features like the typestate stuff that used to be in Rust would someday make the work required to use sound <em>analysis</em> <em>tools</em> in production code smaller. I'm not sure if much thought has been given to what kinds of accommodations languages could give to ease <em>static</em> <em>analysis</em> while still being programmer friendly.<p>It seems that newer languages have actually moved away from <em>analysis</em> friendliness in some respects, however. E.g. in C a signed overflow is always a bug so if <em>analysis</em> can prove one is possible you have something to fix. Several modern languages have defined signed operations to wrap and so that obvious safety test is no longer available. (You could define in your own code that it should never wrap, effectively writing in a subset of the language, but as soon as you call into third party code you never know if an overflow was intended and safe or not— not without extensive <em>analysis</em>)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Frama-C is a suite of <em>tools</em> dedicated to the <em>analysis</em> of software written in C",
          "matchLevel": "partial",
          "matchedWords": [
            "analysis",
            "tools"
          ]
        },
        "story_url": {
          "value": "http://frama-c.com/what_is.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-12T18:14:01.000Z",
      "title": null,
      "url": null,
      "author": "vladd",
      "points": 8,
      "story_text": null,
      "comment_text": "In case you want to try out static analysis on your own code-base, here&#x27;s a link with the list of most popular tools in this field, grouped by language: <a href=\"http://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis\" rel=\"nofollow\">http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_tools_for_static_code_a...</a>",
      "num_comments": null,
      "story_id": 7578427,
      "story_title": "A New Development for Coverity and Heartbleed",
      "story_url": "http://blog.regehr.org/archives/1128",
      "parent_id": 7578427,
      "created_at_i": 1397326441,
      "_tags": [
        "comment",
        "author_vladd",
        "story_7578427"
      ],
      "objectID": "7578615",
      "_highlightResult": {
        "author": {
          "value": "vladd",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In case you want to try out <em>static</em> <em>analysis</em> on your own code-base, here's a link with the list of most popular <em>tools</em> in this field, grouped by language: <a href=\"http://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis\" rel=\"nofollow\">http://en.wikipedia.org/wiki/List_of_<em>tools</em>_for_<em>static</em>_code_a...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "A New Development for Coverity and Heartbleed",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.regehr.org/archives/1128",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-15T22:56:03.000Z",
      "title": null,
      "url": null,
      "author": "fragmede",
      "points": 7,
      "story_text": null,
      "comment_text": "I disagree, security <i>can</i> be estimated, scheduled and tracked to completion.\\nIt&#x27;s not magic, and while new attack vectors are still being discovered, Heartbleed is a very traditional vulnerability that static analysis should have caught - if someone were actually running the analysis.<p>In fact, we don&#x27;t know how long it actually took to find Heartbleed once Codenomicon and Google started looking. It might have been a weekend project for someone new to Codenomicon&#x27;s internal array of tools, who was just looking for a way to get up to speed at a new job. It&#x27;s also possible that it&#x27;s the result of <i>months</i> of painstaking work by Neel Mehta, 6 of which were possibly spent with the status report of &quot;All week long, I looked painstakingly through such such directories and didn&#x27;t find any security issues&quot;, though I&#x27;d bet he didn&#x27;t spend it on HN.<p>For traditional feature development, a dishonest employee could take random code from the internet, rename functions and then check that into version control, and say they were working but instead they were surfing HN. (Stretching out the &quot;Oh, there&#x27;s some problem getting it to compile, I&#x27;m working on it.&quot; excuse for months is left as an exercise for the dishonest.)<p>&quot;Find and fix security bugs in software component X&quot; is about as specific as &quot;add a spell checker in software component X&quot; and can be treated just the same. You break down the task into smaller components until you can visualize the code needed and then you write it. &quot;Audit software component X for security risk A&quot; is something a competent security researcher can be tasked to do and get results for.<p>For instance, after a week of working on timing attacks against an OpenSSL key verification function, the developer assigned to it could say &quot;Here are the numbers I got; the difference between how long it takes to validate this key, vs invalidate this key averages this much, so it&#x27;s not vulnerable to key recovery because X, Y and Z. Additionally, here is the code harness I wrote to generate this data; I also modified the code so that <i>was</i> vulnerable to a timing attack, and here&#x27;s my exploit code, which is why I know that the shipping code is <i>not</i> vulnerable to this class of attacks.<p>Now if you think you can fake your way through six-months of status reports with that much detail, if not more, and also fake out some code for test-harnesses to back it up, all the while surfing HN instead of working, I&#x27;m all ears, but outside of vendors selling snake-oil magic security blankets, security research is a hard field to be in, where sometimes there&#x27;s a lot of work for <i>no</i> payoff. The flip side of that is, that while Neel Mehta isn&#x27;t due to become a household name, he is now quite famous in certain circles, and won&#x27;t have any trouble finding a job if he leaves Google.",
      "num_comments": null,
      "story_id": 8182713,
      "story_title": "Quality Software Costs Money – Heartbleed Was Free",
      "story_url": "http://queue.acm.org/detail.cfm?id=2636165",
      "parent_id": 8183540,
      "created_at_i": 1408143363,
      "_tags": [
        "comment",
        "author_fragmede",
        "story_8182713"
      ],
      "objectID": "8184738",
      "_highlightResult": {
        "author": {
          "value": "fragmede",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I disagree, security <i>can</i> be estimated, scheduled and tracked to completion.\\nIt's not magic, and while new attack vectors are still being discovered, Heartbleed is a very traditional vulnerability that <em>static</em> <em>analysis</em> should have caught - if someone were actually running the <em>analysis.</em><p>In fact, we don't know how long it actually took to find Heartbleed once Codenomicon and Google started looking. It might have been a weekend project for someone new to Codenomicon's internal array of <em>tools</em>, who was just looking for a way to get up to speed at a new job. It's also possible that it's the result of <i>months</i> of painstaking work by Neel Mehta, 6 of which were possibly spent with the status report of &quot;All week long, I looked painstakingly through such such directories and didn't find any security issues&quot;, though I'd bet he didn't spend it on HN.<p>For traditional feature development, a dishonest employee could take random code from the internet, rename functions and then check that into version control, and say they were working but instead they were surfing HN. (Stretching out the &quot;Oh, there's some problem getting it to compile, I'm working on it.&quot; excuse for months is left as an exercise for the dishonest.)<p>&quot;Find and fix security bugs in software component X&quot; is about as specific as &quot;add a spell checker in software component X&quot; and can be treated just the same. You break down the task into smaller components until you can visualize the code needed and then you write it. &quot;Audit software component X for security risk A&quot; is something a competent security researcher can be tasked to do and get results for.<p>For instance, after a week of working on timing attacks against an OpenSSL key verification function, the developer assigned to it could say &quot;Here are the numbers I got; the difference between how long it takes to validate this key, vs invalidate this key averages this much, so it's not vulnerable to key recovery because X, Y and Z. Additionally, here is the code harness I wrote to generate this data; I also modified the code so that <i>was</i> vulnerable to a timing attack, and here's my exploit code, which is why I know that the shipping code is <i>not</i> vulnerable to this class of attacks.<p>Now if you think you can fake your way through six-months of status reports with that much detail, if not more, and also fake out some code for test-harnesses to back it up, all the while surfing HN instead of working, I'm all ears, but outside of vendors selling snake-oil magic security blankets, security research is a hard field to be in, where sometimes there's a lot of work for <i>no</i> payoff. The flip side of that is, that while Neel Mehta isn't due to become a household name, he is now quite famous in certain circles, and won't have any trouble finding a job if he leaves Google.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Quality Software Costs Money – Heartbleed Was Free",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://queue.acm.org/detail.cfm?id=2636165",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-24T22:07:48.000Z",
      "title": null,
      "url": null,
      "author": "d0",
      "points": 7,
      "story_text": null,
      "comment_text": "I know this is getting a lot of fanfare but let us apply four major costly problems I&#x27;m having with the CLR&#x2F;Framework at the moment:<p>1. Microsoft.Build.Tasks (the bit that has been screwing with me all day) contains static sealed classes with nothing in them. I thought this was a reference source rather than a source of empty interfaces and empty implementations? Still having to resort to reflector to find out what is going on. Problem not solved.<p>2. So, ReaderWriterLockSlim has a bug in it with respect to low CPU allocation in virtual machines where 20 concurrent threads accessing a locked object at the point of write cause the spin lock in the implementation to thrash and up blows a race condition taking out the process. I can actually see where the bug is now. Where do I submit this bug, bear in mind I can actually recreate it? I phoned up our MSDN rep - they said raise it on Connect. There isn&#x27;t a place for it on Connect. Phone up generic paid support, three levels of technical staff bounce me around for a week. as a PAID UP GOLD PARTNER, this sucks. If you open your source, track bugs openly too. Problem not solved.<p>3. This is only the core framework. We really need the entire lot including all dependencies and external tools. There aren&#x27;t any symbols on symbol server or this for VSTO or Sharepoint for example? What we do get is another black box somewhere in the system that we can&#x27;t inspect or poke inside even though it&#x27;s a wrapper for a COM API or a product API. Problem not solved.<p>4. Does Rosyln&#x2F;next MSBuild support parallel compilation? Being tied to a single compilation core on a VS2013 build means we have 8 core Xeons sitting there doing nothing. Our only hope of speeding this up is cranking up to high end i7 to get one core with crazy integer performance. 20 minute sit down compiles are too much these days. <a href=\"http://xkcd.com/303/\" rel=\"nofollow\">http:&#x2F;&#x2F;xkcd.com&#x2F;303&#x2F;</a><p>I understand this is progress and Roslyn is cool and all that, but what does it deliver for every day users of the CLR&#x2F;Framework? It doesn&#x27;t really make our day much easier. In fact stuff that really improves developers&#x27; lives has stopped appearing completely and instead we get tedious reengineering projects and new features designed only to lock us further into the system (VS online+sign in anyone?)<p>Also how does this compare to say LLVM&#x2F;Clang?<p>I imagine this semantic compilation stuff will make some static analysis stuff easier and stamp on the toes of Coverity etc but that&#x27;s about it.<p>Edit: sorry if this is purely a content-free rant and unpopular but after 12 years of this crap from Microsoft, I want to see new wheels, not the same ones reinvented and remarketed. Developers are lapping up this crap constantly as if it&#x27;s as good as it gets. We need some REAL CHANGE towards openness and consistency and to ask the community and users what they want rather than telling us what we need.",
      "num_comments": null,
      "story_id": 7292503,
      "story_title": "Announcing the new Roslyn-powered .NET Framework Reference Source",
      "story_url": "http://www.hanselman.com/blog/AnnouncingTheNewRoslynpoweredNETFrameworkReferenceSource.aspx",
      "parent_id": 7292503,
      "created_at_i": 1393279668,
      "_tags": [
        "comment",
        "author_d0",
        "story_7292503"
      ],
      "objectID": "7293746",
      "_highlightResult": {
        "author": {
          "value": "d0",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I know this is getting a lot of fanfare but let us apply four major costly problems I'm having with the CLR/Framework at the moment:<p>1. Microsoft.Build.Tasks (the bit that has been screwing with me all day) contains <em>static</em> sealed classes with nothing in them. I thought this was a reference source rather than a source of empty interfaces and empty implementations? Still having to resort to reflector to find out what is going on. Problem not solved.<p>2. So, ReaderWriterLockSlim has a bug in it with respect to low CPU allocation in virtual machines where 20 concurrent threads accessing a locked object at the point of write cause the spin lock in the implementation to thrash and up blows a race condition taking out the process. I can actually see where the bug is now. Where do I submit this bug, bear in mind I can actually recreate it? I phoned up our MSDN rep - they said raise it on Connect. There isn't a place for it on Connect. Phone up generic paid support, three levels of technical staff bounce me around for a week. as a PAID UP GOLD PARTNER, this sucks. If you open your source, track bugs openly too. Problem not solved.<p>3. This is only the core framework. We really need the entire lot including all dependencies and external <em>tools</em>. There aren't any symbols on symbol server or this for VSTO or Sharepoint for example? What we do get is another black box somewhere in the system that we can't inspect or poke inside even though it's a wrapper for a COM API or a product API. Problem not solved.<p>4. Does Rosyln/next MSBuild support parallel compilation? Being tied to a single compilation core on a VS2013 build means we have 8 core Xeons sitting there doing nothing. Our only hope of speeding this up is cranking up to high end i7 to get one core with crazy integer performance. 20 minute sit down compiles are too much these days. <a href=\"http://xkcd.com/303/\" rel=\"nofollow\">http://xkcd.com/303/</a><p>I understand this is progress and Roslyn is cool and all that, but what does it deliver for every day users of the CLR/Framework? It doesn't really make our day much easier. In fact stuff that really improves developers' lives has stopped appearing completely and instead we get tedious reengineering projects and new features designed only to lock us further into the system (VS online+sign in anyone?)<p>Also how does this compare to say LLVM/Clang?<p>I imagine this semantic compilation stuff will make some <em>static</em> <em>analysis</em> stuff easier and stamp on the toes of Coverity etc but that's about it.<p>Edit: sorry if this is purely a content-free rant and unpopular but after 12 years of this crap from Microsoft, I want to see new wheels, not the same ones reinvented and remarketed. Developers are lapping up this crap constantly as if it's as good as it gets. We need some REAL CHANGE towards openness and consistency and to ask the community and users what they want rather than telling us what we need.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Announcing the new Roslyn-powered .NET Framework Reference Source",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.hanselman.com/blog/AnnouncingTheNewRoslynpoweredNETFrameworkReferenceSource.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-03T15:23:49.000Z",
      "title": "",
      "url": "",
      "author": "giulianob",
      "points": 7,
      "story_text": null,
      "comment_text": "I'd call something with more than 100k LOC a large app. It can get messy even before then though. The main concerns I have with Javascript are:<p>1) Most frameworks try to make JS into a typical OOP language which tends to hurt performance and can make debugging a PITA.<p>2) In \"one page apps\" it can become difficult to map nodes to JS objects so things get cleaned up properly. You often see memory build ups even in jQuery because of html node wrappers and events that get cached but don't get cleaned up.<p>3) Static analysis. It's possible to get some level of static analysis if you use JSDoc but it's still very poor compared to something like C#. For example, you need to add tons of JSDoc code to make autocomplete somewhat usable. After using something like Resharper, you can really see how lack of good static analysis hurts.<p>4) Difficult to refactor large apps. Since the static analysis is poor, it's difficult to use tools to create dependency graphs, finding usages, etc... I really wish Js would just let you specify a type of an object like ActionScript 3 does. You can still use var if you want but 99% of the time an object has an expected type.<p>5) Lack of visibility keywords. This makes it hard to organize code into modules and prevent programmers from getting access to things they aren't supposed to. I'm sure there are entire debates on this point alone.<p>6) Performance. The browsers try to do tons of optimizations during runtime to speed up javascript. If you want to get the most out of JS, you really need to know about them (e.g. always initialize your class vars in the same order).",
      "num_comments": null,
      "story_id": 4470055,
      "story_title": "New C# to Javascript compiler released",
      "story_url": "http://www.erik-kallen.se/blog/saltarelle-open-source-c-to-javascript-compiler",
      "parent_id": 4470367,
      "created_at_i": 1346685829,
      "_tags": [
        "comment",
        "author_giulianob",
        "story_4470055"
      ],
      "objectID": "4470661",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "giulianob",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'd call something with more than 100k LOC a large app. It can get messy even before then though. The main concerns I have with Javascript are:<p>1) Most frameworks try to make JS into a typical OOP language which tends to hurt performance and can make debugging a PITA.<p>2) In \"one page apps\" it can become difficult to map nodes to JS objects so things get cleaned up properly. You often see memory build ups even in jQuery because of html node wrappers and events that get cached but don't get cleaned up.<p>3) <em>Static</em> <em>analysis.</em> It's possible to get some level of <em>static</em> <em>analysis</em> if you use JSDoc but it's still very poor compared to something like C#. For example, you need to add tons of JSDoc code to make autocomplete somewhat usable. After using something like Resharper, you can really see how lack of good <em>static</em> <em>analysis</em> hurts.<p>4) Difficult to refactor large apps. Since the <em>static</em> <em>analysis</em> is poor, it's difficult to use <em>tools</em> to create dependency graphs, finding usages, etc... I really wish Js would just let you specify a type of an object like ActionScript 3 does. You can still use var if you want but 99% of the time an object has an expected type.<p>5) Lack of visibility keywords. This makes it hard to organize code into modules and prevent programmers from getting access to things they aren't supposed to. I'm sure there are entire debates on this point alone.<p>6) Performance. The browsers try to do tons of optimizations during runtime to speed up javascript. If you want to get the most out of JS, you really need to know about them (e.g. always initialize your class vars in the same order).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "New C# to Javascript compiler released",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.erik-kallen.se/blog/saltarelle-open-source-c-to-javascript-compiler",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-28T15:17:21.000Z",
      "title": null,
      "url": null,
      "author": "teamhappy",
      "points": 6,
      "story_text": null,
      "comment_text": "Anybody know Bryan Lunduke? He&#x27;s a guy giving talks called &quot;Linux sucks&quot; in which he basically bashes Linux for 20 minutes and then concludes that Linux is the best FOSS OS community because they can take the bashing (get it?). He&#x27;s been giving these talks for quite a while now. Everybody knows Theo de Raadt is crazy (and Stallman isn&#x27;t) and of course everybody knows Apple fanboys tear up every time somebody implies Apple software has a bug in it.<p>In my experience it&#x27;s the exact opposite. I&#x27;ve been hearing a lot of explanations for the bash debacle in the last couple of days and they all amaze me to a certain degree. Let me share a couple of them with you.<p>1. Total breakdown - &quot;No software is ever safe, so what the hell do you want from me.&quot; Yeah, well ... don&#x27;t write software then.<p>2. It&#x27;s not my fault - &quot;Bash is written in C. C is unsafe.&quot; Quite a lot of people write safe, well tested, maybe even formally verified C code. So, yeah ... don&#x27;t hack in C maybe.<p>3. Linux is still fine - &quot;Bash is just a tiny part of Linux. The rest is still good to go.&quot; Turns out the bash codebase looks a lot like the rest of the GNU&#x2F;Linux universe. Old, untested C code that&#x27;s hard to read and even harder to understand. That&#x27;s why nobody dares to touch it in the first place.<p>4. It&#x27;s FOSS - &quot;You can&#x27;t expect anything to work. Cause, you know, it&#x27;s free.&quot; If that were true, using FOSS would be a terrible idea.<p>5. You&#x27;re using it wrong. ... just wow.<p>Can&#x27;t we just all agree that this kind of thing is an endemic problem in most of the code bases we use (including my beloved FreeBSD) and we have to figure it out over the next couple of years. There are loads of tools that should have never been implemented in C&#x2F;C++ in the first place (SSH, Make, APT, etc.). I&#x27;d say the best idea is to port a lot of these code bases to languages like Go or Rust maybe, but if that&#x27;s not feasible for some reason, at least write some unit tests and do static code analysis. And, this is probably the most important point, if you don&#x27;t want to do any of this, please don&#x27;t make lame excuses when it all falls apart eventually.",
      "num_comments": null,
      "story_id": 8379542,
      "story_title": "Dear clueless assholes: stop bashing bash and GNU",
      "story_url": "https://weev.livejournal.com/409835.html",
      "parent_id": 8379542,
      "created_at_i": 1411917441,
      "_tags": [
        "comment",
        "author_teamhappy",
        "story_8379542"
      ],
      "objectID": "8379927",
      "_highlightResult": {
        "author": {
          "value": "teamhappy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Anybody know Bryan Lunduke? He's a guy giving talks called &quot;Linux sucks&quot; in which he basically bashes Linux for 20 minutes and then concludes that Linux is the best FOSS OS community because they can take the bashing (get it?). He's been giving these talks for quite a while now. Everybody knows Theo de Raadt is crazy (and Stallman isn't) and of course everybody knows Apple fanboys tear up every time somebody implies Apple software has a bug in it.<p>In my experience it's the exact opposite. I've been hearing a lot of explanations for the bash debacle in the last couple of days and they all amaze me to a certain degree. Let me share a couple of them with you.<p>1. Total breakdown - &quot;No software is ever safe, so what the hell do you want from me.&quot; Yeah, well ... don't write software then.<p>2. It's not my fault - &quot;Bash is written in C. C is unsafe.&quot; Quite a lot of people write safe, well tested, maybe even formally verified C code. So, yeah ... don't hack in C maybe.<p>3. Linux is still fine - &quot;Bash is just a tiny part of Linux. The rest is still good to go.&quot; Turns out the bash codebase looks a lot like the rest of the GNU/Linux universe. Old, untested C code that's hard to read and even harder to understand. That's why nobody dares to touch it in the first place.<p>4. It's FOSS - &quot;You can't expect anything to work. Cause, you know, it's free.&quot; If that were true, using FOSS would be a terrible idea.<p>5. You're using it wrong. ... just wow.<p>Can't we just all agree that this kind of thing is an endemic problem in most of the code bases we use (including my beloved FreeBSD) and we have to figure it out over the next couple of years. There are loads of <em>tools</em> that should have never been implemented in C/C++ in the first place (SSH, Make, APT, etc.). I'd say the best idea is to port a lot of these code bases to languages like Go or Rust maybe, but if that's not feasible for some reason, at least write some unit tests and do <em>static</em> code <em>analysis.</em> And, this is probably the most important point, if you don't want to do any of this, please don't make lame excuses when it all falls apart eventually.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dear clueless assholes: stop bashing bash and GNU",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://weev.livejournal.com/409835.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-16T17:08:27.000Z",
      "title": null,
      "url": null,
      "author": "hibikir",
      "points": 6,
      "story_text": null,
      "comment_text": "For this, you don&#x27;t need a style guide, but a static code analysis tool. This specific error causes unreachable lines and has suspicious indentation.<p>In my project, that could could have never gotten into production, because the tools would have stopped us, even without a single unit tests.",
      "num_comments": null,
      "story_id": 7598721,
      "story_title": "Those Who Say Code Does Not Matter",
      "story_url": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
      "parent_id": 7598931,
      "created_at_i": 1397668107,
      "_tags": [
        "comment",
        "author_hibikir",
        "story_7598721"
      ],
      "objectID": "7599033",
      "_highlightResult": {
        "author": {
          "value": "hibikir",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "For this, you don't need a style guide, but a <em>static</em> code <em>analysis</em> tool. This specific error causes unreachable lines and has suspicious indentation.<p>In my project, that could could have never gotten into production, because the <em>tools</em> would have stopped us, even without a single unit tests.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Those Who Say Code Does Not Matter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-12T02:55:05.000Z",
      "title": null,
      "url": null,
      "author": "pcwalton",
      "points": 6,
      "story_text": null,
      "comment_text": "&gt; I&#x27;d hoped that language features like the typestate stuff that used to be in Rust would someday make the work required to use sound analysis tools in production code smaller. I&#x27;m not sure if much thought has been given to what kinds of accommodations languages could give to ease static analysis while still being programmer friendly.<p>Well, since the Rust borrow check is basically a static analysis that&#x27;s always on and is required to pass for the compiler to emit code, we&#x27;ve put a lot of thought into how to make it as programmer friendly as possible. The final trick that seemed to got it to fall into place was restricting data to only one mutable reference at all times—this was a restriction that&#x27;s easy enough to understand and can be readily explained through error messages and tutorials. There&#x27;s still a learning curve, of course, but I think we&#x27;ve got the system down to a reasonable level.",
      "num_comments": null,
      "story_id": 7575191,
      "story_title": "Frama-C is a suite of tools dedicated to the analysis of software written in C",
      "story_url": "http://frama-c.com/what_is.html",
      "parent_id": 7576264,
      "created_at_i": 1397271305,
      "_tags": [
        "comment",
        "author_pcwalton",
        "story_7575191"
      ],
      "objectID": "7576793",
      "_highlightResult": {
        "author": {
          "value": "pcwalton",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; I'd hoped that language features like the typestate stuff that used to be in Rust would someday make the work required to use sound <em>analysis</em> <em>tools</em> in production code smaller. I'm not sure if much thought has been given to what kinds of accommodations languages could give to ease <em>static</em> <em>analysis</em> while still being programmer friendly.<p>Well, since the Rust borrow check is basically a <em>static</em> <em>analysis</em> that's always on and is required to pass for the compiler to emit code, we've put a lot of thought into how to make it as programmer friendly as possible. The final trick that seemed to got it to fall into place was restricting data to only one mutable reference at all times—this was a restriction that's easy enough to understand and can be readily explained through error messages and tutorials. There's still a learning curve, of course, but I think we've got the system down to a reasonable level.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Frama-C is a suite of <em>tools</em> dedicated to the <em>analysis</em> of software written in C",
          "matchLevel": "partial",
          "matchedWords": [
            "analysis",
            "tools"
          ]
        },
        "story_url": {
          "value": "http://frama-c.com/what_is.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-11-29T22:36:43.000Z",
      "title": null,
      "url": null,
      "author": "chc",
      "points": 6,
      "story_text": null,
      "comment_text": "Have you looked into the tools and amenability of Scala to static analysis and found them lacking?<p>Also, it seems a bit odd to call Scala &quot;syntactic sugar&quot;. It&#x27;s a pretty unique language in its own right.",
      "num_comments": null,
      "story_id": 6821145,
      "story_title": "Announcing Scala.js v0.1",
      "story_url": "http://www.scala-lang.org/news/2013/11/29/announcing-scala-js-v0.1.html",
      "parent_id": 6821289,
      "created_at_i": 1385764603,
      "_tags": [
        "comment",
        "author_chc",
        "story_6821145"
      ],
      "objectID": "6821315",
      "_highlightResult": {
        "author": {
          "value": "chc",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Have you looked into the <em>tools</em> and amenability of Scala to <em>static</em> <em>analysis</em> and found them lacking?<p>Also, it seems a bit odd to call Scala &quot;syntactic sugar&quot;. It's a pretty unique language in its own right.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Announcing Scala.js v0.1",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.scala-lang.org/news/2013/11/29/announcing-scala-js-v0.1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-19T05:09:02.000Z",
      "title": "",
      "url": "",
      "author": "rogerbinns",
      "points": 6,
      "story_text": null,
      "comment_text": "I&#x27;m sure malicious code can be hidden in plain site anyway.  Automated tools or human eyeballs won&#x27;t spot it.  For example here is the underhanded C contest demonstrating the principle with C <a href=\"http://underhanded.xcott.com/\" rel=\"nofollow\">http:&#x2F;&#x2F;underhanded.xcott.com&#x2F;</a>  (static analysis won&#x27;t be possible on most JS code)<p>The only way to be sure is to implement a (bug free) sandbox that the code runs in, as then it won&#x27;t matter what the code does.",
      "num_comments": null,
      "story_id": 6409620,
      "story_title": "Opera Rejecting Extensions With Minified Code",
      "story_url": "http://leaptouch.com/blog/2013/09/19/opera-rejecting-extensions-with-minified-code/",
      "parent_id": 6409730,
      "created_at_i": 1379567342,
      "_tags": [
        "comment",
        "author_rogerbinns",
        "story_6409620"
      ],
      "objectID": "6409953",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "rogerbinns",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm sure malicious code can be hidden in plain site anyway.  Automated <em>tools</em> or human eyeballs won't spot it.  For example here is the underhanded C contest demonstrating the principle with C <a href=\"http://underhanded.xcott.com/\" rel=\"nofollow\">http://underhanded.xcott.com/</a>  (<em>static</em> <em>analysis</em> won't be possible on most JS code)<p>The only way to be sure is to implement a (bug free) sandbox that the code runs in, as then it won't matter what the code does.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Opera Rejecting Extensions With Minified Code",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://leaptouch.com/blog/2013/09/19/opera-rejecting-extensions-with-minified-code/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-22T01:22:06.000Z",
      "title": "",
      "url": "",
      "author": "dietrichepp",
      "points": 6,
      "story_text": null,
      "comment_text": "That's dangerous, because you have no way of knowing if you have 100% coverage without doing static analysis, and if you double check everything with static analysis, you might as well only do the static analysis in the first place.  (Static analysis won't always give you an answer, but it won't ever give you a wrong answer.)<p>I am reminded of the folks who optimized .kkrieger, which is a 95 kB first-person shooter.  See \"Metaprogramming for Madmen\":<p><a href=\"http://fgiesen.wordpress.com/2012/04/08/metaprogramming-for-madmen/\" rel=\"nofollow\">http://fgiesen.wordpress.com/2012/04/08/metaprogramming-for-...</a><p>Some highlights: during the test run, the player never pressed the up arrow key in the menu, so that functionality was removed by their tools.  Enemies at the beginning never hit the player, so the code which handles damage was compiled out.  And the system used a certain brand of graphics card, so code necessary for other graphics cards was compiled out.<p>The lesson is: don't let tools change code semantics based only on black-box testing.",
      "num_comments": null,
      "story_id": 5747961,
      "story_title": "Dart Is Not the Language You Think It Is",
      "story_url": "http://programming.oreilly.com/2013/05/dart-is-not-the-language-you-think-it-is.html",
      "parent_id": 5748112,
      "created_at_i": 1369185726,
      "_tags": [
        "comment",
        "author_dietrichepp",
        "story_5747961"
      ],
      "objectID": "5748212",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dietrichepp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's dangerous, because you have no way of knowing if you have 100% coverage without doing <em>static</em> <em>analysis</em>, and if you double check everything with <em>static</em> <em>analysis</em>, you might as well only do the <em>static</em> <em>analysis</em> in the first place.  (<em>Static</em> <em>analysis</em> won't always give you an answer, but it won't ever give you a wrong answer.)<p>I am reminded of the folks who optimized .kkrieger, which is a 95 kB first-person shooter.  See \"Metaprogramming for Madmen\":<p><a href=\"http://fgiesen.wordpress.com/2012/04/08/metaprogramming-for-madmen/\" rel=\"nofollow\">http://fgiesen.wordpress.com/2012/04/08/metaprogramming-for-...</a><p>Some highlights: during the test run, the player never pressed the up arrow key in the menu, so that functionality was removed by their <em>tools</em>.  Enemies at the beginning never hit the player, so the code which handles damage was compiled out.  And the system used a certain brand of graphics card, so code necessary for other graphics cards was compiled out.<p>The lesson is: don't let <em>tools</em> change code semantics based only on black-box testing.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dart Is Not the Language You Think It Is",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://programming.oreilly.com/2013/05/dart-is-not-the-language-you-think-it-is.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-11-23T15:24:12.000Z",
      "title": "",
      "url": "",
      "author": "agentultra",
      "points": 6,
      "story_text": null,
      "comment_text": "Great advice if you want to optimize for salary.<p>Most of this stuff I learned from the streets and I've done pretty well following it.<p>However I've reached a point where a bigger salary, better benefits, and equity offers won't cut it for me anymore.  There's a hidden nugget in this article that suggests that there are things in life outside of work which are better sources of happiness.  One of the sources it fails to mention is accomplishment and achievement.  If you are a programmer that spends their time reading the latest research, crafting your skills by implementing a compiler for some exotic language you're interested in, and following your passion then you will find optimizing your career by writing CRUD forms for an accounting package for 8+ hours a day to be an incredible waste of time and energy.<p>(It's also incredibly hard to develop a source of accomplishment and achievement if you spend the majority of your life being bored)<p>I've once heard the advice that you should optimize for happiness and great things will begin to happen.  If modelling weather simulations is what turns your crank you will never be happy building web APIs to a legacy CRM system.  If you enjoy pushing the envelop of static analysis then what good are you doing for the world hacking on a javascript front-end for a client at a creative agency?  Rather than optimizing for salary you optimized your life around what motivates you and makes you happy then perhaps we'd have better weather predictions and early warning systems for tropical storms or better tools that allow us to write safer, faster, bug-free code.  The icing on the cake is that you'd be happy to do it.<p>If you're just getting out of school though, then I'd follow the advice in this article for a while first.  You don't know where to go without getting a lay of the land first.  And a good salary will help you build up a \"screw-up\" fund for when you're ready to take the dive and follow your calling.",
      "num_comments": null,
      "story_id": 4822015,
      "story_title": "Dont call yourself a programmer (2011)",
      "story_url": "http://www.kalzumeus.com/2011/10/28/",
      "parent_id": 4822015,
      "created_at_i": 1353684252,
      "_tags": [
        "comment",
        "author_agentultra",
        "story_4822015"
      ],
      "objectID": "4822457",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "agentultra",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Great advice if you want to optimize for salary.<p>Most of this stuff I learned from the streets and I've done pretty well following it.<p>However I've reached a point where a bigger salary, better benefits, and equity offers won't cut it for me anymore.  There's a hidden nugget in this article that suggests that there are things in life outside of work which are better sources of happiness.  One of the sources it fails to mention is accomplishment and achievement.  If you are a programmer that spends their time reading the latest research, crafting your skills by implementing a compiler for some exotic language you're interested in, and following your passion then you will find optimizing your career by writing CRUD forms for an accounting package for 8+ hours a day to be an incredible waste of time and energy.<p>(It's also incredibly hard to develop a source of accomplishment and achievement if you spend the majority of your life being bored)<p>I've once heard the advice that you should optimize for happiness and great things will begin to happen.  If modelling weather simulations is what turns your crank you will never be happy building web APIs to a legacy CRM system.  If you enjoy pushing the envelop of <em>static</em> <em>analysis</em> then what good are you doing for the world hacking on a javascript front-end for a client at a creative agency?  Rather than optimizing for salary you optimized your life around what motivates you and makes you happy then perhaps we'd have better weather predictions and early warning systems for tropical storms or better <em>tools</em> that allow us to write safer, faster, bug-free code.  The icing on the cake is that you'd be happy to do it.<p>If you're just getting out of school though, then I'd follow the advice in this article for a while first.  You don't know where to go without getting a lay of the land first.  And a good salary will help you build up a \"screw-up\" fund for when you're ready to take the dive and follow your calling.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dont call yourself a programmer (2011)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.kalzumeus.com/2011/10/28/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-12T14:24:54.000Z",
      "title": "",
      "url": "",
      "author": "sophacles",
      "points": 6,
      "story_text": null,
      "comment_text": "I would like to respectfully suggest you have it backwards.<p>I agree a lot of that stuff would be nice with vim, don't get me wrong, but I think we don't need an IDE layered on top of vim, so much as we to do some work on DEintegrating the development environment.<p>I'm not advocating for getting rid of all-in-one tools, I've seen the power of VS and IntelliJ etal in competent user's hands, they are fine envrionments, if that is your preference and it makes you productive, then awesome.<p>What I think the programming environment world needs (not just vim) is a standard way for user interfaces to talk to tools. Right now if you come up with a great way to auto refactor code, or do inline static analysis or build tool chains or whatever, you have to target a specific environment, or redo a lot of work to have it work  available in multiple tools.  However if there was a standard api or protocol, the same code would work for all developers and you could focus your effort on making the tool that much better.<p>It isn't immediately obvious to me how this would work, and I've been thinking about it off and on for a while now, but I think it could be a major benefit to the world, in the way http/html have freed up a lot of the nonsense around programming interfaces for users in a cross-platform way. My thinking right now is being largely influenced by the git model of \"plumbing\" and \"porcelain\" command setup, where the \"porcelain\" is the editor/environment tool.<p>Anyway, I probably did a poor job of explaining my thinking, it being saturday morning and all.",
      "num_comments": null,
      "story_id": 3962945,
      "story_title": "The Grammar of Vim",
      "story_url": "http://rc3.org/2012/05/12/the-grammar-of-vim/",
      "parent_id": 3963184,
      "created_at_i": 1336832694,
      "_tags": [
        "comment",
        "author_sophacles",
        "story_3962945"
      ],
      "objectID": "3963941",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "sophacles",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I would like to respectfully suggest you have it backwards.<p>I agree a lot of that stuff would be nice with vim, don't get me wrong, but I think we don't need an IDE layered on top of vim, so much as we to do some work on DEintegrating the development environment.<p>I'm not advocating for getting rid of all-in-one <em>tools</em>, I've seen the power of VS and IntelliJ etal in competent user's hands, they are fine envrionments, if that is your preference and it makes you productive, then awesome.<p>What I think the programming environment world needs (not just vim) is a standard way for user interfaces to talk to <em>tools</em>. Right now if you come up with a great way to auto refactor code, or do inline <em>static</em> <em>analysis</em> or build tool chains or whatever, you have to target a specific environment, or redo a lot of work to have it work  available in multiple <em>tools</em>.  However if there was a standard api or protocol, the same code would work for all developers and you could focus your effort on making the tool that much better.<p>It isn't immediately obvious to me how this would work, and I've been thinking about it off and on for a while now, but I think it could be a major benefit to the world, in the way http/html have freed up a lot of the nonsense around programming interfaces for users in a cross-platform way. My thinking right now is being largely influenced by the git model of \"plumbing\" and \"porcelain\" command setup, where the \"porcelain\" is the editor/environment tool.<p>Anyway, I probably did a poor job of explaining my thinking, it being saturday morning and all.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Grammar of Vim",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://rc3.org/2012/05/12/the-grammar-of-vim/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-04-22T10:16:56.000Z",
      "title": "",
      "url": "",
      "author": "GlennS",
      "points": 6,
      "story_text": null,
      "comment_text": "I'm a bit unconvinced about the 'language agnostic' assumption.<p>For Java, you want to get the most out of your static typing. So, you need an IDE filled with analysis tools.<p>For dynamically typed languages, Eclipse doesn't cut it. It gets sluggish and crashes too often and that's not acceptable when your language is designed for rapid feedback.<p>I want something that gives me feedback as if I were using Firebug, but feels like I'm typing into Notepad++, and it seems like LightTable could fill that need.<p>My thinking is that Light Table will live or die by how responsive it feels.",
      "num_comments": null,
      "story_id": 3874324,
      "story_title": "LightTable detailed critique: Concept vs Reality",
      "story_url": "http://eblog.chrononsystems.com/light-table-concept-vs-reality",
      "parent_id": 3874324,
      "created_at_i": 1335089816,
      "_tags": [
        "comment",
        "author_GlennS",
        "story_3874324"
      ],
      "objectID": "3874478",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "GlennS",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm a bit unconvinced about the 'language agnostic' assumption.<p>For Java, you want to get the most out of your <em>static</em> typing. So, you need an IDE filled with <em>analysis</em> <em>tools</em>.<p>For dynamically typed languages, Eclipse doesn't cut it. It gets sluggish and crashes too often and that's not acceptable when your language is designed for rapid feedback.<p>I want something that gives me feedback as if I were using Firebug, but feels like I'm typing into Notepad++, and it seems like LightTable could fill that need.<p>My thinking is that Light Table will live or die by how responsive it feels.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "LightTable detailed critique: Concept vs Reality",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://eblog.chrononsystems.com/light-table-concept-vs-reality",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-04-04T12:43:12.000Z",
      "title": "",
      "url": "",
      "author": "moonchrome",
      "points": 6,
      "story_text": null,
      "comment_text": "&#62;Whether enforced compile-time strong type checking is a benefit seems to depend on the programmer.<p>And, due to the lisp's nature, you can have static type checking as a library, eg. there's some work on it for clojure <a href=\"https://github.com/frenchy64/typed-clojure\" rel=\"nofollow\">https://github.com/frenchy64/typed-clojure</a>, and AFAIK it's based on work already done by Typed Racked/Scheme.<p>Also I believe that because clojure is a lisp, has very few special forms, is immutable, has nice ns/var semantics and overall focuses on simplicity - you could build quality code analysis tools with relative ease, something that will do search on code for common error paterns, maybe even do verification outside type system with custom DSL. It's something that I would like to explore in few months after I finish my current project.",
      "num_comments": null,
      "story_id": 3797019,
      "story_title": "The perils of Lisp in production",
      "story_url": "http://symbo1ics.com/blog/?p=1321",
      "parent_id": 3797146,
      "created_at_i": 1333543392,
      "_tags": [
        "comment",
        "author_moonchrome",
        "story_3797019"
      ],
      "objectID": "3797251",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "moonchrome",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": ">Whether enforced compile-time strong type checking is a benefit seems to depend on the programmer.<p>And, due to the lisp's nature, you can have <em>static</em> type checking as a library, eg. there's some work on it for clojure <a href=\"https://github.com/frenchy64/typed-clojure\" rel=\"nofollow\">https://github.com/frenchy64/typed-clojure</a>, and AFAIK it's based on work already done by Typed Racked/Scheme.<p>Also I believe that because clojure is a lisp, has very few special forms, is immutable, has nice ns/var semantics and overall focuses on simplicity - you could build quality code <em>analysis</em> <em>tools</em> with relative ease, something that will do search on code for common error paterns, maybe even do verification outside type system with custom DSL. It's something that I would like to explore in few months after I finish my current project.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The perils of Lisp in production",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://symbo1ics.com/blog/?p=1321",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-10T13:43:02.000Z",
      "title": null,
      "url": null,
      "author": "drdaeman",
      "points": 5,
      "story_text": null,
      "comment_text": "That creates some mostly unnecessary boilerplate. I.e., if an error happens down the stack in function to read config, which calls a function to parse a file, which calls a function to read a file, you&#x27;ll have to either propagate (or otherwise handle) that `err` manually or lose the precious information.<p>On the contrary, Java-like pattern of functions like `Config readConfig() throws IOError, ParseError` simplifies code quite a bit. No need to deal with IOError in parseConfig - if an exception happens there it&#x27;ll be propagated automatically. And `throws` clause allows for static checking and warning whenever you forgot to handle something. And sane code analysis tools would also warn you whenever you really wanted overly-broad `catch Exception(e)`, too.<p>There&#x27;s a panic&#x2F;recover in Go, but they aren&#x27;t serious. At least, to my limited knowledge of Go, there are no guidelines on using them properly, so everyone panics with whatever they fancy, and this lack of conventions is a bit problematic, like `raise &quot;Failed to open file&quot;` in Python.",
      "num_comments": null,
      "story_id": 7872153,
      "story_title": "Things from Python I'd miss in Go",
      "story_url": "http://www.yosefk.com/blog/things-from-python-id-miss-in-go.html",
      "parent_id": 7872326,
      "created_at_i": 1402407782,
      "_tags": [
        "comment",
        "author_drdaeman",
        "story_7872153"
      ],
      "objectID": "7872395",
      "_highlightResult": {
        "author": {
          "value": "drdaeman",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That creates some mostly unnecessary boilerplate. I.e., if an error happens down the stack in function to read config, which calls a function to parse a file, which calls a function to read a file, you'll have to either propagate (or otherwise handle) that `err` manually or lose the precious information.<p>On the contrary, Java-like pattern of functions like `Config readConfig() throws IOError, ParseError` simplifies code quite a bit. No need to deal with IOError in parseConfig - if an exception happens there it'll be propagated automatically. And `throws` clause allows for <em>static</em> checking and warning whenever you forgot to handle something. And sane code <em>analysis</em> <em>tools</em> would also warn you whenever you really wanted overly-broad `catch Exception(e)`, too.<p>There's a panic/recover in Go, but they aren't serious. At least, to my limited knowledge of Go, there are no guidelines on using them properly, so everyone panics with whatever they fancy, and this lack of conventions is a bit problematic, like `raise &quot;Failed to open file&quot;` in Python.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Things from Python I'd miss in Go",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.yosefk.com/blog/things-from-python-id-miss-in-go.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T14:42:07.000Z",
      "title": null,
      "url": null,
      "author": "peeters",
      "points": 5,
      "story_text": null,
      "comment_text": "It would shock me if those tools would actually have caught this bug.  That would imply that no benevolent contributor or researcher had run them against OpenSSL in the last two years, which I find incredibly hard to believe, as static analysis is a logical first step in researching a code for vulnerabilities, and OpenSSL is probably in the top 5 most valuable pieces of software to validate.",
      "num_comments": null,
      "story_id": 7565764,
      "story_title": "'Heartbleed' contributor denies he inserted it deliberately",
      "story_url": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
      "parent_id": 7566403,
      "created_at_i": 1397140927,
      "_tags": [
        "comment",
        "author_peeters",
        "story_7565764"
      ],
      "objectID": "7566496",
      "_highlightResult": {
        "author": {
          "value": "peeters",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It would shock me if those <em>tools</em> would actually have caught this bug.  That would imply that no benevolent contributor or researcher had run them against OpenSSL in the last two years, which I find incredibly hard to believe, as <em>static</em> <em>analysis</em> is a logical first step in researching a code for vulnerabilities, and OpenSSL is probably in the top 5 most valuable pieces of software to validate.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "'Heartbleed' contributor denies he inserted it deliberately",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-12-20T13:43:28.000Z",
      "title": "",
      "url": "",
      "author": "jasonlotito",
      "points": 5,
      "story_text": null,
      "comment_text": "PHPStorm plays nice when any framework.  The issue it's going to have is when Frameworks do not clearly document, or when they make bad decisions about things.  You can, of course turn off different levels of inspections to account for the project you are working on.  However, I've found that for the most part, if PHPStorm is flagging something like \"undefined method,\" it's essentially saying \"you are hoping that this works as expected.\"  It's a form of static analysis.<p>I'm not surprised that an old CodeIgniter project flagged these issues.<p>As for vi, I use vi every day as well.  I switch between that and PHPStorm.  It depends on the context that I'm in.  Both are wonderful tools.  But I can assure you, auto-complete is a basic feature of PHPStorm.  It's akin to 'set nu'.<p>Edit: This comment comes off as a bit snarky.  It's not intended to be.  I think JetBrains and it's line of products are excellent, and I've only ever had good experiences with them.  I wouldn't want my comment to reflect poorly on them.",
      "num_comments": null,
      "story_id": 4947146,
      "story_title": "JetBrains Doomsday Sale - 75% off for 24 hours only",
      "story_url": "http://www.jetbrains.com/specials/",
      "parent_id": 4947569,
      "created_at_i": 1356011008,
      "_tags": [
        "comment",
        "author_jasonlotito",
        "story_4947146"
      ],
      "objectID": "4947633",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jasonlotito",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "PHPStorm plays nice when any framework.  The issue it's going to have is when Frameworks do not clearly document, or when they make bad decisions about things.  You can, of course turn off different levels of inspections to account for the project you are working on.  However, I've found that for the most part, if PHPStorm is flagging something like \"undefined method,\" it's essentially saying \"you are hoping that this works as expected.\"  It's a form of <em>static</em> <em>analysis.</em><p>I'm not surprised that an old CodeIgniter project flagged these issues.<p>As for vi, I use vi every day as well.  I switch between that and PHPStorm.  It depends on the context that I'm in.  Both are wonderful <em>tools</em>.  But I can assure you, auto-complete is a basic feature of PHPStorm.  It's akin to 'set nu'.<p>Edit: This comment comes off as a bit snarky.  It's not intended to be.  I think JetBrains and it's line of products are excellent, and I've only ever had good experiences with them.  I wouldn't want my comment to reflect poorly on them.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "JetBrains Doomsday Sale - 75% off for 24 hours only",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.jetbrains.com/specials/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-19T22:41:56.000Z",
      "title": "",
      "url": "",
      "author": "timtadh",
      "points": 5,
      "story_text": null,
      "comment_text": "Accuracy. Detail. They have better analysis engines, which do more complex types of program analysis. The static program analysis field is incredibly deep it takes a lot of engineering to make a world class analysis engine. Just like it takes a lot of effort to make a world class optimising complier. (eg. the Intel C Compiler <i>still</i> out performs GCC despite monumental effort on GCC's side. It takes a long time to build this stuff)<p>They also have better rules sets from what I understand than the open source tools.",
      "num_comments": null,
      "story_id": 4543553,
      "story_title": "John Carmack on Static Code Analysis",
      "story_url": "http://www.altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 4545204,
      "created_at_i": 1348094516,
      "_tags": [
        "comment",
        "author_timtadh",
        "story_4543553"
      ],
      "objectID": "4545929",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "timtadh",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Accuracy. Detail. They have better <em>analysis</em> engines, which do more complex types of program <em>analysis.</em> The <em>static</em> program <em>analysis</em> field is incredibly deep it takes a lot of engineering to make a world class <em>analysis</em> engine. Just like it takes a lot of effort to make a world class optimising complier. (eg. the Intel C Compiler <i>still</i> out performs GCC despite monumental effort on GCC's side. It takes a long time to build this stuff)<p>They also have better rules sets from what I understand than the open source <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://www.altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2014-08-11T10:10:58.000Z",
      "title": null,
      "url": null,
      "author": "glibgil",
      "points": 4,
      "story_text": null,
      "comment_text": "The article is about static analysis. Static analysis is the most efficient way to catch a whole host of bugs. Testing would be a waste of everyone&#x27;s time for these types of bugs. Now, the tools in the article are commercial and perform static analysis on C and C++. Other programming languages have static analysis and code path coverage analysis built into their compilers. Many of those languages are free. Writing tests to cover those types of bugs is time wasted on a problem that is already solved.",
      "num_comments": null,
      "story_id": 8162259,
      "story_title": "Can We Trust the Libraries We Use?",
      "story_url": "http://www.viva64.com/en/b/0271/",
      "parent_id": 8162448,
      "created_at_i": 1407751858,
      "_tags": [
        "comment",
        "author_glibgil",
        "story_8162259"
      ],
      "objectID": "8162697",
      "_highlightResult": {
        "author": {
          "value": "glibgil",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The article is about <em>static</em> <em>analysis.</em> <em>Static</em> <em>analysis</em> is the most efficient way to catch a whole host of bugs. Testing would be a waste of everyone's time for these types of bugs. Now, the <em>tools</em> in the article are commercial and perform <em>static</em> <em>analysis</em> on C and C++. Other programming languages have <em>static</em> <em>analysis</em> and code path coverage <em>analysis</em> built into their compilers. Many of those languages are free. Writing tests to cover those types of bugs is time wasted on a problem that is already solved.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Can We Trust the Libraries We Use?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0271/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-01T14:01:34.000Z",
      "title": null,
      "url": null,
      "author": "krg",
      "points": 4,
      "story_text": null,
      "comment_text": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;</a><p>We don&#x27;t want ninjas and rockstars, just good developers<p>We hire people, not skill sets. If you&#x27;re a smart, motivated developer who likes our company culture, let&#x27;s talk.<p>Over the past 16 years we&#x27;ve cultivated a great group of people to work with. Our developers are smart, thoughtful, respectful to each other, opinionated, dedicated, and fun. We don&#x27;t hire often, and when we do, we value these qualities as much as technical abilities.<p>Founded by a former computer science professor, in many ways we keep the same feel as a small computer science lab (without the long hours):<p><pre><code>    Challenging and varied projects\\n    Informal, comfortable environment\\n    Intelligent, engaged people\\n    Lively, respectful technology discussions\\n    Frequent mentoring\\n    Easy camaraderie\\n    General culture of helpfulness and friendliness \\n</code></pre>\\nTeams at TechEmpower are typically between 2 and 6 people. Because of the small size of our teams, we need developers able to work on all aspects of an application (&quot;full stack&quot; developers). We rely on individual developers to do much of the software design, with guidance and discussion, and actively work to improve each other&#x27;s technical capabilities.<p>On average, a typical developer will get exposure to 3 or 4 different projects over the course of a year. Since each project has a different technology stack, developers gain varied experience over time and never stop learning.<p>We pride ourselves on doing the best work we can for our clients. This means working with them to really understand what they need built, carefully planning how to do it, and delivering what we promise while maintaining a sensible work&#x2F;life balance. We build quality applications and have fun doing it.<p>Also, we enjoy programming on high-performance workstations with 4K displays. A lot of code fits in 3840x2160 pixels!<p>The technologies we use vary over time with our mix of projects. Here is a snapshot of the technologies we use at the moment:<p><pre><code>    Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n    Tools: Git, Jenkins (Continuous Integration), Sonar (static code analysis), Eclipse, IntelliJ, Ant, Maven\\n    Web: Dropwizard, .NET MVC 5, Play, Django, Rails, Mustache, Handlebars, Backbone, Angular, Knockout, JSP, Servlets, jQuery, etc.\\n    Mobile: iOS, Android, PhoneGap\\n    Hosting: AWS (EC2, RDS, etc.), Rackspace Cloud, Linux deployments\\n    Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, NoSQL (Redis, MongoDB) \\n</code></pre>\\nWe don&#x27;t expect new hires to have experience with all of these, but developers at TechEmpower can expect to expand their skillsets with most of these over time.<p>If this sounds like the kind of place you&#x27;d like to work, please apply here: \\n<a href=\"http://jobs.techempower.com/hn\" rel=\"nofollow\">http:&#x2F;&#x2F;jobs.techempower.com&#x2F;hn</a>",
      "num_comments": null,
      "story_id": 7970366,
      "story_title": "Ask HN: Who is hiring? (July 2014)",
      "story_url": "",
      "parent_id": 7970366,
      "created_at_i": 1404223294,
      "_tags": [
        "comment",
        "author_krg",
        "story_7970366"
      ],
      "objectID": "7970676",
      "_highlightResult": {
        "author": {
          "value": "krg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http://www.techempower.com/benchmarks/</a><p>We don't want ninjas and rockstars, just good developers<p>We hire people, not skill sets. If you're a smart, motivated developer who likes our company culture, let's talk.<p>Over the past 16 years we've cultivated a great group of people to work with. Our developers are smart, thoughtful, respectful to each other, opinionated, dedicated, and fun. We don't hire often, and when we do, we value these qualities as much as technical abilities.<p>Founded by a former computer science professor, in many ways we keep the same feel as a small computer science lab (without the long hours):<p><pre><code>    Challenging and varied projects\\n    Informal, comfortable environment\\n    Intelligent, engaged people\\n    Lively, respectful technology discussions\\n    Frequent mentoring\\n    Easy camaraderie\\n    General culture of helpfulness and friendliness \\n</code></pre>\\nTeams at TechEmpower are typically between 2 and 6 people. Because of the small size of our teams, we need developers able to work on all aspects of an application (&quot;full stack&quot; developers). We rely on individual developers to do much of the software design, with guidance and discussion, and actively work to improve each other's technical capabilities.<p>On average, a typical developer will get exposure to 3 or 4 different projects over the course of a year. Since each project has a different technology stack, developers gain varied experience over time and never stop learning.<p>We pride ourselves on doing the best work we can for our clients. This means working with them to really understand what they need built, carefully planning how to do it, and delivering what we promise while maintaining a sensible work/life balance. We build quality applications and have fun doing it.<p>Also, we enjoy programming on high-performance workstations with 4K displays. A lot of code fits in 3840x2160 pixels!<p>The technologies we use vary over time with our mix of projects. Here is a snapshot of the technologies we use at the moment:<p><pre><code>    Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n    <em>Tools</em>: Git, Jenkins (Continuous Integration), Sonar (<em>static</em> code <em>analysis</em>), Eclipse, IntelliJ, Ant, Maven\\n    Web: Dropwizard, .NET MVC 5, Play, Django, Rails, Mustache, Handlebars, Backbone, Angular, Knockout, JSP, Servlets, jQuery, etc.\\n    Mobile: iOS, Android, PhoneGap\\n    Hosting: AWS (EC2, RDS, etc.), Rackspace Cloud, Linux deployments\\n    Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, NoSQL (Redis, MongoDB) \\n</code></pre>\\nWe don't expect new hires to have experience with all of these, but developers at TechEmpower can expect to expand their skillsets with most of these over time.<p>If this sounds like the kind of place you'd like to work, please apply here: \\n<a href=\"http://jobs.techempower.com/hn\" rel=\"nofollow\">http://jobs.techempower.com/hn</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (July 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-21T04:31:11.000Z",
      "title": null,
      "url": null,
      "author": "wsxcde",
      "points": 4,
      "story_text": null,
      "comment_text": "Model checking deals with two kinds of properties - safety and liveness. Safety properties effectively say nothing bad ever happens while liveness properties say that something good will eventually happen. For example, &quot;my program will never crash due to a null point dereference&quot; is a safety property. &quot;My arbiter module will output a grant for every input request&quot; is a liveness property.<p>It is true that model checkers are much better are proving safety properties than liveness properties. I think it&#x27;s not too far from the truth to say that model checkers are no good at proving liveness properties in real designs and that only safety properties work (somewhat well) in practice.<p>An alternative here is to abandon model checking altogether and focus on a powerful static analysis. I think the main challenge here is coming up with effective property specification schemes. A powerful type system like Haskell does in fact enable you to prove quite strong statements about your program. But you are inherently limited in terms of what you can prove to whatever it is that the type system can express. To me, it seems that model checkers allow more flexibility in specifying your property, especially when you take into account the fact that you can do your model checking on an augmented&#x2F;instrumented version of your design.<p>&gt; That&#x27;s a different problem scale than &quot;prove the whole thing works as specified&quot;.<p>On a vaguely related note, equivalence checking between designs, especially in the hardware context, is one thing that formal tools have had a lot of success with.",
      "num_comments": null,
      "story_id": 7618406,
      "story_title": "The Case for Formal Verification (2013)",
      "story_url": "http://permalink.gmane.org/gmane.comp.encryption.general/14818",
      "parent_id": 7618905,
      "created_at_i": 1398054671,
      "_tags": [
        "comment",
        "author_wsxcde",
        "story_7618406"
      ],
      "objectID": "7619796",
      "_highlightResult": {
        "author": {
          "value": "wsxcde",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Model checking deals with two kinds of properties - safety and liveness. Safety properties effectively say nothing bad ever happens while liveness properties say that something good will eventually happen. For example, &quot;my program will never crash due to a null point dereference&quot; is a safety property. &quot;My arbiter module will output a grant for every input request&quot; is a liveness property.<p>It is true that model checkers are much better are proving safety properties than liveness properties. I think it's not too far from the truth to say that model checkers are no good at proving liveness properties in real designs and that only safety properties work (somewhat well) in practice.<p>An alternative here is to abandon model checking altogether and focus on a powerful <em>static</em> <em>analysis.</em> I think the main challenge here is coming up with effective property specification schemes. A powerful type system like Haskell does in fact enable you to prove quite strong statements about your program. But you are inherently limited in terms of what you can prove to whatever it is that the type system can express. To me, it seems that model checkers allow more flexibility in specifying your property, especially when you take into account the fact that you can do your model checking on an augmented/instrumented version of your design.<p>&gt; That's a different problem scale than &quot;prove the whole thing works as specified&quot;.<p>On a vaguely related note, equivalence checking between designs, especially in the hardware context, is one thing that formal <em>tools</em> have had a lot of success with.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Case for Formal Verification (2013)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://permalink.gmane.org/gmane.comp.encryption.general/14818",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-21T00:48:05.000Z",
      "title": null,
      "url": null,
      "author": "stormbrew",
      "points": 4,
      "story_text": null,
      "comment_text": "I find it strange to think that TDD and formal verification are at odds with each other. For it to be backwards to write dynamic tests, you seem to be suggesting that it is actually worse than doing neither. I also don&#x27;t see how it can be documentation, glorified or otherwise, and not tell you anything about the properties of the software.<p>Really there are perhaps three practical levels of knowledge about what a piece of code does:\\n- It does something.\\n- If I give it X it gives me Y (for some finite set of X).\\n- It will never do Z (for some finite set of Z).<p>The first is the state most software is in most of the time. The second is achievable with tests and some kinds of static analysis. The last is probably only achievable with formal analysis and code that fits the constraints of that formal analysis.<p>But both levels are at least an improvement on nothing at all. Having functional and documenting tests does bring meaningful knowledge about some subset of what the code does, even if it isn&#x27;t the be-all and end-all of code analysis.<p>So I don&#x27;t see how you can dismiss it so easily, when to me it&#x27;s just a step on that striving you mention in your final sentence. For the moment it is perhaps true that the good is the enemy of the great on this, but that will become less true as the tools get better.<p>After all, even this article talks about only formally verifying part of the code of a web browser. Until and unless formally verifying the entire thing becomes possible, you still probably need the Acid tests to demonstrate its capabilities and help prevent regression.",
      "num_comments": null,
      "story_id": 7618406,
      "story_title": "The Case for Formal Verification (2013)",
      "story_url": "http://permalink.gmane.org/gmane.comp.encryption.general/14818",
      "parent_id": 7618609,
      "created_at_i": 1398041285,
      "_tags": [
        "comment",
        "author_stormbrew",
        "story_7618406"
      ],
      "objectID": "7619098",
      "_highlightResult": {
        "author": {
          "value": "stormbrew",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I find it strange to think that TDD and formal verification are at odds with each other. For it to be backwards to write dynamic tests, you seem to be suggesting that it is actually worse than doing neither. I also don't see how it can be documentation, glorified or otherwise, and not tell you anything about the properties of the software.<p>Really there are perhaps three practical levels of knowledge about what a piece of code does:\\n- It does something.\\n- If I give it X it gives me Y (for some finite set of X).\\n- It will never do Z (for some finite set of Z).<p>The first is the state most software is in most of the time. The second is achievable with tests and some kinds of <em>static</em> <em>analysis.</em> The last is probably only achievable with formal <em>analysis</em> and code that fits the constraints of that formal <em>analysis.</em><p>But both levels are at least an improvement on nothing at all. Having functional and documenting tests does bring meaningful knowledge about some subset of what the code does, even if it isn't the be-all and end-all of code <em>analysis.</em><p>So I don't see how you can dismiss it so easily, when to me it's just a step on that striving you mention in your final sentence. For the moment it is perhaps true that the good is the enemy of the great on this, but that will become less true as the <em>tools</em> get better.<p>After all, even this article talks about only formally verifying part of the code of a web browser. Until and unless formally verifying the entire thing becomes possible, you still probably need the Acid tests to demonstrate its capabilities and help prevent regression.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Case for Formal Verification (2013)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://permalink.gmane.org/gmane.comp.encryption.general/14818",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-16T22:18:35.000Z",
      "title": null,
      "url": null,
      "author": "byuu",
      "points": 4,
      "story_text": null,
      "comment_text": "&gt; If you want safety, stop thinking in terms of blame and vengeance<p>But that&#x27;s the thing, I don&#x27;t think anyone is really doing that in the industry. It&#x27;s not the solution to start blaming the programmer, but it&#x27;s a part of it. The other part is like you said, better accountability. It should be every bit as concerning that the compiler didn&#x27;t catch the dead code, that there was no code reviewer, that there was no static code analysis, that there was no test suite to ensure bad SSLs weren&#x27;t passing validation, etc.<p>&gt; Time for the software industry to mature.<p>Exactly! The way I see it now, there&#x27;s no real accountability. We go, &quot;Oh well, it&#x27;s the fault of the language. It shouldn&#x27;t have let me screw up. If only we had a new language without unbraced-ifs ... and it somehow caught on and replaced all 40-years of legacy C code. Whelp, back to business as usual.&quot;<p>I don&#x27;t see unbraced-ifs as this great security flaw, and I don&#x27;t see &#x27;fixing&#x27; it as curing some endemic problem with language design that&#x27;s going to lead us to not have bugs like this again. It&#x27;s too reactionary.<p>It may not be best-practice to do this, but I&#x27;ll admit there are times I want to add a quick one-liner check: &quot;if(already_initialized) return;&quot;, and it&#x27;s nice not having to put the extra braces there just because an Apple engineer once made a mistake.<p>For better or worse, the nature of technology is pragmatism, and not idealism. C let you use unbraced-ifs, and now it&#x27;s the most used language in the world. We can argue about how this should change, but it&#x27;s never going to. We can design a new language and maybe one day it&#x27;ll overtake C. But until then, let&#x27;s stop blaming our tools for things we should be taught on the first day we start using them.",
      "num_comments": null,
      "story_id": 7598721,
      "story_title": "Those Who Say Code Does Not Matter",
      "story_url": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
      "parent_id": 7599834,
      "created_at_i": 1397686715,
      "_tags": [
        "comment",
        "author_byuu",
        "story_7598721"
      ],
      "objectID": "7600867",
      "_highlightResult": {
        "author": {
          "value": "byuu",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; If you want safety, stop thinking in terms of blame and vengeance<p>But that's the thing, I don't think anyone is really doing that in the industry. It's not the solution to start blaming the programmer, but it's a part of it. The other part is like you said, better accountability. It should be every bit as concerning that the compiler didn't catch the dead code, that there was no code reviewer, that there was no <em>static</em> code <em>analysis</em>, that there was no test suite to ensure bad SSLs weren't passing validation, etc.<p>&gt; Time for the software industry to mature.<p>Exactly! The way I see it now, there's no real accountability. We go, &quot;Oh well, it's the fault of the language. It shouldn't have let me screw up. If only we had a new language without unbraced-ifs ... and it somehow caught on and replaced all 40-years of legacy C code. Whelp, back to business as usual.&quot;<p>I don't see unbraced-ifs as this great security flaw, and I don't see 'fixing' it as curing some endemic problem with language design that's going to lead us to not have bugs like this again. It's too reactionary.<p>It may not be best-practice to do this, but I'll admit there are times I want to add a quick one-liner check: &quot;if(already_initialized) return;&quot;, and it's nice not having to put the extra braces there just because an Apple engineer once made a mistake.<p>For better or worse, the nature of technology is pragmatism, and not idealism. C let you use unbraced-ifs, and now it's the most used language in the world. We can argue about how this should change, but it's never going to. We can design a new language and maybe one day it'll overtake C. But until then, let's stop blaming our <em>tools</em> for things we should be taught on the first day we start using them.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Those Who Say Code Does Not Matter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-01T14:16:28.000Z",
      "title": null,
      "url": null,
      "author": "krg",
      "points": 4,
      "story_text": null,
      "comment_text": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;</a>\\n(We&#x27;re working on getting Round 9 out as soon as possible--we swear!)<p>Here&#x27;s the job:<p>TechEmpower, a small custom software development firm located in El Segundo, seeks developers with good object-oriented experience, preferably in Java, JavaScript, Python, and&#x2F;or Ruby. We specialize in web application development but look for well-rounded application developers. If you are a solid programmer and a team player, this is an opportunity for you. Even if you don&#x27;t have experience with everything listed in this ad, we offer excellent learning opportunities for those who are eager to expand their skill sets.\\nJob Responsibilities<p>Working in small development teams, programmers participate in the architecture, design, and implementation of primarily Java, JavaScript, Python, C#, Ruby, and PHP code to meet client requirements for robust, high-performance, and secure sites and applications. Developers get exposure to several client projects and a variety of technologies over time.\\nJob Qualifications<p>In addition to overall programming capability, candidates must have experience working on collaborative development teams and very strong communication skills. While we employ and enjoy the company of extroverts and introverts alike, we reiterate that the ability to communicate clearly is a must-have for our technical staff. That means writing professional e-mails and interpreting the nuances of clients&#x27; requirements by asking good questions, for example.<p>We work hard to estimate projects accurately so that schedules are reasonable and developers work a normal amount of hours per week. We rely on developers to contribute to those estimates and provide feedback as a project goes along to keep things on track.<p>Ideal candidates will have experience building all facets of software systems including the data model, business logic, and front-end. 3+ years of object-oriented design and development in Java, JavaScript, Python, or Ruby is desired. On the front-end, HTML 5 and CSS experience is required.<p>Knowledge of some or all of the following specific tools and technologies is a plus:<p><pre><code>    Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n    Tools: Continuous Integration (Jenkins, Hudson, etc.), static code analysis (Sonar, etc.), Eclipse, IntelliJ, Ant, Maven\\n    Web: vert.x, Play, Spring, Django, Rails, node.js, JSP, Servlets, jQuery, etc.\\n    Mobile: iOS, Android, PhoneGap, jQuery Mobile or similar\\n    Hosting: AWS (EC2, RDS, etc.), cloud servers, Linux configuration, application servers (Resin, etc.)\\n    Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, Oracle, NoSQL (CouchDB, MongoDB, Cassandra, etc.) \\n</code></pre>\\nWe like technical people who are not afraid to have strong opinions about technology but simultaneously keep an open mind and are flexible enough to work with whatever technology the task at hand requires.<p>That said, we&#x27;re mostly looking for great developers who are great to work with. If you don&#x27;t have experience with everything listed above (and who does?) but are still a solid developer eager to learn new things, you might be a great fit here.<p>Please apply here: <a href=\"http://jobs.techempower.com/hn\" rel=\"nofollow\">http:&#x2F;&#x2F;jobs.techempower.com&#x2F;hn</a>",
      "num_comments": null,
      "story_id": 7507765,
      "story_title": "Ask HN: Who is hiring? (April 2014)",
      "story_url": "",
      "parent_id": 7507765,
      "created_at_i": 1396361788,
      "_tags": [
        "comment",
        "author_krg",
        "story_7507765"
      ],
      "objectID": "7508306",
      "_highlightResult": {
        "author": {
          "value": "krg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http://www.techempower.com/benchmarks/</a>\\n(We're working on getting Round 9 out as soon as possible--we swear!)<p>Here's the job:<p>TechEmpower, a small custom software development firm located in El Segundo, seeks developers with good object-oriented experience, preferably in Java, JavaScript, Python, and/or Ruby. We specialize in web application development but look for well-rounded application developers. If you are a solid programmer and a team player, this is an opportunity for you. Even if you don't have experience with everything listed in this ad, we offer excellent learning opportunities for those who are eager to expand their skill sets.\\nJob Responsibilities<p>Working in small development teams, programmers participate in the architecture, design, and implementation of primarily Java, JavaScript, Python, C#, Ruby, and PHP code to meet client requirements for robust, high-performance, and secure sites and applications. Developers get exposure to several client projects and a variety of technologies over time.\\nJob Qualifications<p>In addition to overall programming capability, candidates must have experience working on collaborative development teams and very strong communication skills. While we employ and enjoy the company of extroverts and introverts alike, we reiterate that the ability to communicate clearly is a must-have for our technical staff. That means writing professional e-mails and interpreting the nuances of clients' requirements by asking good questions, for example.<p>We work hard to estimate projects accurately so that schedules are reasonable and developers work a normal amount of hours per week. We rely on developers to contribute to those estimates and provide feedback as a project goes along to keep things on track.<p>Ideal candidates will have experience building all facets of software systems including the data model, business logic, and front-end. 3+ years of object-oriented design and development in Java, JavaScript, Python, or Ruby is desired. On the front-end, HTML 5 and CSS experience is required.<p>Knowledge of some or all of the following specific <em>tools</em> and technologies is a plus:<p><pre><code>    Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n    <em>Tools</em>: Continuous Integration (Jenkins, Hudson, etc.), <em>static</em> code <em>analysis</em> (Sonar, etc.), Eclipse, IntelliJ, Ant, Maven\\n    Web: vert.x, Play, Spring, Django, Rails, node.js, JSP, Servlets, jQuery, etc.\\n    Mobile: iOS, Android, PhoneGap, jQuery Mobile or similar\\n    Hosting: AWS (EC2, RDS, etc.), cloud servers, Linux configuration, application servers (Resin, etc.)\\n    Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, Oracle, NoSQL (CouchDB, MongoDB, Cassandra, etc.) \\n</code></pre>\\nWe like technical people who are not afraid to have strong opinions about technology but simultaneously keep an open mind and are flexible enough to work with whatever technology the task at hand requires.<p>That said, we're mostly looking for great developers who are great to work with. If you don't have experience with everything listed above (and who does?) but are still a solid developer eager to learn new things, you might be a great fit here.<p>Please apply here: <a href=\"http://jobs.techempower.com/hn\" rel=\"nofollow\">http://jobs.techempower.com/hn</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (April 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-04T07:08:24.000Z",
      "title": null,
      "url": null,
      "author": "pbsd",
      "points": 4,
      "story_text": null,
      "comment_text": "It&#x27;s obfuscation that is dependent on fully homomorphic encryption (FHE), not the other way around. Therefore, Barak&#x27;s impossibility proof is irrelevant to FHE.<p>With respect to FHE, before 2009 we already had some tools. We had RSA, which is multiplicatively homomorphic (this property is the reason behind the need for good padding!). We also had Paillier, which is additively homomorphic. We even had Boneh-Goh-Nissim, where you could do any number of additions plus <i>one</i> multiplication! In 2009 Gentry completed the picture with a partially homomorphic system, based on lattices,  where you could do a number of additions <i>and</i> multiplications before losing &quot;precision&quot;. Perhaps more importantly, he also gave us the bootstrapping notion, which allows you to achieve a fully homomorphic encryption scheme from a partially homomorphic one, provided you have enough &quot;precision&quot;.<p>Now, what the article talks about is not strictly covered by Barak&#x27;s theorem, since it&#x27;s a different notion (also defined in Barak&#x27;s paper): indistinguishability obfuscation. Barak proved that black-box obfuscation is impossible in the general case (i.e., for every possible program). Black-box obfuscation is the usual intuitive notion we have of obfuscation: given an obfuscated problem, you can&#x27;t obtain any more information from it than if you were just querying it as a black-box.<p>Indistinguishability obfuscation is more subtle: given two different programs <i>that compute the same function</i>, you can&#x27;t tell whether an obfuscated program is the obfuscation of the first or the second one. This at first sounds pretty useless as an obfuscation scheme, since it gives us few guarantees, but the authors took advantage of this notion to get some useful functionality out of it (namely functional encryption, and later other things).<p>Even more impressive is the fact that they now have managed to prove that a variant of the original scheme is actually black-box secure [1]. How is this compatible with Barak&#x27;s result, you ask? The black-box proof of [1] is in the multilinear model, which means it is under the assumption that the attacker can only do a limited set of (algebraic) operations. A poor analogy would be to show that some code obfuscation scheme is secure, but only as long as the attacker is limited to using static analysis.<p>[1] <a href=\"https://eprint.iacr.org/2013/631\" rel=\"nofollow\">https:&#x2F;&#x2F;eprint.iacr.org&#x2F;2013&#x2F;631</a>",
      "num_comments": null,
      "story_id": 7172800,
      "story_title": "Cryptography Breakthrough Could Make Software Unhackable",
      "story_url": "http://www.wired.com/wiredscience/2014/02/cryptography-breakthrough/",
      "parent_id": 7172998,
      "created_at_i": 1391497704,
      "_tags": [
        "comment",
        "author_pbsd",
        "story_7172800"
      ],
      "objectID": "7175913",
      "_highlightResult": {
        "author": {
          "value": "pbsd",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's obfuscation that is dependent on fully homomorphic encryption (FHE), not the other way around. Therefore, Barak's impossibility proof is irrelevant to FHE.<p>With respect to FHE, before 2009 we already had some <em>tools</em>. We had RSA, which is multiplicatively homomorphic (this property is the reason behind the need for good padding!). We also had Paillier, which is additively homomorphic. We even had Boneh-Goh-Nissim, where you could do any number of additions plus <i>one</i> multiplication! In 2009 Gentry completed the picture with a partially homomorphic system, based on lattices,  where you could do a number of additions <i>and</i> multiplications before losing &quot;precision&quot;. Perhaps more importantly, he also gave us the bootstrapping notion, which allows you to achieve a fully homomorphic encryption scheme from a partially homomorphic one, provided you have enough &quot;precision&quot;.<p>Now, what the article talks about is not strictly covered by Barak's theorem, since it's a different notion (also defined in Barak's paper): indistinguishability obfuscation. Barak proved that black-box obfuscation is impossible in the general case (i.e., for every possible program). Black-box obfuscation is the usual intuitive notion we have of obfuscation: given an obfuscated problem, you can't obtain any more information from it than if you were just querying it as a black-box.<p>Indistinguishability obfuscation is more subtle: given two different programs <i>that compute the same function</i>, you can't tell whether an obfuscated program is the obfuscation of the first or the second one. This at first sounds pretty useless as an obfuscation scheme, since it gives us few guarantees, but the authors took advantage of this notion to get some useful functionality out of it (namely functional encryption, and later other things).<p>Even more impressive is the fact that they now have managed to prove that a variant of the original scheme is actually black-box secure [1]. How is this compatible with Barak's result, you ask? The black-box proof of [1] is in the multilinear model, which means it is under the assumption that the attacker can only do a limited set of (algebraic) operations. A poor analogy would be to show that some code obfuscation scheme is secure, but only as long as the attacker is limited to using <em>static</em> <em>analysis.</em><p>[1] <a href=\"https://eprint.iacr.org/2013/631\" rel=\"nofollow\">https://eprint.iacr.org/2013/631</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Cryptography Breakthrough Could Make Software Unhackable",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.wired.com/wiredscience/2014/02/cryptography-breakthrough/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-22T15:56:32.000Z",
      "title": null,
      "url": null,
      "author": "kps",
      "points": 4,
      "story_text": null,
      "comment_text": "<p><pre><code>  All of the fancy static analysis that Xcode does is completely tied to clang, for example.\\n</code></pre>\\nXcode doesn&#x27;t do static analysis; Clang&#x2F;LLVM does, and it&#x27;s perfectly possible to do it from the command line, or embed it in other tools. (This is an example of the difference between LLVM&#x27;s modular library architecture and GCC plugins — LLVM doesn&#x27;t insist on being ‘on top’.)",
      "num_comments": null,
      "story_id": 7101824,
      "story_title": "Clang and FSF's strategy",
      "story_url": "http://gcc.gnu.org/ml/gcc/2014-01/msg00176.html",
      "parent_id": 7102765,
      "created_at_i": 1390406192,
      "_tags": [
        "comment",
        "author_kps",
        "story_7101824"
      ],
      "objectID": "7103333",
      "_highlightResult": {
        "author": {
          "value": "kps",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<p><pre><code>  All of the fancy <em>static</em> <em>analysis</em> that Xcode does is completely tied to clang, for example.\\n</code></pre>\\nXcode doesn't do <em>static</em> <em>analysis</em>; Clang/LLVM does, and it's perfectly possible to do it from the command line, or embed it in other <em>tools</em>. (This is an example of the difference between LLVM's modular library architecture and GCC plugins — LLVM doesn't insist on being ‘on top’.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Clang and FSF's strategy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://gcc.gnu.org/ml/gcc/2014-01/msg00176.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-24T07:12:59.000Z",
      "title": null,
      "url": null,
      "author": "apu",
      "points": 4,
      "story_text": null,
      "comment_text": "I know that \"more lax\" languages like python make static code analysis much tougher, but does anyone have any experience with good tools for it?",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388290,
      "created_at_i": 1324710779,
      "_tags": [
        "comment",
        "author_apu",
        "story_3388290"
      ],
      "objectID": "3388428",
      "_highlightResult": {
        "author": {
          "value": "apu",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I know that \"more lax\" languages like python make <em>static</em> code <em>analysis</em> much tougher, but does anyone have any experience with good <em>tools</em> for it?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2014-09-28T15:35:26.000Z",
      "title": null,
      "url": null,
      "author": "quakershake",
      "points": 3,
      "story_text": null,
      "comment_text": "&quot;There are loads of tools that should have never been implemented in C&#x2F;C++ in the first place (SSH, Make, APT, etc.). I&#x27;d say the best idea is to port a lot of these code bases to languages like Go or Rust maybe, but if that&#x27;s not feasible for some reason, at least write some unit tests and do static code analysis.&quot;<p>This is the exact problem with everything today. Languages do not make bugs, people do. If that weren&#x27;t the case, there wouldn&#x27;t be bugs is python&#x2F;ruby&#x2F;shell&#x2F;etc.<p>Rewriting something is only guaranteeing that more bugs be created initially. And all the time and effort gets you..what? The same thing that was just patching in a different language. Awesome...<p>You should be familiar with &quot;bikeshed&quot; being a freebsd user..",
      "num_comments": null,
      "story_id": 8379542,
      "story_title": "Dear clueless assholes: stop bashing bash and GNU",
      "story_url": "https://weev.livejournal.com/409835.html",
      "parent_id": 8379927,
      "created_at_i": 1411918526,
      "_tags": [
        "comment",
        "author_quakershake",
        "story_8379542"
      ],
      "objectID": "8379982",
      "_highlightResult": {
        "author": {
          "value": "quakershake",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&quot;There are loads of <em>tools</em> that should have never been implemented in C/C++ in the first place (SSH, Make, APT, etc.). I'd say the best idea is to port a lot of these code bases to languages like Go or Rust maybe, but if that's not feasible for some reason, at least write some unit tests and do <em>static</em> code <em>analysis.</em>&quot;<p>This is the exact problem with everything today. Languages do not make bugs, people do. If that weren't the case, there wouldn't be bugs is python/ruby/shell/etc.<p>Rewriting something is only guaranteeing that more bugs be created initially. And all the time and effort gets you..what? The same thing that was just patching in a different language. Awesome...<p>You should be familiar with &quot;bikeshed&quot; being a freebsd user..",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dear clueless assholes: stop bashing bash and GNU",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://weev.livejournal.com/409835.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-12T17:05:32.000Z",
      "title": null,
      "url": null,
      "author": "indygreg2",
      "points": 3,
      "story_text": null,
      "comment_text": "The path towards deterministic builds is definitely not clear. As many in this thread have pointed out, it&#x27;s a difficult technical problem. The difficulties are multiplied by a project at Firefox&#x27;s scale.<p>Further complicating matters is our platform breakdown. The majority of Firefox users are on Windows. Deterministic builds on Windows are very painful. And that&#x27;s before you figure PGO into the mix. Tor works around this by compiling Firefox with an open source toolchain and doesn&#x27;t use PGO. But that&#x27;s a non-starter for us because choosing an open source toolchain over Microsoft&#x27;s would result in performance degradations for our users. Believe me, if we could ship a Windows and Mac Firefox built with 100% open source to no detriment to our users, we would. There&#x27;s work to get Firefox building with Clang on Windows (but only for doing ASAN and static analysis, not for shipping to users). That gets us one step closer.<p>All that being said, there has been exploratory talk lately of serving segments of our user base with specialized Firefox builds. e.g. a build with developer tools front and center that caters to the web development community. If that ever happens, I imagine a deterministically-built Firefox with things like Tor built in could be on the table. The way you can make that happen is to direct noise directly at the Mozilla community. Send a well-crafted email to firefox-dev (<a href=\"https://mail.mozilla.org/listinfo/firefox-dev\" rel=\"nofollow\">https:&#x2F;&#x2F;mail.mozilla.org&#x2F;listinfo&#x2F;firefox-dev</a>) explaining your position. Anticipate that people will likely reply by asking you to prioritize this against existing goals, such as shipping 64-bit Firefox on Windows and shipping multi-process Firefox. We don&#x27;t have nearly unlimited resources like some of the other browser vendors, so we can&#x27;t just do everything. Again, I implore people to directly contribute to Mozilla any way they can. <a href=\"https://www.mozilla.org/contribute/\" rel=\"nofollow\">https:&#x2F;&#x2F;www.mozilla.org&#x2F;contribute&#x2F;</a>",
      "num_comments": null,
      "story_id": 8023035,
      "story_title": "Deterministic, bit-identical and/or verifiable Linux builds",
      "story_url": "https://bugzilla.mozilla.org/show_bug.cgi?id=885777",
      "parent_id": 8024323,
      "created_at_i": 1405184732,
      "_tags": [
        "comment",
        "author_indygreg2",
        "story_8023035"
      ],
      "objectID": "8025076",
      "_highlightResult": {
        "author": {
          "value": "indygreg2",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The path towards deterministic builds is definitely not clear. As many in this thread have pointed out, it's a difficult technical problem. The difficulties are multiplied by a project at Firefox's scale.<p>Further complicating matters is our platform breakdown. The majority of Firefox users are on Windows. Deterministic builds on Windows are very painful. And that's before you figure PGO into the mix. Tor works around this by compiling Firefox with an open source toolchain and doesn't use PGO. But that's a non-starter for us because choosing an open source toolchain over Microsoft's would result in performance degradations for our users. Believe me, if we could ship a Windows and Mac Firefox built with 100% open source to no detriment to our users, we would. There's work to get Firefox building with Clang on Windows (but only for doing ASAN and <em>static</em> <em>analysis</em>, not for shipping to users). That gets us one step closer.<p>All that being said, there has been exploratory talk lately of serving segments of our user base with specialized Firefox builds. e.g. a build with developer <em>tools</em> front and center that caters to the web development community. If that ever happens, I imagine a deterministically-built Firefox with things like Tor built in could be on the table. The way you can make that happen is to direct noise directly at the Mozilla community. Send a well-crafted email to firefox-dev (<a href=\"https://mail.mozilla.org/listinfo/firefox-dev\" rel=\"nofollow\">https://mail.mozilla.org/listinfo/firefox-dev</a>) explaining your position. Anticipate that people will likely reply by asking you to prioritize this against existing goals, such as shipping 64-bit Firefox on Windows and shipping multi-process Firefox. We don't have nearly unlimited resources like some of the other browser vendors, so we can't just do everything. Again, I implore people to directly contribute to Mozilla any way they can. <a href=\"https://www.mozilla.org/contribute/\" rel=\"nofollow\">https://www.mozilla.org/contribute/</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Deterministic, bit-identical and/or verifiable Linux builds",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://bugzilla.mozilla.org/show_bug.cgi?id=885777",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-05-11T21:40:29.000Z",
      "title": null,
      "url": null,
      "author": "Sanddancer",
      "points": 3,
      "story_text": null,
      "comment_text": "I singled out the original BSD license because it was extant and the GPL was not compatible with it. Such clauses are pretty common in the software world and give credit where credit&#x27;s due; hell, Microsoft has no problem with it, why does it bind the panties of the average GPL supporter so much?<p>Furthermore, I&#x27;d argue that a lot of those defense mechanisms that copyleft supporters claim are necessary cause much more harm to Free Software than they do to proprietary software. The ability to use GCC for static analysis, for example, was muddied for many years by the GCC team&#x27;s unwillingness to create a suitable API out of fear that it would become easier for proprietary software teams to use GCC without contributing. Meanwhile, proprietary compiler chains, like those Microsoft provided, were easily able to create those same tools because they were not driven by such fears. Additionally, you have statements from people like RMS trying to memory hole software ( <a href=\"http://gcc.gnu.org/ml/gcc/2001-02/msg00895.html\" rel=\"nofollow\">http:&#x2F;&#x2F;gcc.gnu.org&#x2F;ml&#x2F;gcc&#x2F;2001-02&#x2F;msg00895.html</a> ) that doesn&#x27;t agree with his political views. While the goals may be noble, the route the free software community has chosen to get there has devolved into stubbornness and childishness to the detriment of everyone.",
      "num_comments": null,
      "story_id": 7729373,
      "story_title": "Oracle continue to circumvent EXPORT_SYMBOL_GPL()",
      "story_url": "http://mjg59.dreamwidth.org/31357.html",
      "parent_id": 7729997,
      "created_at_i": 1399844429,
      "_tags": [
        "comment",
        "author_Sanddancer",
        "story_7729373"
      ],
      "objectID": "7730111",
      "_highlightResult": {
        "author": {
          "value": "Sanddancer",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I singled out the original BSD license because it was extant and the GPL was not compatible with it. Such clauses are pretty common in the software world and give credit where credit's due; hell, Microsoft has no problem with it, why does it bind the panties of the average GPL supporter so much?<p>Furthermore, I'd argue that a lot of those defense mechanisms that copyleft supporters claim are necessary cause much more harm to Free Software than they do to proprietary software. The ability to use GCC for <em>static</em> <em>analysis</em>, for example, was muddied for many years by the GCC team's unwillingness to create a suitable API out of fear that it would become easier for proprietary software teams to use GCC without contributing. Meanwhile, proprietary compiler chains, like those Microsoft provided, were easily able to create those same <em>tools</em> because they were not driven by such fears. Additionally, you have statements from people like RMS trying to memory hole software ( <a href=\"http://gcc.gnu.org/ml/gcc/2001-02/msg00895.html\" rel=\"nofollow\">http://gcc.gnu.org/ml/gcc/2001-02/msg00895.html</a> ) that doesn't agree with his political views. While the goals may be noble, the route the free software community has chosen to get there has devolved into stubbornness and childishness to the detriment of everyone.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Oracle continue to circumvent EXPORT_SYMBOL_GPL()",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://mjg59.dreamwidth.org/31357.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-12T18:27:22.000Z",
      "title": null,
      "url": null,
      "author": "lbarrow",
      "points": 3,
      "story_text": null,
      "comment_text": "It&#x27;s super cool to see the power of advanced static analysis these days. Props to the Coverity team for using the Heartbleed trainwreck to motivate new research on these problems.<p>That said, are there other ways to fix this class of problem? We have choices. We can continue to build ever-more-advanced tools for patching over the problems of C and C++, or we can start using languages that simply do not have those problems.<p>There will always be a need for C and C++ in device drivers, microcontrollers, etc. But there&#x27;s no compelling reason why SSL implementations in 2014 should use languages designed to run on mainframes in 1973.",
      "num_comments": null,
      "story_id": 7578427,
      "story_title": "A New Development for Coverity and Heartbleed",
      "story_url": "http://blog.regehr.org/archives/1128",
      "parent_id": 7578427,
      "created_at_i": 1397327242,
      "_tags": [
        "comment",
        "author_lbarrow",
        "story_7578427"
      ],
      "objectID": "7578665",
      "_highlightResult": {
        "author": {
          "value": "lbarrow",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's super cool to see the power of advanced <em>static</em> <em>analysis</em> these days. Props to the Coverity team for using the Heartbleed trainwreck to motivate new research on these problems.<p>That said, are there other ways to fix this class of problem? We have choices. We can continue to build ever-more-advanced <em>tools</em> for patching over the problems of C and C++, or we can start using languages that simply do not have those problems.<p>There will always be a need for C and C++ in device drivers, microcontrollers, etc. But there's no compelling reason why SSL implementations in 2014 should use languages designed to run on mainframes in 1973.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "A New Development for Coverity and Heartbleed",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.regehr.org/archives/1128",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T16:19:52.000Z",
      "title": null,
      "url": null,
      "author": "notacoward",
      "points": 3,
      "story_text": null,
      "comment_text": "To put it briefly: no.<p>A little less briefly, then.  ;)  It is absolutely possible to create code that these tools in general, and Coverity in particular, will have difficulty analyzing . . . but you really have to work at it.  Seriously, these guys are good.  It&#x27;s a bit like the &quot;arms race&quot; in building vs. breaking crypto.  These guys have been there, they&#x27;ve seen all the moves, they know all the countermoves.  Sure, if you load up your code with runtime-assigned function pointers and code that only executes if the last five iterations of a loop each went through specific code paths themselves, then that&#x27;s going to cause some problems, but most programmers are unlikely to &quot;win&quot; that battle.<p>However, <i>this</i> particular bug looks like it&#x27;s in the absolute easiest category.  <i>Any</i> static analyzer should have caught it.  As others have pointed out, the real problem is false positives.  If it was caught, but the report was buried in hundreds or thousands of crappy reports about things that actually aren&#x27;t problems, then it might as well not have been caught.  That&#x27;s why the pros at this spend as much time writing code to eliminate false positives as they do writing code to find new things.  In every project I&#x27;ve worked on that used static analysis, the weak link in the chain has been between reporting and remedy, not in the analysis itself.",
      "num_comments": null,
      "story_id": 7565764,
      "story_title": "'Heartbleed' contributor denies he inserted it deliberately",
      "story_url": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
      "parent_id": 7566748,
      "created_at_i": 1397146792,
      "_tags": [
        "comment",
        "author_notacoward",
        "story_7565764"
      ],
      "objectID": "7567485",
      "_highlightResult": {
        "author": {
          "value": "notacoward",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "To put it briefly: no.<p>A little less briefly, then.  ;)  It is absolutely possible to create code that these <em>tools</em> in general, and Coverity in particular, will have difficulty analyzing . . . but you really have to work at it.  Seriously, these guys are good.  It's a bit like the &quot;arms race&quot; in building vs. breaking crypto.  These guys have been there, they've seen all the moves, they know all the countermoves.  Sure, if you load up your code with runtime-assigned function pointers and code that only executes if the last five iterations of a loop each went through specific code paths themselves, then that's going to cause some problems, but most programmers are unlikely to &quot;win&quot; that battle.<p>However, <i>this</i> particular bug looks like it's in the absolute easiest category.  <i>Any</i> <em>static</em> analyzer should have caught it.  As others have pointed out, the real problem is false positives.  If it was caught, but the report was buried in hundreds or thousands of crappy reports about things that actually aren't problems, then it might as well not have been caught.  That's why the pros at this spend as much time writing code to eliminate false positives as they do writing code to find new things.  In every project I've worked on that used <em>static</em> <em>analysis</em>, the weak link in the chain has been between reporting and remedy, not in the <em>analysis</em> itself.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "'Heartbleed' contributor denies he inserted it deliberately",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-10T14:34:09.000Z",
      "title": null,
      "url": null,
      "author": "fit2rule",
      "points": 3,
      "story_text": null,
      "comment_text": "I just can&#x27;t understand why such critical components as OpenSSL just don&#x27;t use Code Coverage tools like Coverity to find such things as this?  Testing, coverage certification, static analysis: this would have been caught if these tools were being used.",
      "num_comments": null,
      "story_id": 7565764,
      "story_title": "'Heartbleed' contributor denies he inserted it deliberately",
      "story_url": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
      "parent_id": 7565764,
      "created_at_i": 1397140449,
      "_tags": [
        "comment",
        "author_fit2rule",
        "story_7565764"
      ],
      "objectID": "7566403",
      "_highlightResult": {
        "author": {
          "value": "fit2rule",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I just can't understand why such critical components as OpenSSL just don't use Code Coverage <em>tools</em> like Coverity to find such things as this?  Testing, coverage certification, <em>static</em> <em>analysis</em>: this would have been caught if these <em>tools</em> were being used.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "'Heartbleed' contributor denies he inserted it deliberately",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.smh.com.au/it-pro/security-it/man-who-introduced-serious-heartbleed-security-flaw-denies-he-inserted-it-deliberately-20140410-zqta1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-04T17:29:06.000Z",
      "title": null,
      "url": null,
      "author": "klibertp",
      "points": 3,
      "story_text": null,
      "comment_text": "&gt; For Groovy this just isn&#x27;t possible<p>It&#x27;s true in general, but in most specific cases it is possible to statically analyse dynamic languages to the point of providing meaningful auto-completion. For example in Python-land there is Jedi (<a href=\"http://jedi.jedidjah.ch/en/latest/\" rel=\"nofollow\">http:&#x2F;&#x2F;jedi.jedidjah.ch&#x2F;en&#x2F;latest&#x2F;</a>), and also commercial Komodo IDE and PyCharm. This is done through static analysis, so that no code is ever run for auto-completion.<p>So, while it&#x27;s impossible in general case, it&#x27;s perfectly possible to create useful auto-completion for dynamic languages. There are such tools for Python, JS and probably others as well.",
      "num_comments": null,
      "story_id": 7530145,
      "story_title": "Xtend – Modernized Java",
      "story_url": "https://www.eclipse.org/xtend/documentation.html",
      "parent_id": 7531486,
      "created_at_i": 1396632546,
      "_tags": [
        "comment",
        "author_klibertp",
        "story_7530145"
      ],
      "objectID": "7532934",
      "_highlightResult": {
        "author": {
          "value": "klibertp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; For Groovy this just isn't possible<p>It's true in general, but in most specific cases it is possible to statically analyse dynamic languages to the point of providing meaningful auto-completion. For example in Python-land there is Jedi (<a href=\"http://jedi.jedidjah.ch/en/latest/\" rel=\"nofollow\">http://jedi.jedidjah.ch/en/latest/</a>), and also commercial Komodo IDE and PyCharm. This is done through <em>static</em> <em>analysis</em>, so that no code is ever run for auto-completion.<p>So, while it's impossible in general case, it's perfectly possible to create useful auto-completion for dynamic languages. There are such <em>tools</em> for Python, JS and probably others as well.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Xtend – Modernized Java",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.eclipse.org/xtend/documentation.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-22T10:19:57.000Z",
      "title": null,
      "url": null,
      "author": "pjmlp",
      "points": 3,
      "story_text": null,
      "comment_text": "- Visual representation of the code structure<p>- Ability to select any symbol and find semantic uses of it<p>- For OO code, being able to visuallize the OO graph usage of certain symbols<p>- Refactoring across the whole project with semantic knowledge (no, search&#x2F;replace does does not cut it)<p>- Navigation in third-party libraries deployed in binary format<p>- Code completion for static&#x2F;dynamic languages, while showing tooltip documentation<p>- Graphical visualization of data structures on the debugger<p>- Background compilation with static analysis<p>- unit test debugging infrastructure<p>- integration with modelling tools<p>- integration with SCM tooling and being able to interact with them directly from the editor. For example, generating a blame file, with navigation across the file revisions.<p>- integration  with continuous integration servers<p>- integration of developer workflow with task management servers<p>As an example of such developer workflows, have the IDE talk to Jira, edit the code, automatically bundle it in a workflow that binds the code changes to the Jira issue being worked on, get a Jenkins notification after the code is checked in and gone through the CI system.<p>Sure you can get part of it in Emacs, after spending a week configuring plugins, with different levels of maturity, and in the end it is still mostly textual.",
      "num_comments": null,
      "story_id": 7278214,
      "story_title": "Neovim",
      "story_url": "https://github.com/neovim/neovim",
      "parent_id": 7281610,
      "created_at_i": 1393064397,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_7278214"
      ],
      "objectID": "7281659",
      "_highlightResult": {
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "- Visual representation of the code structure<p>- Ability to select any symbol and find semantic uses of it<p>- For OO code, being able to visuallize the OO graph usage of certain symbols<p>- Refactoring across the whole project with semantic knowledge (no, search/replace does does not cut it)<p>- Navigation in third-party libraries deployed in binary format<p>- Code completion for <em>static</em>/dynamic languages, while showing tooltip documentation<p>- Graphical visualization of data structures on the debugger<p>- Background compilation with <em>static</em> <em>analysis</em><p>- unit test debugging infrastructure<p>- integration with modelling <em>tools</em><p>- integration with SCM tooling and being able to interact with them directly from the editor. For example, generating a blame file, with navigation across the file revisions.<p>- integration  with continuous integration servers<p>- integration of developer workflow with task management servers<p>As an example of such developer workflows, have the IDE talk to Jira, edit the code, automatically bundle it in a workflow that binds the code changes to the Jira issue being worked on, get a Jenkins notification after the code is checked in and gone through the CI system.<p>Sure you can get part of it in Emacs, after spending a week configuring plugins, with different levels of maturity, and in the end it is still mostly textual.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Neovim",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/neovim/neovim",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-27T19:34:56.000Z",
      "title": null,
      "url": null,
      "author": "agentultra",
      "points": 3,
      "story_text": null,
      "comment_text": "Given the lack of evidence to support the claim I find the argument specious. There are large code bases written in dynamic languages that are well maintained by thousands of contributors that could weaken such a claim without strong data backing it up (OpenStack comes to mind). The author fails to provide a link to a single study and relies purely on intuition for eir argument.<p>I only see one link to that answer on SO that points to a single study. It was provided by another commentator asking for the OP to provide evidence for the &quot;strong correlation,&quot; claim. Not very good.<p>Though I&#x27;d hate to work with a team that used a statically typed language and tools that didn&#x27;t write tests for their software. It&#x27;s not magic soya-sauce that frees you from ever introducing bugs into your software. Most static analyzers I&#x27;ve seen for C-like languages involve computing the fixed-point from a graph (ie: looking for convergence). Generics makes things a little trickier. Tests are as much about specification as they are about correctness.<p>In my experience there are some things you will only ever know at run-time and the trade-off in flexibility for static analysis is not very beneficial in most cases.<p>Some interesting areas in program analysis are, imho, the intersection of logic programming, decomposition methods and constraint programming as applied to whole-program analysis. Projects like kibit in Clojure-land are neat and it would be cool to see them applied more generally to other problems such as, &quot;correctness,&quot; and the like.",
      "num_comments": null,
      "story_id": 7131885,
      "story_title": "Why do dynamic languages make it more difficult to maintain large codebases?",
      "story_url": "http://programmers.stackexchange.com/questions/221615/why-do-dynamic-languages-make-it-more-difficult-to-maintain-large-codebases/221658#221658",
      "parent_id": 7131885,
      "created_at_i": 1390851296,
      "_tags": [
        "comment",
        "author_agentultra",
        "story_7131885"
      ],
      "objectID": "7132577",
      "_highlightResult": {
        "author": {
          "value": "agentultra",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Given the lack of evidence to support the claim I find the argument specious. There are large code bases written in dynamic languages that are well maintained by thousands of contributors that could weaken such a claim without strong data backing it up (OpenStack comes to mind). The author fails to provide a link to a single study and relies purely on intuition for eir argument.<p>I only see one link to that answer on SO that points to a single study. It was provided by another commentator asking for the OP to provide evidence for the &quot;strong correlation,&quot; claim. Not very good.<p>Though I'd hate to work with a team that used a statically typed language and <em>tools</em> that didn't write tests for their software. It's not magic soya-sauce that frees you from ever introducing bugs into your software. Most <em>static</em> analyzers I've seen for C-like languages involve computing the fixed-point from a graph (ie: looking for convergence). Generics makes things a little trickier. Tests are as much about specification as they are about correctness.<p>In my experience there are some things you will only ever know at run-time and the trade-off in flexibility for <em>static</em> <em>analysis</em> is not very beneficial in most cases.<p>Some interesting areas in program <em>analysis</em> are, imho, the intersection of logic programming, decomposition methods and constraint programming as applied to whole-program <em>analysis.</em> Projects like kibit in Clojure-land are neat and it would be cool to see them applied more generally to other problems such as, &quot;correctness,&quot; and the like.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why do dynamic languages make it more difficult to maintain large codebases?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://programmers.stackexchange.com/questions/221615/why-do-dynamic-languages-make-it-more-difficult-to-maintain-large-codebases/221658#221658",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-01T19:14:37.000Z",
      "title": null,
      "url": null,
      "author": "tikhonj",
      "points": 3,
      "story_text": null,
      "comment_text": "SEEKING WORK<p>For various reasons, I&#x27;m taking some time off from school. I&#x27;m looking for some interesting work for anywhere from 3 to 6 months--maybe more.<p>I specialize in programming languages: DSLs, static analysis, verification, program synthesis[1] and so on.<p>Admittedly, this is a narrow field, but it&#x27;s also surprisingly broadly applicable: there are many domains where a small domain-specific language can be much more expressive than a standard library; I then know how to build some powerful tools on top of the language including things like bounded verification and all sorts of static checking. DSLs can be used both to help expert programmers or to make a system more accessible to non-programmers. Especially for the latter, we can also design interesting <i>interactive</i> tools that help non-experts express themselves as they go along.<p>I also do a lot of functional programming: primarily Haskell along with OCaml and Racket. If you&#x27;re interested in experimenting with functional programming at your startup, I&#x27;d really love to help. Apart from actually using functional programming, I really enjoy teaching people about it: for example, I&#x27;m in the top 10 for [haskell] on StackOverflow[2] and I&#x27;ve recently been teaching people about type theory at a meetup in SF[3]. I also have a particular interest in functional reactive programming (FRP); over the summer, I even designed an FRP library for OCaml (in the browser--with js_of_ocaml).<p>If any of this sounds interesting, I&#x27;d love to talk to you! My email is tikhon@jelv.is; you can see a recent resume at <a href\"http://jelv.is/resume.pd\" rel\"nofollo\">http:&#x2F;&#x2F;jelv.is&#x2F;resume.pdf</a> or on <a href\"http://careers.stackoverflow.com/tikhonjelvi\" rel\"nofollo\">http:&#x2F;&#x2F;careers.stackoverflow.com&#x2F;tikhonjelvis</a>. My site, naturally, is <a href\"http://jelv.is\" rel\"nofollo\">http:&#x2F;&#x2F;jelv.is;</a> I have to admit I&#x27;m unreasonably happy with the little domain hack :). Also check out my LinkedIn profile: <a href\"http://www.linkedin.com/pub/tikhon-jelvis/24/237/75\" rel\"nofollo\">http:&#x2F;&#x2F;www.linkedin.com&#x2F;pub&#x2F;tikhon-jelvis&#x2F;24&#x2F;237&#x2F;750</a><p>I&#x27;d prefer to find something in the Bay Area, but I&#x27;m flexible along both remote work or living somewhere else.<p>[1]: Program synthesis is a type of automatic programming--generating programs programmatically, by searching through the space of all possible programs. It&#x27;s an exciting field that has really heated up in the last few years thanks to advances in computational power and SMT solvers. I think it&#x27;s about ripe for some practical applications. I&#x27;ve done some research on the subject and implemented a few different synthesizers, so I have a reasonably rare amount of experience with it.<p>Program synthesis also involves verifying the programs we generate. Our approach to &quot;bounded verification&quot; is actually interesting on its own: we can reasonably quickly check conditions against code <i>exhaustively</i>, using an SMT solver. This could be very useful if you need high levels of assurance about your code.<p>[2]: <a href\"http://stackoverflow.com/tags/haskell/topuser\" rel\"nofollo\">http:&#x2F;&#x2F;stackoverflow.com&#x2F;tags&#x2F;haskell&#x2F;topusers</a><p>[3]: You can see past slides at <a href\"http://jelv.is/talk\" rel\"nofollo\">http:&#x2F;&#x2F;jelv.is&#x2F;talks</a>. Feel free to pop by our next meeting about two weeks from now; we&#x27;re going to have an introduction to basic category theory, with very little mathematical background needed. The actual meetup page: <a href\"http://www.meetup.com/SF-Types-Theorems-and-Programming-Languages\" rel\"nofollo\">http:&#x2F;&#x2F;www.meetup.com&#x2F;SF-Types-Theorems-and-Programming-Lang...</a>",
      "num_comments": null,
      "story_id": 6995014,
      "story_title": "Ask HN: Freelancer? Seeking freelancer? (January 2014)",
      "story_url": "",
      "parent_id": 6995014,
      "created_at_i": 1388603677,
      "_tags": [
        "comment",
        "author_tikhonj",
        "story_6995014"
      ],
      "objectID": "6996094",
      "_highlightResult": {
        "author": {
          "value": "tikhonj",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "SEEKING WORK<p>For various reasons, I'm taking some time off from school. I'm looking for some interesting work for anywhere from 3 to 6 months--maybe more.<p>I specialize in programming languages: DSLs, <em>static</em> <em>analysis</em>, verification, program synthesis[1] and so on.<p>Admittedly, this is a narrow field, but it's also surprisingly broadly applicable: there are many domains where a small domain-specific language can be much more expressive than a standard library; I then know how to build some powerful <em>tools</em> on top of the language including things like bounded verification and all sorts of <em>static</em> checking. DSLs can be used both to help expert programmers or to make a system more accessible to non-programmers. Especially for the latter, we can also design interesting <i>interactive</i> <em>tools</em> that help non-experts express themselves as they go along.<p>I also do a lot of functional programming: primarily Haskell along with OCaml and Racket. If you're interested in experimenting with functional programming at your startup, I'd really love to help. Apart from actually using functional programming, I really enjoy teaching people about it: for example, I'm in the top 10 for [haskell] on StackOverflow[2] and I've recently been teaching people about type theory at a meetup in SF[3]. I also have a particular interest in functional reactive programming (FRP); over the summer, I even designed an FRP library for OCaml (in the browser--with js_of_ocaml).<p>If any of this sounds interesting, I'd love to talk to you! My email is tikhon@jelv.is; you can see a recent resume at <a href\"http://jelv.is/resume.pd\" rel\"nofollo\">http://jelv.is/resume.pdf</a> or on <a href\"http://careers.stackoverflow.com/tikhonjelvi\" rel\"nofollo\">http://careers.stackoverflow.com/tikhonjelvis</a>. My site, naturally, is <a href\"http://jelv.is\" rel\"nofollo\">http://jelv.is;</a> I have to admit I'm unreasonably happy with the little domain hack :). Also check out my LinkedIn profile: <a href\"http://www.linkedin.com/pub/tikhon-jelvis/24/237/75\" rel\"nofollo\">http://www.linkedin.com/pub/tikhon-jelvis/24/237/750</a><p>I'd prefer to find something in the Bay Area, but I'm flexible along both remote work or living somewhere else.<p>[1]: Program synthesis is a type of automatic programming--generating programs programmatically, by searching through the space of all possible programs. It's an exciting field that has really heated up in the last few years thanks to advances in computational power and SMT solvers. I think it's about ripe for some practical applications. I've done some research on the subject and implemented a few different synthesizers, so I have a reasonably rare amount of experience with it.<p>Program synthesis also involves verifying the programs we generate. Our approach to &quot;bounded verification&quot; is actually interesting on its own: we can reasonably quickly check conditions against code <i>exhaustively</i>, using an SMT solver. This could be very useful if you need high levels of assurance about your code.<p>[2]: <a href\"http://stackoverflow.com/tags/haskell/topuser\" rel\"nofollo\">http://stackoverflow.com/tags/haskell/topusers</a><p>[3]: You can see past slides at <a href\"http://jelv.is/talk\" rel\"nofollo\">http://jelv.is/talks</a>. Feel free to pop by our next meeting about two weeks from now; we're going to have an introduction to basic category theory, with very little mathematical background needed. The actual meetup page: <a href\"http://www.meetup.com/SF-Types-Theorems-and-Programming-Languages\" rel\"nofollo\">http://www.meetup.com/SF-Types-Theorems-and-Programming-Lang...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Freelancer? Seeking freelancer? (January 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-10-10T14:20:15.000Z",
      "title": null,
      "url": null,
      "author": "wes-exp",
      "points": 3,
      "story_text": null,
      "comment_text": "&quot;You need static typing to have Java-like tools&quot;<p>This is a widely repeated myth. Static typing does enable a few additional autocomplete capabilities, but most of the other things you probably think of as fancy IDE features are completely possible for dynamic languages.<p>For example, using Common Lisp with emacs and SLIME, I have:<p>Function&#x2F;method name completion, Variable name completion, Jump to definition, Show callers, Rename (heuristic, but usually better than static analysis), Extract method, All sorts of interactive debugging capabilities, Documentation lookup, and Numerous compile-time static analysis checks including type errors!",
      "num_comments": null,
      "story_id": 6524385,
      "story_title": "If Java Is Dying, It Sure Looks Awfully Healthy",
      "story_url": "http://www.drdobbs.com/jvm/if-java-is-dying-it-sure-looks-awfully-h/240162390/",
      "parent_id": 6527004,
      "created_at_i": 1381414815,
      "_tags": [
        "comment",
        "author_wes-exp",
        "story_6524385"
      ],
      "objectID": "6527848",
      "_highlightResult": {
        "author": {
          "value": "wes-exp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&quot;You need <em>static</em> typing to have Java-like <em>tools</em>&quot;<p>This is a widely repeated myth. <em>Static</em> typing does enable a few additional autocomplete capabilities, but most of the other things you probably think of as fancy IDE features are completely possible for dynamic languages.<p>For example, using Common Lisp with emacs and SLIME, I have:<p>Function/method name completion, Variable name completion, Jump to definition, Show callers, Rename (heuristic, but usually better than <em>static</em> <em>analysis</em>), Extract method, All sorts of interactive debugging capabilities, Documentation lookup, and Numerous compile-time <em>static</em> <em>analysis</em> checks including type errors!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "If Java Is Dying, It Sure Looks Awfully Healthy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.drdobbs.com/jvm/if-java-is-dying-it-sure-looks-awfully-h/240162390/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-11-18T16:30:31.000Z",
      "title": "",
      "url": "",
      "author": "kstenerud",
      "points": 3,
      "story_text": null,
      "comment_text": "\"won't venture into some places that a good engineer needs to go, because to be decent at the job you really do need to understand the command-line interface\"<p>This is only true if the IDE has not kept up with the command line interface. Visual Studio and Xcode do pretty much everything their CLI can do except maybe some tool integration like CI or deployment. But that's operations, not programming.<p>\"IDEs are a good tool that ... is very often put to bad use.\"<p>So is every other tool out there. What's your point?<p>\"The one thing they are really good for (reading low-quality code) is something engineers hate doing.\"<p>They are also good for:<p>- Writing good quality code.<p>- Looking up methods.<p>- Code completion.<p>- Code navigation.<p>- Interactive debugging.<p>The list goes on.<p>\"IDE-dependence is evil\"<p>No it is not. You might as well say static analysis dependence is evil or compile-time optimization is evil or profilers are evil or any other convenience is evil. Should we all remain puritans and suffer cryptic and unwieldy tools just because making them more powerful and friendly also makes them more powerful and friendly for bad programmers?<p>Bad programmers will write bad code no matter what tools they use. Blaming the IDE is disingenuous and quite frankly comes off as arrogant and elitist.",
      "num_comments": null,
      "story_id": 4800188,
      "story_title": "The IDE As a Bad Programming Language Enabler",
      "story_url": "http://developers.slashdot.org/story/12/10/30/065244/the-ide-as-a-bad-programming-language-enabler?sdsrc=popbyskid",
      "parent_id": 4800695,
      "created_at_i": 1353256231,
      "_tags": [
        "comment",
        "author_kstenerud",
        "story_4800188"
      ],
      "objectID": "4800849",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "kstenerud",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "\"won't venture into some places that a good engineer needs to go, because to be decent at the job you really do need to understand the command-line interface\"<p>This is only true if the IDE has not kept up with the command line interface. Visual Studio and Xcode do pretty much everything their CLI can do except maybe some tool integration like CI or deployment. But that's operations, not programming.<p>\"IDEs are a good tool that ... is very often put to bad use.\"<p>So is every other tool out there. What's your point?<p>\"The one thing they are really good for (reading low-quality code) is something engineers hate doing.\"<p>They are also good for:<p>- Writing good quality code.<p>- Looking up methods.<p>- Code completion.<p>- Code navigation.<p>- Interactive debugging.<p>The list goes on.<p>\"IDE-dependence is evil\"<p>No it is not. You might as well say <em>static</em> <em>analysis</em> dependence is evil or compile-time optimization is evil or profilers are evil or any other convenience is evil. Should we all remain puritans and suffer cryptic and unwieldy <em>tools</em> just because making them more powerful and friendly also makes them more powerful and friendly for bad programmers?<p>Bad programmers will write bad code no matter what <em>tools</em> they use. Blaming the IDE is disingenuous and quite frankly comes off as arrogant and elitist.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The IDE As a Bad Programming Language Enabler",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://developers.slashdot.org/story/12/10/30/065244/the-ide-as-a-bad-programming-language-enabler?sdsrc=popbyskid",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-10-27T19:09:13.000Z",
      "title": "",
      "url": "",
      "author": "qznc",
      "points": 3,
      "story_text": null,
      "comment_text": "Easier to parse is not only good for the compiler. There is lots of other stuff, which needs to parse a language: syntax highlighting, style checker, reformatter, static program analysis, automatic refactoring. Some simple syntax changes makes it tremendously easier to develop all these tools.<p>C++ is known for being really hard to parse. Rumors say there is no complete C++ compiler so far. Java avoided those pitfalls. As a result you can see that Java has much better IDE support (e.g. refactoring) than C++.",
      "num_comments": null,
      "story_id": 4704898,
      "story_title": "Rob Pike: Go at Google",
      "story_url": "http://talks.golang.org/2012/splash.slide",
      "parent_id": 4705690,
      "created_at_i": 1351364953,
      "_tags": [
        "comment",
        "author_qznc",
        "story_4704898"
      ],
      "objectID": "4706922",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "qznc",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Easier to parse is not only good for the compiler. There is lots of other stuff, which needs to parse a language: syntax highlighting, style checker, reformatter, <em>static</em> program <em>analysis</em>, automatic refactoring. Some simple syntax changes makes it tremendously easier to develop all these <em>tools</em>.<p>C++ is known for being really hard to parse. Rumors say there is no complete C++ compiler so far. Java avoided those pitfalls. As a result you can see that Java has much better IDE support (e.g. refactoring) than C++.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Rob Pike: Go at Google",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://talks.golang.org/2012/splash.slide",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-04-01T18:28:32.000Z",
      "title": "",
      "url": "",
      "author": "ramses",
      "points": 3,
      "story_text": null,
      "comment_text": "Mountain View, CA. Both Full-time and Interns. <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Pattern Insight is a booming startup making code and log analysis tools for a customer base that includes many titans of the tech industry. The data mining and static analysis technologies present in our product have strong research roots, as we grew out of PhD research done at the University of Illinois at Urbana-Champaign. Relatedly, our core engineering team has a strong academic background, and as a whole, published over 100+ articles in peer reviewed journals and conferences.<p>We are looking to expand our engineering team in sunny California. As stated above, we are also looking for a handful of interns. For more specific requirements, please see our career page: <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Come join us, we are still tiny and looking for people ready and willing to make decisions that shape our future.",
      "num_comments": null,
      "story_id": 3783657,
      "story_title": "Ask HN: Who is Hiring? (April 2012)",
      "story_url": "",
      "parent_id": 3783657,
      "created_at_i": 1333304912,
      "_tags": [
        "comment",
        "author_ramses",
        "story_3783657"
      ],
      "objectID": "3784492",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "ramses",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Mountain View, CA. Both Full-time and Interns. <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Pattern Insight is a booming startup making code and log <em>analysis</em> <em>tools</em> for a customer base that includes many titans of the tech industry. The data mining and <em>static</em> <em>analysis</em> technologies present in our product have strong research roots, as we grew out of PhD research done at the University of Illinois at Urbana-Champaign. Relatedly, our core engineering team has a strong academic background, and as a whole, published over 100+ articles in peer reviewed journals and conferences.<p>We are looking to expand our engineering team in sunny California. As stated above, we are also looking for a handful of interns. For more specific requirements, please see our career page: <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Come join us, we are still tiny and looking for people ready and willing to make decisions that shape our future.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is Hiring? (April 2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-16T16:54:25.000Z",
      "title": "",
      "url": "",
      "author": "bdg",
      "points": 3,
      "story_text": null,
      "comment_text": "I'm a bit of an evangelical when it comes to static code analysis like this. I insist your code should work to a spec-- not necessarily Crockford's JSLint spec, but <i>a</i> spec, which is why I really like JSHint.<p>But I find I can't really convince anyone of it being useful, I remember being in an interview for a startup I read about on here and started talking about this as a tool I use (they asked \"What tools do you use\"). They basically brushed it off as \"yeah, I don't think this is super useful, we probably have bigger problems than a missing semicolon\".<p>As I understand it, general perception of people seems to be it's a tool for finding missing semicolons. I don't know how to give this a decent elevator pitch so other people can see the light.",
      "num_comments": null,
      "story_id": 3598915,
      "story_title": "JSHint, A JavaScript Code Quality Tool",
      "story_url": "http://www.jshint.com/",
      "parent_id": 3598915,
      "created_at_i": 1329411265,
      "_tags": [
        "comment",
        "author_bdg",
        "story_3598915"
      ],
      "objectID": "3599511",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "bdg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm a bit of an evangelical when it comes to <em>static</em> code <em>analysis</em> like this. I insist your code should work to a spec-- not necessarily Crockford's JSLint spec, but <i>a</i> spec, which is why I really like JSHint.<p>But I find I can't really convince anyone of it being useful, I remember being in an interview for a startup I read about on here and started talking about this as a tool I use (they asked \"What <em>tools</em> do you use\"). They basically brushed it off as \"yeah, I don't think this is super useful, we probably have bigger problems than a missing semicolon\".<p>As I understand it, general perception of people seems to be it's a tool for finding missing semicolons. I don't know how to give this a decent elevator pitch so other people can see the light.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "JSHint, A JavaScript Code Quality Tool",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.jshint.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-15T22:47:43.000Z",
      "title": null,
      "url": null,
      "author": "gchpaco",
      "points": 3,
      "story_text": null,
      "comment_text": "Yes, this is true, modern Unix isn't remotely pure. When I think of where it could be for these discussions, I think of Plan 9. But even on Unix, syntax aware tools like cscope and ctags are fairly well integrated. The real weakness is the debugging story; modern Unix simply isn't as good at introspection as it could be, or arguably should be.  Some of this is the ahead of time C compilation model making hot fixes hard or impossible, some of it is limitations in debugging tools and tracing tools, some of it is that the Unix stream model doesn't do a very good job of communicating structured data; it's a hard problem.<p>But, then, even Eclipse compares poorly to Genera, and it evolved from VisualAge for Java which was a near port of the Smalltalk product.  So it isn't as though the competition is distinguishing itself through its excellence; look at how much effort in terms of code it is to integrate FindBugs with Eclipse—and all it does is some trivial static analysis!",
      "num_comments": null,
      "story_id": 3594098,
      "story_title": "Unix as IDE",
      "story_url": "http://blog.sanctum.geek.nz/series/unix-as-ide/",
      "parent_id": 3596187,
      "created_at_i": 1329346063,
      "_tags": [
        "comment",
        "author_gchpaco",
        "story_3594098"
      ],
      "objectID": "3596506",
      "_highlightResult": {
        "author": {
          "value": "gchpaco",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Yes, this is true, modern Unix isn't remotely pure. When I think of where it could be for these discussions, I think of Plan 9. But even on Unix, syntax aware <em>tools</em> like cscope and ctags are fairly well integrated. The real weakness is the debugging story; modern Unix simply isn't as good at introspection as it could be, or arguably should be.  Some of this is the ahead of time C compilation model making hot fixes hard or impossible, some of it is limitations in debugging <em>tools</em> and tracing <em>tools</em>, some of it is that the Unix stream model doesn't do a very good job of communicating structured data; it's a hard problem.<p>But, then, even Eclipse compares poorly to Genera, and it evolved from VisualAge for Java which was a near port of the Smalltalk product.  So it isn't as though the competition is distinguishing itself through its excellence; look at how much effort in terms of code it is to integrate FindBugs with Eclipse—and all it does is some trivial <em>static</em> <em>analysis</em>!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Unix as IDE",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.sanctum.geek.nz/series/unix-as-ide/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-15T19:20:21.000Z",
      "title": "",
      "url": "",
      "author": "willsulzer",
      "points": 3,
      "story_text": null,
      "comment_text": "I've been using RubyMine since nearly the first release. I started using the 'Ruby' plugin in the IntelliJ IDEA IDE for Java. IMHO RubyMine is far the away the best IDE for RoR development on the market today. Here's a few of my favorite things about RubyMine:<p>* Great dependency management. The source code of all your Gems is accessible/searchable and always present. If you're using a method in one of your external dependencies, you can 'command-click' through to the Gem source.\n* Full integration with RSpec/Cucumber. You don't need to break out of your work flow to run a test. You will be presented with a small panel that includes our test results and clickable stack traces of failures.\n* Good refactoring tools: Extract a variable or method from a code block with a few keystrokes.\n* Etc.. (the list goes on and on)<p>Given the nature of the Ruby language, the IDE can only do so much, comparatively speaking. The Java IDEA IDE is arguably more powerful than RubyMine because of the static analysis capabilities of the Java language. I'm not at all saying that I would prefer to develop in Java because of 'better' IDE support, it's quite the opposite really. \nRubyMine does a lot to increase productivity by making assumptions about how developers will use the tool that result in a very desirable RoR IDE.",
      "num_comments": null,
      "story_id": 3594467,
      "story_title": "RubyMine 4 is Here to Make You Feel the Productivity",
      "story_url": "http://blog.jetbrains.com/ruby/2012/02/rubymine-4-is-here-to-make-you-feel-the-productivity/",
      "parent_id": 3594467,
      "created_at_i": 1329333621,
      "_tags": [
        "comment",
        "author_willsulzer",
        "story_3594467"
      ],
      "objectID": "3595619",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "willsulzer",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I've been using RubyMine since nearly the first release. I started using the 'Ruby' plugin in the IntelliJ IDEA IDE for Java. IMHO RubyMine is far the away the best IDE for RoR development on the market today. Here's a few of my favorite things about RubyMine:<p>* Great dependency management. The source code of all your Gems is accessible/searchable and always present. If you're using a method in one of your external dependencies, you can 'command-click' through to the Gem source.\n* Full integration with RSpec/Cucumber. You don't need to break out of your work flow to run a test. You will be presented with a small panel that includes our test results and clickable stack traces of failures.\n* Good refactoring <em>tools</em>: Extract a variable or method from a code block with a few keystrokes.\n* Etc.. (the list goes on and on)<p>Given the nature of the Ruby language, the IDE can only do so much, comparatively speaking. The Java IDEA IDE is arguably more powerful than RubyMine because of the <em>static</em> <em>analysis</em> capabilities of the Java language. I'm not at all saying that I would prefer to develop in Java because of 'better' IDE support, it's quite the opposite really. \nRubyMine does a lot to increase productivity by making assumptions about how developers will use the tool that result in a very desirable RoR IDE.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "RubyMine 4 is Here to Make You Feel the Productivity",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.jetbrains.com/ruby/2012/02/rubymine-4-is-here-to-make-you-feel-the-productivity/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-01T17:46:20.000Z",
      "title": null,
      "url": null,
      "author": "jamii",
      "points": 2,
      "story_text": null,
      "comment_text": "Those tools are hard to build. Sure, parsers are easy. Incremental parsers that can deal with half-edited text are hard (that&#x27;s basically the entire function of Intellij MPS). Running static analysis on half-edited text is hard. Keeping text in sync with runtime state is hard. Even diffing text is hard.<p>If we were talking about any other coding problem and I suggested you keep all your data in a complicated text serialisation spread across several hundred text files and resolve conflicts by diffing the files line-by-line, I would be laughed out of the room. The vast majority of work in any IDE, including Light Table, is just working around the fact that plain text is a terrible storage mechanism for complex, concurrently edited data.<p>That&#x27;s not to say that you shouldn&#x27;t use text to write or view the program or that we should all be coding by drawing pretty pictures and connecting lines. Just that we should keep the code in a sensible, networked data-store with support for concurrent editing and ACID transactions and then the way you choose to present and edit it can vary from person to person.",
      "num_comments": null,
      "story_id": 8394381,
      "story_title": "Beyond Light Table",
      "story_url": "http://www.chris-granger.com/2014/10/01/beyond-light-table/",
      "parent_id": 8395625,
      "created_at_i": 1412185580,
      "_tags": [
        "comment",
        "author_jamii",
        "story_8394381"
      ],
      "objectID": "8396329",
      "_highlightResult": {
        "author": {
          "value": "jamii",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Those <em>tools</em> are hard to build. Sure, parsers are easy. Incremental parsers that can deal with half-edited text are hard (that's basically the entire function of Intellij MPS). Running <em>static</em> <em>analysis</em> on half-edited text is hard. Keeping text in sync with runtime state is hard. Even diffing text is hard.<p>If we were talking about any other coding problem and I suggested you keep all your data in a complicated text serialisation spread across several hundred text files and resolve conflicts by diffing the files line-by-line, I would be laughed out of the room. The vast majority of work in any IDE, including Light Table, is just working around the fact that plain text is a terrible storage mechanism for complex, concurrently edited data.<p>That's not to say that you shouldn't use text to write or view the program or that we should all be coding by drawing pretty pictures and connecting lines. Just that we should keep the code in a sensible, networked data-store with support for concurrent editing and ACID transactions and then the way you choose to present and edit it can vary from person to person.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Beyond Light Table",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.chris-granger.com/2014/10/01/beyond-light-table/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-02T18:32:39.000Z",
      "title": null,
      "url": null,
      "author": "radicalbyte",
      "points": 2,
      "story_text": null,
      "comment_text": "Hahaha, no problem.<p>Static Analysis would be my second step, but first I&#x27;d have a look at the architectural documentation. I can&#x27;t imagine that a project of this size wouldn&#x27;t at least have a Powerpoint explaining the structure and concepts of the code.<p>Then it&#x27;s time to start using tools.",
      "num_comments": null,
      "story_id": 8257327,
      "story_title": "Ask HN: I have to analyze 100M lines of Java – where do I start?",
      "story_url": "",
      "parent_id": 8257637,
      "created_at_i": 1409682759,
      "_tags": [
        "comment",
        "author_radicalbyte",
        "story_8257327"
      ],
      "objectID": "8259290",
      "_highlightResult": {
        "author": {
          "value": "radicalbyte",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Hahaha, no problem.<p><em>Static</em> <em>Analysis</em> would be my second step, but first I'd have a look at the architectural documentation. I can't imagine that a project of this size wouldn't at least have a Powerpoint explaining the structure and concepts of the code.<p>Then it's time to start using <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: I have to analyze 100M lines of Java – where do I start?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-01T14:50:12.000Z",
      "title": null,
      "url": null,
      "author": "krg",
      "points": 2,
      "story_text": null,
      "comment_text": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;</a><p>Work Hard, Have Fun, Be Nice<p>Let&#x27;s be honest: you became a developer because you like to build things. Interesting things, useful things, cool things. It&#x27;s like building with Legos, only you get paid, and there are always plenty of the right color pieces.<p>At TechEmpower, we build things. Interesting things. Cool things, mostly in webapp form. We build them as individuals, because we&#x27;re creative people. We build them as teams, because we like to help each other grow, and because we know that collaboration improves even the best code.<p>Having the best people doesn&#x27;t hurt, either. We&#x27;ve got most of them already, and we&#x27;re looking to find the rest. You can build things with us. What&#x27;s the catch? We&#x27;re pretty darn selective.<p>To work as an individual, you have to be motivated and creative and thoughtful and serious. To work on a team, you have to be respectful and energetic and open and absolutely not a jerk. We need developers who can work on every part of an application, from the data store to the page–sometimes known as full stack developers. And to be a full stack developer, you have to know technology and want to learn more technology, because those acronyms just keep coming.<p>Our clients expect us to work with them, not for them. We help them define their problems, and we provide solutions, on time and on target. We&#x27;re service-oriented, and you should be too.<p>Still reading? Please apply! And check out our Web Framework Benchmarks while you&#x27;re at it.  We pretty much wrote the book on that one.<p>Just so you know:<p><pre><code>   Teams range between 2-6 people\\n   Developers are exposed to 3-4 projects per year\\n   All development is done on high-performance workstations with 4K displays. A lot of code fits in 3840x2160 pixels!\\n   We maintain an informal, comfortable environment, just like the old college computer science lab, but with grown-up hours\\n   Everybody&#x27;s nice\\n</code></pre>\\nThe technologies we use vary over time with our mix of projects. Here is a snapshot of what we&#x27;re using now:<p><pre><code>   Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n   Tools: Git, Jenkins (Continuous Integration), Sonar (static code analysis), Eclipse, IntelliJ, Ant, Maven\\n   Web: Dropwizard, .NET MVC 5, Play, Django, Rails, Mustache, Handlebars, Backbone, Angular, Knockout, JSP, Servlets, jQuery, etc.\\n   Mobile: iOS, Android, PhoneGap\\n   Hosting: AWS (EC2, RDS, etc.), Rackspace Cloud, Linux deployments\\n   Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, NoSQL (Redis, MongoDB)\\n</code></pre>\\nWe don&#x27;t expect new hires to have experience with all of these, but we do expect you&#x27;ll learn more about them every day.<p>If this sounds like the kind of place you&#x27;d like to work, please apply here: <a href=\"http://jobs.techempower.com/hn2\" rel=\"nofollow\">http:&#x2F;&#x2F;jobs.techempower.com&#x2F;hn2</a>",
      "num_comments": null,
      "story_id": 8120070,
      "story_title": "Ask HN: Who is hiring? (August 2014)",
      "story_url": "",
      "parent_id": 8120070,
      "created_at_i": 1406904612,
      "_tags": [
        "comment",
        "author_krg",
        "story_8120070"
      ],
      "objectID": "8120111",
      "_highlightResult": {
        "author": {
          "value": "krg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http://www.techempower.com/benchmarks/</a><p>Work Hard, Have Fun, Be Nice<p>Let's be honest: you became a developer because you like to build things. Interesting things, useful things, cool things. It's like building with Legos, only you get paid, and there are always plenty of the right color pieces.<p>At TechEmpower, we build things. Interesting things. Cool things, mostly in webapp form. We build them as individuals, because we're creative people. We build them as teams, because we like to help each other grow, and because we know that collaboration improves even the best code.<p>Having the best people doesn't hurt, either. We've got most of them already, and we're looking to find the rest. You can build things with us. What's the catch? We're pretty darn selective.<p>To work as an individual, you have to be motivated and creative and thoughtful and serious. To work on a team, you have to be respectful and energetic and open and absolutely not a jerk. We need developers who can work on every part of an application, from the data store to the page–sometimes known as full stack developers. And to be a full stack developer, you have to know technology and want to learn more technology, because those acronyms just keep coming.<p>Our clients expect us to work with them, not for them. We help them define their problems, and we provide solutions, on time and on target. We're service-oriented, and you should be too.<p>Still reading? Please apply! And check out our Web Framework Benchmarks while you're at it.  We pretty much wrote the book on that one.<p>Just so you know:<p><pre><code>   Teams range between 2-6 people\\n   Developers are exposed to 3-4 projects per year\\n   All development is done on high-performance workstations with 4K displays. A lot of code fits in 3840x2160 pixels!\\n   We maintain an informal, comfortable environment, just like the old college computer science lab, but with grown-up hours\\n   Everybody's nice\\n</code></pre>\\nThe technologies we use vary over time with our mix of projects. Here is a snapshot of what we're using now:<p><pre><code>   Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n   <em>Tools</em>: Git, Jenkins (Continuous Integration), Sonar (<em>static</em> code <em>analysis</em>), Eclipse, IntelliJ, Ant, Maven\\n   Web: Dropwizard, .NET MVC 5, Play, Django, Rails, Mustache, Handlebars, Backbone, Angular, Knockout, JSP, Servlets, jQuery, etc.\\n   Mobile: iOS, Android, PhoneGap\\n   Hosting: AWS (EC2, RDS, etc.), Rackspace Cloud, Linux deployments\\n   Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, NoSQL (Redis, MongoDB)\\n</code></pre>\\nWe don't expect new hires to have experience with all of these, but we do expect you'll learn more about them every day.<p>If this sounds like the kind of place you'd like to work, please apply here: <a href=\"http://jobs.techempower.com/hn2\" rel=\"nofollow\">http://jobs.techempower.com/hn2</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (August 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-14T00:15:51.000Z",
      "title": null,
      "url": null,
      "author": "taeric",
      "points": 2,
      "story_text": null,
      "comment_text": "No we weren&#x27;t.  We were talking about &quot;being less bug prone&quot; and &quot;easier to read.&quot;<p>Though, I&#x27;m not entirely sure that really changes much.  :(<p>Look, I&#x27;m not against static typing.  I confess to being somewhat in love with lisp at the moment.  And, I&#x27;m trying to learn MIXAL for some unholy reason.  At the same time, I try to type my systems as well as I can.  I am far from convinced that typing will be the way to go.<p>Especially if you consider auxiliary tools.  Having used Coverity some, it is down right impressive the stability you can bring to a C codebase with proper discipline and the appropriate tooling.  Compared to using something such as a Scala codebase, where right now your only recourse is the compiler.<p>That is, static analysis does not begin and end with the compiler.  Sadly, in moving to &quot;newer&quot; statically typed languages, you through out many of the tools that currently exist in the older languages.<p>And this is not just for &quot;correctness&quot;.  Having finally added &quot;-march=native&quot; to my flags for a build of software, I&#x27;m literally amazed at how well optimized a compile can be versus just using &quot;-O3&quot;.  Optimizations in the modern world are quite amazing without necessarily needing &quot;better types.&quot;",
      "num_comments": null,
      "story_id": 7890449,
      "story_title": "Typed Lua: An Optional Type System for Lua [pdf]",
      "story_url": "http://www.lifl.fr/dyla14/papers/dyla14-4-typed-lua-an-optional-type-system.pdf",
      "parent_id": 7891088,
      "created_at_i": 1402704951,
      "_tags": [
        "comment",
        "author_taeric",
        "story_7890449"
      ],
      "objectID": "7891524",
      "_highlightResult": {
        "author": {
          "value": "taeric",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "No we weren't.  We were talking about &quot;being less bug prone&quot; and &quot;easier to read.&quot;<p>Though, I'm not entirely sure that really changes much.  :(<p>Look, I'm not against <em>static</em> typing.  I confess to being somewhat in love with lisp at the moment.  And, I'm trying to learn MIXAL for some unholy reason.  At the same time, I try to type my systems as well as I can.  I am far from convinced that typing will be the way to go.<p>Especially if you consider auxiliary <em>tools</em>.  Having used Coverity some, it is down right impressive the stability you can bring to a C codebase with proper discipline and the appropriate tooling.  Compared to using something such as a Scala codebase, where right now your only recourse is the compiler.<p>That is, <em>static</em> <em>analysis</em> does not begin and end with the compiler.  Sadly, in moving to &quot;newer&quot; statically typed languages, you through out many of the <em>tools</em> that currently exist in the older languages.<p>And this is not just for &quot;correctness&quot;.  Having finally added &quot;-march=native&quot; to my flags for a build of software, I'm literally amazed at how well optimized a compile can be versus just using &quot;-O3&quot;.  Optimizations in the modern world are quite amazing without necessarily needing &quot;better types.&quot;",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Typed Lua: An Optional Type System for Lua [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.lifl.fr/dyla14/papers/dyla14-4-typed-lua-an-optional-type-system.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-09T23:45:52.000Z",
      "title": null,
      "url": null,
      "author": "qohen",
      "points": 2,
      "story_text": null,
      "comment_text": "Another tool you might want to check out is erlang.mk, by the author of the Cowboy webserver, Loïc Hoguin -- from the announcement[1]:<p><i>erlang.mk is a rebar replacement. It was initially created for allowing a faster development process than rebar and for better compatibility with Linux build tools. It should work on Linux and OSX with GNU Make installed.</i><p>Here&#x27;s how erlang.mk and relx can be used together to build releases (this is from a post by Loïc)[2]:<p><i>There is two steps to building a release. First you need to build the various OTP applications you want to include in the release. Once done, you need to create the release itself, by including the Erlang runtime system alongside the applications, a boot script to start the node and all its applications, and some configuration files.<p>erlang.mk solves the first step. It is an include file for GNU Make. Just including it in a Makefile is enough to allow building your project, fetching and building dependencies, building documentation, performing static analysis and more.<p>relx solves the second step. It is a release creation tool, wrapped into a single executable file. It doesn&#x27;t require a configuration file. And if you do need one, it will be a pretty small one.</i><p>And here&#x27;s a quick excerpt from a user-testimonial for erlang.mk, by Jesper L. Andersen[3]:<p><i>When compiling from warm, it takes rebar 9 seconds to figure out that there is nothing to do in the project. erlang.mk does the same thing in 0.2 seconds.</i><p>[1] <a href=\"http://erlang.org/pipermail/erlang-questions/2013-August/075097.html\" rel=\"nofollow\">http:&#x2F;&#x2F;erlang.org&#x2F;pipermail&#x2F;erlang-questions&#x2F;2013-August&#x2F;075...</a><p>[2] <a href=\"http://ninenines.eu/articles/erlang.mk-and-relx/\" rel=\"nofollow\">http:&#x2F;&#x2F;ninenines.eu&#x2F;articles&#x2F;erlang.mk-and-relx&#x2F;</a><p>[3] <a href=\"https://medium.com/p/708597c0dd08\" rel=\"nofollow\">https:&#x2F;&#x2F;medium.com&#x2F;p&#x2F;708597c0dd08</a>",
      "num_comments": null,
      "story_id": 7869179,
      "story_title": "2048 in Erlang",
      "story_url": "http://kukuruku.co/hub/erlang/2048-in-erlang",
      "parent_id": 7869563,
      "created_at_i": 1402357552,
      "_tags": [
        "comment",
        "author_qohen",
        "story_7869179"
      ],
      "objectID": "7871159",
      "_highlightResult": {
        "author": {
          "value": "qohen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Another tool you might want to check out is erlang.mk, by the author of the Cowboy webserver, Loïc Hoguin -- from the announcement[1]:<p><i>erlang.mk is a rebar replacement. It was initially created for allowing a faster development process than rebar and for better compatibility with Linux build <em>tools</em>. It should work on Linux and OSX with GNU Make installed.</i><p>Here's how erlang.mk and relx can be used together to build releases (this is from a post by Loïc)[2]:<p><i>There is two steps to building a release. First you need to build the various OTP applications you want to include in the release. Once done, you need to create the release itself, by including the Erlang runtime system alongside the applications, a boot script to start the node and all its applications, and some configuration files.<p>erlang.mk solves the first step. It is an include file for GNU Make. Just including it in a Makefile is enough to allow building your project, fetching and building dependencies, building documentation, performing <em>static</em> <em>analysis</em> and more.<p>relx solves the second step. It is a release creation tool, wrapped into a single executable file. It doesn't require a configuration file. And if you do need one, it will be a pretty small one.</i><p>And here's a quick excerpt from a user-testimonial for erlang.mk, by Jesper L. Andersen[3]:<p><i>When compiling from warm, it takes rebar 9 seconds to figure out that there is nothing to do in the project. erlang.mk does the same thing in 0.2 seconds.</i><p>[1] <a href=\"http://erlang.org/pipermail/erlang-questions/2013-August/075097.html\" rel=\"nofollow\">http://erlang.org/pipermail/erlang-questions/2013-August/075...</a><p>[2] <a href=\"http://ninenines.eu/articles/erlang.mk-and-relx/\" rel=\"nofollow\">http://ninenines.eu/articles/erlang.mk-and-relx/</a><p>[3] <a href=\"https://medium.com/p/708597c0dd08\" rel=\"nofollow\">https://medium.com/p/708597c0dd08</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "2048 in Erlang",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://kukuruku.co/hub/erlang/2048-in-erlang",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-16T19:45:33.000Z",
      "title": null,
      "url": null,
      "author": "DatBear",
      "points": 2,
      "story_text": null,
      "comment_text": "&gt;Do they let plumbers operate on patients because it&#x27;s now much safer? Not where I live, the laws are pretty strict with respect to who can practice medicine.<p>But there aren&#x27;t laws that determine who can program...<p>&gt;If you want safety, stop thinking in terms of blame and vengeance and design systems that avoid errors, and reduce their impact if they occur. This includes culture, processes and tools to protect against errors by those who do the work, and some regulation to stop management from putting employees in situations where they are likely to cause harm.<p>There obviously already are systems that are designed to avoid errors... Unit testing, static code analysis, automatic formatting, etc.<p>The author of the article said to throw all those out and put all of the safeguards into the language spec. OP is just saying that they don&#x27;t belong there.",
      "num_comments": null,
      "story_id": 7598721,
      "story_title": "Those Who Say Code Does Not Matter",
      "story_url": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
      "parent_id": 7599834,
      "created_at_i": 1397677533,
      "_tags": [
        "comment",
        "author_DatBear",
        "story_7598721"
      ],
      "objectID": "7600085",
      "_highlightResult": {
        "author": {
          "value": "DatBear",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;Do they let plumbers operate on patients because it's now much safer? Not where I live, the laws are pretty strict with respect to who can practice medicine.<p>But there aren't laws that determine who can program...<p>&gt;If you want safety, stop thinking in terms of blame and vengeance and design systems that avoid errors, and reduce their impact if they occur. This includes culture, processes and <em>tools</em> to protect against errors by those who do the work, and some regulation to stop management from putting employees in situations where they are likely to cause harm.<p>There obviously already are systems that are designed to avoid errors... Unit testing, <em>static</em> code <em>analysis</em>, automatic formatting, etc.<p>The author of the article said to throw all those out and put all of the safeguards into the language spec. OP is just saying that they don't belong there.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Those Who Say Code Does Not Matter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-16T18:05:48.000Z",
      "title": null,
      "url": null,
      "author": "wellpast",
      "points": 2,
      "story_text": null,
      "comment_text": "This is terribly wrong.<p>Correctness is brought about by ALL of your tools in hand. These tools include unit testing, processes like continuous integration and code review, and so on, <i>in addition</i> to language features such as its syntax and static analysis capabilities.<p>The job of the programmer is to understand all of your tools and to then use them conscientiously and use them well. There is NO tool a programmer can&#x27;t shoot themselves with. There&#x27;s no prima facie perfect tool. And the combination of your tools is a better thing to evaluate anyway. A nail isn&#x27;t universally useful. With a Phillip&#x27;s head screwdriver things get a little better; but with a hammer, you&#x27;ll start moving.<p>A good architecture and intelligent, disciplined execution is WAY WAY WAY more important than the specific tools we use. Arguments like this one are bike shedding.",
      "num_comments": null,
      "story_id": 7598721,
      "story_title": "Those Who Say Code Does Not Matter",
      "story_url": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
      "parent_id": 7598721,
      "created_at_i": 1397671548,
      "_tags": [
        "comment",
        "author_wellpast",
        "story_7598721"
      ],
      "objectID": "7599404",
      "_highlightResult": {
        "author": {
          "value": "wellpast",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is terribly wrong.<p>Correctness is brought about by ALL of your <em>tools</em> in hand. These <em>tools</em> include unit testing, processes like continuous integration and code review, and so on, <i>in addition</i> to language features such as its syntax and <em>static</em> <em>analysis</em> capabilities.<p>The job of the programmer is to understand all of your <em>tools</em> and to then use them conscientiously and use them well. There is NO tool a programmer can't shoot themselves with. There's no prima facie perfect tool. And the combination of your <em>tools</em> is a better thing to evaluate anyway. A nail isn't universally useful. With a Phillip's head screwdriver things get a little better; but with a hammer, you'll start moving.<p>A good architecture and intelligent, disciplined execution is WAY WAY WAY more important than the specific <em>tools</em> we use. Arguments like this one are bike shedding.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Those Who Say Code Does Not Matter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-03-26T18:07:09.000Z",
      "title": null,
      "url": null,
      "author": "tel",
      "points": 2,
      "story_text": null,
      "comment_text": "I&#x27;m sure it&#x27;s more my poor choice of word, sorry about that. I just meant that if you&#x27;re starting from scratch on a language there&#x27;s a fairly large amount of non-useful stuff that must be done before it becomes valuable.<p>I&#x27;m basically assuming that the only reason why you&#x27;d have enough business value in creating a new language comes from it either modeling something interesting or having a different semantic focus. Everything else is just wasted time then.<p>Some examples:<p>1. Documentation. How do people know what your language means? How do they know what happens when it breaks?<p>2. Shaking out edge cases (much harder to do than debugging a program!)<p>3. Syntax. Picking it. Parsing it. Ensuring it&#x27;s complete and doesn&#x27;t have weird edge cases.<p>4. Compiler. Runtime. Parallel (!) runtime? Platform independence? Efficiency?<p>5. Static analysis (type checking, memory analysis, nulls)<p>6. Managing modules&#x2F;files&#x2F;packages<p>7. Foreign calls<p>8. Dependency management<p>All of these are fun in their own right, but most businesses would have a hard time arguing that they&#x27;re worth working on unless they&#x27;ve <i>already</i> got a language tied into their core value proposition. It&#x27;s also important to mention that there exist tools to make some of them easier (bnfc, llvm, &amp;c).<p>But if you just start with an embedded DSL you can get right to the modeling or semantic issues by piggy-backing on the host language for (most of) 2, 3, 4, 5, 6, 7, and 8. If you prove that there&#x27;s something valuable there and the host language is slowing you down then you can start to unembed it by building the &quot;whole ecosystem&quot;.",
      "num_comments": null,
      "story_id": 7472452,
      "story_title": "What it's like to use Haskell",
      "story_url": "http://engineering.imvu.com/2014/03/24/what-its-like-to-use-haskell",
      "parent_id": 7475005,
      "created_at_i": 1395857229,
      "_tags": [
        "comment",
        "author_tel",
        "story_7472452"
      ],
      "objectID": "7475161",
      "_highlightResult": {
        "author": {
          "value": "tel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm sure it's more my poor choice of word, sorry about that. I just meant that if you're starting from scratch on a language there's a fairly large amount of non-useful stuff that must be done before it becomes valuable.<p>I'm basically assuming that the only reason why you'd have enough business value in creating a new language comes from it either modeling something interesting or having a different semantic focus. Everything else is just wasted time then.<p>Some examples:<p>1. Documentation. How do people know what your language means? How do they know what happens when it breaks?<p>2. Shaking out edge cases (much harder to do than debugging a program!)<p>3. Syntax. Picking it. Parsing it. Ensuring it's complete and doesn't have weird edge cases.<p>4. Compiler. Runtime. Parallel (!) runtime? Platform independence? Efficiency?<p>5. <em>Static</em> <em>analysis</em> (type checking, memory <em>analysis</em>, nulls)<p>6. Managing modules/files/packages<p>7. Foreign calls<p>8. Dependency management<p>All of these are fun in their own right, but most businesses would have a hard time arguing that they're worth working on unless they've <i>already</i> got a language tied into their core value proposition. It's also important to mention that there exist <em>tools</em> to make some of them easier (bnfc, llvm, &amp;c).<p>But if you just start with an embedded DSL you can get right to the modeling or semantic issues by piggy-backing on the host language for (most of) 2, 3, 4, 5, 6, 7, and 8. If you prove that there's something valuable there and the host language is slowing you down then you can start to unembed it by building the &quot;whole ecosystem&quot;.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What it's like to use Haskell",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://engineering.imvu.com/2014/03/24/what-its-like-to-use-haskell",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-27T17:54:41.000Z",
      "title": null,
      "url": null,
      "author": "pessimizer",
      "points": 2,
      "story_text": null,
      "comment_text": "I haven&#x27;t. I&#x27;d like links, though. If I can see with my eyes that code will never be executed, I&#x27;d like to know what&#x27;s wrong with the state of current static analysis.<p>edit: <a href=\"http://blog.veracode.com/2014/02/do-not-pass-qa-do-not-goto-fail-catching-subtle-bugs-in-the-act/\" rel=\"nofollow\">http:&#x2F;&#x2F;blog.veracode.com&#x2F;2014&#x2F;02&#x2F;do-not-pass-qa-do-not-goto-...</a><p>Veracode does static analysis of the binary, and says that it would be thwarted because it wouldn&#x27;t know that some functions were meant to be called. Static code analysis would tell you that it was impossible for some of the code to be run.<p>edit 2:(the second comment on the vericode blog)<p><i>caf | February 24, 2014 11:05 pm</i><p>In the Evil Unit Tests part you can use code coverage tools to at least verify that your unit tests exercise all code paths. It won’t catch every bug, but it would have caught this one.",
      "num_comments": null,
      "story_id": 7311879,
      "story_title": "Was the iOS SSL Flaw Deliberate?",
      "story_url": "https://www.schneier.com/blog/archives/2014/02/was_the_ios_ssl.html",
      "parent_id": 7313613,
      "created_at_i": 1393523681,
      "_tags": [
        "comment",
        "author_pessimizer",
        "story_7311879"
      ],
      "objectID": "7313678",
      "_highlightResult": {
        "author": {
          "value": "pessimizer",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I haven't. I'd like links, though. If I can see with my eyes that code will never be executed, I'd like to know what's wrong with the state of current <em>static</em> <em>analysis.</em><p>edit: <a href=\"http://blog.veracode.com/2014/02/do-not-pass-qa-do-not-goto-fail-catching-subtle-bugs-in-the-act/\" rel=\"nofollow\">http://blog.veracode.com/2014/02/do-not-pass-qa-do-not-goto-...</a><p>Veracode does <em>static</em> <em>analysis</em> of the binary, and says that it would be thwarted because it wouldn't know that some functions were meant to be called. <em>Static</em> code <em>analysis</em> would tell you that it was impossible for some of the code to be run.<p>edit 2:(the second comment on the vericode blog)<p><i>caf | February 24, 2014 11:05 pm</i><p>In the Evil Unit Tests part you can use code coverage <em>tools</em> to at least verify that your unit tests exercise all code paths. It won’t catch every bug, but it would have caught this one.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Was the iOS SSL Flaw Deliberate?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.schneier.com/blog/archives/2014/02/was_the_ios_ssl.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-22T16:50:36.000Z",
      "title": null,
      "url": null,
      "author": "kps",
      "points": 2,
      "story_text": null,
      "comment_text": "I don&#x27;t work for Apple and have never seen Xcode source, but my guess (based on what <i>I</i> would do) would be that Xcode invokes Clang&#x2F;LLVM as libraries rather than a standalone binary, in order to keep persistent state. In principle GCC could present such an interface, but in practice FSF policies prevent it. The point is that the static analysis can be used directly or by other tools (there is a web interface, for instance); it is not restricted to Xcode.",
      "num_comments": null,
      "story_id": 7101824,
      "story_title": "Clang and FSF's strategy",
      "story_url": "http://gcc.gnu.org/ml/gcc/2014-01/msg00176.html",
      "parent_id": 7103626,
      "created_at_i": 1390409436,
      "_tags": [
        "comment",
        "author_kps",
        "story_7101824"
      ],
      "objectID": "7103761",
      "_highlightResult": {
        "author": {
          "value": "kps",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't work for Apple and have never seen Xcode source, but my guess (based on what <i>I</i> would do) would be that Xcode invokes Clang/LLVM as libraries rather than a standalone binary, in order to keep persistent state. In principle GCC could present such an interface, but in practice FSF policies prevent it. The point is that the <em>static</em> <em>analysis</em> can be used directly or by other <em>tools</em> (there is a web interface, for instance); it is not restricted to Xcode.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Clang and FSF's strategy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://gcc.gnu.org/ml/gcc/2014-01/msg00176.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-21T02:25:58.000Z",
      "title": "",
      "url": "",
      "author": "chongli",
      "points": 2,
      "story_text": null,
      "comment_text": "<i>programming will be much more of a two-way conversation with your tooling.</i><p>Do you have any experience programming in Haskell? I ask because this statement exactly describes my experience with it. The language goes extremely far down the path of &quot;static analysis&quot; with its type system. Couple this with simple tools such as ghci, flymake and haskell-mode for emacs and you have a very interactive system with an enormous amount of feedback.",
      "num_comments": null,
      "story_id": 6243993,
      "story_title": "John Carmack discusses the art and science of software engineering (2012)",
      "story_url": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
      "parent_id": 6247628,
      "created_at_i": 1377051958,
      "_tags": [
        "comment",
        "author_chongli",
        "story_6243993"
      ],
      "objectID": "6247807",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "chongli",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>programming will be much more of a two-way conversation with your tooling.</i><p>Do you have any experience programming in Haskell? I ask because this statement exactly describes my experience with it. The language goes extremely far down the path of &quot;<em>static</em> <em>analysis</em>&quot; with its type system. Couple this with simple <em>tools</em> such as ghci, flymake and haskell-mode for emacs and you have a very interactive system with an enormous amount of feedback.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack discusses the art and science of software engineering (2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-30T19:17:40.000Z",
      "title": "",
      "url": "",
      "author": "willvarfar",
      "points": 2,
      "story_text": null,
      "comment_text": "Doubtless it'll come down to some silly mistakes, like having a `for(var attrname in obj)` (as was the construct that caused V8 to unoptimise their Oz game, link above).  I've been coding for long enough - started with the ZX81 and 286 - to know we're all mortal.<p>The tools for finding this stuff suck.  The tools for finding and fixing this stuff for just a handful of mainstream browsers - Firefox, Chrome and Safari - suck.<p>I want Chrome and Firefox to show code hotness inline in their script browser panes of their developer tools.  I want profiling to work for web workers.  I want all this without needing to compile my own copy of V8 (as Google advocate in the video above).<p>Just when profiling, electric-fencing and static analysis begin to become mainstream for C++ developers, we're thrown back to basics in browsers.<p>Just because wanting to see asset load and understand the fold are mainstream profiling problems for people making shopping websites, doesn't mean browsers aren't going to get used more and more for gaming-style workloads and will need the profiling and debugging tools that problem demands.",
      "num_comments": null,
      "story_id": 5791441,
      "story_title": "Optimizing your JavaScript game for Firefox OS",
      "story_url": "https://hacks.mozilla.org/2013/05/optimizing-your-javascript-game-for-firefox-os/",
      "parent_id": 5793635,
      "created_at_i": 1369941460,
      "_tags": [
        "comment",
        "author_willvarfar",
        "story_5791441"
      ],
      "objectID": "5794603",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "willvarfar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Doubtless it'll come down to some silly mistakes, like having a `for(var attrname in obj)` (as was the construct that caused V8 to unoptimise their Oz game, link above).  I've been coding for long enough - started with the ZX81 and 286 - to know we're all mortal.<p>The <em>tools</em> for finding this stuff suck.  The <em>tools</em> for finding and fixing this stuff for just a handful of mainstream browsers - Firefox, Chrome and Safari - suck.<p>I want Chrome and Firefox to show code hotness inline in their script browser panes of their developer <em>tools</em>.  I want profiling to work for web workers.  I want all this without needing to compile my own copy of V8 (as Google advocate in the video above).<p>Just when profiling, electric-fencing and <em>static</em> <em>analysis</em> begin to become mainstream for C++ developers, we're thrown back to basics in browsers.<p>Just because wanting to see asset load and understand the fold are mainstream profiling problems for people making shopping websites, doesn't mean browsers aren't going to get used more and more for gaming-style workloads and will need the profiling and debugging <em>tools</em> that problem demands.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Optimizing your JavaScript game for Firefox OS",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://hacks.mozilla.org/2013/05/optimizing-your-javascript-game-for-firefox-os/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-22T03:34:25.000Z",
      "title": "",
      "url": "",
      "author": "zaphoyd",
      "points": 2,
      "story_text": null,
      "comment_text": "#define is a problem in general because the compiler doesn't understand as well what is happening because the substitutions take place outside of the language's type system. Extensive preprocessor use makes writing analysis tools, refactoring IDEs, and sane compiler errors much more complicated. Const in C doesn't behave similarly to #define so it isn't really a substitute.<p>Note: in C++, global/static const values <i>do</i> behave as compile time constant expressions and are an excellent tool for this purpose.",
      "num_comments": null,
      "story_id": 5746533,
      "story_title": "Vim 7.3.1000",
      "story_url": "http://ftp.vim.org/pub/vim/patches/7.3/7.3.1000",
      "parent_id": 5748568,
      "created_at_i": 1369193665,
      "_tags": [
        "comment",
        "author_zaphoyd",
        "story_5746533"
      ],
      "objectID": "5748714",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "zaphoyd",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "#define is a problem in general because the compiler doesn't understand as well what is happening because the substitutions take place outside of the language's type system. Extensive preprocessor use makes writing <em>analysis</em> <em>tools</em>, refactoring IDEs, and sane compiler errors much more complicated. Const in C doesn't behave similarly to #define so it isn't really a substitute.<p>Note: in C++, global/<em>static</em> const values <i>do</i> behave as compile time constant expressions and are an excellent tool for this purpose.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Vim 7.3.1000",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ftp.vim.org/pub/vim/patches/7.3/7.3.1000",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-16T08:53:30.000Z",
      "title": "",
      "url": "",
      "author": "pkolaczk",
      "points": 2,
      "story_text": null,
      "comment_text": "There are also other means to assure high quality of code. Testing is just one of many tools. And even 100% coverage does not guarantee your code still isn't crap. Your tests might be crap as well. By testing you can only prove there <i>is</i> a bug but you can't prove there <i>isn't</i>. You can only <i>hope</i> that if you tested the right things, it is likely your code works fine.<p>For example static code analysis is sometimes superior to testing, because it can prove for absence of some wide classes of bugs.<p>And in code reviews we often find subtle bugs that would be extremely hard to write tests for (e.g. concurrency related bugs).<p>You can also decrease bug rates by writing clean, understandable code. Which is often related to hiring a few great programmers instead of a bunch of cheap ones.",
      "num_comments": null,
      "story_id": 5554600,
      "story_title": "Tests Are Overhyped",
      "story_url": "http://sturgill.github.io/2013/04/15/tests-are-overhyped/",
      "parent_id": 5556193,
      "created_at_i": 1366102410,
      "_tags": [
        "comment",
        "author_pkolaczk",
        "story_5554600"
      ],
      "objectID": "5557043",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pkolaczk",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "There are also other means to assure high quality of code. Testing is just one of many <em>tools</em>. And even 100% coverage does not guarantee your code still isn't crap. Your tests might be crap as well. By testing you can only prove there <i>is</i> a bug but you can't prove there <i>isn't</i>. You can only <i>hope</i> that if you tested the right things, it is likely your code works fine.<p>For example <em>static</em> code <em>analysis</em> is sometimes superior to testing, because it can prove for absence of some wide classes of bugs.<p>And in code reviews we often find subtle bugs that would be extremely hard to write tests for (e.g. concurrency related bugs).<p>You can also decrease bug rates by writing clean, understandable code. Which is often related to hiring a few great programmers instead of a bunch of cheap ones.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Tests Are Overhyped",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://sturgill.github.io/2013/04/15/tests-are-overhyped/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-02-18T21:00:28.000Z",
      "title": "",
      "url": "",
      "author": "WayneDB",
      "points": 2,
      "story_text": null,
      "comment_text": "* You get enough static analysis so that broken code won't compile.<p>* Testing can be done through other tools such as Nunit.<p>* With VS2012, you get extensions developed by Microsoft, such as NuGet.",
      "num_comments": null,
      "story_id": 5238788,
      "story_title": "Performance-Wise, C# Trumps Java",
      "story_url": "http://www.datacenteracceleration.com/author.asp?section_id=2933",
      "parent_id": 5239346,
      "created_at_i": 1361221228,
      "_tags": [
        "comment",
        "author_WayneDB",
        "story_5238788"
      ],
      "objectID": "5240600",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "WayneDB",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "* You get enough <em>static</em> <em>analysis</em> so that broken code won't compile.<p>* Testing can be done through other <em>tools</em> such as Nunit.<p>* With VS2012, you get extensions developed by Microsoft, such as NuGet.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Performance-Wise, C# Trumps Java",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.datacenteracceleration.com/author.asp?section_id=2933",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-07-09T10:43:32.000Z",
      "title": "",
      "url": "",
      "author": "heretohelp",
      "points": 2,
      "story_text": null,
      "comment_text": "I'm a grumpy old clisper. I know well the benefits of functional programming. (And Perlis languages in general. If you don't know the c2 page for this, you should feel deep shame.)<p>Thing is, my fellow lispers, and our scheming siblings too, spent most our time talking about programming or actual code. The former being the means or mode to produce the latter.<p>Why don't Haskellers ever seem to be talking about programming or actual code when I encounter them in the wild?<p>Haskell seems to be some mad science project that came about after some grad students happened across an ML manual and a bottle of scotch. (At least you guys didn't make that 31-bit integer mistake. Oof, tagged pointers.)<p>The emphasis on the type system seems to be a bit revisionist to me. The original (pre-Haskell '98) emphasis was on the <i>laziness</i> really. That turned out to be a huge mistake outside of some cute demonstrations for the purpose of understanding the runtime behavior of your code, so you're choosing to ignore this monstrous mistake and instead promulgate this type safety nonsense as if static analysis has gone anywhere in the last few decades.<p>So back to my original questions, why don't I ever seem to find you people talking about actual code?<p>When I encounter fellow Python programmers, they're usually talking about cool libraries, solving interesting problems, neat tools they've discovered or made, best practices, etc.<p>With Haskell it's more like I've bumped into a rather unpleasant evangelical minister or Amway salesman bred with Doc Brown from <i>Back to the Future</i>. It's like the Haskell community has two modes of operation: proselytization and mathematical gibberish.",
      "num_comments": null,
      "story_id": 4214589,
      "story_title": "Confession of a Haskell Hacker",
      "story_url": "http://r6.ca/blog/20120708T122219Z.html",
      "parent_id": 4217385,
      "created_at_i": 1341830612,
      "_tags": [
        "comment",
        "author_heretohelp",
        "story_4214589"
      ],
      "objectID": "4217506",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "heretohelp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm a grumpy old clisper. I know well the benefits of functional programming. (And Perlis languages in general. If you don't know the c2 page for this, you should feel deep shame.)<p>Thing is, my fellow lispers, and our scheming siblings too, spent most our time talking about programming or actual code. The former being the means or mode to produce the latter.<p>Why don't Haskellers ever seem to be talking about programming or actual code when I encounter them in the wild?<p>Haskell seems to be some mad science project that came about after some grad students happened across an ML manual and a bottle of scotch. (At least you guys didn't make that 31-bit integer mistake. Oof, tagged pointers.)<p>The emphasis on the type system seems to be a bit revisionist to me. The original (pre-Haskell '98) emphasis was on the <i>laziness</i> really. That turned out to be a huge mistake outside of some cute demonstrations for the purpose of understanding the runtime behavior of your code, so you're choosing to ignore this monstrous mistake and instead promulgate this type safety nonsense as if <em>static</em> <em>analysis</em> has gone anywhere in the last few decades.<p>So back to my original questions, why don't I ever seem to find you people talking about actual code?<p>When I encounter fellow Python programmers, they're usually talking about cool libraries, solving interesting problems, neat <em>tools</em> they've discovered or made, best practices, etc.<p>With Haskell it's more like I've bumped into a rather unpleasant evangelical minister or Amway salesman bred with Doc Brown from <i>Back to the Future</i>. It's like the Haskell community has two modes of operation: proselytization and mathematical gibberish.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Confession of a Haskell Hacker",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://r6.ca/blog/20120708T122219Z.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-01T17:54:22.000Z",
      "title": "",
      "url": "",
      "author": "ehinter",
      "points": 2,
      "story_text": null,
      "comment_text": "Mountain View, CA. Full time.<p><a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Pattern Insight is a booming startup making code and log analysis tools for a customer base that includes many titans of the tech industry. The data mining and static analysis technologies present in our product have strong research roots, as we grew out of PhD research done at the University of Illinois at Urbana-Champaign. Relatedly, our core engineering team has a strong academic background and as a whole has published over 100+ articles in peer reviewed journals and conferences.<p>We are looking to expand our engineering team in sunny California. As stated above, we are also looking for a handful of interns. For more specific requirements, please see our career page: <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Come join us, we are still tiny and looking for people ready and willing to make decisions that shape our future.",
      "num_comments": null,
      "story_id": 3913997,
      "story_title": "Ask HN: Who Is Hiring? (May 2012)",
      "story_url": "",
      "parent_id": 3913997,
      "created_at_i": 1335894862,
      "_tags": [
        "comment",
        "author_ehinter",
        "story_3913997"
      ],
      "objectID": "3915574",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "ehinter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Mountain View, CA. Full time.<p><a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Pattern Insight is a booming startup making code and log <em>analysis</em> <em>tools</em> for a customer base that includes many titans of the tech industry. The data mining and <em>static</em> <em>analysis</em> technologies present in our product have strong research roots, as we grew out of PhD research done at the University of Illinois at Urbana-Champaign. Relatedly, our core engineering team has a strong academic background and as a whole has published over 100+ articles in peer reviewed journals and conferences.<p>We are looking to expand our engineering team in sunny California. As stated above, we are also looking for a handful of interns. For more specific requirements, please see our career page: <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Come join us, we are still tiny and looking for people ready and willing to make decisions that shape our future.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who Is Hiring? (May 2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-03T19:25:22.000Z",
      "title": "",
      "url": "",
      "author": "greyfade",
      "points": 2,
      "story_text": null,
      "comment_text": "Well, with the exception of a class tree (which I've had trouble using in the past), those are all the reasons I just use a text editor. So, I guess I still don't understand.<p>You see, I have file/project trees, warning/error buffers, build status and shells (among other things) in Vim and Emacs with keyboard-driven access to all the tools I use, without having to hunt through a twisty passage of menus, all alike.<p>Even static analysis and error highlighting is available (even for C++ with vim-clang-complete, for example).<p>So I guess what I don't understand is why there is a need for all of this to be \"integrated\" in a WIMP-style GUI.",
      "num_comments": null,
      "story_id": 3546478,
      "story_title": "VsVim",
      "story_url": "http://visualstudiogallery.msdn.microsoft.com/59ca71b3-a4a3-46ca-8fe1-0e90e3f79329",
      "parent_id": 3548058,
      "created_at_i": 1328297122,
      "_tags": [
        "comment",
        "author_greyfade",
        "story_3546478"
      ],
      "objectID": "3548469",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "greyfade",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Well, with the exception of a class tree (which I've had trouble using in the past), those are all the reasons I just use a text editor. So, I guess I still don't understand.<p>You see, I have file/project trees, warning/error buffers, build status and shells (among other things) in Vim and Emacs with keyboard-driven access to all the <em>tools</em> I use, without having to hunt through a twisty passage of menus, all alike.<p>Even <em>static</em> <em>analysis</em> and error highlighting is available (even for C++ with vim-clang-complete, for example).<p>So I guess what I don't understand is why there is a need for all of this to be \"integrated\" in a WIMP-style GUI.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "VsVim",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://visualstudiogallery.msdn.microsoft.com/59ca71b3-a4a3-46ca-8fe1-0e90e3f79329",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-03T17:46:41.000Z",
      "title": "",
      "url": "",
      "author": "BHSPitMonkey",
      "points": 2,
      "story_text": null,
      "comment_text": "For one, they provide a way to stay immersed in all aspects of your project continually while switching around between tasks (seeing your files/class tree + code + warnings/errors + status simultaneously on one screen).  Even if you're savvy enough to achieve some of this through a careful terminal splitting/tiling setup, you're just halfway-implementing a graphical interface.<p>Like most GUIs, you're also provided with organized menu-based access to tools and features you might otherwise have to spend time remembering or learning how to do from a terminal.<p>Finally, IDE-centric features like in-editor static analysis / error highlighting can come in handy from time to time (Oops! Forgot a paren. Glad I didn't have to waste 15 seconds attempting to build, reading/understanding the error output, and coming back to this file/line).<p>(I agree that a lot of IDEs I've tried such as MSVC and Eclipse can be burdensome to use. I like using Geany, since it's foremost an editor, with useful panes and functionality added in.)",
      "num_comments": null,
      "story_id": 3546478,
      "story_title": "VsVim",
      "story_url": "http://visualstudiogallery.msdn.microsoft.com/59ca71b3-a4a3-46ca-8fe1-0e90e3f79329",
      "parent_id": 3548001,
      "created_at_i": 1328291201,
      "_tags": [
        "comment",
        "author_BHSPitMonkey",
        "story_3546478"
      ],
      "objectID": "3548058",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "BHSPitMonkey",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "For one, they provide a way to stay immersed in all aspects of your project continually while switching around between tasks (seeing your files/class tree + code + warnings/errors + status simultaneously on one screen).  Even if you're savvy enough to achieve some of this through a careful terminal splitting/tiling setup, you're just halfway-implementing a graphical interface.<p>Like most GUIs, you're also provided with organized menu-based access to <em>tools</em> and features you might otherwise have to spend time remembering or learning how to do from a terminal.<p>Finally, IDE-centric features like in-editor <em>static</em> <em>analysis</em> / error highlighting can come in handy from time to time (Oops! Forgot a paren. Glad I didn't have to waste 15 seconds attempting to build, reading/understanding the error output, and coming back to this file/line).<p>(I agree that a lot of IDEs I've tried such as MSVC and Eclipse can be burdensome to use. I like using Geany, since it's foremost an editor, with useful panes and functionality added in.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "VsVim",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://visualstudiogallery.msdn.microsoft.com/59ca71b3-a4a3-46ca-8fe1-0e90e3f79329",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-01T15:42:50.000Z",
      "title": "",
      "url": "",
      "author": "jayp",
      "points": 2,
      "story_text": null,
      "comment_text": "Mountain View, CA. Both Full-time and Interns.\n<a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Pattern Insight - a booming startup making code and log analysis tools for a customer base that includes many titans of the tech industry - is hiring software engineers and interns in sunny California. (Relocation options available for full-time positions).<p>We are looking to expand our engineering team by hiring both developers (both systems and application) and QA. For job-specific skills, please see our career page: <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Our data mining and static analysis technologies have strong research roots, as we grew out of research done at the University of Illinois at Urbana-Champaign. Relatedly, our core engineering team is extremely strong, and as a whole, published over 100+ articles in peer reviewed journals and conferences.<p>Come join us, we are still tiny and looking for people ready and willing to make decisions for our future.",
      "num_comments": null,
      "story_id": 3537881,
      "story_title": "Ask HN: Who is Hiring? (February 2012)",
      "story_url": "",
      "parent_id": 3537881,
      "created_at_i": 1328110970,
      "_tags": [
        "comment",
        "author_jayp",
        "story_3537881"
      ],
      "objectID": "3538370",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jayp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Mountain View, CA. Both Full-time and Interns.\n<a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Pattern Insight - a booming startup making code and log <em>analysis</em> <em>tools</em> for a customer base that includes many titans of the tech industry - is hiring software engineers and interns in sunny California. (Relocation options available for full-time positions).<p>We are looking to expand our engineering team by hiring both developers (both systems and application) and QA. For job-specific skills, please see our career page: <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Our data mining and <em>static</em> <em>analysis</em> technologies have strong research roots, as we grew out of research done at the University of Illinois at Urbana-Champaign. Relatedly, our core engineering team is extremely strong, and as a whole, published over 100+ articles in peer reviewed journals and conferences.<p>Come join us, we are still tiny and looking for people ready and willing to make decisions for our future.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is Hiring? (February 2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-01-04T05:49:02.000Z",
      "title": "",
      "url": "",
      "author": "gambler",
      "points": 2,
      "story_text": null,
      "comment_text": "Sure, there are complexities like that in the world. However, where programmer A writes an if-else statement or, maybe, a 5-line dynamic dispatch, programmer B installs some \"enterprise\" framework or a rules engine, instantly making the entire system an order of magnitude more complex.<p>What programmers like B often doesn't realize is that they push core logic of the application from <i>their</i> source code (Turing complete, expressive, versioned, benefiting from static and dynamic analysis and all the testing/refactoring tools available for the language) into an obscure XML notation or even some proprietary rules database, worked upon by a complicated blob of <i>3d party</i> code that has nothing to do with the original business problem.",
      "num_comments": null,
      "story_id": 3420184,
      "story_title": "The MicroPHP Manifesto",
      "story_url": "http://funkatron.com/posts/the-microphp-manifesto.html",
      "parent_id": 3422202,
      "created_at_i": 1325656142,
      "_tags": [
        "comment",
        "author_gambler",
        "story_3420184"
      ],
      "objectID": "3422980",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "gambler",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Sure, there are complexities like that in the world. However, where programmer A writes an if-else statement or, maybe, a 5-line dynamic dispatch, programmer B installs some \"enterprise\" framework or a rules engine, instantly making the entire system an order of magnitude more complex.<p>What programmers like B often doesn't realize is that they push core logic of the application from <i>their</i> source code (Turing complete, expressive, versioned, benefiting from <em>static</em> and dynamic <em>analysis</em> and all the testing/refactoring <em>tools</em> available for the language) into an obscure XML notation or even some proprietary rules database, worked upon by a complicated blob of <i>3d party</i> code that has nothing to do with the original business problem.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The MicroPHP Manifesto",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://funkatron.com/posts/the-microphp-manifesto.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-25T18:47:23.000Z",
      "title": null,
      "url": null,
      "author": "emu",
      "points": 2,
      "story_text": null,
      "comment_text": "Well, unfortunately most interesting static analysis problems are undecidable. There can be no \"general\" solution.<p>What we have in practice are approximations and heuristics; over time we will develop better approximations for the kinds of code people write in practice. Unfortunately fragility of analysis will always be a problem; if you change your code just a little bit then reasoning may fail.<p>As someone who has spent years doing research on shape analysis my personal belief is that the dream of a fully automated \"find my bugs\" static analysis is unrealistic. Some of the problems you must solve to analyze the heap, say, are very hard indeed.<p>We need to think more about the interactions between language design and verification, rather than hoping that people will build better tools to analyze existing code. Strong typing (e.g., the Hindley-Milner type system) is one example of a sweet spot that demonstrates how language design (type annotation, type declarations) interacts with tools (type inference, type checking). Type systems are some of the most widely used bug finding tools today. Trying to build verification tools without considering language design is always going to be difficult.",
      "num_comments": null,
      "story_id": 3388290,
      "story_title": "John Carmack on the importance of Static Code Analysis",
      "story_url": "http://altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 3388500,
      "created_at_i": 1324838843,
      "_tags": [
        "comment",
        "author_emu",
        "story_3388290"
      ],
      "objectID": "3391380",
      "_highlightResult": {
        "author": {
          "value": "emu",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Well, unfortunately most interesting <em>static</em> <em>analysis</em> problems are undecidable. There can be no \"general\" solution.<p>What we have in practice are approximations and heuristics; over time we will develop better approximations for the kinds of code people write in practice. Unfortunately fragility of <em>analysis</em> will always be a problem; if you change your code just a little bit then reasoning may fail.<p>As someone who has spent years doing research on shape <em>analysis</em> my personal belief is that the dream of a fully automated \"find my bugs\" <em>static</em> <em>analysis</em> is unrealistic. Some of the problems you must solve to analyze the heap, say, are very hard indeed.<p>We need to think more about the interactions between language design and verification, rather than hoping that people will build better <em>tools</em> to analyze existing code. Strong typing (e.g., the Hindley-Milner type system) is one example of a sweet spot that demonstrates how language design (type annotation, type declarations) interacts with <em>tools</em> (type inference, type checking). Type systems are some of the most widely used bug finding <em>tools</em> today. Trying to build verification <em>tools</em> without considering language design is always going to be difficult.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on the importance of <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2011-09-19T22:14:48.000Z",
      "title": "",
      "url": "",
      "author": "jklp",
      "points": 2,
      "story_text": null,
      "comment_text": "&#62; [...] when you fire up Apples Xcode and start building CocoaTouch applications in Objective-C youre going to come face-to-face with a toolset that has not had the sort of love put into it that the open source community has put into the Java toolset and associate platforms, or that Microsoft has put into VS and .NET over the past 10 years<p>I think I'd have to agree with this statement.  As someone who's recently started developing in Objective C and coming from a Java / Eclipse background, the toolset provided in Xcode seems to fall short of what Eclipse has to offer (I can't speak for Visual studio).<p>For instance I don't think Xcode does proper static analysis.  I.e. it doesn't allow me to produce a proper class hierarchy for a class I'm using, nor can I run a command to see a call hierarchy on a method.  And refactoring isn't 100% accurate either, and also very limited, i.e. I can't extract methods from a code fragment, and also once extracted, move that method into another class without issue (typical workflow for extracting helper methods).<p>It's not to say I can't do good work in Xcode.  I just have to be aware of it's limitations and keep accurate documentation as I code, instead of relying on the IDE for a lot of the heavy lifting.",
      "num_comments": null,
      "story_id": 3015198,
      "story_title": "The Unfamiliar (Objective-C & Cocoa)",
      "story_url": "http://daringfireball.net/linked/2011/09/19/the-unfamiliar",
      "parent_id": 3015198,
      "created_at_i": 1316470488,
      "_tags": [
        "comment",
        "author_jklp",
        "story_3015198"
      ],
      "objectID": "3015429",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jklp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> [...] when you fire up Apples Xcode and start building CocoaTouch applications in Objective-C youre going to come face-to-face with a <em>tools</em>et that has not had the sort of love put into it that the open source community has put into the Java <em>tools</em>et and associate platforms, or that Microsoft has put into VS and .NET over the past 10 years<p>I think I'd have to agree with this statement.  As someone who's recently started developing in Objective C and coming from a Java / Eclipse background, the <em>tools</em>et provided in Xcode seems to fall short of what Eclipse has to offer (I can't speak for Visual studio).<p>For instance I don't think Xcode does proper <em>static</em> <em>analysis.</em>  I.e. it doesn't allow me to produce a proper class hierarchy for a class I'm using, nor can I run a command to see a call hierarchy on a method.  And refactoring isn't 100% accurate either, and also very limited, i.e. I can't extract methods from a code fragment, and also once extracted, move that method into another class without issue (typical workflow for extracting helper methods).<p>It's not to say I can't do good work in Xcode.  I just have to be aware of it's limitations and keep accurate documentation as I code, instead of relying on the IDE for a lot of the heavy lifting.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Unfamiliar (Objective-C & Cocoa)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://daringfireball.net/linked/2011/09/19/the-unfamiliar",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-07-09T20:09:55.000Z",
      "title": "",
      "url": "",
      "author": "msbarnett",
      "points": 2,
      "story_text": null,
      "comment_text": "It's not a matter of IDEs having to \"catch up\". C and C++ weren't designed with the constraint that they had to be highly amenable to static analysis, so there's quite simply less that automated refactoring tools can <i>know</i> they can safely change without breaking anything.",
      "num_comments": null,
      "story_id": 2745637,
      "story_title": "Tenacious C shows you what points to what",
      "story_url": "http://tenaciousc.com/",
      "parent_id": 2746193,
      "created_at_i": 1310242195,
      "_tags": [
        "comment",
        "author_msbarnett",
        "story_2745637"
      ],
      "objectID": "2746255",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "msbarnett",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's not a matter of IDEs having to \"catch up\". C and C++ weren't designed with the constraint that they had to be highly amenable to <em>static</em> <em>analysis</em>, so there's quite simply less that automated refactoring <em>tools</em> can <i>know</i> they can safely change without breaking anything.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Tenacious C shows you what points to what",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://tenaciousc.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-01T21:10:12.000Z",
      "title": null,
      "url": null,
      "author": "jamii",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt; Is it planned that users of Eve will routinely construct new or modify existing domain-specific editors to the task at hand?<p>Not sure at this point. For now we are focusing on the core interactions and we&#x27;ll build out the rest once we&#x27;ve put tools in peoples hands and seen how they work.<p>&gt; What domain-specific editors are you planning to include in public release? Something for UI construction on the web?<p>The table, rule and function editors for managing data and logic. A UI editor, hopefully with some constraint-based layout model. Various debugging&#x2F;tracing&#x2F;understanding tools.<p>&gt; Since first focus of Eve is on web apps (and it&#x27;s hosted on javascript, correct?), will it cover both client and server applications?<p>It will have to. Not sure yet how that will work. We can do websocket-style stuff at the moment but we will want to provide something simpler on top of that.<p>&gt; Will there be an FFI?<p>Yes. You will be able to add new functions &#x2F; datatypes (like <a href=\"http://www.postgresql.org/docs/9.1/static/xtypes.html\" rel=\"nofollow\">http:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;9.1&#x2F;static&#x2F;xtypes.html</a>), new table&#x2F;index data-structures (like <a href=\"http://www.postgresql.org/docs/9.1/static/gist-intro.html\" rel=\"nofollow\">http:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;9.1&#x2F;static&#x2F;gist-intro.html</a>) and new query-plan&#x2F;data-flow nodes.<p>The editor and compiler are mostly written in Eve. The core language is tiny but very extensible - since execution order is not specified explicitly but determined from data-flow you can drop new logic in anywhere to add new compiler optimisations or new editor commands.<p>The language is also very data-centric - this week I was playing with programs that modify their own code by writing to the ast tables, triggering the incremental compiler to update the dataflow plan.<p>&gt; If I remember correctly, you&#x27;re planning to use datalog+time+constraints and plan to use materialized views extensively, is it so? Will ability to work with changes as a stream and aggregate over them in more interesting ways than &quot;the last always wins&quot; be builtin in Eve?<p>We&#x27;re still trying out different models of time. The ideal semantic model is append-only, never forget. Implementing that on a real machine needs some restrictions to prevent exploding. Dedalus (<a href=\"http://db.cs.berkeley.edu/papers/datalog2011-dedalus.pdf\" rel=\"nofollow\">http:&#x2F;&#x2F;db.cs.berkeley.edu&#x2F;papers&#x2F;datalog2011-dedalus.pdf</a>) attaches epochs to each facts and only allows rules to query the current or last epoch. Edelweiss (<a href=\"http://db.cs.berkeley.edu/papers/vldb14-edelweiss.pdf\" rel=\"nofollow\">http:&#x2F;&#x2F;db.cs.berkeley.edu&#x2F;papers&#x2F;vldb14-edelweiss.pdf</a>) allows querying any epoch but uses static analysis to figure out when data can be safely deleted without changing the results.<p>&gt; Have you tried to show a prototype to children and how do they respond in learning such system if so? What was the reaction of academic friends who were not too familiar with standard forms of programming (like you did with the first prototype of Aurora)?<p>No children yet. We test things on adult non-programmers regularly. That lead to a couple of surprising changes like getting rid of nesting &#x2F; scoping (no matter what we did visually, people just couldn&#x27;t figure it out).<p>&gt; If I&#x27;ll ask more questions will it be all right and not too much trouble? :)<p>Keep &#x27;em coming.",
      "num_comments": null,
      "story_id": 8394381,
      "story_title": "Beyond Light Table",
      "story_url": "http://www.chris-granger.com/2014/10/01/beyond-light-table/",
      "parent_id": 8395751,
      "created_at_i": 1412197812,
      "_tags": [
        "comment",
        "author_jamii",
        "story_8394381"
      ],
      "objectID": "8397747",
      "_highlightResult": {
        "author": {
          "value": "jamii",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; Is it planned that users of Eve will routinely construct new or modify existing domain-specific editors to the task at hand?<p>Not sure at this point. For now we are focusing on the core interactions and we'll build out the rest once we've put <em>tools</em> in peoples hands and seen how they work.<p>&gt; What domain-specific editors are you planning to include in public release? Something for UI construction on the web?<p>The table, rule and function editors for managing data and logic. A UI editor, hopefully with some constraint-based layout model. Various debugging/tracing/understanding <em>tools</em>.<p>&gt; Since first focus of Eve is on web apps (and it's hosted on javascript, correct?), will it cover both client and server applications?<p>It will have to. Not sure yet how that will work. We can do websocket-style stuff at the moment but we will want to provide something simpler on top of that.<p>&gt; Will there be an FFI?<p>Yes. You will be able to add new functions / datatypes (like <a href=\"http://www.postgresql.org/docs/9.1/static/xtypes.html\" rel=\"nofollow\">http://www.postgresql.org/docs/9.1/<em>static</em>/xtypes.html</a>), new table/index data-structures (like <a href=\"http://www.postgresql.org/docs/9.1/static/gist-intro.html\" rel=\"nofollow\">http://www.postgresql.org/docs/9.1/<em>static</em>/gist-intro.html</a>) and new query-plan/data-flow nodes.<p>The editor and compiler are mostly written in Eve. The core language is tiny but very extensible - since execution order is not specified explicitly but determined from data-flow you can drop new logic in anywhere to add new compiler optimisations or new editor commands.<p>The language is also very data-centric - this week I was playing with programs that modify their own code by writing to the ast tables, triggering the incremental compiler to update the dataflow plan.<p>&gt; If I remember correctly, you're planning to use datalog+time+constraints and plan to use materialized views extensively, is it so? Will ability to work with changes as a stream and aggregate over them in more interesting ways than &quot;the last always wins&quot; be builtin in Eve?<p>We're still trying out different models of time. The ideal semantic model is append-only, never forget. Implementing that on a real machine needs some restrictions to prevent exploding. Dedalus (<a href=\"http://db.cs.berkeley.edu/papers/datalog2011-dedalus.pdf\" rel=\"nofollow\">http://db.cs.berkeley.edu/papers/datalog2011-dedalus.pdf</a>) attaches epochs to each facts and only allows rules to query the current or last epoch. Edelweiss (<a href=\"http://db.cs.berkeley.edu/papers/vldb14-edelweiss.pdf\" rel=\"nofollow\">http://db.cs.berkeley.edu/papers/vldb14-edelweiss.pdf</a>) allows querying any epoch but uses <em>static</em> <em>analysis</em> to figure out when data can be safely deleted without changing the results.<p>&gt; Have you tried to show a prototype to children and how do they respond in learning such system if so? What was the reaction of academic friends who were not too familiar with standard forms of programming (like you did with the first prototype of Aurora)?<p>No children yet. We test things on adult non-programmers regularly. That lead to a couple of surprising changes like getting rid of nesting / scoping (no matter what we did visually, people just couldn't figure it out).<p>&gt; If I'll ask more questions will it be all right and not too much trouble? :)<p>Keep 'em coming.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Beyond Light Table",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.chris-granger.com/2014/10/01/beyond-light-table/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-01T20:28:08.000Z",
      "title": null,
      "url": null,
      "author": "humanrebar",
      "points": 1,
      "story_text": null,
      "comment_text": "1. OK, you have prima facia case that some problems won&#x27;t be problems anymore. But the problems you mention are mostly nice-to-haves and not must-haves. For example, I can do static analysis manually or when it&#x27;s safe (pre-commit, during saves).<p>&gt; If we were talking about any other coding problem and I suggested you keep all your data in a complicated text serialisation spread across several hundred text files...<p>Except developing code in a team of size greater than one is a distributed computation problem. Distributed persistence mechanisms are basically a bunch of files spread across a system. And they deal with some of the same problems (availability, versioning, reconciliation, replication, etc.). Speaking of which, these are problems are typically solved through tools (git, etc.) that presume textual languages.<p>3. To be more concrete:<p>Q: How do I post code samples to sites like StackOverflow?<p>Q: How do I create patches from and apply patches to my codebase?<p>Q: Does git (or some other offline editing mode) work?<p>...some of the answers may include statements like, &quot;Well, wiring and metadata is all XML (or something) under the hood, so use your existing merge tools.&quot; In that case, we&#x27;re dealing with two things: a language and a configuration spec. We&#x27;re not really talking about a system that&#x27;s friendly to coders after all.<p>...again, these are technically solvable problems. I just think people are vastly underestimating the level of effort needed to get to feature parity with the current way of doing things.<p>The best way to prove me too skeptical is to develop a decent-sized project across a decent-sized team, which is something non-text development tools (including Excel and Photoshop) haven&#x27;t been particularly good at. My bet is that this won&#x27;t happen and that at best Eve will be a successful enterprise tool for domain-specific problems that can be tackled by small teams (again, like Excel, Photoshop, LabView, etc.).<p>Not that there&#x27;s anything wrong with that. Adobe is a successful company.",
      "num_comments": null,
      "story_id": 8394381,
      "story_title": "Beyond Light Table",
      "story_url": "http://www.chris-granger.com/2014/10/01/beyond-light-table/",
      "parent_id": 8396329,
      "created_at_i": 1412195288,
      "_tags": [
        "comment",
        "author_humanrebar",
        "story_8394381"
      ],
      "objectID": "8397487",
      "_highlightResult": {
        "author": {
          "value": "humanrebar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "1. OK, you have prima facia case that some problems won't be problems anymore. But the problems you mention are mostly nice-to-haves and not must-haves. For example, I can do <em>static</em> <em>analysis</em> manually or when it's safe (pre-commit, during saves).<p>&gt; If we were talking about any other coding problem and I suggested you keep all your data in a complicated text serialisation spread across several hundred text files...<p>Except developing code in a team of size greater than one is a distributed computation problem. Distributed persistence mechanisms are basically a bunch of files spread across a system. And they deal with some of the same problems (availability, versioning, reconciliation, replication, etc.). Speaking of which, these are problems are typically solved through <em>tools</em> (git, etc.) that presume textual languages.<p>3. To be more concrete:<p>Q: How do I post code samples to sites like StackOverflow?<p>Q: How do I create patches from and apply patches to my codebase?<p>Q: Does git (or some other offline editing mode) work?<p>...some of the answers may include statements like, &quot;Well, wiring and metadata is all XML (or something) under the hood, so use your existing merge <em>tools</em>.&quot; In that case, we're dealing with two things: a language and a configuration spec. We're not really talking about a system that's friendly to coders after all.<p>...again, these are technically solvable problems. I just think people are vastly underestimating the level of effort needed to get to feature parity with the current way of doing things.<p>The best way to prove me too skeptical is to develop a decent-sized project across a decent-sized team, which is something non-text development <em>tools</em> (including Excel and Photoshop) haven't been particularly good at. My bet is that this won't happen and that at best Eve will be a successful enterprise tool for domain-specific problems that can be tackled by small teams (again, like Excel, Photoshop, LabView, etc.).<p>Not that there's anything wrong with that. Adobe is a successful company.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Beyond Light Table",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.chris-granger.com/2014/10/01/beyond-light-table/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-01T14:40:43.000Z",
      "title": null,
      "url": null,
      "author": "krg",
      "points": 1,
      "story_text": null,
      "comment_text": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;</a><p>Work Hard, Have Fun, Be Nice<p>Let&#x27;s be honest: you became a developer because you like to build things. Interesting things, useful things, cool things. It&#x27;s like building with Legos, only you get paid, and there are always plenty of the right color pieces.<p>At TechEmpower, we build things. Interesting things. Cool things, mostly in webapp form. We build them as individuals, because we&#x27;re creative people. We build them as teams, because we like to help each other grow, and because we know that collaboration improves even the best code.<p>Having the best people doesn&#x27;t hurt, either. We&#x27;ve got most of them already, and we&#x27;re looking to find the rest. You can build things with us. What&#x27;s the catch? We&#x27;re pretty darn selective.<p>To work as an individual, you have to be motivated and creative and thoughtful and serious. To work on a team, you have to be respectful and energetic and open and absolutely not a jerk. We need developers who can work on every part of an application, from the data store to the page–sometimes known as full stack developers. And to be a full stack developer, you have to know technology and want to learn more technology, because those acronyms just keep coming.<p>Our clients expect us to work with them, not for them. We help them define their problems, and we provide solutions, on time and on target. We&#x27;re service-oriented, and you should be too.<p>Still reading? Please apply! And check out our Web Framework Benchmarks while you&#x27;re at it. We pretty much wrote the book on that one.<p>Just so you know:<p><pre><code>   Teams range between 2-6 people\\n   Developers are exposed to 3-4 projects per year\\n   All development is done on high-performance workstations with 4K displays. A lot of code fits in 3840x2160 pixels!\\n   We maintain an informal, comfortable environment, just like the old college computer science lab, but with grown-up hours\\n   Everybody&#x27;s nice\\n</code></pre>\\nThe technologies we use vary over time with our mix of projects. Here is a snapshot of what we&#x27;re using now:<p><pre><code>   Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n   Tools: Git, Jenkins (Continuous Integration), Sonar (static code analysis), Eclipse, IntelliJ, Ant, Maven\\n   Web: Dropwizard, .NET MVC 5, Play, Django, Rails, Mustache, Handlebars, Backbone, Angular, Knockout, JSP, Servlets, jQuery, etc.\\n   Mobile: iOS, Android, PhoneGap\\n   Hosting: AWS (EC2, RDS, etc.), Rackspace Cloud, Linux deployments\\n   Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, NoSQL (Redis, MongoDB)\\n</code></pre>\\nWe don&#x27;t expect new hires to have experience with all of these, but we do expect you&#x27;ll learn more about them every day.<p>If this sounds like the kind of place you&#x27;d like to work, please apply here: <a href=\"http://jobs.techempower.com/hn2\" rel=\"nofollow\">http:&#x2F;&#x2F;jobs.techempower.com&#x2F;hn2</a>",
      "num_comments": null,
      "story_id": 8394339,
      "story_title": "Ask HN: Who is hiring? (October 2014)",
      "story_url": "",
      "parent_id": 8394339,
      "created_at_i": 1412174443,
      "_tags": [
        "comment",
        "author_krg",
        "story_8394339"
      ],
      "objectID": "8394706",
      "_highlightResult": {
        "author": {
          "value": "krg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http://www.techempower.com/benchmarks/</a><p>Work Hard, Have Fun, Be Nice<p>Let's be honest: you became a developer because you like to build things. Interesting things, useful things, cool things. It's like building with Legos, only you get paid, and there are always plenty of the right color pieces.<p>At TechEmpower, we build things. Interesting things. Cool things, mostly in webapp form. We build them as individuals, because we're creative people. We build them as teams, because we like to help each other grow, and because we know that collaboration improves even the best code.<p>Having the best people doesn't hurt, either. We've got most of them already, and we're looking to find the rest. You can build things with us. What's the catch? We're pretty darn selective.<p>To work as an individual, you have to be motivated and creative and thoughtful and serious. To work on a team, you have to be respectful and energetic and open and absolutely not a jerk. We need developers who can work on every part of an application, from the data store to the page–sometimes known as full stack developers. And to be a full stack developer, you have to know technology and want to learn more technology, because those acronyms just keep coming.<p>Our clients expect us to work with them, not for them. We help them define their problems, and we provide solutions, on time and on target. We're service-oriented, and you should be too.<p>Still reading? Please apply! And check out our Web Framework Benchmarks while you're at it. We pretty much wrote the book on that one.<p>Just so you know:<p><pre><code>   Teams range between 2-6 people\\n   Developers are exposed to 3-4 projects per year\\n   All development is done on high-performance workstations with 4K displays. A lot of code fits in 3840x2160 pixels!\\n   We maintain an informal, comfortable environment, just like the old college computer science lab, but with grown-up hours\\n   Everybody's nice\\n</code></pre>\\nThe technologies we use vary over time with our mix of projects. Here is a snapshot of what we're using now:<p><pre><code>   Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n   <em>Tools</em>: Git, Jenkins (Continuous Integration), Sonar (<em>static</em> code <em>analysis</em>), Eclipse, IntelliJ, Ant, Maven\\n   Web: Dropwizard, .NET MVC 5, Play, Django, Rails, Mustache, Handlebars, Backbone, Angular, Knockout, JSP, Servlets, jQuery, etc.\\n   Mobile: iOS, Android, PhoneGap\\n   Hosting: AWS (EC2, RDS, etc.), Rackspace Cloud, Linux deployments\\n   Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, NoSQL (Redis, MongoDB)\\n</code></pre>\\nWe don't expect new hires to have experience with all of these, but we do expect you'll learn more about them every day.<p>If this sounds like the kind of place you'd like to work, please apply here: <a href=\"http://jobs.techempower.com/hn2\" rel=\"nofollow\">http://jobs.techempower.com/hn2</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (October 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-02T16:40:55.000Z",
      "title": null,
      "url": null,
      "author": "krg",
      "points": 1,
      "story_text": null,
      "comment_text": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;</a><p>Work Hard, Have Fun, Be Nice<p>Let&#x27;s be honest: you became a developer because you like to build things. Interesting things, useful things, cool things. It&#x27;s like building with Legos, only you get paid, and there are always plenty of the right color pieces.<p>At TechEmpower, we build things. Interesting things. Cool things, mostly in webapp form. We build them as individuals, because we&#x27;re creative people. We build them as teams, because we like to help each other grow, and because we know that collaboration improves even the best code.<p>Having the best people doesn&#x27;t hurt, either. We&#x27;ve got most of them already, and we&#x27;re looking to find the rest. You can build things with us. What&#x27;s the catch? We&#x27;re pretty darn selective.<p>To work as an individual, you have to be motivated and creative and thoughtful and serious. To work on a team, you have to be respectful and energetic and open and absolutely not a jerk. We need developers who can work on every part of an application, from the data store to the page–sometimes known as full stack developers. And to be a full stack developer, you have to know technology and want to learn more technology, because those acronyms just keep coming.<p>Our clients expect us to work with them, not for them. We help them define their problems, and we provide solutions, on time and on target. We&#x27;re service-oriented, and you should be too.<p>Still reading? Please apply! And check out our Web Framework Benchmarks while you&#x27;re at it. We pretty much wrote the book on that one.<p>Just so you know:<p><pre><code>   Teams range between 2-6 people\\n   Developers are exposed to 3-4 projects per year\\n   All development is done on high-performance workstations with 4K displays. A lot of code fits in 3840x2160 pixels!\\n   We maintain an informal, comfortable environment, just like the old college computer science lab, but with grown-up hours\\n   Everybody&#x27;s nice\\n</code></pre>\\nThe technologies we use vary over time with our mix of projects. Here is a snapshot of what we&#x27;re using now:<p><pre><code>   Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n   Tools: Git, Jenkins (Continuous Integration), Sonar (static code analysis), Eclipse, IntelliJ, Ant, Maven\\n   Web: Dropwizard, .NET MVC 5, Play, Django, Rails, Mustache, Handlebars, Backbone, Angular, Knockout, JSP, Servlets, jQuery, etc.\\n   Mobile: iOS, Android, PhoneGap\\n   Hosting: AWS (EC2, RDS, etc.), Rackspace Cloud, Linux deployments\\n   Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, NoSQL (Redis, MongoDB)\\n</code></pre>\\nWe don&#x27;t expect new hires to have experience with all of these, but we do expect you&#x27;ll learn more about them every day.<p>If this sounds like the kind of place you&#x27;d like to work, please apply here: <a href=\"http://jobs.techempower.com/hn2\" rel=\"nofollow\">http:&#x2F;&#x2F;jobs.techempower.com&#x2F;hn2</a>",
      "num_comments": null,
      "story_id": 8252715,
      "story_title": "Ask HN: Who is hiring? (September 2014)",
      "story_url": "",
      "parent_id": 8252715,
      "created_at_i": 1409676055,
      "_tags": [
        "comment",
        "author_krg",
        "story_8252715"
      ],
      "objectID": "8258624",
      "_highlightResult": {
        "author": {
          "value": "krg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http://www.techempower.com/benchmarks/</a><p>Work Hard, Have Fun, Be Nice<p>Let's be honest: you became a developer because you like to build things. Interesting things, useful things, cool things. It's like building with Legos, only you get paid, and there are always plenty of the right color pieces.<p>At TechEmpower, we build things. Interesting things. Cool things, mostly in webapp form. We build them as individuals, because we're creative people. We build them as teams, because we like to help each other grow, and because we know that collaboration improves even the best code.<p>Having the best people doesn't hurt, either. We've got most of them already, and we're looking to find the rest. You can build things with us. What's the catch? We're pretty darn selective.<p>To work as an individual, you have to be motivated and creative and thoughtful and serious. To work on a team, you have to be respectful and energetic and open and absolutely not a jerk. We need developers who can work on every part of an application, from the data store to the page–sometimes known as full stack developers. And to be a full stack developer, you have to know technology and want to learn more technology, because those acronyms just keep coming.<p>Our clients expect us to work with them, not for them. We help them define their problems, and we provide solutions, on time and on target. We're service-oriented, and you should be too.<p>Still reading? Please apply! And check out our Web Framework Benchmarks while you're at it. We pretty much wrote the book on that one.<p>Just so you know:<p><pre><code>   Teams range between 2-6 people\\n   Developers are exposed to 3-4 projects per year\\n   All development is done on high-performance workstations with 4K displays. A lot of code fits in 3840x2160 pixels!\\n   We maintain an informal, comfortable environment, just like the old college computer science lab, but with grown-up hours\\n   Everybody's nice\\n</code></pre>\\nThe technologies we use vary over time with our mix of projects. Here is a snapshot of what we're using now:<p><pre><code>   Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n   <em>Tools</em>: Git, Jenkins (Continuous Integration), Sonar (<em>static</em> code <em>analysis</em>), Eclipse, IntelliJ, Ant, Maven\\n   Web: Dropwizard, .NET MVC 5, Play, Django, Rails, Mustache, Handlebars, Backbone, Angular, Knockout, JSP, Servlets, jQuery, etc.\\n   Mobile: iOS, Android, PhoneGap\\n   Hosting: AWS (EC2, RDS, etc.), Rackspace Cloud, Linux deployments\\n   Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, NoSQL (Redis, MongoDB)\\n</code></pre>\\nWe don't expect new hires to have experience with all of these, but we do expect you'll learn more about them every day.<p>If this sounds like the kind of place you'd like to work, please apply here: <a href=\"http://jobs.techempower.com/hn2\" rel=\"nofollow\">http://jobs.techempower.com/hn2</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (September 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-02T14:09:59.000Z",
      "title": null,
      "url": null,
      "author": "klibertp",
      "points": 1,
      "story_text": null,
      "comment_text": "Downvoted.<p>Even if the design docs would exist, it would take months to read them, without any guarantee that they correspond to the reality.<p>Meanwhile, automated analysis of actual code can give you at least high-level overview of the codebase and maybe a hint where to start digging. Getting AST is a first step required for most automated tools to do their work.<p>EDIT: I acted too rashly and downvoted your post before I realized what are we really talking about. Sorry about this. I still am convinced that automatic, static analysis of the code is the way to go, but you obviously don&#x27;t deserve a downvote for having different opinion. I&#x27;ll try to make it up to you by being more careful in the future :)",
      "num_comments": null,
      "story_id": 8257327,
      "story_title": "Ask HN: I have to analyze 100M lines of Java – where do I start?",
      "story_url": "",
      "parent_id": 8257519,
      "created_at_i": 1409666999,
      "_tags": [
        "comment",
        "author_klibertp",
        "story_8257327"
      ],
      "objectID": "8257637",
      "_highlightResult": {
        "author": {
          "value": "klibertp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Downvoted.<p>Even if the design docs would exist, it would take months to read them, without any guarantee that they correspond to the reality.<p>Meanwhile, automated <em>analysis</em> of actual code can give you at least high-level overview of the codebase and maybe a hint where to start digging. Getting AST is a first step required for most automated <em>tools</em> to do their work.<p>EDIT: I acted too rashly and downvoted your post before I realized what are we really talking about. Sorry about this. I still am convinced that automatic, <em>static</em> <em>analysis</em> of the code is the way to go, but you obviously don't deserve a downvote for having different opinion. I'll try to make it up to you by being more careful in the future :)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: I have to analyze 100M lines of Java – where do I start?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-12T03:06:22.000Z",
      "title": null,
      "url": null,
      "author": "arghbleargh",
      "points": 1,
      "story_text": null,
      "comment_text": "This is a pretty interesting concept, but the site doesn&#x27;t do a good job of explaining exactly what it does. A realistic step-by-step example would help a lot. Is it doing some kind of static analysis, or is it looking at the object graph at some specified point in the program&#x27;s execution?<p>I think it would be really useful to have a tool that visualizes execution paths of programs to help you understand the general architecture of someone else&#x27;s project. I believe debugging tools are able to do this to some extent, but I haven&#x27;t seen anything that exactly fits, especially for JS. I would want to be able to do some interaction (e.g. mouse click) and see a visualization summarizing all the lines of code that were run without stepping through them one-by-one. Maybe this is a direction that PojoViz could go in eventually.",
      "num_comments": null,
      "story_id": 8165522,
      "story_title": "Show HN: PojoViz – Visualize the structure of any JavaScript library, framework",
      "story_url": "http://maurizzzio.github.io/PojoViz/public/vulcanize.html#readme",
      "parent_id": 8165522,
      "created_at_i": 1407812782,
      "_tags": [
        "comment",
        "author_arghbleargh",
        "story_8165522"
      ],
      "objectID": "8166422",
      "_highlightResult": {
        "author": {
          "value": "arghbleargh",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is a pretty interesting concept, but the site doesn't do a good job of explaining exactly what it does. A realistic step-by-step example would help a lot. Is it doing some kind of <em>static</em> <em>analysis</em>, or is it looking at the object graph at some specified point in the program's execution?<p>I think it would be really useful to have a tool that visualizes execution paths of programs to help you understand the general architecture of someone else's project. I believe debugging <em>tools</em> are able to do this to some extent, but I haven't seen anything that exactly fits, especially for JS. I would want to be able to do some interaction (e.g. mouse click) and see a visualization summarizing all the lines of code that were run without stepping through them one-by-one. Maybe this is a direction that PojoViz could go in eventually.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Show HN: PojoViz – Visualize the structure of any JavaScript library, framework",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://maurizzzio.github.io/PojoViz/public/vulcanize.html#readme",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-01T20:16:05.000Z",
      "title": null,
      "url": null,
      "author": "Plasmoid",
      "points": 1,
      "story_text": null,
      "comment_text": "Coverity - <a href=\"http://www.coverity.com\" rel=\"nofollow\">http:&#x2F;&#x2F;www.coverity.com</a> - San Francisco, Seattle, Calgary - VISA<p>We make software to find bugs in software.  Static Analysis, Dynamic Analysis, Security Analysis, and Test Analysis.  It&#x27;s an awesome place to work.<p>* Senior Build Engineer *<p>--------------------------------<p>We are looking for a Senior Build Engineer to support the Continuous Integration process&#x2F;infrastructure for Coverity products and components.  Our build environment is comprised of a myriad of platforms including different versions of Windows, Linux, Unix, and MacOSX with codebases in C&#x2F;C++, Java, and C#.  The ideal candidate is someone who despises doing a lot of busy manual work and prefers to develop automation for anything that he&#x2F;she feels can and should be automated.  The ideal candidate is also someone who is very comfortable interacting and working with pretty much everyone in the R&amp;D team as he&#x2F;she will be supporting Developers and QA.  We are looking for someone who finds it difficult to sleep at night knowing something might be wrong with his&#x2F;her build system.<p>More details - <a href=\"http://jobvite.com/m?3WDvAgwp\" rel=\"nofollow\">http:&#x2F;&#x2F;jobvite.com&#x2F;m?3WDvAgwp</a><p>-----------------------------------<p>*  Java Backend Developer *<p>-----------------------------------<p>We&#x27;re looking for an engineer with significant design and implementation experience with the back end components of web applications.  This person will be part of Coverity’s Web Application team, which is charged with the delivery of advanced management capabilities for Coverity’s suite of code analysis tools. As Coverity grows and its solutions are more widely deployed, the accompanying management capabilities must become increasingly effective for a growing number of stakeholders and be capable of scaling to larger deployments.  The challenge this position holds is to meet these goals while continuing to satisfy the expert users of the application as it is currently implemented.<p>More details - <a href=\"http://jobvite.com/m?3nEvAgwR\" rel=\"nofollow\">http:&#x2F;&#x2F;jobvite.com&#x2F;m?3nEvAgwR</a><p>-------------------------------------<p>* Senior User Interface Developer *<p>-------------------------------------<p>The Coverity Desktop team is looking for an experienced Java developer to help take our desktop GUI’s to the next level.  This includes IDE plugins (like Eclipse and IntelliJ IDEA) and stand-alone Java&#x2F;RCP GUI applications as well.<p>More details - <a href=\"http://jobvite.com/m?33EvAgwx\" rel=\"nofollow\">http:&#x2F;&#x2F;jobvite.com&#x2F;m?33EvAgwx</a><p>Feel free to ask me any questions about Coverity",
      "num_comments": null,
      "story_id": 8120070,
      "story_title": "Ask HN: Who is hiring? (August 2014)",
      "story_url": "",
      "parent_id": 8120070,
      "created_at_i": 1406924165,
      "_tags": [
        "comment",
        "author_Plasmoid",
        "story_8120070"
      ],
      "objectID": "8122549",
      "_highlightResult": {
        "author": {
          "value": "Plasmoid",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Coverity - <a href=\"http://www.coverity.com\" rel=\"nofollow\">http://www.coverity.com</a> - San Francisco, Seattle, Calgary - VISA<p>We make software to find bugs in software.  <em>Static</em> <em>Analysis</em>, Dynamic <em>Analysis</em>, Security <em>Analysis</em>, and Test <em>Analysis.</em>  It's an awesome place to work.<p>* Senior Build Engineer *<p>--------------------------------<p>We are looking for a Senior Build Engineer to support the Continuous Integration process/infrastructure for Coverity products and components.  Our build environment is comprised of a myriad of platforms including different versions of Windows, Linux, Unix, and MacOSX with codebases in C/C++, Java, and C#.  The ideal candidate is someone who despises doing a lot of busy manual work and prefers to develop automation for anything that he/she feels can and should be automated.  The ideal candidate is also someone who is very comfortable interacting and working with pretty much everyone in the R&amp;D team as he/she will be supporting Developers and QA.  We are looking for someone who finds it difficult to sleep at night knowing something might be wrong with his/her build system.<p>More details - <a href=\"http://jobvite.com/m?3WDvAgwp\" rel=\"nofollow\">http://jobvite.com/m?3WDvAgwp</a><p>-----------------------------------<p>*  Java Backend Developer *<p>-----------------------------------<p>We're looking for an engineer with significant design and implementation experience with the back end components of web applications.  This person will be part of Coverity’s Web Application team, which is charged with the delivery of advanced management capabilities for Coverity’s suite of code <em>analysis</em> <em>tools</em>. As Coverity grows and its solutions are more widely deployed, the accompanying management capabilities must become increasingly effective for a growing number of stakeholders and be capable of scaling to larger deployments.  The challenge this position holds is to meet these goals while continuing to satisfy the expert users of the application as it is currently implemented.<p>More details - <a href=\"http://jobvite.com/m?3nEvAgwR\" rel=\"nofollow\">http://jobvite.com/m?3nEvAgwR</a><p>-------------------------------------<p>* Senior User Interface Developer *<p>-------------------------------------<p>The Coverity Desktop team is looking for an experienced Java developer to help take our desktop GUI’s to the next level.  This includes IDE plugins (like Eclipse and IntelliJ IDEA) and stand-alone Java/RCP GUI applications as well.<p>More details - <a href=\"http://jobvite.com/m?33EvAgwx\" rel=\"nofollow\">http://jobvite.com/m?33EvAgwx</a><p>Feel free to ask me any questions about Coverity",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (August 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-12T15:44:00.000Z",
      "title": null,
      "url": null,
      "author": "notacoward",
      "points": 1,
      "story_text": null,
      "comment_text": "I don&#x27;t believe the kernel attack surface is as small as you seem to think, nor is the browser attack surface as large.<p>Let&#x27;s look at the kernel first.  Yes, the LOC numbers are bloated by bazillions of drivers, but even the core components that most people use are pretty large.  I just counted on Linux 3.16 and there are 1.2M lines in components I definitely use on one machine.  That&#x27;s excluding <i>anything</i> in drivers&#x2F;; include what I use from there and we&#x27;re probably over 2M.  I don&#x27;t think any reasonable person can claim that 2M lines is a small attack surface, so DJB is already wrong.<p>Now let&#x27;s look at Firefox.  Downloading 30.0 I see ~13M lines of C, C++ and JS.  Subtract at least 2M for the build system itself, build-time-selectable components, dev tools, and NSS which is part of the OS attack surface as well.  There are a bunch of other components that I&#x27;m sure most people never use, or even have explicitly disabled&#x2F;blocked, but let&#x27;s leave them in so we have 11M.  Hey, 11M is still larger than 2M, so you and DJB must be right.  Not so fast.  Attack surface is not just about LOC, and certainly not single-component LOC.  Let&#x27;s look at some other confounding factors.<p>* The exact same algorithm, with the exact same attack surface, can be expressed in more or less verbose form.  The Mozilla code is written in a more verbose style, but shouldn&#x27;t necessarily get credit for that.  In many ways, that&#x27;s likely to make auditing harder.<p>* The kernel code is harder to audit.  There are fewer people even remotely able to do it, it contains more low-level trickery requiring expertise in a particular platform to analyze, it has more asynchronous&#x2F;reentrant&#x2F;etc. control flows that defeat static analysis, etc.  Line for line, analyzing kernel code is many times harder than analyzing Mozilla code.<p>* Across an entire enterprise, the number of platforms and drivers that need to be considered for the kernel - from phones and embedded devices to servers and desktops - increases significantly.  So does the attack surface, and real security isn&#x27;t about single machines in isolation.  The corresponding increase for Firefox is very small.<p>* An <i>operating</i> system is more than a kernel.  Even if we only include the utilities that are essential to boot a system and do minimal work on it, we might blow right through that 11M mark.<p>So yes, if you pick silly definitions and squint hard enough, DJB&#x27;s statements about the two attack surfaces might be pedantically correct.  They&#x27;re still not <i>practically</i> correct.  He frames it as &quot;easy&quot; vs. &quot;hard&quot; - a qualitative policy-driving distinction - and that&#x27;s misleading at best.  Even if you can&#x27;t accept that he got the relative difficulty exactly wrong, it&#x27;s clear they are well within the same ballpark.  The supposed continental divide that DJB uses to justify the rest of his argument is in fact vapor-thin, and deserves derision.",
      "num_comments": null,
      "story_id": 8023812,
      "story_title": "Making sure software stays insecure [pdf]",
      "story_url": "http://cr.yp.to/talks/2014.07.10/slides-djb-20140710-a4.pdf",
      "parent_id": 8024512,
      "created_at_i": 1405179840,
      "_tags": [
        "comment",
        "author_notacoward",
        "story_8023812"
      ],
      "objectID": "8024829",
      "_highlightResult": {
        "author": {
          "value": "notacoward",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't believe the kernel attack surface is as small as you seem to think, nor is the browser attack surface as large.<p>Let's look at the kernel first.  Yes, the LOC numbers are bloated by bazillions of drivers, but even the core components that most people use are pretty large.  I just counted on Linux 3.16 and there are 1.2M lines in components I definitely use on one machine.  That's excluding <i>anything</i> in drivers/; include what I use from there and we're probably over 2M.  I don't think any reasonable person can claim that 2M lines is a small attack surface, so DJB is already wrong.<p>Now let's look at Firefox.  Downloading 30.0 I see ~13M lines of C, C++ and JS.  Subtract at least 2M for the build system itself, build-time-selectable components, dev <em>tools</em>, and NSS which is part of the OS attack surface as well.  There are a bunch of other components that I'm sure most people never use, or even have explicitly disabled/blocked, but let's leave them in so we have 11M.  Hey, 11M is still larger than 2M, so you and DJB must be right.  Not so fast.  Attack surface is not just about LOC, and certainly not single-component LOC.  Let's look at some other confounding factors.<p>* The exact same algorithm, with the exact same attack surface, can be expressed in more or less verbose form.  The Mozilla code is written in a more verbose style, but shouldn't necessarily get credit for that.  In many ways, that's likely to make auditing harder.<p>* The kernel code is harder to audit.  There are fewer people even remotely able to do it, it contains more low-level trickery requiring expertise in a particular platform to analyze, it has more asynchronous/reentrant/etc. control flows that defeat <em>static</em> <em>analysis</em>, etc.  Line for line, analyzing kernel code is many times harder than analyzing Mozilla code.<p>* Across an entire enterprise, the number of platforms and drivers that need to be considered for the kernel - from phones and embedded devices to servers and desktops - increases significantly.  So does the attack surface, and real security isn't about single machines in isolation.  The corresponding increase for Firefox is very small.<p>* An <i>operating</i> system is more than a kernel.  Even if we only include the utilities that are essential to boot a system and do minimal work on it, we might blow right through that 11M mark.<p>So yes, if you pick silly definitions and squint hard enough, DJB's statements about the two attack surfaces might be pedantically correct.  They're still not <i>practically</i> correct.  He frames it as &quot;easy&quot; vs. &quot;hard&quot; - a qualitative policy-driving distinction - and that's misleading at best.  Even if you can't accept that he got the relative difficulty exactly wrong, it's clear they are well within the same ballpark.  The supposed continental divide that DJB uses to justify the rest of his argument is in fact vapor-thin, and deserves derision.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Making sure software stays insecure [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cr.yp.to/talks/2014.07.10/slides-djb-20140710-a4.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-27T21:08:03.000Z",
      "title": null,
      "url": null,
      "author": "mythz",
      "points": 1,
      "story_text": null,
      "comment_text": "Not sure what you mean: MS has a history of abandoning its developer platforms and frameworks that thier developers have invested in, so much so that there&#x27;s no longer a clear UI story for building native desktop windows apps, i.e. VB6, Silverlight, WinForms and WPF are all effectively deprecated. Although they have long support life, when they officially abandon a platform they also refuse to Open Source it so others can keep it alive (e.g. VB6 <a href=\"http://bit.ly/KPMUS6\" rel=\"nofollow\">http:&#x2F;&#x2F;bit.ly&#x2F;KPMUS6</a>). I personally can&#x27;t see how anyone can put trust into building native Windows desktop apps (i.e. over web apps) given the repeated a history of abandonment.<p>Even the #1 feature for VS.NET is to continue developing very popular XNA framework:\\n<a href=\"http://visualstudio.uservoice.com/forums/121579-visual-studio/filters/top\" rel=\"nofollow\">http:&#x2F;&#x2F;visualstudio.uservoice.com&#x2F;forums&#x2F;121579-visual-studi...</a><p>Likewise on the server side there&#x27;s been history of deprecated frameworks a lot of developers have invested a lot of energy into learning, e.g: .asmx, CSF, WCF, WCF&#x2F;REST, WSE, WCF DataServices, RIA<p>Whilst VisualStudio is a great IDE, I find it a subpar experience without R#. The major advantages Dart has over C# is that it still provides an enjoyable experience to develop even without an IDE which also includes support for the most popular text editors: <a href=\"https://www.dartlang.org/tools/\" rel=\"nofollow\">https:&#x2F;&#x2F;www.dartlang.org&#x2F;tools&#x2F;</a>\\nIf you like IDE and tooling support, the DartEditor offers a good experience with built-in analyzer, debugging and refactoring support you can expect from a well engineered language.<p>By contrast, C#&#x27;s configuration model, msbuild project format, heavy frameworks and tooling makes it unfeasible to develop without an IDE.<p>The other major advantage Dart has is that it compiles down to JS where even the compiler is completely self-hosting and runs inside a browser without plugins: <a href=\"http://try.dartlang.org/\" rel=\"nofollow\">http:&#x2F;&#x2F;try.dartlang.org&#x2F;</a>\\nBeing able to share the same code on client and server and having a single integrated development full-stack experience is a huge win in re-usability and utility.<p>Another killer feature is that the language and tooling is cross-platform which supports Windows, OSX and Linux. Something .NET devs often miss out on is the value and utility of being able to host apps on cost-effective Linux servers.<p>Google continues to invest a tonne of resources in Dart and Polymer which are massive undertakings that are providing a much simplified and consistent experience for developing large, complex web apps. Nothing like Dart or Polymer exists. Dart is a platform that transpiles to JS, includes a native Dart VM, an entire toolchain including IDE, analyzer and debugger both in Dart Editor as well as in Chrome, in both the Dart VM as well as debugging with Source maps.<p>The worlds best VM engineers work on the Dart VM, i.e. the same pedigree responsible for the StrongTalk VM that was later acquired by Sun to form the basis of the world-class Java Hotspot VM that later went on to develop V8, are now leading the development on the Dart VM.<p>The excellence shows itself in the consistency and minimalism goals in the language, providing a productive, iterative dynamic language experience for fast prototyping with the benefit of static analysis with optional typing when scaling up to a maintainable, well-documented code-base (best of both worlds).<p>Not only is Dart a productive dynamic language, it also has excellent performance, the best performance of all languages I benchmarked with a port of Peter Norvig&#x27;s Sudoku solver: <a href=\"https://github.com/dartist/sudoku_solver#benchmarks\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dartist&#x2F;sudoku_solver#benchmarks</a>",
      "num_comments": null,
      "story_id": 7954778,
      "story_title": "Dart 1.5",
      "story_url": "http://news.dartlang.org/2014/06/dart-15-makes-it-easier-to-develop-for.html",
      "parent_id": 7955828,
      "created_at_i": 1403903283,
      "_tags": [
        "comment",
        "author_mythz",
        "story_7954778"
      ],
      "objectID": "7956307",
      "_highlightResult": {
        "author": {
          "value": "mythz",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Not sure what you mean: MS has a history of abandoning its developer platforms and frameworks that thier developers have invested in, so much so that there's no longer a clear UI story for building native desktop windows apps, i.e. VB6, Silverlight, WinForms and WPF are all effectively deprecated. Although they have long support life, when they officially abandon a platform they also refuse to Open Source it so others can keep it alive (e.g. VB6 <a href=\"http://bit.ly/KPMUS6\" rel=\"nofollow\">http://bit.ly/KPMUS6</a>). I personally can't see how anyone can put trust into building native Windows desktop apps (i.e. over web apps) given the repeated a history of abandonment.<p>Even the #1 feature for VS.NET is to continue developing very popular XNA framework:\\n<a href=\"http://visualstudio.uservoice.com/forums/121579-visual-studio/filters/top\" rel=\"nofollow\">http://visualstudio.uservoice.com/forums/121579-visual-studi...</a><p>Likewise on the server side there's been history of deprecated frameworks a lot of developers have invested a lot of energy into learning, e.g: .asmx, CSF, WCF, WCF/REST, WSE, WCF DataServices, RIA<p>Whilst VisualStudio is a great IDE, I find it a subpar experience without R#. The major advantages Dart has over C# is that it still provides an enjoyable experience to develop even without an IDE which also includes support for the most popular text editors: <a href=\"https://www.dartlang.org/tools/\" rel=\"nofollow\">https://www.dartlang.org/<em>tools</em>/</a>\\nIf you like IDE and tooling support, the DartEditor offers a good experience with built-in analyzer, debugging and refactoring support you can expect from a well engineered language.<p>By contrast, C#'s configuration model, msbuild project format, heavy frameworks and tooling makes it unfeasible to develop without an IDE.<p>The other major advantage Dart has is that it compiles down to JS where even the compiler is completely self-hosting and runs inside a browser without plugins: <a href=\"http://try.dartlang.org/\" rel=\"nofollow\">http://try.dartlang.org/</a>\\nBeing able to share the same code on client and server and having a single integrated development full-stack experience is a huge win in re-usability and utility.<p>Another killer feature is that the language and tooling is cross-platform which supports Windows, OSX and Linux. Something .NET devs often miss out on is the value and utility of being able to host apps on cost-effective Linux servers.<p>Google continues to invest a tonne of resources in Dart and Polymer which are massive undertakings that are providing a much simplified and consistent experience for developing large, complex web apps. Nothing like Dart or Polymer exists. Dart is a platform that transpiles to JS, includes a native Dart VM, an entire toolchain including IDE, analyzer and debugger both in Dart Editor as well as in Chrome, in both the Dart VM as well as debugging with Source maps.<p>The worlds best VM engineers work on the Dart VM, i.e. the same pedigree responsible for the StrongTalk VM that was later acquired by Sun to form the basis of the world-class Java Hotspot VM that later went on to develop V8, are now leading the development on the Dart VM.<p>The excellence shows itself in the consistency and minimalism goals in the language, providing a productive, iterative dynamic language experience for fast prototyping with the benefit of <em>static</em> <em>analysis</em> with optional typing when scaling up to a maintainable, well-documented code-base (best of both worlds).<p>Not only is Dart a productive dynamic language, it also has excellent performance, the best performance of all languages I benchmarked with a port of Peter Norvig's Sudoku solver: <a href=\"https://github.com/dartist/sudoku_solver#benchmarks\" rel=\"nofollow\">https://github.com/dartist/sudoku_solver#benchmarks</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dart 1.5",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://news.dartlang.org/2014/06/dart-15-makes-it-easier-to-develop-for.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-02T17:16:19.000Z",
      "title": null,
      "url": null,
      "author": "krg",
      "points": 1,
      "story_text": null,
      "comment_text": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;</a><p>Here&#x27;s the job:<p>TechEmpower, a small custom software development firm located in El Segundo, seeks developers with good object-oriented experience, preferably in Java, JavaScript, Python, and&#x2F;or Ruby. We specialize in web application development but look for well-rounded application developers. If you are a solid programmer and a team player, this is an opportunity for you. Even if you don&#x27;t have experience with everything listed in this ad, we offer excellent learning opportunities for those who are eager to expand their skill sets. Job Responsibilities<p>Working in small development teams, programmers participate in the architecture, design, and implementation of primarily Java, JavaScript, Python, C#, Ruby, and PHP code to meet client requirements for robust, high-performance, and secure sites and applications. Developers get exposure to several client projects and a variety of technologies over time. Job Qualifications<p>In addition to overall programming capability, candidates must have experience working on collaborative development teams and very strong communication skills. While we employ and enjoy the company of extroverts and introverts alike, we reiterate that the ability to communicate clearly is a must-have for our technical staff. That means writing professional e-mails and interpreting the nuances of clients&#x27; requirements by asking good questions, for example.<p>We work hard to estimate projects accurately so that schedules are reasonable and developers work a normal amount of hours per week. We rely on developers to contribute to those estimates and provide feedback as a project goes along to keep things on track.<p>Ideal candidates will have experience building all facets of software systems including the data model, business logic, and front-end. 3+ years of object-oriented design and development in Java, JavaScript, Python, or Ruby is desired. On the front-end, HTML 5 and CSS experience is required.<p>Knowledge of some or all of the following specific tools and technologies is a plus:<p><pre><code>    Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n    Tools: Continuous Integration (Jenkins, Hudson, etc.), static code analysis (Sonar, etc.), Eclipse, IntelliJ, Ant, Maven\\n    Web: vert.x, Play, Spring, Django, Rails, node.js, JSP, Servlets, jQuery, etc.\\n    Mobile: iOS, Android, PhoneGap, jQuery Mobile or similar\\n    Hosting: AWS (EC2, RDS, etc.), cloud servers, Linux configuration, application servers (Resin, etc.)\\n    Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, Oracle, NoSQL (CouchDB, MongoDB, Cassandra, etc.) \\n</code></pre>\\nWe like technical people who are not afraid to have strong opinions about technology but simultaneously keep an open mind and are flexible enough to work with whatever technology the task at hand requires.<p>That said, we&#x27;re mostly looking for great developers who are great to work with. If you don&#x27;t have experience with everything listed above (and who does?) but are still a solid developer eager to learn new things, you might be a great fit here.<p>Please apply here: <a href=\"http://jobs.techempower.com/hn\" rel=\"nofollow\">http:&#x2F;&#x2F;jobs.techempower.com&#x2F;hn</a>",
      "num_comments": null,
      "story_id": 7829042,
      "story_title": "Ask HN: Who is hiring? (June 2014)",
      "story_url": "",
      "parent_id": 7829042,
      "created_at_i": 1401729379,
      "_tags": [
        "comment",
        "author_krg",
        "story_7829042"
      ],
      "objectID": "7834572",
      "_highlightResult": {
        "author": {
          "value": "krg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http://www.techempower.com/benchmarks/</a><p>Here's the job:<p>TechEmpower, a small custom software development firm located in El Segundo, seeks developers with good object-oriented experience, preferably in Java, JavaScript, Python, and/or Ruby. We specialize in web application development but look for well-rounded application developers. If you are a solid programmer and a team player, this is an opportunity for you. Even if you don't have experience with everything listed in this ad, we offer excellent learning opportunities for those who are eager to expand their skill sets. Job Responsibilities<p>Working in small development teams, programmers participate in the architecture, design, and implementation of primarily Java, JavaScript, Python, C#, Ruby, and PHP code to meet client requirements for robust, high-performance, and secure sites and applications. Developers get exposure to several client projects and a variety of technologies over time. Job Qualifications<p>In addition to overall programming capability, candidates must have experience working on collaborative development teams and very strong communication skills. While we employ and enjoy the company of extroverts and introverts alike, we reiterate that the ability to communicate clearly is a must-have for our technical staff. That means writing professional e-mails and interpreting the nuances of clients' requirements by asking good questions, for example.<p>We work hard to estimate projects accurately so that schedules are reasonable and developers work a normal amount of hours per week. We rely on developers to contribute to those estimates and provide feedback as a project goes along to keep things on track.<p>Ideal candidates will have experience building all facets of software systems including the data model, business logic, and front-end. 3+ years of object-oriented design and development in Java, JavaScript, Python, or Ruby is desired. On the front-end, HTML 5 and CSS experience is required.<p>Knowledge of some or all of the following specific <em>tools</em> and technologies is a plus:<p><pre><code>    Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n    <em>Tools</em>: Continuous Integration (Jenkins, Hudson, etc.), <em>static</em> code <em>analysis</em> (Sonar, etc.), Eclipse, IntelliJ, Ant, Maven\\n    Web: vert.x, Play, Spring, Django, Rails, node.js, JSP, Servlets, jQuery, etc.\\n    Mobile: iOS, Android, PhoneGap, jQuery Mobile or similar\\n    Hosting: AWS (EC2, RDS, etc.), cloud servers, Linux configuration, application servers (Resin, etc.)\\n    Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, Oracle, NoSQL (CouchDB, MongoDB, Cassandra, etc.) \\n</code></pre>\\nWe like technical people who are not afraid to have strong opinions about technology but simultaneously keep an open mind and are flexible enough to work with whatever technology the task at hand requires.<p>That said, we're mostly looking for great developers who are great to work with. If you don't have experience with everything listed above (and who does?) but are still a solid developer eager to learn new things, you might be a great fit here.<p>Please apply here: <a href=\"http://jobs.techempower.com/hn\" rel=\"nofollow\">http://jobs.techempower.com/hn</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (June 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-05-01T13:24:48.000Z",
      "title": null,
      "url": null,
      "author": "krg",
      "points": 1,
      "story_text": null,
      "comment_text": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;</a> (Look for Round 9 to be published later today!)<p>Here&#x27;s the job:<p>TechEmpower, a small custom software development firm located in El Segundo, seeks developers with good object-oriented experience, preferably in Java, JavaScript, Python, and&#x2F;or Ruby. We specialize in web application development but look for well-rounded application developers. If you are a solid programmer and a team player, this is an opportunity for you. Even if you don&#x27;t have experience with everything listed in this ad, we offer excellent learning opportunities for those who are eager to expand their skill sets. Job Responsibilities<p>Working in small development teams, programmers participate in the architecture, design, and implementation of primarily Java, JavaScript, Python, C#, Ruby, and PHP code to meet client requirements for robust, high-performance, and secure sites and applications. Developers get exposure to several client projects and a variety of technologies over time. Job Qualifications<p>In addition to overall programming capability, candidates must have experience working on collaborative development teams and very strong communication skills. While we employ and enjoy the company of extroverts and introverts alike, we reiterate that the ability to communicate clearly is a must-have for our technical staff. That means writing professional e-mails and interpreting the nuances of clients&#x27; requirements by asking good questions, for example.<p>We work hard to estimate projects accurately so that schedules are reasonable and developers work a normal amount of hours per week. We rely on developers to contribute to those estimates and provide feedback as a project goes along to keep things on track.<p>Ideal candidates will have experience building all facets of software systems including the data model, business logic, and front-end. 3+ years of object-oriented design and development in Java, JavaScript, Python, or Ruby is desired. On the front-end, HTML 5 and CSS experience is required.<p>Knowledge of some or all of the following specific tools and technologies is a plus:<p><pre><code>    Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n    Tools: Continuous Integration (Jenkins, Hudson, etc.), static code analysis (Sonar, etc.), Eclipse, IntelliJ, Ant, Maven\\n    Web: vert.x, Play, Spring, Django, Rails, node.js, JSP, Servlets, jQuery, etc.\\n    Mobile: iOS, Android, PhoneGap, jQuery Mobile or similar\\n    Hosting: AWS (EC2, RDS, etc.), cloud servers, Linux configuration, application servers (Resin, etc.)\\n    Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, Oracle, NoSQL (CouchDB, MongoDB, Cassandra, etc.) \\n</code></pre>\\nWe like technical people who are not afraid to have strong opinions about technology but simultaneously keep an open mind and are flexible enough to work with whatever technology the task at hand requires.<p>That said, we&#x27;re mostly looking for great developers who are great to work with. If you don&#x27;t have experience with everything listed above (and who does?) but are still a solid developer eager to learn new things, you might be a great fit here.<p>Please apply here: <a href=\"http://jobs.techempower.com/hn\" rel=\"nofollow\">http:&#x2F;&#x2F;jobs.techempower.com&#x2F;hn</a>",
      "num_comments": null,
      "story_id": 7679431,
      "story_title": "Ask HN: Who is hiring? (May 2014)",
      "story_url": "",
      "parent_id": 7679431,
      "created_at_i": 1398950688,
      "_tags": [
        "comment",
        "author_krg",
        "story_7679431"
      ],
      "objectID": "7679541",
      "_highlightResult": {
        "author": {
          "value": "krg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TechEmpower - Los Angeles area, California (El Segundo, near LAX)<p>You may recognize us from the Web Framework Benchmarks that have been discussed on HN periodically: <a href=\"http://www.techempower.com/benchmarks/\" rel=\"nofollow\">http://www.techempower.com/benchmarks/</a> (Look for Round 9 to be published later today!)<p>Here's the job:<p>TechEmpower, a small custom software development firm located in El Segundo, seeks developers with good object-oriented experience, preferably in Java, JavaScript, Python, and/or Ruby. We specialize in web application development but look for well-rounded application developers. If you are a solid programmer and a team player, this is an opportunity for you. Even if you don't have experience with everything listed in this ad, we offer excellent learning opportunities for those who are eager to expand their skill sets. Job Responsibilities<p>Working in small development teams, programmers participate in the architecture, design, and implementation of primarily Java, JavaScript, Python, C#, Ruby, and PHP code to meet client requirements for robust, high-performance, and secure sites and applications. Developers get exposure to several client projects and a variety of technologies over time. Job Qualifications<p>In addition to overall programming capability, candidates must have experience working on collaborative development teams and very strong communication skills. While we employ and enjoy the company of extroverts and introverts alike, we reiterate that the ability to communicate clearly is a must-have for our technical staff. That means writing professional e-mails and interpreting the nuances of clients' requirements by asking good questions, for example.<p>We work hard to estimate projects accurately so that schedules are reasonable and developers work a normal amount of hours per week. We rely on developers to contribute to those estimates and provide feedback as a project goes along to keep things on track.<p>Ideal candidates will have experience building all facets of software systems including the data model, business logic, and front-end. 3+ years of object-oriented design and development in Java, JavaScript, Python, or Ruby is desired. On the front-end, HTML 5 and CSS experience is required.<p>Knowledge of some or all of the following specific <em>tools</em> and technologies is a plus:<p><pre><code>    Languages: Java, JavaScript, Python, C#, Ruby, PHP\\n    <em>Tools</em>: Continuous Integration (Jenkins, Hudson, etc.), <em>static</em> code <em>analysis</em> (Sonar, etc.), Eclipse, IntelliJ, Ant, Maven\\n    Web: vert.x, Play, Spring, Django, Rails, node.js, JSP, Servlets, jQuery, etc.\\n    Mobile: iOS, Android, PhoneGap, jQuery Mobile or similar\\n    Hosting: AWS (EC2, RDS, etc.), cloud servers, Linux configuration, application servers (Resin, etc.)\\n    Data Persistence: ORM (Hibernate, etc.), MySQL, Postgres, MS SQL Server, Oracle, NoSQL (CouchDB, MongoDB, Cassandra, etc.) \\n</code></pre>\\nWe like technical people who are not afraid to have strong opinions about technology but simultaneously keep an open mind and are flexible enough to work with whatever technology the task at hand requires.<p>That said, we're mostly looking for great developers who are great to work with. If you don't have experience with everything listed above (and who does?) but are still a solid developer eager to learn new things, you might be a great fit here.<p>Please apply here: <a href=\"http://jobs.techempower.com/hn\" rel=\"nofollow\">http://jobs.techempower.com/hn</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (May 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-29T18:50:27.000Z",
      "title": null,
      "url": null,
      "author": "taeric",
      "points": 1,
      "story_text": null,
      "comment_text": "I&#x27;m not sure how that even follows from what I wrote.<p>Note, I am all for extensive static analysis.  To the point that I am excited about such tools as Coverity and friends.<p>I am beginning to take exception to requiring ever more from the programmer.  To the point that a programmer can&#x27;t &quot;in practice&quot; specify a program correctly without a type checker.  (Which... is what the parent post says.  Right?)<p>I would much rather have it such that &quot;in practice&quot; we can specify programs without help.  Since that implies that we can &quot;in practice&quot; read and reason about programs without extensive help, as well.",
      "num_comments": null,
      "story_id": 7654601,
      "story_title": "“Mostly functional” programming does not work",
      "story_url": "http://queue.acm.org/detail.cfm?ref=rss&id=2611829",
      "parent_id": 7668895,
      "created_at_i": 1398797427,
      "_tags": [
        "comment",
        "author_taeric",
        "story_7654601"
      ],
      "objectID": "7669157",
      "_highlightResult": {
        "author": {
          "value": "taeric",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm not sure how that even follows from what I wrote.<p>Note, I am all for extensive <em>static</em> <em>analysis.</em>  To the point that I am excited about such <em>tools</em> as Coverity and friends.<p>I am beginning to take exception to requiring ever more from the programmer.  To the point that a programmer can't &quot;in practice&quot; specify a program correctly without a type checker.  (Which... is what the parent post says.  Right?)<p>I would much rather have it such that &quot;in practice&quot; we can specify programs without help.  Since that implies that we can &quot;in practice&quot; read and reason about programs without extensive help, as well.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "“Mostly functional” programming does not work",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://queue.acm.org/detail.cfm?ref=rss&id=2611829",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-29T11:30:23.000Z",
      "title": null,
      "url": null,
      "author": "toolslive",
      "points": 1,
      "story_text": null,
      "comment_text": "Some compilers (MLton, fe) have static analysis in place to skip the check when no overflow can occur.",
      "num_comments": null,
      "story_id": 7665254,
      "story_title": "How Should You Write a Fast Integer Overflow Check?",
      "story_url": "http://blog.regehr.org/archives/1139",
      "parent_id": 7665254,
      "created_at_i": 1398771023,
      "_tags": [
        "comment",
        "author_toolslive",
        "story_7665254"
      ],
      "objectID": "7666240",
      "_highlightResult": {
        "author": {
          "value": "<em>tools</em>live",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "comment_text": {
          "value": "Some compilers (MLton, fe) have <em>static</em> <em>analysis</em> in place to skip the check when no overflow can occur.",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_title": {
          "value": "How Should You Write a Fast Integer Overflow Check?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.regehr.org/archives/1139",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-16T19:48:01.000Z",
      "title": null,
      "url": null,
      "author": "byuu",
      "points": 1,
      "story_text": null,
      "comment_text": "No, I&#x27;m more claiming that there&#x27;s too much eagerness to blame ones tools. And that&#x27;s very dangerous to me, because they blunt my tools in the name of safety.<p>So you have these advocates coming in, saying we should stop using goto, stop using pointers, stop allowing implicit type conversion, not allow return statements anywhere but the end of the function, rely only on garbage collection, and so on. I end up needing to jump through hoops in order to safeguard an amateur that doesn&#x27;t know what he&#x27;s doing.<p>This Apple bug was a failure on many levels. This was one of the most beginner-level bugs imaginable, on one of the most important libraries imaginable. Where was the programmer accountability? Where was the internal review process for this change? Where was the static code analysis to catch this block of unreachable code? Where was the security auditing suite to make sure the library was functioning as intended? Where was the corporate accountability? Blaming the tool for being sharp, to me, sounds like passing the blame entirely.<p>The {} enforcement is, solely by itself, very benign. It doesn&#x27;t remove any language functionality or expressiveness, and it&#x27;s a good thing to do anyway. Aside from requiring us to go back and patch up decades of old code, it&#x27;s in a very rare category of <i>easy</i> wins. From it, you could easily say the same about always explicitly casting everything, so that there are no surprises. And put all your literals on the left-hand side, in case someone forgets an extra =.<p>if(!x) a = b * c + d;<p>if(0u == x) {\\n  a = reinterpret_cast&lt;int&gt;(b) * c + reinterpret_cast&lt;int&gt;(d);\\n}<p>The code does exactly the same thing, yet the latter is going to have a real toll on code readability. My 1080p monitor is going to see a few less lines of code at once. I&#x27;m going to have to scroll a bit more. I&#x27;ll have to filter out a few casts, flip a few compares in my head. But it adds up.<p>Yet what I&#x27;m most afraid of, is that I&#x27;m very hard-pressed to think of safety changes to C that won&#x27;t remove any functionality, aside from the aforementioned. In fact, I start seeing odd things creep up, like Clang warning when switching on a boolean value. It apparently catches some odd mistake some guy made at some point. It was thought that nobody would ever switch on a boolean. Except that I did. (see my post history here if you want details on that.) I&#x27;m getting a bit tired of being grouped in with programmers like the goto fail guy. Sure I&#x27;m not perfect, but I&#x27;m also not making these kinds of trivial mistakes. I am not eager to go through hundreds of thousands of lines of code to add these changes.",
      "num_comments": null,
      "story_id": 7598721,
      "story_title": "Those Who Say Code Does Not Matter",
      "story_url": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
      "parent_id": 7599598,
      "created_at_i": 1397677681,
      "_tags": [
        "comment",
        "author_byuu",
        "story_7598721"
      ],
      "objectID": "7600105",
      "_highlightResult": {
        "author": {
          "value": "byuu",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "No, I'm more claiming that there's too much eagerness to blame ones <em>tools</em>. And that's very dangerous to me, because they blunt my <em>tools</em> in the name of safety.<p>So you have these advocates coming in, saying we should stop using goto, stop using pointers, stop allowing implicit type conversion, not allow return statements anywhere but the end of the function, rely only on garbage collection, and so on. I end up needing to jump through hoops in order to safeguard an amateur that doesn't know what he's doing.<p>This Apple bug was a failure on many levels. This was one of the most beginner-level bugs imaginable, on one of the most important libraries imaginable. Where was the programmer accountability? Where was the internal review process for this change? Where was the <em>static</em> code <em>analysis</em> to catch this block of unreachable code? Where was the security auditing suite to make sure the library was functioning as intended? Where was the corporate accountability? Blaming the tool for being sharp, to me, sounds like passing the blame entirely.<p>The {} enforcement is, solely by itself, very benign. It doesn't remove any language functionality or expressiveness, and it's a good thing to do anyway. Aside from requiring us to go back and patch up decades of old code, it's in a very rare category of <i>easy</i> wins. From it, you could easily say the same about always explicitly casting everything, so that there are no surprises. And put all your literals on the left-hand side, in case someone forgets an extra =.<p>if(!x) a = b * c + d;<p>if(0u == x) {\\n  a = reinterpret_cast&lt;int&gt;(b) * c + reinterpret_cast&lt;int&gt;(d);\\n}<p>The code does exactly the same thing, yet the latter is going to have a real toll on code readability. My 1080p monitor is going to see a few less lines of code at once. I'm going to have to scroll a bit more. I'll have to filter out a few casts, flip a few compares in my head. But it adds up.<p>Yet what I'm most afraid of, is that I'm very hard-pressed to think of safety changes to C that won't remove any functionality, aside from the aforementioned. In fact, I start seeing odd things creep up, like Clang warning when switching on a boolean value. It apparently catches some odd mistake some guy made at some point. It was thought that nobody would ever switch on a boolean. Except that I did. (see my post history here if you want details on that.) I'm getting a bit tired of being grouped in with programmers like the goto fail guy. Sure I'm not perfect, but I'm also not making these kinds of trivial mistakes. I am not eager to go through hundreds of thousands of lines of code to add these changes.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Those Who Say Code Does Not Matter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cacm.acm.org/blogs/blog-cacm/173827-those-who-say-code-does-not-matter/fulltext",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-03-29T15:43:20.000Z",
      "title": null,
      "url": null,
      "author": "Edmond",
      "points": 1,
      "story_text": null,
      "comment_text": "Not sure about the overall proposal but static code analysis and code completion as a service is something I have been wishing for.<p>But that is only for a selfish reason, it would save me from having to do the work for my own IDE HiveMind (crudzilla.com) :)<p>*Perhaps this is something the Eclipse project should undertake, decouple the JDT from the Eclipse IDE so that it can be used by other developer front-end tools.",
      "num_comments": null,
      "story_id": 7492375,
      "story_title": "Crowd-sourced Eclipse Autocompletion",
      "story_url": "http://de.slideshare.net/Microbiotic/being-amazon-for-software-developers-ide-20-crowdsourcing-mal-anders-javaland-2014",
      "parent_id": 7492375,
      "created_at_i": 1396107800,
      "_tags": [
        "comment",
        "author_Edmond",
        "story_7492375"
      ],
      "objectID": "7492574",
      "_highlightResult": {
        "author": {
          "value": "Edmond",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Not sure about the overall proposal but <em>static</em> code <em>analysis</em> and code completion as a service is something I have been wishing for.<p>But that is only for a selfish reason, it would save me from having to do the work for my own IDE HiveMind (crudzilla.com) :)<p>*Perhaps this is something the Eclipse project should undertake, decouple the JDT from the Eclipse IDE so that it can be used by other developer front-end <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Crowd-sourced Eclipse Autocompletion",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://de.slideshare.net/Microbiotic/being-amazon-for-software-developers-ide-20-crowdsourcing-mal-anders-javaland-2014",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-27T19:49:52.000Z",
      "title": null,
      "url": null,
      "author": "ampersandy",
      "points": 1,
      "story_text": null,
      "comment_text": "I&#x27;d prefer static analysis that extracts strings from calls like t(&quot;Check out our Jobs page {{url}}!&quot;) and auto-populates the appropriate locale files&#x2F;databases, etc. Referencing keys all over the place seems like a poor substitute to just writing the content in a natural way and having the tools do the heavy lifting for you. For instance, I know that Twitter and Facebook both handle I18N content in such a way, and you can see the text-strings that they use in the translation dashboards.<p>There&#x27;s also a good technical overview of Facebook&#x27;s I18N framework here: <a href=\"https://www.quora.com/Facebook-Internationalization/What-was-the-process-Facebook-went-about-getting-their-website-translated-into-different-languages\" rel=\"nofollow\">https:&#x2F;&#x2F;www.quora.com&#x2F;Facebook-Internationalization&#x2F;What-was...</a> .",
      "num_comments": null,
      "story_id": 7312390,
      "story_title": "Internationalization made easier with static analysis",
      "story_url": "http://blog.glebm.com/2014/02/27/i18n-made-easier-with-static-analysis.html",
      "parent_id": 7312390,
      "created_at_i": 1393530592,
      "_tags": [
        "comment",
        "author_ampersandy",
        "story_7312390"
      ],
      "objectID": "7314520",
      "_highlightResult": {
        "author": {
          "value": "ampersandy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'd prefer <em>static</em> <em>analysis</em> that extracts strings from calls like t(&quot;Check out our Jobs page {{url}}!&quot;) and auto-populates the appropriate locale files/databases, etc. Referencing keys all over the place seems like a poor substitute to just writing the content in a natural way and having the <em>tools</em> do the heavy lifting for you. For instance, I know that Twitter and Facebook both handle I18N content in such a way, and you can see the text-strings that they use in the translation dashboards.<p>There's also a good technical overview of Facebook's I18N framework here: <a href=\"https://www.quora.com/Facebook-Internationalization/What-was-the-process-Facebook-went-about-getting-their-website-translated-into-different-languages\" rel=\"nofollow\">https://www.quora.com/Facebook-Internationalization/What-was...</a> .",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Internationalization made easier with <em>static</em> <em>analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://blog.glebm.com/2014/02/27/i18n-made-easier-with-<em>static</em>-<em>analysis</em>.html",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2014-02-24T06:37:34.000Z",
      "title": null,
      "url": null,
      "author": "kplaxmaster",
      "points": 1,
      "story_text": null,
      "comment_text": "Haha love the whitespace comment.  This also makes you think of the static source-code analysis done at Apple.  Surely static tools would have picked this up, no...?",
      "num_comments": null,
      "story_id": 7279261,
      "story_title": "About the security content of iOS 7.0.6",
      "story_url": "http://support.apple.com/kb/HT6147",
      "parent_id": 7286848,
      "created_at_i": 1393223854,
      "_tags": [
        "comment",
        "author_kplaxmaster",
        "story_7279261"
      ],
      "objectID": "7289405",
      "_highlightResult": {
        "author": {
          "value": "kplaxmaster",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Haha love the whitespace comment.  This also makes you think of the <em>static</em> source-code <em>analysis</em> done at Apple.  Surely <em>static</em> <em>tools</em> would have picked this up, no...?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "About the security content of iOS 7.0.6",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://support.apple.com/kb/HT6147",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-27T01:25:59.000Z",
      "title": null,
      "url": null,
      "author": "rm82",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt;I think that&#x27;s a broad mischaraterization of functional programming<p>Yes, but it&#x27;s a common one, because its a correct characterization of Haskell and Haskell-derived languages. Functional programming is very popular and used all the time. Consider jQuery, SQL or LINQ. Consider things like Facebook&#x27;s react library. Functional programming is a very usefull tool, in a much larger toolset.<p>But it has a bad reputation by being associated with the language design mess that is Haskell. And here we have a derived language, making it even worse. The problem is not the functional nature of the language. It&#x27;s the syntax rooted in ancient (paper) math combined with lazy evalution, and the illusions perpetuated by their followers.<p>To illustrate just how far anti-human this Haskell dialect is: <i></i>it uses greek symbols!<i></i>. This alone excludes 99.99% of the world population. The majority of the world population will not be able to even phrase the question &quot;what does that symbol mean&quot; without pointing to a screenshot. We don&#x27;t calculate the speed of a space rocket using horse power, and we shouldn&#x27;t encourage anyone introducing greek symbols into a programming language that is intented to me more than esoteric.<p>Haskell and haskell derived languages are and will continue to fail to become mainstream, because:<p>- <i></i>they were not designed with that goal in mind<i></i> (actual statements of the language designers)<p>- <i></i>the syntax isn&#x27;t optimized to limit the cognitive load of actual real world use-cases.<i></i> Instead, it&#x27;s optimized to make a fibonacci function look as much like ancient math as possible. Has anyone ever been paid to code that function? No. Is this function particularly difficult to implement in other languages? No.<p>- <i></i>they pretend computers don&#x27;t exist<i></i>. Haskell implementations have operational semantics: they are just under-specified, unpredictable and implementation-specific.  Performance and scalablility don&#x27;t need to be good; they need to be predictable by a human. The algorithmic complexitiy of any operation, should not became a secret hidden behind a curtain of mystery.<p>- <i></i>it fails the main challange of large scale software development: coordination state mutations<i></i> We need standardisation and normalisation of state. Yet by making all state explicit arguments, and being all religious about it, you end with a zillion competing ways to structure and reflect on the state. Knee-deep in monad transformers that convert one type of state to some other type of state, one has to wonder: is it so bad that most programming languages just wrap every computation is one standarized state-monad? No! That&#x27;s actually a good thing. Let&#x27;s not pretend that encapsulation of state, can only be done functionally.<p>- The cult surrounding it keeps propagating misconceptions about the nature of computation itself. Take your comment for example:<p>&gt;Ultimately, functional programming lets you talk about what where imperative languages force you to talk about how.<p>This not true. Functional programming does not let you talk about the what. Haskell definately doesn&#x27;t let you just talk about the what. If i put &quot;e = m * c&quot; into haskell, i won&#x27;t suddenly get m, given an e. Just because the operational semantics of Haskell are under-specified and incomprehensible by anyone without an academic background, doesn&#x27;t mean there is no operational semantics. <i></i>At it&#x27;s core, it&#x27;s just a term rewriter with a lot of fine print, that nobody bothered to properly document, and which is far from intuitive.<i></i><p>&gt;even concepts like mutable variables and loops are not particularity intuitive.<p>Correct. But combined with term rewriting, dataflow and logic programming, and a bunch of other paradigms the best tools we&#x27;ve got to deal with a wide scenario of our real world use-cases.<p>Functional programming is doing fine. Static type analysis is a great tool and many use it often, but few if any are using it exclusively, because it is the enemy of exploration: A run-time type error, is one that carries real example data!<p><i></i>But lazy evaluation, underspecified and unpredictable operational semantics, and foreign alphabets means that the the average can&#x27;t even verbalize the question you guys don&#x27;t the answer to.<i></i>",
      "num_comments": null,
      "story_id": 6964369,
      "story_title": "Lamdu - towards the next generation IDE",
      "story_url": "http://peaker.github.io/lamdu/",
      "created_at_i": 1388107559,
      "_tags": [
        "comment",
        "author_rm82",
        "story_6964369"
      ],
      "objectID": "6968965",
      "_highlightResult": {
        "author": {
          "value": "rm82",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;I think that's a broad mischaraterization of functional programming<p>Yes, but it's a common one, because its a correct characterization of Haskell and Haskell-derived languages. Functional programming is very popular and used all the time. Consider jQuery, SQL or LINQ. Consider things like Facebook's react library. Functional programming is a very usefull tool, in a much larger <em>tools</em>et.<p>But it has a bad reputation by being associated with the language design mess that is Haskell. And here we have a derived language, making it even worse. The problem is not the functional nature of the language. It's the syntax rooted in ancient (paper) math combined with lazy evalution, and the illusions perpetuated by their followers.<p>To illustrate just how far anti-human this Haskell dialect is: <i></i>it uses greek symbols!<i></i>. This alone excludes 99.99% of the world population. The majority of the world population will not be able to even phrase the question &quot;what does that symbol mean&quot; without pointing to a screenshot. We don't calculate the speed of a space rocket using horse power, and we shouldn't encourage anyone introducing greek symbols into a programming language that is intented to me more than esoteric.<p>Haskell and haskell derived languages are and will continue to fail to become mainstream, because:<p>- <i></i>they were not designed with that goal in mind<i></i> (actual statements of the language designers)<p>- <i></i>the syntax isn't optimized to limit the cognitive load of actual real world use-cases.<i></i> Instead, it's optimized to make a fibonacci function look as much like ancient math as possible. Has anyone ever been paid to code that function? No. Is this function particularly difficult to implement in other languages? No.<p>- <i></i>they pretend computers don't exist<i></i>. Haskell implementations have operational semantics: they are just under-specified, unpredictable and implementation-specific.  Performance and scalablility don't need to be good; they need to be predictable by a human. The algorithmic complexitiy of any operation, should not became a secret hidden behind a curtain of mystery.<p>- <i></i>it fails the main challange of large scale software development: coordination state mutations<i></i> We need standardisation and normalisation of state. Yet by making all state explicit arguments, and being all religious about it, you end with a zillion competing ways to structure and reflect on the state. Knee-deep in monad transformers that convert one type of state to some other type of state, one has to wonder: is it so bad that most programming languages just wrap every computation is one standarized state-monad? No! That's actually a good thing. Let's not pretend that encapsulation of state, can only be done functionally.<p>- The cult surrounding it keeps propagating misconceptions about the nature of computation itself. Take your comment for example:<p>&gt;Ultimately, functional programming lets you talk about what where imperative languages force you to talk about how.<p>This not true. Functional programming does not let you talk about the what. Haskell definately doesn't let you just talk about the what. If i put &quot;e = m * c&quot; into haskell, i won't suddenly get m, given an e. Just because the operational semantics of Haskell are under-specified and incomprehensible by anyone without an academic background, doesn't mean there is no operational semantics. <i></i>At it's core, it's just a term rewriter with a lot of fine print, that nobody bothered to properly document, and which is far from intuitive.<i></i><p>&gt;even concepts like mutable variables and loops are not particularity intuitive.<p>Correct. But combined with term rewriting, dataflow and logic programming, and a bunch of other paradigms the best <em>tools</em> we've got to deal with a wide scenario of our real world use-cases.<p>Functional programming is doing fine. <em>Static</em> type <em>analysis</em> is a great tool and many use it often, but few if any are using it exclusively, because it is the enemy of exploration: A run-time type error, is one that carries real example data!<p><i></i>But lazy evaluation, underspecified and unpredictable operational semantics, and foreign alphabets means that the the average can't even verbalize the question you guys don't the answer to.<i></i>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lamdu - towards the next generation IDE",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://peaker.github.io/lamdu/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-27T01:07:40.000Z",
      "title": null,
      "url": null,
      "author": "rm82",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt;I think that&#x27;s a broad mischaraterization of functional programming<p>Yes, but it&#x27;s a common one, because its a correct characterization of Haskell and Haskell-derived languages.<p>Functional programming is very popular and used all the time. Consider jQuery, SQL or LINQ. Consider things like Facebook&#x27;s react library. Functional programming is a very usefull tool, in a much larger toolset.<p>But it has a bad reputation by being associated with the language design mess that is Haskell. And here we have a derived language, making it even worse.<p>The problem is not the functional nature of the language. It&#x27;s the syntax rooted in ancient (paper) math combined with lazy evalution, and the illusions perpetuated by their followers.<p>To illustrate just how far anti-human this Haskell dialect is: _it uses greek symbols_. This alone excludes 99.99% of the world population.<p>Yet, the language designer&#x27;s intent is for this to &#x27;cure programming&#x27;. To improve things. Yes, what computer science needs is more symbols, that aren&#x27;t even on our keyboards. Symbols a majority of the world doesn&#x27;t even know how to pronounce.<p>To ask the question &quot;what does that lambda symbol mean?&quot; one would have to make a screenshot and mark it. A new student having to learn the language, lacks both the ability to verbalize, as well as type, the symbol. How out of reach with reality can one be to suggest this would ever become mainstream?<p>It was mainstream. 2500 years ago. We don&#x27;t calculate the speed of a space rocket using horse power, and we shouldn&#x27;t encourage anyone introducing greek symbols into a programming language that is intented to me more than esoteric.<p>I&#x27;m often baffled why this is not more appearant to everyone. Haskell and haskell derived languages are failing to become mainstream, because:<p>- they were not designed with that goal in mind (actual statements of the language designers)<p>- the syntax is only friendly to those humans that wasted their life, studying the variant of math syntax, that stopped having an economic value the moment computers were invented. The syntax isn&#x27;t optimized to limit the cognitive load of actual real world use-cases. Instead, it&#x27;s optimized to make a fibonacci function look as much like ancient math as possible. Has anyone ever beed paid to code that function? No. Is this function particularly difficult to implement in other languages? No.<p>- They pretend computers don&#x27;t exist. Haskell implementations have operational semantics: they are just under-specified, unpredictable and implementation-specific.  Pretending computers don&#x27;t exist, doesn&#x27;t solve any problem in computer science. Performance and scalablility don&#x27;t need to be good; they need to be predictable by a human. The algorithmic complexitiy of any operation, should not became a secret hidden behind a curtain of mystery.<p>- The core problem we have with large code-bases is coordination of state. This requires standardisation and normalisation.. By making all state explicit arguments, and being all religious about it, you end with a zillion competing ways to structure and reflect on the state. Knee-deep in monad transformers that convert one type of state to some other type of state, one has to wonder: is it so bad that most programming languages just wrap every computation is one standarized state-monad? No! That&#x27;s actually a good thing.<p>- The cult surrounding it keeps propagating misconceptions about the nature of computation itself. Take your comment for example:<p>&gt;Ultimately, functional programming lets you talk about what where imperative languages force you to talk about how.<p>This not true. Functional programming does not let you talk about the what. Haskell definately doesn&#x27;t let you just talk about the what. If i put &quot;e = m * c&quot; into haskell, i won&#x27;t suddenly get m, given an e. Just because the operational semantics of Haskell are under-specified and incomprehensible by anyone without an academic background and years of experience wasting time with Haskell, doesn&#x27;t mean there is no operational semantics. At it&#x27;s core, it&#x27;s just a term rewriter with a lot of fine print, that nobody bothered to properly document, and which is far from intuitive.<p>&gt;even concepts like mutable variables and loops are not particularity intuitive.<p>Correct. But combined with term rewriting, dataflow and logic programming, and a bunch of other paradigms the best tools we&#x27;ve got to deal with a wide scenario of use-cases.<p>Functional programming is doing fine. Static type analysis is a great tool and we all use it often, but not exclusively, because it is the enemy of exploration. (A run-time type error, is one that carries real example data!)<p>It&#x27;s just that a lazy evaluated language drenched in a syntax that had its peak a millenium ago, pushed by fanatic supporters combined with completely unrealistic notions of computation and real-world use-cases, isn&#x27;t contributing.<p>And this Haskell derivate, is even worse. It has an actual lambda symbol. Everything about it screams to the uninitiated: i don&#x27;t want to be understand. I am exclusive.<p>The notion we need more ancient math syntax in a modern programming language, is similar to the notion we need more Shakesperian acting in Breaking Bad. People have been using math to produce economic value. They are just using languages that are optimized for their cultural background (using the dictionary and alphabet of our times), their cognitive skills, modern technology (auto-complete, refactoring) and their actual use-cases. These languages are commonly referred to as &quot;mainstream programming languages&quot;.",
      "num_comments": null,
      "story_id": 6964369,
      "story_title": "Lamdu - towards the next generation IDE",
      "story_url": "http://peaker.github.io/lamdu/",
      "created_at_i": 1388106460,
      "_tags": [
        "comment",
        "author_rm82",
        "story_6964369"
      ],
      "objectID": "6968921",
      "_highlightResult": {
        "author": {
          "value": "rm82",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;I think that's a broad mischaraterization of functional programming<p>Yes, but it's a common one, because its a correct characterization of Haskell and Haskell-derived languages.<p>Functional programming is very popular and used all the time. Consider jQuery, SQL or LINQ. Consider things like Facebook's react library. Functional programming is a very usefull tool, in a much larger <em>tools</em>et.<p>But it has a bad reputation by being associated with the language design mess that is Haskell. And here we have a derived language, making it even worse.<p>The problem is not the functional nature of the language. It's the syntax rooted in ancient (paper) math combined with lazy evalution, and the illusions perpetuated by their followers.<p>To illustrate just how far anti-human this Haskell dialect is: _it uses greek symbols_. This alone excludes 99.99% of the world population.<p>Yet, the language designer's intent is for this to 'cure programming'. To improve things. Yes, what computer science needs is more symbols, that aren't even on our keyboards. Symbols a majority of the world doesn't even know how to pronounce.<p>To ask the question &quot;what does that lambda symbol mean?&quot; one would have to make a screenshot and mark it. A new student having to learn the language, lacks both the ability to verbalize, as well as type, the symbol. How out of reach with reality can one be to suggest this would ever become mainstream?<p>It was mainstream. 2500 years ago. We don't calculate the speed of a space rocket using horse power, and we shouldn't encourage anyone introducing greek symbols into a programming language that is intented to me more than esoteric.<p>I'm often baffled why this is not more appearant to everyone. Haskell and haskell derived languages are failing to become mainstream, because:<p>- they were not designed with that goal in mind (actual statements of the language designers)<p>- the syntax is only friendly to those humans that wasted their life, studying the variant of math syntax, that stopped having an economic value the moment computers were invented. The syntax isn't optimized to limit the cognitive load of actual real world use-cases. Instead, it's optimized to make a fibonacci function look as much like ancient math as possible. Has anyone ever beed paid to code that function? No. Is this function particularly difficult to implement in other languages? No.<p>- They pretend computers don't exist. Haskell implementations have operational semantics: they are just under-specified, unpredictable and implementation-specific.  Pretending computers don't exist, doesn't solve any problem in computer science. Performance and scalablility don't need to be good; they need to be predictable by a human. The algorithmic complexitiy of any operation, should not became a secret hidden behind a curtain of mystery.<p>- The core problem we have with large code-bases is coordination of state. This requires standardisation and normalisation.. By making all state explicit arguments, and being all religious about it, you end with a zillion competing ways to structure and reflect on the state. Knee-deep in monad transformers that convert one type of state to some other type of state, one has to wonder: is it so bad that most programming languages just wrap every computation is one standarized state-monad? No! That's actually a good thing.<p>- The cult surrounding it keeps propagating misconceptions about the nature of computation itself. Take your comment for example:<p>&gt;Ultimately, functional programming lets you talk about what where imperative languages force you to talk about how.<p>This not true. Functional programming does not let you talk about the what. Haskell definately doesn't let you just talk about the what. If i put &quot;e = m * c&quot; into haskell, i won't suddenly get m, given an e. Just because the operational semantics of Haskell are under-specified and incomprehensible by anyone without an academic background and years of experience wasting time with Haskell, doesn't mean there is no operational semantics. At it's core, it's just a term rewriter with a lot of fine print, that nobody bothered to properly document, and which is far from intuitive.<p>&gt;even concepts like mutable variables and loops are not particularity intuitive.<p>Correct. But combined with term rewriting, dataflow and logic programming, and a bunch of other paradigms the best <em>tools</em> we've got to deal with a wide scenario of use-cases.<p>Functional programming is doing fine. <em>Static</em> type <em>analysis</em> is a great tool and we all use it often, but not exclusively, because it is the enemy of exploration. (A run-time type error, is one that carries real example data!)<p>It's just that a lazy evaluated language drenched in a syntax that had its peak a millenium ago, pushed by fanatic supporters combined with completely unrealistic notions of computation and real-world use-cases, isn't contributing.<p>And this Haskell derivate, is even worse. It has an actual lambda symbol. Everything about it screams to the uninitiated: i don't want to be understand. I am exclusive.<p>The notion we need more ancient math syntax in a modern programming language, is similar to the notion we need more Shakesperian acting in Breaking Bad. People have been using math to produce economic value. They are just using languages that are optimized for their cultural background (using the dictionary and alphabet of our times), their cognitive skills, modern technology (auto-complete, refactoring) and their actual use-cases. These languages are commonly referred to as &quot;mainstream programming languages&quot;.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lamdu - towards the next generation IDE",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://peaker.github.io/lamdu/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-23T05:26:43.000Z",
      "title": null,
      "url": null,
      "author": "seanmcdirmid",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt; My point was that super fancy IDEs and plain old text editors alike could reuse the same tooling and not have to reimplement things like language parsing, analysis, and refactoring tooling.<p>Parsing and analysis are great examples: if you accept that batch is the best that can be done, they are completely reusable in lots of different contexts. As soon as you want something interactive, standardization and integration become much more tricky (I know directly from experience in writing interactive parsing and analysis tools).<p>&gt; Also if you refuse, on account of bias, to understand why people might find such a design (command-line application invoked from different programming environments to augment functionality) then you are damning yourself to be ignorant of how other people think and work.<p>My early 90s self completely agrees with you. My current self is much more interested in non-batch interactive tooling, the mainstream is also.<p>&gt; Maybe that&#x27;s not an ethos at Microsoft or MSR, but it is in the various open source communities I&#x27;ve been in.<p>Along with much of the OO PL community, please don&#x27;t forget (though we divide into static easy-to-tool languages and dynamic hard-to-tool languages).<p>&gt; You clearly have not used Emacs or any of the Haskell tooling I use.<p>I was a heavy emacs user in the 90s (from about 92 to 2003 or so). It was a fine text editor, I would have never called it an IDE though.<p>&gt; My Emacs environment of today would be utterly alien to myself-10-years-ago. Or even 3-5 years ago. Or even 2 years ago. A lot of evolution can happen when you&#x27;ve been improving the same tooling over and over for multiple decades.<p>Please educate me. How about your own workflow: does your emacs IDE provide code assist (I think Haskell Eclipse does right?), does it provide a nice debugger?<p>&gt; You should really try immersing yourself in how Emacs users work these days, you really have no idea at all.<p>I used Emacs for 10 years in the 90s, early 00s, I don&#x27;t miss it at all. Language-aware editing with code completion has been a huge win in PL and I don&#x27;t see us going back. But these kinds of tools are complicated and not as interoperable as the old text pipe-based batch tooling was in the past.",
      "num_comments": null,
      "story_id": 6942905,
      "story_title": "IDEas: Tools for Coders",
      "story_url": "http://omegaortega.com/ideas-tools-for-coders/",
      "parent_id": 6953124,
      "created_at_i": 1387776403,
      "_tags": [
        "comment",
        "author_seanmcdirmid",
        "story_6942905"
      ],
      "objectID": "6953202",
      "_highlightResult": {
        "author": {
          "value": "seanmcdirmid",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; My point was that super fancy IDEs and plain old text editors alike could reuse the same tooling and not have to reimplement things like language parsing, <em>analysis</em>, and refactoring tooling.<p>Parsing and <em>analysis</em> are great examples: if you accept that batch is the best that can be done, they are completely reusable in lots of different contexts. As soon as you want something interactive, standardization and integration become much more tricky (I know directly from experience in writing interactive parsing and <em>analysis</em> <em>tools</em>).<p>&gt; Also if you refuse, on account of bias, to understand why people might find such a design (command-line application invoked from different programming environments to augment functionality) then you are damning yourself to be ignorant of how other people think and work.<p>My early 90s self completely agrees with you. My current self is much more interested in non-batch interactive tooling, the mainstream is also.<p>&gt; Maybe that's not an ethos at Microsoft or MSR, but it is in the various open source communities I've been in.<p>Along with much of the OO PL community, please don't forget (though we divide into <em>static</em> easy-to-tool languages and dynamic hard-to-tool languages).<p>&gt; You clearly have not used Emacs or any of the Haskell tooling I use.<p>I was a heavy emacs user in the 90s (from about 92 to 2003 or so). It was a fine text editor, I would have never called it an IDE though.<p>&gt; My Emacs environment of today would be utterly alien to myself-10-years-ago. Or even 3-5 years ago. Or even 2 years ago. A lot of evolution can happen when you've been improving the same tooling over and over for multiple decades.<p>Please educate me. How about your own workflow: does your emacs IDE provide code assist (I think Haskell Eclipse does right?), does it provide a nice debugger?<p>&gt; You should really try immersing yourself in how Emacs users work these days, you really have no idea at all.<p>I used Emacs for 10 years in the 90s, early 00s, I don't miss it at all. Language-aware editing with code completion has been a huge win in PL and I don't see us going back. But these kinds of <em>tools</em> are complicated and not as interoperable as the old text pipe-based batch tooling was in the past.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "IDEas: <em>Tools</em> for Coders",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "http://omegaortega.com/ideas-<em>tools</em>-for-coders/",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        }
      }
    },
    {
      "created_at": "2013-11-26T09:09:29.000Z",
      "title": null,
      "url": null,
      "author": "aardvarkoffnord",
      "points": 1,
      "story_text": null,
      "comment_text": "Coming from a safety-critical background, I found this a very interesting read. I am a massive fan of static analysis, and I hadn&#x27;t realised that the open source tools had come this far.",
      "num_comments": null,
      "story_id": 6800033,
      "story_title": "Practical static analysis",
      "story_url": "http://vincentsanders.blogspot.co.uk/2013/11/error-analysis-is-sweet-spot-for.html",
      "parent_id": 6800033,
      "created_at_i": 1385456969,
      "_tags": [
        "comment",
        "author_aardvarkoffnord",
        "story_6800033"
      ],
      "objectID": "6800078",
      "_highlightResult": {
        "author": {
          "value": "aardvarkoffnord",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Coming from a safety-critical background, I found this a very interesting read. I am a massive fan of <em>static</em> <em>analysis</em>, and I hadn't realised that the open source <em>tools</em> had come this far.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Practical <em>static</em> <em>analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://vincentsanders.blogspot.co.uk/2013/11/error-<em>analysis</em>-is-sweet-spot-for.html",
          "matchLevel": "partial",
          "matchedWords": [
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2013-11-10T22:43:53.000Z",
      "title": "",
      "url": "",
      "author": "klibertp",
      "points": 1,
      "story_text": null,
      "comment_text": "I think it&#x27;s not &quot;fundamentally different&quot;. Type info is there in the code, it&#x27;s just much more implicit and requires much more work to extract and use. One thing which does just this is Jedi project (for python) and it&#x27;s absolutely astonishing how much data you can get out of it!<p>Also I think that dynamic languages were meant to run inside a dynamic environment. For example in Pharo Smalltalk (probably all Smalltalks) every single piece of metadata <i>is</i> runtime data. Static analysis has no sense, because in Pharo there is no &quot;static&quot; at all - everything happens inside a living environment and (for example) as soon as you write a method it&#x27;s turned into CompiledMethod object which has all the data about the method you would ever need for you to query easily. Good luck implementing better refactoring tools than those in Smalltalk for any other language.<p>Essentially the same approach is used in Emacs Lisp. For example, if you see a function you don&#x27;t recognize, you can jump to it&#x27;s definition. The thing here is that Emacs doesn&#x27;t know where the definition is because of static analysis - it just has this compiled chunk of code in memory which happens to have a name you&#x27;re looking for. This chunk of code knows a location of it&#x27;s definition and many other pieces of metadata which are all available on runtime. It of course doesn&#x27;t work if the function isn&#x27;t already loaded into Emacs.<p>Most statically typed languages retain almost no type data in runtime. Most dynamically typed languages have almost no type data on compile time. I see this as largely equivalent.<p>So I guess what I want to say is that there is no fundamental difference in what the dynamic and static languages are, but there is (and should be) a very fundamental difference in how they are used. Choosing the between the two is I think almost exclusively a matter of preference. A good programmer should feel comfortable with both, though.",
      "num_comments": null,
      "story_id": 6704679,
      "story_title": "Android: The Land That Python Forgot",
      "story_url": "https://speakerdeck.com/pyconca/android-the-land-that-python-forgot-christopher-neugebauer",
      "parent_id": 6707708,
      "created_at_i": 1384123433,
      "_tags": [
        "comment",
        "author_klibertp",
        "story_6704679"
      ],
      "objectID": "6708808",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "klibertp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I think it's not &quot;fundamentally different&quot;. Type info is there in the code, it's just much more implicit and requires much more work to extract and use. One thing which does just this is Jedi project (for python) and it's absolutely astonishing how much data you can get out of it!<p>Also I think that dynamic languages were meant to run inside a dynamic environment. For example in Pharo Smalltalk (probably all Smalltalks) every single piece of metadata <i>is</i> runtime data. <em>Static</em> <em>analysis</em> has no sense, because in Pharo there is no &quot;<em>static</em>&quot; at all - everything happens inside a living environment and (for example) as soon as you write a method it's turned into CompiledMethod object which has all the data about the method you would ever need for you to query easily. Good luck implementing better refactoring <em>tools</em> than those in Smalltalk for any other language.<p>Essentially the same approach is used in Emacs Lisp. For example, if you see a function you don't recognize, you can jump to it's definition. The thing here is that Emacs doesn't know where the definition is because of <em>static</em> <em>analysis</em> - it just has this compiled chunk of code in memory which happens to have a name you're looking for. This chunk of code knows a location of it's definition and many other pieces of metadata which are all available on runtime. It of course doesn't work if the function isn't already loaded into Emacs.<p>Most statically typed languages retain almost no type data in runtime. Most dynamically typed languages have almost no type data on compile time. I see this as largely equivalent.<p>So I guess what I want to say is that there is no fundamental difference in what the dynamic and <em>static</em> languages are, but there is (and should be) a very fundamental difference in how they are used. Choosing the between the two is I think almost exclusively a matter of preference. A good programmer should feel comfortable with both, though.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Android: The Land That Python Forgot",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://speakerdeck.com/pyconca/android-the-land-that-python-forgot-christopher-neugebauer",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-11-10T22:11:32.000Z",
      "title": "",
      "url": "",
      "author": "jsmeaton",
      "points": 1,
      "story_text": null,
      "comment_text": "And users of dynamically typed languages will sometimes argue that the need for code generation tools is less necessary. You lose the ability to have tools do a lot of the work, but you also lose the need to have tools do a lot of the work. It&#x27;s a trade off.<p>Type [an]notations are also useful for compilers when generating performant code. But projects like pypy and V8 (javascript) show that a well written interpreter can do run-time analysis, and generate performant code, just like a static analysis.",
      "num_comments": null,
      "story_id": 6704679,
      "story_title": "Android: The Land That Python Forgot",
      "story_url": "https://speakerdeck.com/pyconca/android-the-land-that-python-forgot-christopher-neugebauer",
      "parent_id": 6707656,
      "created_at_i": 1384121492,
      "_tags": [
        "comment",
        "author_jsmeaton",
        "story_6704679"
      ],
      "objectID": "6708681",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jsmeaton",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "And users of dynamically typed languages will sometimes argue that the need for code generation <em>tools</em> is less necessary. You lose the ability to have <em>tools</em> do a lot of the work, but you also lose the need to have <em>tools</em> do a lot of the work. It's a trade off.<p>Type [an]notations are also useful for compilers when generating performant code. But projects like pypy and V8 (javascript) show that a well written interpreter can do run-time <em>analysis</em>, and generate performant code, just like a <em>static</em> <em>analysis.</em>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Android: The Land That Python Forgot",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://speakerdeck.com/pyconca/android-the-land-that-python-forgot-christopher-neugebauer",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-10-02T21:05:55.000Z",
      "title": "",
      "url": "",
      "author": "aaronem",
      "points": 1,
      "story_text": null,
      "comment_text": "There&#x27;s barely any such thing as a debugger, and no such thing as an object graph, and even modifying a function in place is far more complicated than real tools would make it -- but nonetheless, in the sort of browser-based Javascript development I do on an almost daily basis, I sense a faint echo of the <i>je ne sais quoi</i> to which you refer; specifically, iteratively fiddling with a live system until it behaves more like how you want, then baking those changes into the serialized form of it (also called &quot;source code&quot;) so that they&#x27;re incorporated next time the system is instantiated.<p>Granted, I have only the most trivial experience with Smalltalk; I&#x27;m pretty sure at least some of the concepts I have in mind here are entirely meaningless in that context, but I wonder if it would be fair nonetheless to consider the modern browser Javascript environment, for example Firefox with Firebug and a proper REPL instead of the single-line console, as potentially possessing at least some of the flexibility a Smalltalker considers <i>de rigeur</i>.<p>On the other hand, if you wanted to build, for example, an object-graph generator in pure Javascript, I don&#x27;t think you could do so, at least not one worth having; unless I&#x27;m very much mistaken, Javascript&#x27;s reflection facilities don&#x27;t suffice to allow one thing to notice when another thing changes, unless the latter thing explicitly notifies the former of the change. So you&#x27;d have what would be essentially static analysis on running code; you could recursively walk properties from the global object on down, following references where necessary, but it&#x27;d be dog-slow in modern JS implementations; worse, there&#x27;d be no way to keep it synchronized with the actual state of the objects to which it refers, short of rewalking everything to spot the changes, which would be ugly in theory and unusable in practice. So it&#x27;s probably also accurate to say that the modern browser Javascript environment offers no immediate prospect of attaining anything remotely resembling the facilities a Smalltalker considers <i>de rigeur</i>.<p>Which is a shame, because what I&#x27;ve seen of Smalltalk has been impressive in the extreme, especially by contrast to the tools whose use I can actually justify in my professional life.",
      "num_comments": null,
      "story_id": 6484300,
      "story_title": "Smalltalk: Swimming with the fish",
      "story_url": "http://simberon.blogspot.nl/2013/01/swimming-with-fish.html",
      "parent_id": 6485018,
      "created_at_i": 1380747955,
      "_tags": [
        "comment",
        "author_aaronem",
        "story_6484300"
      ],
      "objectID": "6485380",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "aaronem",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "There's barely any such thing as a debugger, and no such thing as an object graph, and even modifying a function in place is far more complicated than real <em>tools</em> would make it -- but nonetheless, in the sort of browser-based Javascript development I do on an almost daily basis, I sense a faint echo of the <i>je ne sais quoi</i> to which you refer; specifically, iteratively fiddling with a live system until it behaves more like how you want, then baking those changes into the serialized form of it (also called &quot;source code&quot;) so that they're incorporated next time the system is instantiated.<p>Granted, I have only the most trivial experience with Smalltalk; I'm pretty sure at least some of the concepts I have in mind here are entirely meaningless in that context, but I wonder if it would be fair nonetheless to consider the modern browser Javascript environment, for example Firefox with Firebug and a proper REPL instead of the single-line console, as potentially possessing at least some of the flexibility a Smalltalker considers <i>de rigeur</i>.<p>On the other hand, if you wanted to build, for example, an object-graph generator in pure Javascript, I don't think you could do so, at least not one worth having; unless I'm very much mistaken, Javascript's reflection facilities don't suffice to allow one thing to notice when another thing changes, unless the latter thing explicitly notifies the former of the change. So you'd have what would be essentially <em>static</em> <em>analysis</em> on running code; you could recursively walk properties from the global object on down, following references where necessary, but it'd be dog-slow in modern JS implementations; worse, there'd be no way to keep it synchronized with the actual state of the objects to which it refers, short of rewalking everything to spot the changes, which would be ugly in theory and unusable in practice. So it's probably also accurate to say that the modern browser Javascript environment offers no immediate prospect of attaining anything remotely resembling the facilities a Smalltalker considers <i>de rigeur</i>.<p>Which is a shame, because what I've seen of Smalltalk has been impressive in the extreme, especially by contrast to the <em>tools</em> whose use I can actually justify in my professional life.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Smalltalk: Swimming with the fish",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://simberon.blogspot.nl/2013/01/swimming-with-fish.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-16T19:07:08.000Z",
      "title": "",
      "url": "",
      "author": "StringyBob",
      "points": 1,
      "story_text": null,
      "comment_text": "Yes - Static Timing Analysis is used to work out worst likely timing (slowest&#x2F;fastest delay) paths and check it runs at your target MHz<p>For ASIC work there are a couple of tools used these days:\n<a href=\"http://www.cadence.com/products/mfg/tempus/pages/default.aspx\" rel=\"nofollow\">http:&#x2F;&#x2F;www.cadence.com&#x2F;products&#x2F;mfg&#x2F;tempus&#x2F;pages&#x2F;default.asp...</a><p><a href=\"http://www.synopsys.com/Tools/Implementation/SignOff/Pages/PrimeTime.aspx\" rel=\"nofollow\">http:&#x2F;&#x2F;www.synopsys.com&#x2F;Tools&#x2F;Implementation&#x2F;SignOff&#x2F;Pages&#x2F;P...</a><p>Electronic Design Automation is a tough market to crack - for most startups the exit strategy is to be bought by one of the 2 (or 3) big players without being sued by them first!",
      "num_comments": null,
      "story_id": 6391203,
      "story_title": "How to Write Safe Verilog: Become a PL Troll",
      "story_url": "http://danluu.com/pl-troll/",
      "parent_id": 6391479,
      "created_at_i": 1379358428,
      "_tags": [
        "comment",
        "author_StringyBob",
        "story_6391203"
      ],
      "objectID": "6395132",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "StringyBob",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Yes - <em>Static</em> Timing <em>Analysis</em> is used to work out worst likely timing (slowest/fastest delay) paths and check it runs at your target MHz<p>For ASIC work there are a couple of <em>tools</em> used these days:\n<a href=\"http://www.cadence.com/products/mfg/tempus/pages/default.aspx\" rel=\"nofollow\">http://www.cadence.com/products/mfg/tempus/pages/default.asp...</a><p><a href=\"http://www.synopsys.com/Tools/Implementation/SignOff/Pages/PrimeTime.aspx\" rel=\"nofollow\">http://www.synopsys.com/<em>Tools</em>/Implementation/SignOff/Pages/P...</a><p>Electronic Design Automation is a tough market to crack - for most startups the exit strategy is to be bought by one of the 2 (or 3) big players without being sued by them first!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How to Write Safe Verilog: Become a PL Troll",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://danluu.com/pl-troll/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-25T01:48:25.000Z",
      "title": "",
      "url": "",
      "author": "cheald",
      "points": 1,
      "story_text": null,
      "comment_text": "Plenty of tools do what you describe, and far better than Turbo Pascal did in the 90s. Try Visual Studio or IntelliJ, for example.<p>When you can&#x27;t perform static analysis (which is very difficult to do effectively in dynamically-typed languages), many of those tools you are talking about are just not possible.",
      "num_comments": null,
      "story_id": 6264657,
      "story_title": "How Flow-Based Programming Could Save The Sanity Of Web Developers",
      "story_url": "http://www.fastcolabs.com/3016289/how-an-arcane-coding-method-from-1970s-banking-software-could-save-the-sanity-of-web-develop",
      "parent_id": 6268700,
      "created_at_i": 1377395305,
      "_tags": [
        "comment",
        "author_cheald",
        "story_6264657"
      ],
      "objectID": "6270552",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "cheald",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Plenty of <em>tools</em> do what you describe, and far better than Turbo Pascal did in the 90s. Try Visual Studio or IntelliJ, for example.<p>When you can't perform <em>static</em> <em>analysis</em> (which is very difficult to do effectively in dynamically-typed languages), many of those <em>tools</em> you are talking about are just not possible.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How Flow-Based Programming Could Save The Sanity Of Web Developers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.fastcolabs.com/3016289/how-an-arcane-coding-method-from-1970s-banking-software-could-save-the-sanity-of-web-develop",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-21T22:07:27.000Z",
      "title": "",
      "url": "",
      "author": "jasonlotito",
      "points": 1,
      "story_text": null,
      "comment_text": "That&#x27;s really just being lazy on your part though.  I&#x27;m not going to sit here and list everything that&#x27;s come onto the scene since 1990.  Every new language.  Every new methodology.  Every new practice, pattern, and tool.  And not just new things, but also improvements over way things are done.<p>Unless you are going to sit here and suggest that ARC or GC don&#x27;t help decrease memory errors, or that languages like Python or Java haven&#x27;t helped move things along.  Heck, even C has been steadily improved over the years.  Compilers are getting smarter.  Tools like valgrind.  Agile methodologies, and formalized code testing.  Static analysis and even improve code reviews.  Heck, even simple things like IDEs and editors.<p>So much has changed, so much as evolved.  Does that mean everything is wrong? No.  But relying on studies that can&#x27;t be replicated and don&#x27;t account for common programming practices and environments today is dangerous.",
      "num_comments": null,
      "story_id": 6228297,
      "story_title": "Callbacks are Pretty Okay",
      "story_url": "http://andrewkelley.me/post/js-callback-organization.html",
      "parent_id": 6234247,
      "created_at_i": 1377122847,
      "_tags": [
        "comment",
        "author_jasonlotito",
        "story_6228297"
      ],
      "objectID": "6253627",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jasonlotito",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's really just being lazy on your part though.  I'm not going to sit here and list everything that's come onto the scene since 1990.  Every new language.  Every new methodology.  Every new practice, pattern, and tool.  And not just new things, but also improvements over way things are done.<p>Unless you are going to sit here and suggest that ARC or GC don't help decrease memory errors, or that languages like Python or Java haven't helped move things along.  Heck, even C has been steadily improved over the years.  Compilers are getting smarter.  <em>Tools</em> like valgrind.  Agile methodologies, and formalized code testing.  <em>Static</em> <em>analysis</em> and even improve code reviews.  Heck, even simple things like IDEs and editors.<p>So much has changed, so much as evolved.  Does that mean everything is wrong? No.  But relying on studies that can't be replicated and don't account for common programming practices and environments today is dangerous.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Callbacks are Pretty Okay",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://andrewkelley.me/post/js-callback-organization.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-15T17:00:17.000Z",
      "title": "",
      "url": "",
      "author": "rsynnott",
      "points": 1,
      "story_text": null,
      "comment_text": "Apple certainly has technical reasons for using clang; good luck getting the degree of integration XCode has with clang with GCC (the plugin system added as a response to clang existing would help, but would not be sufficient in itself). BSD has less clear ones, though I would hope that other C&#x2F;C++ IDEs will start adding similar levels of integration.<p>Ultimately, clang offers a way forward without having to adopt GPLv3 software, and besides that offers considerable benefit to people making development tools. Its big selling point has never really been speed; that it can generally keep up is enough.<p>EDIT: You could certainly also make the claim that Clang&#x27;s far faster compilation is a technical feature, especially for C++ programmers. There are actually people who use clang for development, for the fast compilation and static analysis, then build for production with a newish GCC.",
      "num_comments": null,
      "story_id": 6208419,
      "story_title": "Why is FreeBSD deprecating GCC in favor of Clang/LLVM?",
      "story_url": "http://unix.stackexchange.com/questions/49906/why-is-freebsd-deprecating-gcc-in-favor-of-clang-llvm",
      "parent_id": 6209994,
      "created_at_i": 1376586017,
      "_tags": [
        "comment",
        "author_rsynnott",
        "story_6208419"
      ],
      "objectID": "6219165",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "rsynnott",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Apple certainly has technical reasons for using clang; good luck getting the degree of integration XCode has with clang with GCC (the plugin system added as a response to clang existing would help, but would not be sufficient in itself). BSD has less clear ones, though I would hope that other C/C++ IDEs will start adding similar levels of integration.<p>Ultimately, clang offers a way forward without having to adopt GPLv3 software, and besides that offers considerable benefit to people making development <em>tools</em>. Its big selling point has never really been speed; that it can generally keep up is enough.<p>EDIT: You could certainly also make the claim that Clang's far faster compilation is a technical feature, especially for C++ programmers. There are actually people who use clang for development, for the fast compilation and <em>static</em> <em>analysis</em>, then build for production with a newish GCC.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why is FreeBSD deprecating GCC in favor of Clang/LLVM?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://unix.stackexchange.com/questions/49906/why-is-freebsd-deprecating-gcc-in-favor-of-clang-llvm",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-29T17:12:47.000Z",
      "title": "",
      "url": "",
      "author": "CGamesPlay",
      "points": 1,
      "story_text": null,
      "comment_text": "The best thing I can say is that when interacting with other people, subtle course correction early on has a big effect in the long run. When I've tried to influence other people to change practices (in my case it was building more testable code), I've found that making the right path the easiest path is the best way. There are a lot of ways to do this. Code review is an easy one if you're not doing it already. It gives everyone the power to have influence over the code before it lands in the repository [1]. Building tools that make the right thing easy is also useful. I spent about a year making development tools to enable rapid testing of some of our JS modules, as well as doing a little bit of static analysis to automatically detect and fix certain classes of errors. By doing these things, every engineer gets guided to the right path without needing to reach out to anyone and without a huge cognitive overhead (like reading an interface guideline or something like that).<p>[1] <a href=\"http://www.phabricator.com/docs/phabricator/article/User_Guide_Review_vs_Audit.html#advantages-of-review\" rel=\"nofollow\">http://www.phabricator.com/docs/phabricator/article/User_Gui...</a>",
      "num_comments": null,
      "story_id": 5783945,
      "story_title": "This week marks the beginning of my 4th year at Facebook",
      "story_url": "https://www.facebook.com/ry/posts/10151494199879822",
      "parent_id": 5787009,
      "created_at_i": 1369847567,
      "_tags": [
        "comment",
        "author_CGamesPlay",
        "story_5783945"
      ],
      "objectID": "5787595",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "CGamesPlay",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The best thing I can say is that when interacting with other people, subtle course correction early on has a big effect in the long run. When I've tried to influence other people to change practices (in my case it was building more testable code), I've found that making the right path the easiest path is the best way. There are a lot of ways to do this. Code review is an easy one if you're not doing it already. It gives everyone the power to have influence over the code before it lands in the repository [1]. Building <em>tools</em> that make the right thing easy is also useful. I spent about a year making development <em>tools</em> to enable rapid testing of some of our JS modules, as well as doing a little bit of <em>static</em> <em>analysis</em> to automatically detect and fix certain classes of errors. By doing these things, every engineer gets guided to the right path without needing to reach out to anyone and without a huge cognitive overhead (like reading an interface guideline or something like that).<p>[1] <a href=\"http://www.phabricator.com/docs/phabricator/article/User_Guide_Review_vs_Audit.html#advantages-of-review\" rel=\"nofollow\">http://www.phabricator.com/docs/phabricator/article/User_Gui...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "This week marks the beginning of my 4th year at Facebook",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.facebook.com/ry/posts/10151494199879822",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-27T23:10:23.000Z",
      "title": "",
      "url": "",
      "author": "BrendanEich",
      "points": 1,
      "story_text": null,
      "comment_text": "Tern's static analysis is based loosely on SpiderMonkey's type inference, which does well with most JS libraries.<p>Yes, some overloaded octopus methods fall back on Object. What helps the SpiderMonkey type-inference-driven JIT is online live-data profiling, as Marijn notes. This may be the crucial difference.<p>However, new algorithms such as CFA2 promise more precision even without runtime feedback.<p>And I suggest you are missing the bigger picture: TypeScript, Dart, et al., require (unsound) type annotations, a tax on all programmers, in hope of gaining better tooling of the kind you work on.<p>Is this a good trade? Users will vote with their fingers provided the tools show up. In big orgs (Google, where Closure is still used to preprocess JS) they may, but in general, no.<p>Renaming is just not high-enough frequency from what I hear to motivate JS devs to swallow type annotation.<p>/be",
      "num_comments": null,
      "story_id": 5754848,
      "story_title": "Mozilla can produce near-native performance on the Web",
      "story_url": "http://arstechnica.com/information-technology/2013/05/native-level-performance-on-the-web-a-brief-examination-of-asm-js/",
      "parent_id": 5776992,
      "created_at_i": 1369696223,
      "_tags": [
        "comment",
        "author_BrendanEich",
        "story_5754848"
      ],
      "objectID": "5777083",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "BrendanEich",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Tern's <em>static</em> <em>analysis</em> is based loosely on SpiderMonkey's type inference, which does well with most JS libraries.<p>Yes, some overloaded octopus methods fall back on Object. What helps the SpiderMonkey type-inference-driven JIT is online live-data profiling, as Marijn notes. This may be the crucial difference.<p>However, new algorithms such as CFA2 promise more precision even without runtime feedback.<p>And I suggest you are missing the bigger picture: TypeScript, Dart, et al., require (unsound) type annotations, a tax on all programmers, in hope of gaining better tooling of the kind you work on.<p>Is this a good trade? Users will vote with their fingers provided the <em>tools</em> show up. In big orgs (Google, where Closure is still used to preprocess JS) they may, but in general, no.<p>Renaming is just not high-enough frequency from what I hear to motivate JS devs to swallow type annotation.<p>/be",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mozilla can produce near-native performance on the Web",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://arstechnica.com/information-technology/2013/05/native-level-performance-on-the-web-a-brief-examination-of-asm-js/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-22T04:58:44.000Z",
      "title": "",
      "url": "",
      "author": "stcredzero",
      "points": 1,
      "story_text": null,
      "comment_text": "<i>&#62; That's dangerous, because you have no way of knowing if you have 100% coverage without doing static analysis</i><p>You are right from a theoretical standpoint, but I'm not so sure this fits with how web applications are known to run and the patterns development usually follows.<p>Developers who shove an object of one type in an instance or temporary variable one time, and a different one another time are usually doing something bad, even in dynamic environments -- unless there is a specific interface involved. Just because \"duck typing\" is fast, doesn't mean that it has to be loose.<p>The point, actually, is to discover where types are being misused as much as to discover what the types are.<p><i>&#62; The lesson is: don't let tools change code semantics based only on black-box testing.</i><p>I'm also advocating this. However, it seems like you're mainly familiar with dealing with types in statically typed environments. In dynamic environments, the developers still need to know the types. Often, there are hard and fast rules only enforced by convention. This is indeed a source of errors, but by and large, programmers are very good at managing this. In other words, very often, the programmers will <i>know</i>. I see environments like Dart as a way to eliminate such conventions, but still enable very fast prototyping in the beginning. (Ultimately, static types are better for maintenance.)",
      "num_comments": null,
      "story_id": 5747961,
      "story_title": "Dart Is Not the Language You Think It Is",
      "story_url": "http://programming.oreilly.com/2013/05/dart-is-not-the-language-you-think-it-is.html",
      "parent_id": 5748212,
      "created_at_i": 1369198724,
      "_tags": [
        "comment",
        "author_stcredzero",
        "story_5747961"
      ],
      "objectID": "5748970",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "stcredzero",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>> That's dangerous, because you have no way of knowing if you have 100% coverage without doing <em>static</em> <em>analysis</em></i><p>You are right from a theoretical standpoint, but I'm not so sure this fits with how web applications are known to run and the patterns development usually follows.<p>Developers who shove an object of one type in an instance or temporary variable one time, and a different one another time are usually doing something bad, even in dynamic environments -- unless there is a specific interface involved. Just because \"duck typing\" is fast, doesn't mean that it has to be loose.<p>The point, actually, is to discover where types are being misused as much as to discover what the types are.<p><i>> The lesson is: don't let <em>tools</em> change code semantics based only on black-box testing.</i><p>I'm also advocating this. However, it seems like you're mainly familiar with dealing with types in statically typed environments. In dynamic environments, the developers still need to know the types. Often, there are hard and fast rules only enforced by convention. This is indeed a source of errors, but by and large, programmers are very good at managing this. In other words, very often, the programmers will <i>know</i>. I see environments like Dart as a way to eliminate such conventions, but still enable very fast prototyping in the beginning. (Ultimately, <em>static</em> types are better for maintenance.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dart Is Not the Language You Think It Is",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://programming.oreilly.com/2013/05/dart-is-not-the-language-you-think-it-is.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-03-24T07:38:24.000Z",
      "title": "",
      "url": "",
      "author": "jacques_chester",
      "points": 1,
      "story_text": null,
      "comment_text": "Positive human action means that somebody must take some action in order for the system to work. That is, effort above a natural baseline. Such systems are not failsafe.<p>The classic example in C/C++ is avoiding buffer overflow defects. If you code naively to the language, they will creep in. Additional effort is require to apply policies and procedures to prevent such errors from occurring -- enabling warnings, using static analysis, using particular libraries like BString and so on. Further effort is required to ensure compliance.<p>I use the term \"positive\" by analogy with legal positivism, which is (very roughly) that law is created by legislative action and doesn't exist until that has occurred. Similarly, many kinds of safety in C don't exist until you have taken that positive step to introduce additional safeguards.<p>In languages with a more complete view of strings, all of this additional activity is unnecessary. Positive human effort is not required to prevent buffer overflows in such languages. No new procedures, policies, libraries or tools need to be introduced or mandated. The system's baseline configuration is already safe against that class of errors.<p>Why does this matter?<p>Two reasons.<p>Firstly, positive human action is expensive.<p>Secondly, and this is more important, it's unreliable. Any time your safety depends on somebody <i>always</i> sticking to the rules, <i>always</i> remembering to flick a switch, then safety is <i>not</i> assurable. Humans subvert because they disagree, get distracted, make errors, have simple lapses of memory or judgement and so on.<p>That you can remedy some or all of these problems through lashing together a large management system is one thing. Whether that was the cheapest overall option is another thing entirely.<p>Mind you, this is all a bit pie in the sky. Apart from Ada (and even then only partly) I'm not aware of an industrial language that fulfills both my requirements and the requirements of SpaceX that I'm pretending can be solved at a stroke. I suspect Rust will be that language. Let's see.",
      "num_comments": null,
      "story_id": 5430891,
      "story_title": "Lessons Learned Developing Software for Space Vehicles",
      "story_url": "http://lwn.net/Articles/540368/",
      "parent_id": 5431350,
      "created_at_i": 1364110704,
      "_tags": [
        "comment",
        "author_jacques_chester",
        "story_5430891"
      ],
      "objectID": "5431415",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jacques_chester",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Positive human action means that somebody must take some action in order for the system to work. That is, effort above a natural baseline. Such systems are not failsafe.<p>The classic example in C/C++ is avoiding buffer overflow defects. If you code naively to the language, they will creep in. Additional effort is require to apply policies and procedures to prevent such errors from occurring -- enabling warnings, using <em>static</em> <em>analysis</em>, using particular libraries like BString and so on. Further effort is required to ensure compliance.<p>I use the term \"positive\" by analogy with legal positivism, which is (very roughly) that law is created by legislative action and doesn't exist until that has occurred. Similarly, many kinds of safety in C don't exist until you have taken that positive step to introduce additional safeguards.<p>In languages with a more complete view of strings, all of this additional activity is unnecessary. Positive human effort is not required to prevent buffer overflows in such languages. No new procedures, policies, libraries or <em>tools</em> need to be introduced or mandated. The system's baseline configuration is already safe against that class of errors.<p>Why does this matter?<p>Two reasons.<p>Firstly, positive human action is expensive.<p>Secondly, and this is more important, it's unreliable. Any time your safety depends on somebody <i>always</i> sticking to the rules, <i>always</i> remembering to flick a switch, then safety is <i>not</i> assurable. Humans subvert because they disagree, get distracted, make errors, have simple lapses of memory or judgement and so on.<p>That you can remedy some or all of these problems through lashing together a large management system is one thing. Whether that was the cheapest overall option is another thing entirely.<p>Mind you, this is all a bit pie in the sky. Apart from Ada (and even then only partly) I'm not aware of an industrial language that fulfills both my requirements and the requirements of SpaceX that I'm pretending can be solved at a stroke. I suspect Rust will be that language. Let's see.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lessons Learned Developing Software for Space Vehicles",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lwn.net/Articles/540368/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-03-16T20:23:00.000Z",
      "title": "",
      "url": "",
      "author": "zaphar",
      "points": 1,
      "story_text": null,
      "comment_text": "roughly 50%  of my current duties involve parsing and transforming an AST. As well as performing static analysis.<p>All of it is to support web developers by giving them tools to handle html and css well. But this is not the usual case for my career much of it has been exactly what you describe instead.<p>I'm just glad that I knew enough of this stuff to be able to tackle these problems when there was a need to.",
      "num_comments": null,
      "story_id": 5385523,
      "story_title": "Ask HN: How much of your time is spent on classical algorithmic problems?",
      "story_url": "",
      "parent_id": 5385523,
      "created_at_i": 1363465380,
      "_tags": [
        "comment",
        "author_zaphar",
        "story_5385523"
      ],
      "objectID": "5386649",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "zaphar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "roughly 50%  of my current duties involve parsing and transforming an AST. As well as performing <em>static</em> <em>analysis.</em><p>All of it is to support web developers by giving them <em>tools</em> to handle html and css well. But this is not the usual case for my career much of it has been exactly what you describe instead.<p>I'm just glad that I knew enough of this stuff to be able to tackle these problems when there was a need to.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: How much of your time is spent on classical algorithmic problems?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-02-03T23:03:53.000Z",
      "title": null,
      "url": null,
      "author": "edwinnathaniel",
      "points": 1,
      "story_text": null,
      "comment_text": "Yet you're using:<p>C# - A language that can do (almost) everything: mobile, web, desktop, etc (Java still beat you guys on embedded devices).<p>VS.NET - An IDE that can do build, run your tests, UML modelling and many more...<p>Final thoughts on Maven: What I care is a tool that perform build for me and in 2013, validations are part of the build: validate that your code compiles (compiler), validate that your code can be packaged according to the agreeable standard (dll, jar, whatever), some level of behaviour validation (unit-test, integration-test) .<p>If you disagree then perhaps we have philosophical differences when it comes to good software engineering practices since the beginning.<p>Eventually you either: build something from scratch to mimic Maven on .NET ecosystems or use various tools (MSBuild, NAnt, NuGET) that perform the same workflow that Maven gives to you. Either way you got nothing like Maven in .NET ecosystems which is a huge loss for me since why would I learn various tools or build some piece of the puzzles on my own when I have _the_ tool that can do what we all have to do on day-to-day base anyway...<p>You're not saying anything remotely close to display how the .NET ecosystem is richer than Java. Perhaps because it isn't.<p>PS: Maven is composed by plugins, the fact that some of the plugins can do unit-test while others can do static code analysis are just... awesome.<p>I'm done.",
      "num_comments": null,
      "story_id": 5140697,
      "story_title": "Visual Studio and Team Foundation Server will have Git support",
      "story_url": "http://blogs.msdn.com/b/bharry/archive/2013/01/30/git-init-vs.aspx",
      "parent_id": 5151769,
      "created_at_i": 1359932633,
      "_tags": [
        "comment",
        "author_edwinnathaniel",
        "story_5140697"
      ],
      "objectID": "5161592",
      "_highlightResult": {
        "author": {
          "value": "edwinnathaniel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Yet you're using:<p>C# - A language that can do (almost) everything: mobile, web, desktop, etc (Java still beat you guys on embedded devices).<p>VS.NET - An IDE that can do build, run your tests, UML modelling and many more...<p>Final thoughts on Maven: What I care is a tool that perform build for me and in 2013, validations are part of the build: validate that your code compiles (compiler), validate that your code can be packaged according to the agreeable standard (dll, jar, whatever), some level of behaviour validation (unit-test, integration-test) .<p>If you disagree then perhaps we have philosophical differences when it comes to good software engineering practices since the beginning.<p>Eventually you either: build something from scratch to mimic Maven on .NET ecosystems or use various <em>tools</em> (MSBuild, NAnt, NuGET) that perform the same workflow that Maven gives to you. Either way you got nothing like Maven in .NET ecosystems which is a huge loss for me since why would I learn various <em>tools</em> or build some piece of the puzzles on my own when I have _the_ tool that can do what we all have to do on day-to-day base anyway...<p>You're not saying anything remotely close to display how the .NET ecosystem is richer than Java. Perhaps because it isn't.<p>PS: Maven is composed by plugins, the fact that some of the plugins can do unit-test while others can do <em>static</em> code <em>analysis</em> are just... awesome.<p>I'm done.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Visual Studio and Team Foundation Server will have Git support",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.msdn.com/b/bharry/archive/2013/01/30/git-init-vs.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-26T03:33:31.000Z",
      "title": "",
      "url": "",
      "author": "zmmmmm",
      "points": 1,
      "story_text": null,
      "comment_text": "Hey, just want to say thanks for the great discussion again. I'm a bit humbled at the length &#38; depth of thought you're putting into it.<p>&#62; The problem with this approach is because figuring out where the files are requires knowledge of the tool inner workings, that can only be acquired from reading the code or documentation<p>I suppose this is true but it's really not an issue I have in practice. I run the pipeline and it produces (let's say) a .csv file as a result. I execute<p><pre><code>    ls -lt *.csv\n</code></pre>\nAnd I see my result at the top. There's really not a huge inconvenience in trying to find the output. Having the pipeline tool automatically name everything instead of me having to specify it is definitely a win in my case. I suspect we're using these tools in very different contexts and that's why we feel differently about this. It sounds like you need the output to be well defined (probably because there's some other automated process that then takes the files?) You <i>can</i> specify the output file exactly with Bpipe, it's just not something you generally <i>want</i> to do. There's nothing wrong with either one - right tool for the job always wins!<p>&#62; if you use the same code in multiple steps, things can become quite confusing. How will BPipe name them<p>It just keeps appending the identifiers:<p><pre><code>   run { fix_names + fix_names + fix_names }\n</code></pre>\nwill produce input.fix_names.fix_names.fix_names.csv. So there's no problem with file names stepping on each other, and it'll even be clear from the name that the file got processed 3 times. One problem is you <i>do</i> end up with huge file names - by the time it gets though 10 stages it's not uncommon to have gigantic 200 character file names. But after getting used to that I actually like the explicitness of it.<p>&#62; Imagine a step which takes 3 inputs - one separate, one which is output #2 of a previous step, and one which is output #6 of yet another step<p>Absolutely - you can get situations like this. We're sort of into the 20% of cases that need more advanced syntax (eventually we'll explore all of Bpipes's functions this way :-) ). But basically Bpipe gives you a query language that lets you \"glob\" the results of the pipeline output tree (not the files in the directory) to find input files. So to get files from specific stages you could write:<p><pre><code>    from(\".xls\", \".fix_names.csv\", \".extract_evergreens.csv\") {\n        exec \"combine_stuff.py $input.xls $input1.csv $input2.csv\"\n    }\n</code></pre>\nIt doesn't solve <i>everything</i>, but I guess the idea is, make it work right for the majority of cases (\"sensible defaults\") and then offer ways to deal with harder cases (\"make simple things easy, hard things possible\"). And when you really get in trouble it's actually groovy code so you can write any programmatic logic you like to find and figure out the inputs if you really need to.<p>&#62; Instead of naming hundreds of files, you have to name hundreds of methods (commands)<p>Not at all - if my pipeline has 15 stages then I have 15 commands to name. Those 15 stages might easily create hundreds of outputs though.<p>&#62; The major difference is that we think you need to identify inputs and outputs to build the graph, and the method name is insignificant until you want code re-use, and BPipe seems to take the opposite position - that you need to give method names, and then use a separate expression to build the graph<p>Again, a really insightful comment, but I'd take it further (and this goes back to my very first comment). Bpipe isn't just not trying to build a graph up front, it really doesn't think there is a graph at all! At least, not an interesting one. The \"graph\" is a <i>runtime product of the pipeline's execution</i>. We don't actually know the graph until the pipeline finished. An individual pipeline stage can use if / then logic <i>at runtime</i> to decide whether to use a certain input or a different input and that will change the dependency graph. You have to go back and ask why you care about having the graph up front in the first place, and in fact it turns out you can get nearly everything you want without it. By not having the graph you lose some ability to do static analysis on the pipeline, but to <i>have</i> it you are giving up dynamic flexibility. So that's a tradeoff Bpipe makes (and there <i>are</i> downsides, it's just in the context where Bpipe shines the tradeoff is worth it).<p>&#62;  In the example you provided you identify different outputs by adding a number to their names. Is that how subsequent steps are supposed to refer to them as inputs - by the positional output number from the step that used to generate them<p>I think the \"from\" example above probably illustrates it. The simplest method is positional, but it doesn't have to be, you can filter with glob style matching to get inputs as well so if you need to pick out one then you just do so.<p>&#62; 1) As far as different philosophies go, I find BPipe's one to be a bit problematic for complicated cases.<p>I can't argue with that - but that's sort of the idea: simple things easy, hard things possible. Complicated cases are complicated with every tool. I guess I would say that pipeline tools live at a level of abstraction where they aren't meant to get <i>that</i> complicated.<p>&#62; 2) And for simple cases, it all comes down to syntactic sugar.<p>I guess I'd have to disagree with this, as I really think there are some fundamental differences in approach that go well beyond syntactic sugar.<p>&#62; Give me an example of a BPipe workflow that you particularly like, and I'll put it in Drake<p>I wouldn't mind doing that - I'll need to look around and find an example I can share that would make sense (what I do is very domain specific - unless you have familiarity with bioinformatics it will probably be very hard to understand). I'll pm you when I manage to do this, but it may take me a little while (apologies).<p>Thanks as always for the interesting discussion. I think this is a fascinating space, not least because there have been <i>so many</i> attempts at it - I would say there are probably dozens of tools like this going back over 20 years or so - and it seems like nobody has ever nailed it. Bpipe has  problems, but so does every tool I've ever tried (I'm probably up to my 8th one or so now!).",
      "num_comments": null,
      "story_id": 5110921,
      "story_title": "Introducing Drake, a kind of make for data",
      "story_url": "http://blog.factual.com/introducing-drake-a-kind-of-make-for-data",
      "parent_id": 5118328,
      "created_at_i": 1359171211,
      "_tags": [
        "comment",
        "author_zmmmmm",
        "story_5110921"
      ],
      "objectID": "5119115",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "zmmmmm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Hey, just want to say thanks for the great discussion again. I'm a bit humbled at the length & depth of thought you're putting into it.<p>> The problem with this approach is because figuring out where the files are requires knowledge of the tool inner workings, that can only be acquired from reading the code or documentation<p>I suppose this is true but it's really not an issue I have in practice. I run the pipeline and it produces (let's say) a .csv file as a result. I execute<p><pre><code>    ls -lt *.csv\n</code></pre>\nAnd I see my result at the top. There's really not a huge inconvenience in trying to find the output. Having the pipeline tool automatically name everything instead of me having to specify it is definitely a win in my case. I suspect we're using these <em>tools</em> in very different contexts and that's why we feel differently about this. It sounds like you need the output to be well defined (probably because there's some other automated process that then takes the files?) You <i>can</i> specify the output file exactly with Bpipe, it's just not something you generally <i>want</i> to do. There's nothing wrong with either one - right tool for the job always wins!<p>> if you use the same code in multiple steps, things can become quite confusing. How will BPipe name them<p>It just keeps appending the identifiers:<p><pre><code>   run { fix_names + fix_names + fix_names }\n</code></pre>\nwill produce input.fix_names.fix_names.fix_names.csv. So there's no problem with file names stepping on each other, and it'll even be clear from the name that the file got processed 3 times. One problem is you <i>do</i> end up with huge file names - by the time it gets though 10 stages it's not uncommon to have gigantic 200 character file names. But after getting used to that I actually like the explicitness of it.<p>> Imagine a step which takes 3 inputs - one separate, one which is output #2 of a previous step, and one which is output #6 of yet another step<p>Absolutely - you can get situations like this. We're sort of into the 20% of cases that need more advanced syntax (eventually we'll explore all of Bpipes's functions this way :-) ). But basically Bpipe gives you a query language that lets you \"glob\" the results of the pipeline output tree (not the files in the directory) to find input files. So to get files from specific stages you could write:<p><pre><code>    from(\".xls\", \".fix_names.csv\", \".extract_evergreens.csv\") {\n        exec \"combine_stuff.py $input.xls $input1.csv $input2.csv\"\n    }\n</code></pre>\nIt doesn't solve <i>everything</i>, but I guess the idea is, make it work right for the majority of cases (\"sensible defaults\") and then offer ways to deal with harder cases (\"make simple things easy, hard things possible\"). And when you really get in trouble it's actually groovy code so you can write any programmatic logic you like to find and figure out the inputs if you really need to.<p>> Instead of naming hundreds of files, you have to name hundreds of methods (commands)<p>Not at all - if my pipeline has 15 stages then I have 15 commands to name. Those 15 stages might easily create hundreds of outputs though.<p>> The major difference is that we think you need to identify inputs and outputs to build the graph, and the method name is insignificant until you want code re-use, and BPipe seems to take the opposite position - that you need to give method names, and then use a separate expression to build the graph<p>Again, a really insightful comment, but I'd take it further (and this goes back to my very first comment). Bpipe isn't just not trying to build a graph up front, it really doesn't think there is a graph at all! At least, not an interesting one. The \"graph\" is a <i>runtime product of the pipeline's execution</i>. We don't actually know the graph until the pipeline finished. An individual pipeline stage can use if / then logic <i>at runtime</i> to decide whether to use a certain input or a different input and that will change the dependency graph. You have to go back and ask why you care about having the graph up front in the first place, and in fact it turns out you can get nearly everything you want without it. By not having the graph you lose some ability to do <em>static</em> <em>analysis</em> on the pipeline, but to <i>have</i> it you are giving up dynamic flexibility. So that's a tradeoff Bpipe makes (and there <i>are</i> downsides, it's just in the context where Bpipe shines the tradeoff is worth it).<p>>  In the example you provided you identify different outputs by adding a number to their names. Is that how subsequent steps are supposed to refer to them as inputs - by the positional output number from the step that used to generate them<p>I think the \"from\" example above probably illustrates it. The simplest method is positional, but it doesn't have to be, you can filter with glob style matching to get inputs as well so if you need to pick out one then you just do so.<p>> 1) As far as different philosophies go, I find BPipe's one to be a bit problematic for complicated cases.<p>I can't argue with that - but that's sort of the idea: simple things easy, hard things possible. Complicated cases are complicated with every tool. I guess I would say that pipeline <em>tools</em> live at a level of abstraction where they aren't meant to get <i>that</i> complicated.<p>> 2) And for simple cases, it all comes down to syntactic sugar.<p>I guess I'd have to disagree with this, as I really think there are some fundamental differences in approach that go well beyond syntactic sugar.<p>> Give me an example of a BPipe workflow that you particularly like, and I'll put it in Drake<p>I wouldn't mind doing that - I'll need to look around and find an example I can share that would make sense (what I do is very domain specific - unless you have familiarity with bioinformatics it will probably be very hard to understand). I'll pm you when I manage to do this, but it may take me a little while (apologies).<p>Thanks as always for the interesting discussion. I think this is a fascinating space, not least because there have been <i>so many</i> attempts at it - I would say there are probably dozens of <em>tools</em> like this going back over 20 years or so - and it seems like nobody has ever nailed it. Bpipe has  problems, but so does every tool I've ever tried (I'm probably up to my 8th one or so now!).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Introducing Drake, a kind of make for data",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.factual.com/introducing-drake-a-kind-of-make-for-data",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-24T06:09:47.000Z",
      "title": "",
      "url": "",
      "author": "niggler",
      "points": 1,
      "story_text": null,
      "comment_text": "Google, through Closure Tools, and other groups and people have built tools around javascript. For example, JSHint is a pretty good linter and fixjsstyle is a nice little tool to fix formatting.  Certainly JS isn't as amenable to static analysis as C, but with time we'll see more.",
      "num_comments": null,
      "story_id": 5107474,
      "story_title": "Node, Twitter, and Apologies",
      "story_url": "http://blog.steveklabnik.com/posts/2013-01-23-node",
      "parent_id": 5107637,
      "created_at_i": 1359007787,
      "_tags": [
        "comment",
        "author_niggler",
        "story_5107474"
      ],
      "objectID": "5107842",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "niggler",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Google, through Closure <em>Tools</em>, and other groups and people have built <em>tools</em> around javascript. For example, JSHint is a pretty good linter and fixjsstyle is a nice little tool to fix formatting.  Certainly JS isn't as amenable to <em>static</em> <em>analysis</em> as C, but with time we'll see more.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Node, Twitter, and Apologies",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.steveklabnik.com/posts/2013-01-23-node",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-24T06:08:09.000Z",
      "title": "",
      "url": "",
      "author": "frugalmail",
      "points": 1,
      "story_text": null,
      "comment_text": "You get something in exchange to that overhead:<p>1) predictability\n2) static analysis\n3) quality (static typeing vs. duck typing)\n4) sophistication/maturity\n5) reproducabilty\n6) tooling<p>All that's not always necessary, but if you know the thing you're building has a shelf life of at least 2 years then ruby/rake are pretty shitty tools.",
      "num_comments": null,
      "story_id": 5105164,
      "story_title": "Why Everyone Eventually Hates or Leaves Maven",
      "story_url": "http://nealford.com/memeagora/2013/01/22/why_everyone_eventually_hates_maven.html",
      "parent_id": 5106401,
      "created_at_i": 1359007689,
      "_tags": [
        "comment",
        "author_frugalmail",
        "story_5105164"
      ],
      "objectID": "5107834",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "frugalmail",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You get something in exchange to that overhead:<p>1) predictability\n2) <em>static</em> <em>analysis</em>\n3) quality (<em>static</em> typeing vs. duck typing)\n4) sophistication/maturity\n5) reproducabilty\n6) tooling<p>All that's not always necessary, but if you know the thing you're building has a shelf life of at least 2 years then ruby/rake are pretty shitty <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Everyone Eventually Hates or Leaves Maven",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://nealford.com/memeagora/2013/01/22/why_everyone_eventually_hates_maven.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-12-01T23:40:13.000Z",
      "title": "",
      "url": "",
      "author": "w_t_payne",
      "points": 1,
      "story_text": null,
      "comment_text": "I think that we are only scratching the surface as regards support for static analysis and automated refactoring.<p>Also, I think that we will start to apply some of the machine learning and statistical pattern recognition techniques that have become so \"du jour\" recently to programming - enabling development tools to do some really sophisticated things.",
      "num_comments": null,
      "story_id": 4858928,
      "story_title": "Ask HN: What's the next innovation in computer languages?",
      "story_url": "",
      "parent_id": 4858928,
      "created_at_i": 1354405213,
      "_tags": [
        "comment",
        "author_w_t_payne",
        "story_4858928"
      ],
      "objectID": "4859442",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "w_t_payne",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I think that we are only scratching the surface as regards support for <em>static</em> <em>analysis</em> and automated refactoring.<p>Also, I think that we will start to apply some of the machine learning and statistical pattern recognition techniques that have become so \"du jour\" recently to programming - enabling development <em>tools</em> to do some really sophisticated things.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: What's the next innovation in computer languages?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-11-29T19:37:40.000Z",
      "title": "",
      "url": "",
      "author": "loumf",
      "points": 1,
      "story_text": null,
      "comment_text": "I hated every attempt at static analysis until I started programming with Xcode. In my usage, Build and Analyze is always right -- that's the difference. Other tools (lint, FXCop) are too noisy.  Even warnings in some compilers are an annoyance that you have to code around to eliminate.",
      "num_comments": null,
      "story_id": 4848456,
      "story_title": "Eric Lippert is leaving Microsoft",
      "story_url": "http://ericlippert.com/",
      "parent_id": 4848774,
      "created_at_i": 1354217860,
      "_tags": [
        "comment",
        "author_loumf",
        "story_4848456"
      ],
      "objectID": "4849800",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "loumf",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I hated every attempt at <em>static</em> <em>analysis</em> until I started programming with Xcode. In my usage, Build and Analyze is always right -- that's the difference. Other <em>tools</em> (lint, FXCop) are too noisy.  Even warnings in some compilers are an annoyance that you have to code around to eliminate.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Eric Lippert is leaving Microsoft",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ericlippert.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-25T11:36:52.000Z",
      "title": "",
      "url": "",
      "author": "dillinger",
      "points": 1,
      "story_text": null,
      "comment_text": "1. Put it under Version control. Preferably GIT, You will need a lot of the tools that git and github provide. A private Github account will do but hosted github is what I'd prefer.<p>2. Get a Test System that has enough horsepower.<p>3. Create a deployscript<p>4. Deploy until it seems to work.<p>5. Start working with CI and static code analysis. You might  get lucky when it comes to copy paste code. Copy-Paste detection and Coding Standards come to mind at first but there are a lot more helpers<p>6. Automatically create some API Documentation. The worst code cant hide what is inheriting from which class etc. Integrate  Generation of Docs into the CI.<p>7. Create some basic so called \"Smoke Tests\". I'd prefer some very basic Selenium Tests opening the most important parts of the app. This is straight forward. Run them against the APP with error logging turned on on every E_ALL. This error.log is your scary list.<p>8. Setup Single Builds and try to integrate with More than one Version of Vtiger, PHP and Mysql. Since you have 150 Customers, chance is great that you have 150 different setups.<p>Note: You havent changed one line of code yet. Sit down with the customer and discuss all your findings and metrics.<p>9. Start creating different GIT repos with the above process for all the modules that are added by your customer. Integrate with the build and run the tests until you have the same amount of errors like before. start extending the build To build Against your Mysql, PHP Versions<p>... I could go on forever .. but basically this will get you up and running.",
      "num_comments": null,
      "story_id": 4557919,
      "story_title": "Ask HN: I just inherited 700K+ lines of bad PHP. Advice?",
      "story_url": "",
      "parent_id": 4557919,
      "created_at_i": 1348573012,
      "_tags": [
        "comment",
        "author_dillinger",
        "story_4557919"
      ],
      "objectID": "4569769",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dillinger",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "1. Put it under Version control. Preferably GIT, You will need a lot of the <em>tools</em> that git and github provide. A private Github account will do but hosted github is what I'd prefer.<p>2. Get a Test System that has enough horsepower.<p>3. Create a deployscript<p>4. Deploy until it seems to work.<p>5. Start working with CI and <em>static</em> code <em>analysis.</em> You might  get lucky when it comes to copy paste code. Copy-Paste detection and Coding Standards come to mind at first but there are a lot more helpers<p>6. Automatically create some API Documentation. The worst code cant hide what is inheriting from which class etc. Integrate  Generation of Docs into the CI.<p>7. Create some basic so called \"Smoke Tests\". I'd prefer some very basic Selenium Tests opening the most important parts of the app. This is straight forward. Run them against the APP with error logging turned on on every E_ALL. This error.log is your scary list.<p>8. Setup Single Builds and try to integrate with More than one Version of Vtiger, PHP and Mysql. Since you have 150 Customers, chance is great that you have 150 different setups.<p>Note: You havent changed one line of code yet. Sit down with the customer and discuss all your findings and metrics.<p>9. Start creating different GIT repos with the above process for all the modules that are added by your customer. Integrate with the build and run the tests until you have the same amount of errors like before. start extending the build To build Against your Mysql, PHP Versions<p>... I could go on forever .. but basically this will get you up and running.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: I just inherited 700K+ lines of bad PHP. Advice?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-09-24T19:03:55.000Z",
      "title": "",
      "url": "",
      "author": "zwieback",
      "points": 1,
      "story_text": null,
      "comment_text": "Real eye opener for me. Been coding for 30 years and have not heard of hardly any of these things. I'm sure this is focussed mainly on web/social/mobile developers but I would have thought there's more overlap with traditional app development and embedded development, which is what I'm doing.<p>My favorite tools:<p>- Keil IDE + Eclipse, Visual Studio<p>- Coverity for static analysis<p>- git and SVN on our own servers<p>- Jenkins for CI<p>- homegrown unit testing framework<p>- RallyDev for tracking<p>What I'm seeing on the list from the article is a lot of online tools for faster collaboration. That's really where I can see traditional development models could learn from the web crowd.",
      "num_comments": null,
      "story_id": 4565993,
      "story_title": "Tools for Coders and Developers",
      "story_url": "http://dailytekk.com/2012/09/24/100-terrific-tools-for-coders-developers/",
      "parent_id": 4565993,
      "created_at_i": 1348513435,
      "_tags": [
        "comment",
        "author_zwieback",
        "story_4565993"
      ],
      "objectID": "4566333",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "zwieback",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Real eye opener for me. Been coding for 30 years and have not heard of hardly any of these things. I'm sure this is focussed mainly on web/social/mobile developers but I would have thought there's more overlap with traditional app development and embedded development, which is what I'm doing.<p>My favorite <em>tools</em>:<p>- Keil IDE + Eclipse, Visual Studio<p>- Coverity for <em>static</em> <em>analysis</em><p>- git and SVN on our own servers<p>- Jenkins for CI<p>- homegrown unit testing framework<p>- RallyDev for tracking<p>What I'm seeing on the list from the article is a lot of online <em>tools</em> for faster collaboration. That's really where I can see traditional development models could learn from the web crowd.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "<em>Tools</em> for Coders and Developers",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "http://dailytekk.com/2012/09/24/100-terrific-<em>tools</em>-for-coders-developers/",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        }
      }
    },
    {
      "created_at": "2012-09-20T04:54:51.000Z",
      "title": "",
      "url": "",
      "author": "Darmani",
      "points": 1,
      "story_text": null,
      "comment_text": "Your tool looks pretty cool and useful, but it seems quite a bit different than tools like Coverity and Astree which reason about the behavior of programs under all possible inputs. Coverity can detect race conditions. Your tool looks like it's using technology closer to that of Refactoring Crawler, which was a quite impressive achievement, but not a static analysis tool.",
      "num_comments": null,
      "story_id": 4543553,
      "story_title": "John Carmack on Static Code Analysis",
      "story_url": "http://www.altdevblogaday.com/2011/12/24/static-code-analysis/",
      "parent_id": 4546383,
      "created_at_i": 1348116891,
      "_tags": [
        "comment",
        "author_Darmani",
        "story_4543553"
      ],
      "objectID": "4547023",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Darmani",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Your tool looks pretty cool and useful, but it seems quite a bit different than <em>tools</em> like Coverity and Astree which reason about the behavior of programs under all possible inputs. Coverity can detect race conditions. Your tool looks like it's using technology closer to that of Refactoring Crawler, which was a quite impressive achievement, but not a <em>static</em> <em>analysis</em> tool.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack on <em>Static</em> Code <em>Analysis</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://www.altdevblogaday.com/2011/12/24/<em>static</em>-code-<em>analysis</em>/",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        }
      }
    },
    {
      "created_at": "2012-08-30T10:54:49.000Z",
      "title": "",
      "url": "",
      "author": "koide",
      "points": 1,
      "story_text": null,
      "comment_text": "Appropriately, it's a book: <a href=\"http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052\" rel=\"nofollow\">http://www.amazon.com/Working-Effectively-Legacy-Michael-Fea...</a><p>Some automatic tools could help (although I doubt thay'll work on DBase III): Static analysis to see what's there, version control to start at the top and log your way through and be able to rollback to a previous working version.<p>But it's at the very least weeks of pain.",
      "num_comments": null,
      "story_id": 4453270,
      "story_title": "Hopefully more controversial programming opinions",
      "story_url": "http://prog21.dadgum.com/149.html",
      "parent_id": 4453875,
      "created_at_i": 1346324089,
      "_tags": [
        "comment",
        "author_koide",
        "story_4453270"
      ],
      "objectID": "4453973",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "koide",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Appropriately, it's a book: <a href=\"http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052\" rel=\"nofollow\">http://www.amazon.com/Working-Effectively-Legacy-Michael-Fea...</a><p>Some automatic <em>tools</em> could help (although I doubt thay'll work on DBase III): <em>Static</em> <em>analysis</em> to see what's there, version control to start at the top and log your way through and be able to rollback to a previous working version.<p>But it's at the very least weeks of pain.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Hopefully more controversial programming opinions",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://prog21.dadgum.com/149.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-22T19:11:51.000Z",
      "title": "",
      "url": "",
      "author": "anoplus",
      "points": 1,
      "story_text": null,
      "comment_text": "Recently I was thinking maybe software industry is too much obsessive about tool making. I wouldn't mind spending much more time and effort using a bad IDE re-factoring bad code that works good and cures cancer. I don't really care how awesome the static analysis tool I am using, or how awesome the meta-meta-meta-meta-meta-meta-meta-meta programming language I am using if I work on pointless product. Maybe I am wrong and those tools are the only way for real breakthroughs in bioinformatics.<p>what do you think?",
      "num_comments": null,
      "story_id": 4008107,
      "story_title": "The future is specific",
      "story_url": "http://www.chris-granger.com/2012/05/21/the-future-is-specific/",
      "parent_id": 4008107,
      "created_at_i": 1337713911,
      "_tags": [
        "comment",
        "author_anoplus",
        "story_4008107"
      ],
      "objectID": "4009383",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "anoplus",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Recently I was thinking maybe software industry is too much obsessive about tool making. I wouldn't mind spending much more time and effort using a bad IDE re-factoring bad code that works good and cures cancer. I don't really care how awesome the <em>static</em> <em>analysis</em> tool I am using, or how awesome the meta-meta-meta-meta-meta-meta-meta-meta programming language I am using if I work on pointless product. Maybe I am wrong and those <em>tools</em> are the only way for real breakthroughs in bioinformatics.<p>what do you think?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The future is specific",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.chris-granger.com/2012/05/21/the-future-is-specific/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-04T15:48:40.000Z",
      "title": "",
      "url": "",
      "author": "larsberg",
      "points": 1,
      "story_text": null,
      "comment_text": "You are correct --- PCC (AFAIK) has not come about in the sense of carrying along a proof object that a formal verifier can validate is both correct and corresponds to the code payload.<p>As the other commenter pointed out, the SLAM tools are part of the Windows Device Driver Development Kit. The last time I talked to the kit's dev manager (~2003), they were talking about making it mandatory that you pass the formal verification in order to have your driver signed by Microsoft. Since those signatures are then verified at driver installation time, that feels very close to it!<p>I have to confess I'm only familiar with the publications on Native Client and not the actual product. From what I'd read, I understood that the verifier did some basic static analysis to prove that all possible executions did not validate some properties. In that case, no proof object is required, as the source code itself is the proof object. Assuming, of course, that they're actually doing the stuff talked about in the papers and in practice don't just \"grep for dangerous instructions.\"",
      "num_comments": null,
      "story_id": 3660417,
      "story_title": "Research in programming languages",
      "story_url": "http://tagide.com/blog/2012/03/research-in-programming-languages/",
      "parent_id": 3661176,
      "created_at_i": 1330876120,
      "_tags": [
        "comment",
        "author_larsberg",
        "story_3660417"
      ],
      "objectID": "3662968",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "larsberg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You are correct --- PCC (AFAIK) has not come about in the sense of carrying along a proof object that a formal verifier can validate is both correct and corresponds to the code payload.<p>As the other commenter pointed out, the SLAM <em>tools</em> are part of the Windows Device Driver Development Kit. The last time I talked to the kit's dev manager (~2003), they were talking about making it mandatory that you pass the formal verification in order to have your driver signed by Microsoft. Since those signatures are then verified at driver installation time, that feels very close to it!<p>I have to confess I'm only familiar with the publications on Native Client and not the actual product. From what I'd read, I understood that the verifier did some basic <em>static</em> <em>analysis</em> to prove that all possible executions did not validate some properties. In that case, no proof object is required, as the source code itself is the proof object. Assuming, of course, that they're actually doing the stuff talked about in the papers and in practice don't just \"grep for dangerous instructions.\"",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Research in programming languages",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://tagide.com/blog/2012/03/research-in-programming-languages/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-01T15:33:55.000Z",
      "title": "",
      "url": "",
      "author": "jayp",
      "points": 1,
      "story_text": null,
      "comment_text": "Mountain View, CA. Both Full-time and Interns. <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Pattern Insight is a booming startup making code and log analysis tools for a customer base that includes many titans of the tech industry. The data mining and static analysis technologies present in our product have strong research roots, as we grew out of PhD research done at the University of Illinois at Urbana-Champaign. Relatedly, our core engineering team has a strong academic background, and as a whole, published over 100+ articles in peer reviewed journals and conferences.<p>We are looking to expand our engineering team in sunny California. As stated above, we are also looking for a handful of interns. For more specific requirements, please see our career page: <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Come join us, we are still tiny and looking for people ready and willing to make decisions that shape our future.",
      "num_comments": null,
      "story_id": 3652041,
      "story_title": "Ask HN: Who is Hiring? (March 2012)",
      "story_url": "",
      "parent_id": 3652041,
      "created_at_i": 1330616035,
      "_tags": [
        "comment",
        "author_jayp",
        "story_3652041"
      ],
      "objectID": "3652461",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jayp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Mountain View, CA. Both Full-time and Interns. <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Pattern Insight is a booming startup making code and log <em>analysis</em> <em>tools</em> for a customer base that includes many titans of the tech industry. The data mining and <em>static</em> <em>analysis</em> technologies present in our product have strong research roots, as we grew out of PhD research done at the University of Illinois at Urbana-Champaign. Relatedly, our core engineering team has a strong academic background, and as a whole, published over 100+ articles in peer reviewed journals and conferences.<p>We are looking to expand our engineering team in sunny California. As stated above, we are also looking for a handful of interns. For more specific requirements, please see our career page: <a href=\"http://patterninsight.com/company/careers/\" rel=\"nofollow\">http://patterninsight.com/company/careers/</a><p>Come join us, we are still tiny and looking for people ready and willing to make decisions that shape our future.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is Hiring? (March 2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-14T16:18:14.000Z",
      "title": null,
      "url": null,
      "author": "hello_moto",
      "points": 1,
      "story_text": null,
      "comment_text": "I use Guava extensively and it has helped me quite significantly to reduce some of the code normally Java developers wrote.<p>I use Rails for CRUD app and I use Spring MVC too.<p>I used Python a lot a few years ago from writing tools (testing, scripting, automation), to small web-apps.<p>Saying that 100k can be cut to 10k (or 1k) is like pulling number out of thin air, that's what I find... \"magical\". It's like some CEO of a startup giving a deadline to the developer to write Hadoop in 4 hours; pulling the number out of thin air.<p>Compiler =&#62; helped syntax errors and types (95%, 5% consist of reflection hackery that might bite).<p>Static code analysis =&#62; One level up from syntax errors, focused on common pitfalls and bug patterns<p>One step, two step, three step, doesn't matter, it helps, that's the bottom line.<p>What I refer to \"except that happens as well in dynamic language\" is to the business logics, the app logics, not syntax and whatnot, you _got it wrong_. We all got business logics bugs that can't be caught by anything other than testing the app themselves (QA, automation, whatever).<p>So we agree that dynamic languages requires you to write more testing code because there's no compiler? Gotcha.<p>I never say anywhere that using a static language requires NO testing.<p>What I found is that a bunch of old-timers who wrote Java back in 98-2003 and didn't use more modern Java frameworks and tools but already jumped the band-wagon to Rails or Node.js keep singing the same tune.<p>When I use Rails, then Spring MVC + Spring Data, I noticed that the amount of business logics that I have to write is more or less the same. 10x is again out of thin-air. I admit writing code in Java requires more typing albeit Eclipse helps a lot (and please don't bring the old argument of \"But You need an IDE!\", who cares what I need as long as it helps me to do my job).<p>Picking one example to refute the epidemic that occurs in the ecosystem is probably not a strong argument (Rails is well maintained, I give you that, although it takes Rails up to version 3.x to realize that they need to cool down and stabilize but I give you that, but that doesn't mean the other plugins and libraries are held the same level of quality and commitment with Rails).",
      "num_comments": null,
      "story_id": 3586883,
      "story_title": ".NET: So long and thanks for all the fish",
      "story_url": "http://lucisferre.net/2012/02/08/dot-net-so-long-and-thanks-for-all-the-fish/",
      "parent_id": 3589832,
      "created_at_i": 1329236294,
      "_tags": [
        "comment",
        "author_hello_moto",
        "story_3586883"
      ],
      "objectID": "3590532",
      "_highlightResult": {
        "author": {
          "value": "hello_moto",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I use Guava extensively and it has helped me quite significantly to reduce some of the code normally Java developers wrote.<p>I use Rails for CRUD app and I use Spring MVC too.<p>I used Python a lot a few years ago from writing <em>tools</em> (testing, scripting, automation), to small web-apps.<p>Saying that 100k can be cut to 10k (or 1k) is like pulling number out of thin air, that's what I find... \"magical\". It's like some CEO of a startup giving a deadline to the developer to write Hadoop in 4 hours; pulling the number out of thin air.<p>Compiler => helped syntax errors and types (95%, 5% consist of reflection hackery that might bite).<p><em>Static</em> code <em>analysis</em> => One level up from syntax errors, focused on common pitfalls and bug patterns<p>One step, two step, three step, doesn't matter, it helps, that's the bottom line.<p>What I refer to \"except that happens as well in dynamic language\" is to the business logics, the app logics, not syntax and whatnot, you _got it wrong_. We all got business logics bugs that can't be caught by anything other than testing the app themselves (QA, automation, whatever).<p>So we agree that dynamic languages requires you to write more testing code because there's no compiler? Gotcha.<p>I never say anywhere that using a <em>static</em> language requires NO testing.<p>What I found is that a bunch of old-timers who wrote Java back in 98-2003 and didn't use more modern Java frameworks and <em>tools</em> but already jumped the band-wagon to Rails or Node.js keep singing the same tune.<p>When I use Rails, then Spring MVC + Spring Data, I noticed that the amount of business logics that I have to write is more or less the same. 10x is again out of thin-air. I admit writing code in Java requires more typing albeit Eclipse helps a lot (and please don't bring the old argument of \"But You need an IDE!\", who cares what I need as long as it helps me to do my job).<p>Picking one example to refute the epidemic that occurs in the ecosystem is probably not a strong argument (Rails is well maintained, I give you that, although it takes Rails up to version 3.x to realize that they need to cool down and stabilize but I give you that, but that doesn't mean the other plugins and libraries are held the same level of quality and commitment with Rails).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": ".NET: So long and thanks for all the fish",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lucisferre.net/2012/02/08/dot-net-so-long-and-thanks-for-all-the-fish/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-12-21T13:33:00.000Z",
      "title": "",
      "url": "",
      "author": "seurahepo",
      "points": 1,
      "story_text": null,
      "comment_text": "Apple does not want to support two sets of tools forever, it would not be cost effective.<p>GCC is obsolete on Apple's platforms because Apple has chosen LLVM as the future basis of their tools. The reasoning was mostly technical, LLVM project also seems more nimble and aligned better with Apple's goals. Surely saner license did not hurt.<p>LLVM has technical benefits compared to GCC, biggest being modularity, speed and memory usage come second. Modularity helps Apple make Xcode a better IDE. You can already see stuff in Xcode that would have been very hard to make with less modular toolset, as GCC. I expect it to pick up after the transition period is over.<p>As an example they are using clang to parse the code for syntax highliting and code completion instead of a custom parser they used before. To use one codebase for parsing both in the IDE and compiler has inherent virtues.<p>LLVM is also used by Apple in other products in addition to of Xcode. OpenGL runtime and OpenCL tools come to mind, efforts in LLVM project have good return on investment.<p>Everyone, old or new projects should consider switching to clang, for speed and static analysis. Whether to use new objc features that require clang, is another question, in most cases it makes sense.",
      "num_comments": null,
      "story_id": 3376019,
      "story_title": "Poll: What compiler do you use for iOS development?",
      "story_url": null,
      "parent_id": 3376366,
      "created_at_i": 1324474380,
      "_tags": [
        "comment",
        "author_seurahepo",
        "story_3376019"
      ],
      "objectID": "3377427",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "seurahepo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Apple does not want to support two sets of <em>tools</em> forever, it would not be cost effective.<p>GCC is obsolete on Apple's platforms because Apple has chosen LLVM as the future basis of their <em>tools</em>. The reasoning was mostly technical, LLVM project also seems more nimble and aligned better with Apple's goals. Surely saner license did not hurt.<p>LLVM has technical benefits compared to GCC, biggest being modularity, speed and memory usage come second. Modularity helps Apple make Xcode a better IDE. You can already see stuff in Xcode that would have been very hard to make with less modular <em>tools</em>et, as GCC. I expect it to pick up after the transition period is over.<p>As an example they are using clang to parse the code for syntax highliting and code completion instead of a custom parser they used before. To use one codebase for parsing both in the IDE and compiler has inherent virtues.<p>LLVM is also used by Apple in other products in addition to of Xcode. OpenGL runtime and OpenCL <em>tools</em> come to mind, efforts in LLVM project have good return on investment.<p>Everyone, old or new projects should consider switching to clang, for speed and <em>static</em> <em>analysis.</em> Whether to use new objc features that require clang, is another question, in most cases it makes sense.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Poll: What compiler do you use for iOS development?",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-10-01T14:08:16.000Z",
      "title": "",
      "url": "",
      "author": "urbanautomaton",
      "points": 1,
      "story_text": null,
      "comment_text": "I was responding specifically to the somewhat alarming claim that faith in the operation of one's IDE is a substitute for regularly running tests. I wasn't denying that automated refactoring tools are nice to have; they obviously are.<p>Regardless, I don't really think that the examples you give have much to do with the IDE vs (editor+plugins) debate; they're to do with the amenability of one's language to static analysis. Certainly code modification features are available to statically typed languages that aren't available to dynamically-typed ones (and this may explain why users of the latter are less drawn to IDEs), but there are compensatory benefits to using a dynamic language. Let's not get into that one, though, eh? One eternal flame-war per thread is probably sufficient. :-)",
      "num_comments": null,
      "story_id": 3059520,
      "story_title": "Why not just use an IDE if you want IDE features?",
      "story_url": "http://davidlynch.org/blog/2011/09/why-not-just-use-an-ide-if-you-want-ide-features/",
      "parent_id": 3060014,
      "created_at_i": 1317478096,
      "_tags": [
        "comment",
        "author_urbanautomaton",
        "story_3059520"
      ],
      "objectID": "3060072",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "urbanautomaton",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I was responding specifically to the somewhat alarming claim that faith in the operation of one's IDE is a substitute for regularly running tests. I wasn't denying that automated refactoring <em>tools</em> are nice to have; they obviously are.<p>Regardless, I don't really think that the examples you give have much to do with the IDE vs (editor+plugins) debate; they're to do with the amenability of one's language to <em>static</em> <em>analysis.</em> Certainly code modification features are available to statically typed languages that aren't available to dynamically-typed ones (and this may explain why users of the latter are less drawn to IDEs), but there are compensatory benefits to using a dynamic language. Let's not get into that one, though, eh? One eternal flame-war per thread is probably sufficient. :-)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why not just use an IDE if you want IDE features?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://davidlynch.org/blog/2011/09/why-not-just-use-an-ide-if-you-want-ide-features/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-07-28T02:20:31.000Z",
      "title": "",
      "url": "",
      "author": "michaelochurch",
      "points": 1,
      "story_text": null,
      "comment_text": "It depends. I feel like a lot of dev. tools compensate for illnesses in software engineering that should be cured in a way that doesn't depend on one's environment.<p>For example, apparently Java doesn't totally suck if one uses the appropriate tools and environment. But Ocaml and Haskell are great regardless of whether one uses vi, emacs, or whatever else. Ocaml, for example, has this great static analysis tool far more powerful than all but the most premium SA tools for C++ and Java-- <i>the compiler</i>.",
      "num_comments": null,
      "story_id": 2814032,
      "story_title": "Hacker News Fires Steve Yegge ",
      "story_url": "http://steve-yegge.blogspot.com/2011/07/hacker-news-fires-steve-yegge.html",
      "parent_id": 2814457,
      "created_at_i": 1311819631,
      "_tags": [
        "comment",
        "author_michaelochurch",
        "story_2814032"
      ],
      "objectID": "2815097",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "michaelochurch",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It depends. I feel like a lot of dev. <em>tools</em> compensate for illnesses in software engineering that should be cured in a way that doesn't depend on one's environment.<p>For example, apparently Java doesn't totally suck if one uses the appropriate <em>tools</em> and environment. But Ocaml and Haskell are great regardless of whether one uses vi, emacs, or whatever else. Ocaml, for example, has this great <em>static</em> <em>analysis</em> tool far more powerful than all but the most premium SA <em>tools</em> for C++ and Java-- <i>the compiler</i>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Hacker News Fires Steve Yegge ",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://steve-yegge.blogspot.com/2011/07/hacker-news-fires-steve-yegge.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-06-15T23:15:35.000Z",
      "title": null,
      "url": null,
      "author": "jerryr",
      "points": 1,
      "story_text": null,
      "comment_text": "I'm used to pricing for commercial embedded tools, which is rarely this straightforward or inexpensive. I'm not saying that's a good thing, but that's why I found this \"cheap\". Of course, I can't really speak to its value without having evaluated it. The \"only\" qualifier presumed it's a comprehensive, commercially-supported static analysis tool that I would find valuable, but the call for actual users' opinions was my first step in testing this presumption. I'm installing it now.",
      "num_comments": null,
      "story_id": 2656982,
      "story_title": "PVS-Studio vs Chromium",
      "story_url": "http://software.intel.com/en-us/articles/pvs-studio-vs-chromium/",
      "parent_id": 2659419,
      "created_at_i": 1308179735,
      "_tags": [
        "comment",
        "author_jerryr",
        "story_2656982"
      ],
      "objectID": "2659464",
      "_highlightResult": {
        "author": {
          "value": "jerryr",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm used to pricing for commercial embedded <em>tools</em>, which is rarely this straightforward or inexpensive. I'm not saying that's a good thing, but that's why I found this \"cheap\". Of course, I can't really speak to its value without having evaluated it. The \"only\" qualifier presumed it's a comprehensive, commercially-supported <em>static</em> <em>analysis</em> tool that I would find valuable, but the call for actual users' opinions was my first step in testing this presumption. I'm installing it now.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "PVS-Studio vs Chromium",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://software.intel.com/en-us/articles/pvs-studio-vs-chromium/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-25T06:22:35.000Z",
      "title": null,
      "url": null,
      "author": "x0054",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; First, itself &quot;wild&quot; and not &quot;wiled&quot;.<p>Thank you for the correction, and I am guessing you mean &quot;it is&quot; rather than &quot;itself&quot; in the above correction of my spelling.<p>&gt; Second, Apple doesn&#x27;t allow &quot;virus scanners,&quot; which is why you&#x27;ll never hear companies like Sophos talking about malware on iOS -- they have nothing to gain.<p>1. Until recently Apple did allow virus scanners on iOS. However, those programs were largely useless for 2 reasons. First, because without a jailbreak you can not run unsigned code on iOS, unless you have found a jailbreak vulnerability that can be exploited directly on the device, but I haven&#x27;t see those since iOS 3 or 4. Second, because iOS jails each app, so one app can not scan the file system or any of the other apps on the OS. Conversely, one app can not maliciously attack or install unsigned code on the OS without a jailbreak.<p>2. Sophos would have a lot to gain from exposing wide spread malware in the App Store. Such news would pressure Apple to reconsider their decision and allow virus scanners into the App Store, or at least clean up their act. One way or another, it would be a lot of GOOD pub for Sophos.<p>3. Given that there are many jailbroken iPhones, and that it&#x27;s trivial to access app files on a jailbroken iPhone, it would be easy for Google to run their own Malware scanners on AppStore submissions. Considering that they would most certainly (according to you) find hundreds, if not hundreds of thousands, instances of Malware, it would be a wonderful PR story for Google, once and for all proving the undeniable superiority of the Android OS. And yet, I have yet to read that story. Forget Google, HTC, Sony, LG, and any number of other manufacturers would have direct pecuniary interest in discrediting Apple by proving to the world that the AppStore is teaming with Malware. I guess all of the above mentioned companies are operated by utter idiots, if we are to believe your assertions.<p>&gt; If you are in the right circles, you know there is plenty of malware on the App Store -- it&#x27;s significantly easier to get it on the App Store than it is to get it on the Play Store.<p>What are these &quot;right circles?&quot; Links, facts, anything to backup the above statement?<p>&gt; The main deterrent to malware on both platforms is the requirement that the app publisher have a credit card, which the stores both verify.<p>Use a prepaid VISA card, put any name and address you like. Works like a charm, you can register an account like that on either store.<p>&gt; Finally, you seem to be confusing manual scanning, static analysis, dynamic analysis, and human review to the point where it&#x27;s hard to even figure out what you&#x27;re claiming.<p>You are confusing the meaning of such terms as manual scanning, static analysis, dynamic analysis, and human review. There, we both made utterly unsubstantiated claims, now we are even!<p>&gt; Google implemented dynamic analysis long before 2014 (your &quot;wiled west&quot;), which Apple very clearly still hasn&#x27;t done.<p>1. Thank you yet again for pointing out the SAME typo in my previous post for the second time in your reply. To return the curtesy, I would also like to point out that &quot;itself&quot; and &quot;it is&quot; do not have the same meaning in the english language. I do understand that this page is frequented by many people from other countries, who may speak different languages. I, for instance, speak fluently 2 languages, in addition to English. So I do apologize ahead of time if you are indeed an ESL person, but to improve your knowledge of the English language I felt the need to point out your mistake yet again.<p>2. Could you please provide any proof what so ever to your claimed assertion that Apple does NOT conduct dynamic analysis.<p>3. Please refer to this article [0] which details utter inaptitude of PlayStore&#x27;s dynamic analysis tools in 2014.<p>[0] <a href=\"http:&#x2F;&#x2F;www.syssec-project.eu&#x2F;m&#x2F;page-media&#x2F;3&#x2F;petsas_rage_%20against_the_virtual_machine.pdf\" rel=\"nofollow\">http:&#x2F;&#x2F;www.syssec-project.eu&#x2F;m&#x2F;page-media&#x2F;3&#x2F;petsas_rage_%20a...</a>",
      "num_comments": null,
      "story_id": 9594158,
      "story_title": "Firefox tracking protection decreases page load time by 44%",
      "story_url": "http://monica-at-mozilla.blogspot.com/2015/05/tracking-protection-for-firefox-at-web.html",
      "parent_id": 9598355,
      "created_at_i": 1432534955,
      "_tags": [
        "comment",
        "author_x0054",
        "story_9594158"
      ],
      "objectID": "9598884",
      "_highlightResult": {
        "author": {
          "value": "x0054",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; First, itself &quot;wild&quot; and not &quot;wiled&quot;.<p>Thank you for the correction, and I am guessing you mean &quot;it is&quot; rather than &quot;itself&quot; in the above correction of my spelling.<p>&gt; Second, Apple doesn't allow &quot;virus scanners,&quot; which is why you'll never hear companies like Sophos talking about malware on iOS -- they have nothing to gain.<p>1. Until recently Apple did allow virus scanners on iOS. However, those programs were largely useless for 2 reasons. First, because without a jailbreak you can not run unsigned code on iOS, unless you have found a jailbreak vulnerability that can be exploited directly on the device, but I haven't see those since iOS 3 or 4. Second, because iOS jails each app, so one app can not scan the file system or any of the other apps on the OS. Conversely, one app can not maliciously attack or install unsigned code on the OS without a jailbreak.<p>2. Sophos would have a lot to gain from exposing wide spread malware in the App Store. Such news would pressure Apple to reconsider their decision and allow virus scanners into the App Store, or at least clean up their act. One way or another, it would be a lot of GOOD pub for Sophos.<p>3. Given that there are many jailbroken iPhones, and that it's trivial to access app files on a jailbroken iPhone, it would be easy for Google to run their own Malware scanners on AppStore submissions. Considering that they would most certainly (according to you) find hundreds, if not hundreds of thousands, instances of Malware, it would be a wonderful PR story for Google, once and for all proving the undeniable superiority of the Android OS. And yet, I have yet to read that story. Forget Google, HTC, Sony, LG, and any number of other manufacturers would have direct pecuniary interest in discrediting Apple by proving to the world that the AppStore is teaming with Malware. I guess all of the above mentioned companies are operated by utter idiots, if we are to believe your assertions.<p>&gt; If you are in the right circles, you know there is plenty of malware on the App Store -- it's significantly easier to get it on the App Store than it is to get it on the Play Store.<p>What are these &quot;right circles?&quot; Links, facts, anything to backup the above statement?<p>&gt; The main deterrent to malware on both platforms is the requirement that the app publisher have a credit card, which the stores both verify.<p>Use a prepaid VISA card, put any name and address you like. Works like a charm, you can register an account like that on either store.<p>&gt; Finally, you seem to be confusing manual scanning, <em>static</em> <em>analysis</em>, dynamic <em>analysis</em>, and human review to the point where it's hard to even figure out what you're claiming.<p>You are confusing the meaning of such terms as manual scanning, <em>static</em> <em>analysis</em>, dynamic <em>analysis</em>, and human review. There, we both made utterly unsubstantiated claims, now we are even!<p>&gt; Google implemented dynamic <em>analysis</em> long before 2014 (your &quot;wiled west&quot;), which Apple very clearly still hasn't done.<p>1. Thank you yet again for pointing out the SAME typo in my previous post for the second time in your reply. To return the curtesy, I would also like to point out that &quot;itself&quot; and &quot;it is&quot; do not have the same meaning in the english language. I do understand that this page is frequented by many people from other countries, who may speak different languages. I, for instance, speak fluently 2 languages, in addition to English. So I do apologize ahead of time if you are indeed an ESL person, but to improve your knowledge of the English language I felt the need to point out your mistake yet again.<p>2. Could you please provide any proof what so ever to your claimed assertion that Apple does NOT conduct dynamic <em>analysis.</em><p>3. Please refer to this article [0] which details utter inaptitude of PlayStore's dynamic <em>analysis</em> <em>tools</em> in 2014.<p>[0] <a href=\"http://www.syssec-project.eu/m/page-media/3/petsas_rage_%20against_the_virtual_machine.pdf\" rel=\"nofollow\">http://www.syssec-project.eu/m/page-media/3/petsas_rage_%20a...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Firefox tracking protection decreases page load time by 44%",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://monica-at-mozilla.blogspot.com/2015/05/tracking-protection-for-firefox-at-web.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-21T23:18:33.000Z",
      "title": null,
      "url": null,
      "author": "saidajigumi",
      "points": null,
      "story_text": null,
      "comment_text": "I&#x27;ll agree that this is interesting, but it seems like a lot of people in this thread miss the point: we&#x27;re working with multi-layer tools now.  This enables modeling of multi-layer processes.  The code generation as it stands is a obviously a toy, but what happens if we actually think about the real processing layers?<p>Take this example of code processing, and instead front it with a parser that generates an AST. For now, an actual parser for a single language.  Maybe later, a network trained to be a parser.  The AST is then fed to our network.  What could we get out of the AST network?  Could we get interesting static analysis out of it?  Tell us the time and&#x2F;or space complexity?  Perhaps we discover that we need other layers to perform certain tasks.<p>This, of course, has parallels in language processing.  Humans don&#x27;t just go in a single (neural) step from excitation of inner ear cells (&quot;sound&quot;) directly to &quot;meaning&quot;.  Cog sci and linguistics work has broken out a number of discrete functions of language processing.  Some have been derived via experiment, some observed via individuals with brain lesions, others worked out by studies of children and adult language learners.  These &quot;layers&quot; provide their own information and inspiration for building deep learning systems.",
      "num_comments": null,
      "story_id": 9584325,
      "story_title": "The Unreasonable Effectiveness of Recurrent Neural Networks",
      "story_url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/",
      "parent_id": 9585707,
      "created_at_i": 1432250313,
      "_tags": [
        "comment",
        "author_saidajigumi",
        "story_9584325"
      ],
      "objectID": "9585923",
      "_highlightResult": {
        "author": {
          "value": "saidajigumi",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'll agree that this is interesting, but it seems like a lot of people in this thread miss the point: we're working with multi-layer <em>tools</em> now.  This enables modeling of multi-layer processes.  The code generation as it stands is a obviously a toy, but what happens if we actually think about the real processing layers?<p>Take this example of code processing, and instead front it with a parser that generates an AST. For now, an actual parser for a single language.  Maybe later, a network trained to be a parser.  The AST is then fed to our network.  What could we get out of the AST network?  Could we get interesting <em>static</em> <em>analysis</em> out of it?  Tell us the time and/or space complexity?  Perhaps we discover that we need other layers to perform certain tasks.<p>This, of course, has parallels in language processing.  Humans don't just go in a single (neural) step from excitation of inner ear cells (&quot;sound&quot;) directly to &quot;meaning&quot;.  Cog sci and linguistics work has broken out a number of discrete functions of language processing.  Some have been derived via experiment, some observed via individuals with brain lesions, others worked out by studies of children and adult language learners.  These &quot;layers&quot; provide their own information and inspiration for building deep learning systems.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Unreasonable Effectiveness of Recurrent Neural Networks",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-02T14:49:39.000Z",
      "title": null,
      "url": null,
      "author": "denim_chicken",
      "points": null,
      "story_text": null,
      "comment_text": "The C ecosystem has tools designed to compensate for its issues.  There&#x27;s valgrind, static analysis, debuggers, asan, tsan, etc..  With its immense popularity, its flexibility and portability, and its mature, comprehensive ecosystem behind it, there&#x27;s no all-purpose programming language better than C (expect maybe C++).",
      "num_comments": null,
      "story_id": 9477006,
      "story_title": "Death to C",
      "story_url": "http://techcrunch.com/2015/05/02/and-c-plus-plus-too/",
      "parent_id": 9477006,
      "created_at_i": 1430578179,
      "_tags": [
        "comment",
        "author_denim_chicken",
        "story_9477006"
      ],
      "objectID": "9477261",
      "_highlightResult": {
        "author": {
          "value": "denim_chicken",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The C ecosystem has <em>tools</em> designed to compensate for its issues.  There's valgrind, <em>static</em> <em>analysis</em>, debuggers, asan, tsan, etc..  With its immense popularity, its flexibility and portability, and its mature, comprehensive ecosystem behind it, there's no all-purpose programming language better than C (expect maybe C++).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Death to C",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://techcrunch.com/2015/05/02/and-c-plus-plus-too/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-30T19:40:45.000Z",
      "title": null,
      "url": null,
      "author": "jdlshore",
      "points": null,
      "story_text": null,
      "comment_text": "Poor practices are more common among front-end developers, partly due to people coming in from non-programming fields (graphic design, for example) and partly due to people who should know better saying &quot;it&#x27;s JavaScript, JavaScript sucks, fuck it, I&#x27;m not responsible.&quot;<p>Don&#x27;t get sucked in to the JS blame game. There are many excellent tools and libraries available (e.g., Karma for cross-browser testing; JSHint for static analysis; npm for installing and updating packages) and good practices are entirely possible. Keep up the good fight.<p>I have a screencast series on this topic at <a href=\"http:&#x2F;&#x2F;www.letscodejavascript.com\" rel=\"nofollow\">http:&#x2F;&#x2F;www.letscodejavascript.com</a> (subscription required) and an essay on tooling and workflow at <a href=\"http:&#x2F;&#x2F;www.letscodejavascript.com&#x2F;v3&#x2F;blog&#x2F;2015&#x2F;02&#x2F;javascript_tooling\" rel=\"nofollow\">http:&#x2F;&#x2F;www.letscodejavascript.com&#x2F;v3&#x2F;blog&#x2F;2015&#x2F;02&#x2F;javascript...</a> (free).",
      "num_comments": null,
      "story_id": 9467043,
      "story_title": "Ask HN: Elitist or reasonable concerns on state of front end development?",
      "story_url": "",
      "parent_id": 9467043,
      "created_at_i": 1430422845,
      "_tags": [
        "comment",
        "author_jdlshore",
        "story_9467043"
      ],
      "objectID": "9467176",
      "_highlightResult": {
        "author": {
          "value": "jdlshore",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Poor practices are more common among front-end developers, partly due to people coming in from non-programming fields (graphic design, for example) and partly due to people who should know better saying &quot;it's JavaScript, JavaScript sucks, fuck it, I'm not responsible.&quot;<p>Don't get sucked in to the JS blame game. There are many excellent <em>tools</em> and libraries available (e.g., Karma for cross-browser testing; JSHint for <em>static</em> <em>analysis</em>; npm for installing and updating packages) and good practices are entirely possible. Keep up the good fight.<p>I have a screencast series on this topic at <a href=\"http://www.letscodejavascript.com\" rel=\"nofollow\">http://www.letscodejavascript.com</a> (subscription required) and an essay on tooling and workflow at <a href=\"http://www.letscodejavascript.com/v3/blog/2015/02/javascript_tooling\" rel=\"nofollow\">http://www.letscodejavascript.com/v3/blog/2015/02/javascript...</a> (free).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Elitist or reasonable concerns on state of front end development?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-29T15:45:39.000Z",
      "title": null,
      "url": null,
      "author": "ftomassetti",
      "points": null,
      "story_text": null,
      "comment_text": "Well, I am very interested in parsing and static analysis and if you idea and suggestions feel free to open as many tickets as you want on the project.<p>Yes, Hoogle is super cool, it would be definitely useful to have something like that.<p>I wrote in the past tools to manipulate ASTs of several languages but I have never looked in a Scala parser. Can you suggest one?",
      "num_comments": null,
      "story_id": 9458174,
      "story_title": "Show HN: Effective java – A tool to explore your Java code written in Clojure",
      "story_url": "https://github.com/ftomassetti/effectivejava",
      "parent_id": 9459072,
      "created_at_i": 1430322339,
      "_tags": [
        "comment",
        "author_ftomassetti",
        "story_9458174"
      ],
      "objectID": "9459141",
      "_highlightResult": {
        "author": {
          "value": "ftomassetti",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Well, I am very interested in parsing and <em>static</em> <em>analysis</em> and if you idea and suggestions feel free to open as many tickets as you want on the project.<p>Yes, Hoogle is super cool, it would be definitely useful to have something like that.<p>I wrote in the past <em>tools</em> to manipulate ASTs of several languages but I have never looked in a Scala parser. Can you suggest one?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Show HN: Effective java – A tool to explore your Java code written in Clojure",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/ftomassetti/effectivejava",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-28T17:43:43.000Z",
      "title": null,
      "url": null,
      "author": "colomon",
      "points": null,
      "story_text": null,
      "comment_text": "Hmmm?  I&#x27;m not sure what you mean by &quot;books and book packages&quot;, but as a small developer I&#x27;ve certainly bought development tools priced under $100.  That&#x27;s a sort of dividing line for me, though -- I don&#x27;t think I&#x27;ve ever purchased development software priced over $100 unless I absolutely had to.<p>And yeah, Windows-only static analysis software priced at $250 would be a very hard sell for me...",
      "num_comments": null,
      "story_id": 9450743,
      "story_title": "We Are Closing Down the CppCat Project",
      "story_url": "http://www.viva64.com/en/b/0320/",
      "parent_id": 9451497,
      "created_at_i": 1430243023,
      "_tags": [
        "comment",
        "author_colomon",
        "story_9450743"
      ],
      "objectID": "9454023",
      "_highlightResult": {
        "author": {
          "value": "colomon",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Hmmm?  I'm not sure what you mean by &quot;books and book packages&quot;, but as a small developer I've certainly bought development <em>tools</em> priced under $100.  That's a sort of dividing line for me, though -- I don't think I've ever purchased development software priced over $100 unless I absolutely had to.<p>And yeah, Windows-only <em>static</em> <em>analysis</em> software priced at $250 would be a very hard sell for me...",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "We Are Closing Down the CppCat Project",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0320/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-27T16:27:37.000Z",
      "title": null,
      "url": null,
      "author": "ska",
      "points": null,
      "story_text": null,
      "comment_text": "Well, unless I&#x27;ve missed something, it is by definition static analysis -- so that&#x27;s probably a good start.<p>The way I look at it is that every minute you spend discussing a point in a review that could have been caught&#x2F;corrected by a static tool is a minute wasted.  But these tools can&#x27;t do any of the actual work of the review.<p>By the way, linting is a fairly well known term with a long history, but it wouldn&#x27;t surprise me if there are communities that don&#x27;t know the term.",
      "num_comments": null,
      "story_id": 9446080,
      "story_title": "Automated code review for Python, Django, etc.",
      "story_url": "https://www.quantifiedcode.com",
      "parent_id": 9447047,
      "created_at_i": 1430152057,
      "_tags": [
        "comment",
        "author_ska",
        "story_9446080"
      ],
      "objectID": "9447305",
      "_highlightResult": {
        "author": {
          "value": "ska",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Well, unless I've missed something, it is by definition <em>static</em> <em>analysis</em> -- so that's probably a good start.<p>The way I look at it is that every minute you spend discussing a point in a review that could have been caught/corrected by a <em>static</em> tool is a minute wasted.  But these <em>tools</em> can't do any of the actual work of the review.<p>By the way, linting is a fairly well known term with a long history, but it wouldn't surprise me if there are communities that don't know the term.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Automated code review for Python, Django, etc.",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.quantifiedcode.com",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-27T14:42:17.000Z",
      "title": null,
      "url": null,
      "author": "ThePhysicist",
      "points": null,
      "story_text": null,
      "comment_text": "Good point! When asking developers about their use of static code analysis to ensure code quality we found that most development teams use such tools only sporadically or not at all, and just very few teams have a systematic process or set of guidelines for ensuring code quality throughout all of their projects. So while some technologies already exist for this, we definitely think that there&#x27;s room for more.",
      "num_comments": null,
      "story_id": 9446080,
      "story_title": "Automated code review for Python, Django, etc.",
      "story_url": "https://www.quantifiedcode.com",
      "parent_id": 9446477,
      "created_at_i": 1430145737,
      "_tags": [
        "comment",
        "author_ThePhysicist",
        "story_9446080"
      ],
      "objectID": "9446594",
      "_highlightResult": {
        "author": {
          "value": "ThePhysicist",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Good point! When asking developers about their use of <em>static</em> code <em>analysis</em> to ensure code quality we found that most development teams use such <em>tools</em> only sporadically or not at all, and just very few teams have a systematic process or set of guidelines for ensuring code quality throughout all of their projects. So while some technologies already exist for this, we definitely think that there's room for more.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Automated code review for Python, Django, etc.",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.quantifiedcode.com",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-14T21:00:20.000Z",
      "title": null,
      "url": null,
      "author": "conistonwater",
      "points": null,
      "story_text": null,
      "comment_text": "Hi, thanks for replying.<p>&gt; The paper reports overhead numbers from existing research. For instance, see Figure 18 in <a href=\"http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1312.1411\" rel=\"nofollow\">http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1312.1411</a>, which shows the cost of SC for memcached - 1% on x86 and 3% on ARM.<p>But that&#x27;s the bit I don&#x27;t find nearly convincing enough. You say (p.5) that you&#x27;re going to &quot;rebut these arguments&quot; that &quot;SC is too expensive&quot;, but the main figure of 1%&#x2F;3% is from a non-standard research-level static analysis tool that, if I read that paper correctly, works on codes up to 10k LOC and takes a few minutes to run, producing the 1%&#x2F;3% figure. Can that really be generalised? I&#x27;m not quite sure. The other tools in comparison did much worse, which I think <i>may be closer</i> to what one would get in practice. So I think that&#x27;s not a good rebuttal: if you consider the tools actually available SC may well be too expensive.<p>I&#x27;m not saying you&#x27;re wrong, just that I don&#x27;t think you&#x27;ve proven your case very clearly. I was kind of expecting a much clearer rebuttal than I found, sorry about the snark.",
      "num_comments": null,
      "story_id": 9359925,
      "story_title": "The Silently Shifting Semicolon [pdf]",
      "story_url": "http://www.cs.ucla.edu/~todd/research/snapl15.pdf",
      "parent_id": 9372599,
      "created_at_i": 1429045220,
      "_tags": [
        "comment",
        "author_conistonwater",
        "story_9359925"
      ],
      "objectID": "9377314",
      "_highlightResult": {
        "author": {
          "value": "conistonwater",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Hi, thanks for replying.<p>&gt; The paper reports overhead numbers from existing research. For instance, see Figure 18 in <a href=\"http://arxiv.org/abs/1312.1411\" rel=\"nofollow\">http://arxiv.org/abs/1312.1411</a>, which shows the cost of SC for memcached - 1% on x86 and 3% on ARM.<p>But that's the bit I don't find nearly convincing enough. You say (p.5) that you're going to &quot;rebut these arguments&quot; that &quot;SC is too expensive&quot;, but the main figure of 1%/3% is from a non-standard research-level <em>static</em> <em>analysis</em> tool that, if I read that paper correctly, works on codes up to 10k LOC and takes a few minutes to run, producing the 1%/3% figure. Can that really be generalised? I'm not quite sure. The other <em>tools</em> in comparison did much worse, which I think <i>may be closer</i> to what one would get in practice. So I think that's not a good rebuttal: if you consider the <em>tools</em> actually available SC may well be too expensive.<p>I'm not saying you're wrong, just that I don't think you've proven your case very clearly. I was kind of expecting a much clearer rebuttal than I found, sorry about the snark.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The Silently Shifting Semicolon [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.cs.ucla.edu/~todd/research/snapl15.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-20T20:58:40.000Z",
      "title": null,
      "url": null,
      "author": "pbiggar",
      "points": null,
      "story_text": null,
      "comment_text": "I made phc (<a href=\"http://phpcompiler.org\" rel=\"nofollow\">http:&#x2F;&#x2F;phpcompiler.org</a>), which is conceptually similar to HippyVM, before applying to YC. And I got into YC, and now run a post-Series A startup, so I probably have a tiny bit of insight.<p>Trying to sell a PHP compiler is a very bad business plan. In fact, trying to sell any compiler is a very bad business plan, because you&#x27;re basically competing with free. You have to compete against OSS with massive communities (like gcc) or against deep pockets (like Visual Studio) or against reference implementations (like the OSS PHP engine).<p>Imagine trying to sell a PHP compiler. You can try to get wide community adoption and sell bottom-up. Good luck with that, the PHP community is not that interested in tools. So you can try to sell top-down to enterprises with slow PHP problems. Very few companies have slow PHP problems, and those that do could just use HHVM.<p>For 30 years, commercial lisp engines, C++ compilers, Java VMs, and tons of similar things have all been commercially unsuccessful (though not all failed outright). A PHP engine will have to compete with with Facebook&#x27;s HHVM (OSS + deep pockets), against the Zend engine (community adoption + reference implementation) and against Zend corp (a known and established quantity in the space).<p>I spent a bit of time in compiler research and met with tons of compiler companies at events. One of them said that they couldn&#x27;t think of any compiler company that didnt make its money off consulting, and that worse, about 85% of them made their money off a single client.<p>Quick, name a successful compiler company! There aren&#x27;t too many and they weren&#x27;t that famous. There is Coverity in the closely related static analysis space, that sold for $375m. There is Cilk that sold to intel for $100m. Dredging my memory there&#x27;s companies like Anamorphic which was acquihired by Sun in 97 to work on Java.<p>You&#x27;re almost better off being a HHVM consultancy than building a competing compiler and ending\nup having to innovate on the product as well as providing consulting.",
      "num_comments": null,
      "story_id": 9237137,
      "story_title": "HippyVM goes to Y Combinator and fails",
      "story_url": "http://lostinjit.blogspot.com/2015/03/hippyvm-goes-to-y-combinator-and-fails.html",
      "parent_id": 9237137,
      "created_at_i": 1426885120,
      "_tags": [
        "comment",
        "author_pbiggar",
        "story_9237137"
      ],
      "objectID": "9240659",
      "_highlightResult": {
        "author": {
          "value": "pbiggar",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I made phc (<a href=\"http://phpcompiler.org\" rel=\"nofollow\">http://phpcompiler.org</a>), which is conceptually similar to HippyVM, before applying to YC. And I got into YC, and now run a post-Series A startup, so I probably have a tiny bit of insight.<p>Trying to sell a PHP compiler is a very bad business plan. In fact, trying to sell any compiler is a very bad business plan, because you're basically competing with free. You have to compete against OSS with massive communities (like gcc) or against deep pockets (like Visual Studio) or against reference implementations (like the OSS PHP engine).<p>Imagine trying to sell a PHP compiler. You can try to get wide community adoption and sell bottom-up. Good luck with that, the PHP community is not that interested in <em>tools</em>. So you can try to sell top-down to enterprises with slow PHP problems. Very few companies have slow PHP problems, and those that do could just use HHVM.<p>For 30 years, commercial lisp engines, C++ compilers, Java VMs, and tons of similar things have all been commercially unsuccessful (though not all failed outright). A PHP engine will have to compete with with Facebook's HHVM (OSS + deep pockets), against the Zend engine (community adoption + reference implementation) and against Zend corp (a known and established quantity in the space).<p>I spent a bit of time in compiler research and met with tons of compiler companies at events. One of them said that they couldn't think of any compiler company that didnt make its money off consulting, and that worse, about 85% of them made their money off a single client.<p>Quick, name a successful compiler company! There aren't too many and they weren't that famous. There is Coverity in the closely related <em>static</em> <em>analysis</em> space, that sold for $375m. There is Cilk that sold to intel for $100m. Dredging my memory there's companies like Anamorphic which was acquihired by Sun in 97 to work on Java.<p>You're almost better off being a HHVM consultancy than building a competing compiler and ending\nup having to innovate on the product as well as providing consulting.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "HippyVM goes to Y Combinator and fails",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lostinjit.blogspot.com/2015/03/hippyvm-goes-to-y-combinator-and-fails.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-20T17:27:06.000Z",
      "title": null,
      "url": null,
      "author": "SCHiM",
      "points": null,
      "story_text": null,
      "comment_text": "@GP<p>4. By using various forms static&#x2F;dynamic analysis (taint analysis, fault propagation, fault injection).<p>5. By fuzz-testing the software.<p>Taint analysis is looking at which registers&#x2F;memory locations you have access to. You inject data into a process and then check where in memory that data shows up, which execution branches are taken, which registers are used with the data, what the stack does, etc.<p>Fault propagation looks at where errors and faults are handled and how they are handled. The idea is to get a good idea of how a process manages errors and then find an error that is not handled (correctly).<p>Fault injection is injecting errors into a process and then watch the fireworks. Think of this as the brute-force approach to fault propagation analysis.<p>Fuzz testing is bombarding the process with semi-valid&#x2F;semi-random input and watching what happens. There are many tools with this. Example output for browser-fuzzing could look like this:<p>&lt;html&gt;&gt;style=&quot;\\&gt;&gt;overflow:none&quot;&gt;&lt;&#x2F;body&gt;&lt;html&gt;<p>Obviously none of today&#x27;s browsers would be exploited by that, but with mutli-threaded rendering, memory management, javascript reading&#x2F;writing html and all that stuff going on at the same time it&#x27;s not surprising that fuzz testing can turn up lots of errors (though not all exploitable).",
      "num_comments": null,
      "story_id": 9238639,
      "story_title": "All Major Browsers Fall at Pwn2Own Day Two",
      "story_url": "https://threatpost.com/all-major-browsers-fall-at-pwn2own-day-2/111731",
      "parent_id": 9238940,
      "created_at_i": 1426872426,
      "_tags": [
        "comment",
        "author_SCHiM",
        "story_9238639"
      ],
      "objectID": "9239121",
      "_highlightResult": {
        "author": {
          "value": "SCHiM",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "@GP<p>4. By using various forms <em>static</em>/dynamic <em>analysis</em> (taint <em>analysis</em>, fault propagation, fault injection).<p>5. By fuzz-testing the software.<p>Taint <em>analysis</em> is looking at which registers/memory locations you have access to. You inject data into a process and then check where in memory that data shows up, which execution branches are taken, which registers are used with the data, what the stack does, etc.<p>Fault propagation looks at where errors and faults are handled and how they are handled. The idea is to get a good idea of how a process manages errors and then find an error that is not handled (correctly).<p>Fault injection is injecting errors into a process and then watch the fireworks. Think of this as the brute-force approach to fault propagation <em>analysis.</em><p>Fuzz testing is bombarding the process with semi-valid/semi-random input and watching what happens. There are many <em>tools</em> with this. Example output for browser-fuzzing could look like this:<p>&lt;html&gt;&gt;style=&quot;\\&gt;&gt;overflow:none&quot;&gt;&lt;/body&gt;&lt;html&gt;<p>Obviously none of today's browsers would be exploited by that, but with mutli-threaded rendering, memory management, javascript reading/writing html and all that stuff going on at the same time it's not surprising that fuzz testing can turn up lots of errors (though not all exploitable).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "All Major Browsers Fall at Pwn2Own Day Two",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://threatpost.com/all-major-browsers-fall-at-pwn2own-day-2/111731",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-20T17:04:34.000Z",
      "title": null,
      "url": null,
      "author": "diminoten",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; Using an out-of-bounds read&#x2F;write vulnerability he claims he found through static analysis, ilxu1a’s attack led to medium-integrity code execution in what ZDI called “sub-seconds,” earning $15,000.<p>Looks like some code analysis tools helped for one researcher.",
      "num_comments": null,
      "story_id": 9238639,
      "story_title": "All Major Browsers Fall at Pwn2Own Day Two",
      "story_url": "https://threatpost.com/all-major-browsers-fall-at-pwn2own-day-2/111731",
      "parent_id": 9238829,
      "created_at_i": 1426871074,
      "_tags": [
        "comment",
        "author_diminoten",
        "story_9238639"
      ],
      "objectID": "9238867",
      "_highlightResult": {
        "author": {
          "value": "diminoten",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; Using an out-of-bounds read/write vulnerability he claims he found through <em>static</em> <em>analysis</em>, ilxu1a’s attack led to medium-integrity code execution in what ZDI called “sub-seconds,” earning $15,000.<p>Looks like some code <em>analysis</em> <em>tools</em> helped for one researcher.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "All Major Browsers Fall at Pwn2Own Day Two",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://threatpost.com/all-major-browsers-fall-at-pwn2own-day-2/111731",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-07T22:41:23.000Z",
      "title": null,
      "url": null,
      "author": "hmsimha",
      "points": null,
      "story_text": null,
      "comment_text": "Rubocop is an absolute pleasure to work with, but it also helps that the ruby community seems to have a more widely-agreed upon style guide than other communities (Javascript comes to mind). There are similar tools for Javascript, and I imagine many of them are configurable as well to cover most use cases. But with the diversity of Javascript style guides and the lack of cohesiveness in the js community, it seems unlikely that many of these would be as useful as rubocop &#x27;out-of-the-box&#x27;.<p>It would be <i>amazing</i> if a similar static code analysis tool existed with settings to conform to the most popular javascript style guides: npm, idiomatic, jQuery, etc. But even within these style guides there is a lot of &#x27;undefined behavior&#x27;, or situations that aren&#x27;t explicitly described in the guides.",
      "num_comments": null,
      "story_id": 9162711,
      "story_title": "RuboCop – A Ruby static code analyzer",
      "story_url": "http://batsov.com/rubocop/",
      "parent_id": 9162711,
      "created_at_i": 1425768083,
      "_tags": [
        "comment",
        "author_hmsimha",
        "story_9162711"
      ],
      "objectID": "9163381",
      "_highlightResult": {
        "author": {
          "value": "hmsimha",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Rubocop is an absolute pleasure to work with, but it also helps that the ruby community seems to have a more widely-agreed upon style guide than other communities (Javascript comes to mind). There are similar <em>tools</em> for Javascript, and I imagine many of them are configurable as well to cover most use cases. But with the diversity of Javascript style guides and the lack of cohesiveness in the js community, it seems unlikely that many of these would be as useful as rubocop 'out-of-the-box'.<p>It would be <i>amazing</i> if a similar <em>static</em> code <em>analysis</em> tool existed with settings to conform to the most popular javascript style guides: npm, idiomatic, jQuery, etc. But even within these style guides there is a lot of 'undefined behavior', or situations that aren't explicitly described in the guides.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "RuboCop – A Ruby <em>static</em> code analyzer",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "http://batsov.com/rubocop/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-03T13:29:07.000Z",
      "title": null,
      "url": null,
      "author": "taspeotis",
      "points": null,
      "story_text": null,
      "comment_text": "Microsoft&#x27;s code quality evangelism pains me a bit. With one hand they publish articles like this and add tools to Visual Studio to help with code quality (e.g. adding static code analysis to VS2012 Express and later). And with the other hand they go &quot;haha fuck you&quot; and arbitrarily lock out some code quality tools unless you&#x27;re using Visual Studio Ultimate. (my Visual Studio with MSDN Premium isn&#x27;t enough, it seems.)<p>&quot;Smart Unit Tests&quot; [1] is the most recent in a long list of things tucked away in Ultimate.<p>[1] <a href=\"https://msdn.microsoft.com/library/dn823749(v=vs.140).aspx\" rel=\"nofollow\">https:&#x2F;&#x2F;msdn.microsoft.com&#x2F;library&#x2F;dn823749(v=vs.140).aspx</a>",
      "num_comments": null,
      "story_id": 9137014,
      "story_title": "Solving Likely Problems in Your Multithreaded Code",
      "story_url": "https://msdn.microsoft.com/en-us/magazine/cc817398.aspx",
      "parent_id": 9137014,
      "created_at_i": 1425389347,
      "_tags": [
        "comment",
        "author_taspeotis",
        "story_9137014"
      ],
      "objectID": "9137511",
      "_highlightResult": {
        "author": {
          "value": "taspeotis",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Microsoft's code quality evangelism pains me a bit. With one hand they publish articles like this and add <em>tools</em> to Visual Studio to help with code quality (e.g. adding <em>static</em> code <em>analysis</em> to VS2012 Express and later). And with the other hand they go &quot;haha fuck you&quot; and arbitrarily lock out some code quality <em>tools</em> unless you're using Visual Studio Ultimate. (my Visual Studio with MSDN Premium isn't enough, it seems.)<p>&quot;Smart Unit Tests&quot; [1] is the most recent in a long list of things tucked away in Ultimate.<p>[1] <a href=\"https://msdn.microsoft.com/library/dn823749(v=vs.140).aspx\" rel=\"nofollow\">https://msdn.microsoft.com/library/dn823749(v=vs.140).aspx</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Solving Likely Problems in Your Multithreaded Code",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://msdn.microsoft.com/en-us/magazine/cc817398.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-24T04:27:41.000Z",
      "title": null,
      "url": null,
      "author": "abfan1127",
      "points": null,
      "story_text": null,
      "comment_text": "TCL is the defacto language in EDA ASIC Design Tools (synthesis, place-and-route, static timing analysis). In my opinion, its a terrible language, especially since the tool vendors all add their own flavors. The flow control is painful to use, it lacks OOP data structures. If given the opportunity, I&#x27;d avoid it at all costs.",
      "num_comments": null,
      "story_id": 9098617,
      "story_title": "What is Tcl?",
      "story_url": "http://wiki.tcl.tk/299",
      "parent_id": 9098617,
      "created_at_i": 1424752061,
      "_tags": [
        "comment",
        "author_abfan1127",
        "story_9098617"
      ],
      "objectID": "9098680",
      "_highlightResult": {
        "author": {
          "value": "abfan1127",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "TCL is the defacto language in EDA ASIC Design <em>Tools</em> (synthesis, place-and-route, <em>static</em> timing <em>analysis</em>). In my opinion, its a terrible language, especially since the tool vendors all add their own flavors. The flow control is painful to use, it lacks OOP data structures. If given the opportunity, I'd avoid it at all costs.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What is Tcl?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://wiki.tcl.tk/299",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-12T18:30:48.000Z",
      "title": null,
      "url": null,
      "author": "MrDosu",
      "points": null,
      "story_text": null,
      "comment_text": "I would (almost) completely disagree with this.<p>C++ support in VS is horrible, that&#x27;s correct, but having the ability to be supported by compiler services that can parse (invalid) code is a major milestone when it comes to handling more complex codebases.<p>It does not matter how smart you are, the easier it is for you to understand and reason about the code, the more will fit in your head.<p>Refactoring is just one of the many amazing tools that make me a much better and more productive programmer today then I was without when using vi in the 90s. Add in static analysis, intellisense etc... Every bit of complexity that tooling can hide from you is worth gold.<p>Reality for C++ is grim though in this regard. Let&#x27;s hope we get better compiler services for it soon.",
      "num_comments": null,
      "story_id": 9037151,
      "story_title": "The bell has tolled for rand()",
      "story_url": "http://cpp.indi.frih.net/blog/2014/12/the-bell-has-tolled-for-rand/",
      "parent_id": 9039678,
      "created_at_i": 1423765848,
      "_tags": [
        "comment",
        "author_MrDosu",
        "story_9037151"
      ],
      "objectID": "9040383",
      "_highlightResult": {
        "author": {
          "value": "MrDosu",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I would (almost) completely disagree with this.<p>C++ support in VS is horrible, that's correct, but having the ability to be supported by compiler services that can parse (invalid) code is a major milestone when it comes to handling more complex codebases.<p>It does not matter how smart you are, the easier it is for you to understand and reason about the code, the more will fit in your head.<p>Refactoring is just one of the many amazing <em>tools</em> that make me a much better and more productive programmer today then I was without when using vi in the 90s. Add in <em>static</em> <em>analysis</em>, intellisense etc... Every bit of complexity that tooling can hide from you is worth gold.<p>Reality for C++ is grim though in this regard. Let's hope we get better compiler services for it soon.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "The bell has tolled for rand()",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cpp.indi.frih.net/blog/2014/12/the-bell-has-tolled-for-rand/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-12T12:46:03.000Z",
      "title": null,
      "url": null,
      "author": "irungentoo",
      "points": null,
      "story_text": null,
      "comment_text": "First of all the choice of C is because it was the language I was the most confidant writing secure code in. I&#x27;m not going to learn a new language and then right away start try to write secure code with it.<p>Clang has some great tools I use like the various sanitizers. Static analysis sucks and almost never finds any real issues but we still use it.<p>If you think toxcore should use protocol buffers, feel free to port it. This is an open source project and contributions are welcome. If you do a better job than me then I will merge your contribution. We are at #tox-dev on freenode.",
      "num_comments": null,
      "story_id": 9036550,
      "story_title": "Toxic – A distributed, secure, command-line based instant messenging client",
      "story_url": "https://github.com/Tox/toxic",
      "parent_id": 9037221,
      "created_at_i": 1423745163,
      "_tags": [
        "comment",
        "author_irungentoo",
        "story_9036550"
      ],
      "objectID": "9038516",
      "_highlightResult": {
        "author": {
          "value": "irungentoo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "First of all the choice of C is because it was the language I was the most confidant writing secure code in. I'm not going to learn a new language and then right away start try to write secure code with it.<p>Clang has some great <em>tools</em> I use like the various sanitizers. <em>Static</em> <em>analysis</em> sucks and almost never finds any real issues but we still use it.<p>If you think toxcore should use protocol buffers, feel free to port it. This is an open source project and contributions are welcome. If you do a better job than me then I will merge your contribution. We are at #tox-dev on freenode.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Toxic – A distributed, secure, command-line based instant messenging client",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/Tox/toxic",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-12T03:32:30.000Z",
      "title": null,
      "url": null,
      "author": "jbangert",
      "points": null,
      "story_text": null,
      "comment_text": "My one experience with the Tox project was that I made a few (I thought) constructive suggestions. First, I suggested they use some form of static analysis or perhaps a &#x27;safer&#x27; language to implement their core functionality - such as Rust or Go, instead of rather messy (at the time) C code.<p>Furthermore, having spent a lot of time researching parsers and how parser differentials can affect the security of systems, I suggested they use some tools, such as protocol buffers, to eliminate handwritten parsing code. The response I got was rather disheartening and downright hostile - it boiled down to the fact that protocol buffers involves C++ code which they are a priori against, without actually engaging in a factual argument  (I wrote an article in the current USENIX login&#x2F; last years OSDI about parsers for binary protocols  for anyone interested in background: <a href=\"https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-bangert.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;conference&#x2F;osdi14&#x2F;osdi14...</a> and github.com&#x2F;jbangert&#x2F;nail)",
      "num_comments": null,
      "story_id": 9036550,
      "story_title": "Toxic – A distributed, secure, command-line based instant messenging client",
      "story_url": "https://github.com/Tox/toxic",
      "parent_id": 9036550,
      "created_at_i": 1423711950,
      "_tags": [
        "comment",
        "author_jbangert",
        "story_9036550"
      ],
      "objectID": "9037221",
      "_highlightResult": {
        "author": {
          "value": "jbangert",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "My one experience with the Tox project was that I made a few (I thought) constructive suggestions. First, I suggested they use some form of <em>static</em> <em>analysis</em> or perhaps a 'safer' language to implement their core functionality - such as Rust or Go, instead of rather messy (at the time) C code.<p>Furthermore, having spent a lot of time researching parsers and how parser differentials can affect the security of systems, I suggested they use some <em>tools</em>, such as protocol buffers, to eliminate handwritten parsing code. The response I got was rather disheartening and downright hostile - it boiled down to the fact that protocol buffers involves C++ code which they are a priori against, without actually engaging in a factual argument  (I wrote an article in the current USENIX login/ last years OSDI about parsers for binary protocols  for anyone interested in background: <a href=\"https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-bangert.pdf\" rel=\"nofollow\">https://www.usenix.org/system/files/conference/osdi14/osdi14...</a> and github.com/jbangert/nail)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Toxic – A distributed, secure, command-line based instant messenging client",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/Tox/toxic",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-02-06T07:47:27.000Z",
      "title": null,
      "url": null,
      "author": "mng2",
      "points": null,
      "story_text": null,
      "comment_text": "What are you guys doing for physical verification, static timing analysis, stuff like that? As far as I know those tools still cost big bucks.",
      "num_comments": null,
      "story_id": 9004705,
      "story_title": "YC for Hardware",
      "story_url": "http://blog.ycombinator.com/yc-for-hardware",
      "parent_id": 9007150,
      "created_at_i": 1423208847,
      "_tags": [
        "comment",
        "author_mng2",
        "story_9004705"
      ],
      "objectID": "9008066",
      "_highlightResult": {
        "author": {
          "value": "mng2",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "What are you guys doing for physical verification, <em>static</em> timing <em>analysis</em>, stuff like that? As far as I know those <em>tools</em> still cost big bucks.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "YC for Hardware",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.ycombinator.com/yc-for-hardware",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-27T16:25:23.000Z",
      "title": null,
      "url": null,
      "author": "fundamental",
      "points": null,
      "story_text": null,
      "comment_text": "So far I haven&#x27;t used much manual code review, but I do use static code analysis to find possible bugs once in a while.<p>Up until recently a big pain point for me was finding code which could block within a time constrained function (aka realtime safety). There weren&#x27;t any tools out there, so I ended up making one with llvm named stoat[1] (originally static function property verification, sfpv). It&#x27;s hard to say if this tool would really have wider usefulness as it essentially is just checking function attributes on the transitive closure of the callgraph, but it works for me.<p>[1] <a href=\"https://github.com/fundamental/stoat\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;fundamental&#x2F;stoat</a>",
      "num_comments": null,
      "story_id": 8951467,
      "story_title": "Manual code review and static code analysis tools",
      "story_url": "",
      "parent_id": 8951467,
      "created_at_i": 1422375923,
      "_tags": [
        "comment",
        "author_fundamental",
        "story_8951467"
      ],
      "objectID": "8953920",
      "_highlightResult": {
        "author": {
          "value": "fundamental",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "So far I haven't used much manual code review, but I do use <em>static</em> code <em>analysis</em> to find possible bugs once in a while.<p>Up until recently a big pain point for me was finding code which could block within a time constrained function (aka realtime safety). There weren't any <em>tools</em> out there, so I ended up making one with llvm named stoat[1] (originally <em>static</em> function property verification, sfpv). It's hard to say if this tool would really have wider usefulness as it essentially is just checking function attributes on the transitive closure of the callgraph, but it works for me.<p>[1] <a href=\"https://github.com/fundamental/stoat\" rel=\"nofollow\">https://github.com/fundamental/stoat</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Manual code review and <em>static</em> code <em>analysis</em> <em>tools</em>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-27T09:57:20.000Z",
      "title": null,
      "url": null,
      "author": "andersonvieira",
      "points": null,
      "story_text": null,
      "comment_text": "Where I work we use SonarQube [1] for static code analysis. You can customize specific rule profiles for different projects and in the site they say it&#x27;s available for many programming languages [2]. We only use it for Java so I don&#x27;t know how good is the support for the other languages listed.<p>My experience with these tools is that they are a great way to see how the code evolves during a project, help you keep it clean in maintenance mode, and may even teach you a couple of things about good coding practices. Just don&#x27;t let it fall into the hands of management. They will love all those metrics and graphs, and soon enough you will have goals and performance reviews based on it.<p>[1] <a href=\"http://www.sonarqube.org\" rel=\"nofollow\">http:&#x2F;&#x2F;www.sonarqube.org</a><p>[2] <a href=\"http://docs.sonarqube.org/display/SONAR/Plugin+Library\" rel=\"nofollow\">http:&#x2F;&#x2F;docs.sonarqube.org&#x2F;display&#x2F;SONAR&#x2F;Plugin+Library</a>",
      "num_comments": null,
      "story_id": 8951467,
      "story_title": "Manual code review and static code analysis tools",
      "story_url": "",
      "parent_id": 8951467,
      "created_at_i": 1422352640,
      "_tags": [
        "comment",
        "author_andersonvieira",
        "story_8951467"
      ],
      "objectID": "8952218",
      "_highlightResult": {
        "author": {
          "value": "andersonvieira",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Where I work we use SonarQube [1] for <em>static</em> code <em>analysis.</em> You can customize specific rule profiles for different projects and in the site they say it's available for many programming languages [2]. We only use it for Java so I don't know how good is the support for the other languages listed.<p>My experience with these <em>tools</em> is that they are a great way to see how the code evolves during a project, help you keep it clean in maintenance mode, and may even teach you a couple of things about good coding practices. Just don't let it fall into the hands of management. They will love all those metrics and graphs, and soon enough you will have goals and performance reviews based on it.<p>[1] <a href=\"http://www.sonarqube.org\" rel=\"nofollow\">http://www.sonarqube.org</a><p>[2] <a href=\"http://docs.sonarqube.org/display/SONAR/Plugin+Library\" rel=\"nofollow\">http://docs.sonarqube.org/display/SONAR/Plugin+Library</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Manual code review and <em>static</em> code <em>analysis</em> <em>tools</em>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-22T13:20:22.000Z",
      "title": null,
      "url": null,
      "author": "ObviousScience",
      "points": null,
      "story_text": null,
      "comment_text": "&gt;  The idea of having tools to parse and rewrite my code to be as generic as possible came to me years ago.<p>You basically want an obfuscator that replaces all the names of things with generics, and then randomly permutes blocks of code without changing the code paths possible in the final binary. (Perhaps some optimized-for-performance version of this, but that might identify the tool you use.)<p>It sounds relatively easy to write if you stick to certain coding guidelines (like using techniques amenable to static analysis).<p>However, this still won&#x27;t work in some cases, because you&#x27;d need more advanced tools to handle profiling of what sized functions and such you ended up writing.<p>It would be interesting to try and write a tool which defeated any analysis of author patterns in the code, but would require understanding the program across the boundary of function calls, which is a difficult problem. (You probably couldn&#x27;t write Turing complete code, for example.)",
      "num_comments": null,
      "story_id": 8925597,
      "story_title": "Anonymous programmers can be identified by analyzing coding style",
      "story_url": "https://freedom-to-tinker.com/blog/aylin/anonymous-programmers-can-be-identified-by-analyzing-coding-style/",
      "parent_id": 8927569,
      "created_at_i": 1421932822,
      "_tags": [
        "comment",
        "author_ObviousScience",
        "story_8925597"
      ],
      "objectID": "8928972",
      "_highlightResult": {
        "author": {
          "value": "ObviousScience",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;  The idea of having <em>tools</em> to parse and rewrite my code to be as generic as possible came to me years ago.<p>You basically want an obfuscator that replaces all the names of things with generics, and then randomly permutes blocks of code without changing the code paths possible in the final binary. (Perhaps some optimized-for-performance version of this, but that might identify the tool you use.)<p>It sounds relatively easy to write if you stick to certain coding guidelines (like using techniques amenable to <em>static</em> <em>analysis</em>).<p>However, this still won't work in some cases, because you'd need more advanced <em>tools</em> to handle profiling of what sized functions and such you ended up writing.<p>It would be interesting to try and write a tool which defeated any <em>analysis</em> of author patterns in the code, but would require understanding the program across the boundary of function calls, which is a difficult problem. (You probably couldn't write Turing complete code, for example.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Anonymous programmers can be identified by analyzing coding style",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://freedom-to-tinker.com/blog/aylin/anonymous-programmers-can-be-identified-by-analyzing-coding-style/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-12T21:34:20.000Z",
      "title": null,
      "url": null,
      "author": "mfocaraccio",
      "points": null,
      "story_text": null,
      "comment_text": "Pretty interesting! Besides static code analysis, do you use any tool to manage manual code review, functional testing and integrations with deployment and task&#x2F;issues management tools?",
      "num_comments": null,
      "story_id": 8876356,
      "story_title": "How do you manage the code quality of your projects?",
      "story_url": "",
      "parent_id": 8876519,
      "created_at_i": 1421098460,
      "_tags": [
        "comment",
        "author_mfocaraccio",
        "story_8876356"
      ],
      "objectID": "8876564",
      "_highlightResult": {
        "author": {
          "value": "mfocaraccio",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Pretty interesting! Besides <em>static</em> code <em>analysis</em>, do you use any tool to manage manual code review, functional testing and integrations with deployment and task/issues management <em>tools</em>?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How do you manage the code quality of your projects?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-08T21:20:30.000Z",
      "title": null,
      "url": null,
      "author": "nullc",
      "points": null,
      "story_text": null,
      "comment_text": "&quot;these bugs, as a class&quot;<p>It absolutely would not eliminate CVE-2014-3570 or many other of the cryptographic bugs that show up in OpenSSL and other TLS implementations.<p>This kind of axiomatic thinking that memory safety equals all safety almost resulted in Rust being less safe (IMO) than C in these other respects: the normal types in rust are all defined to overflow even though overflow is almost always a bug, and so you couldn&#x27;t use static analysis on arbitrary rust codebases to warn you about these issues (where you can in C because signed overflow is undefined, so an analysis tool can always flag that as an error without it being a false positive).  Fortunately, it sounds like Rust is moving to fix this ( <a href=\"http://discuss.rust-lang.org/t/a-tale-of-twos-complement/1062\" rel=\"nofollow\">http:&#x2F;&#x2F;discuss.rust-lang.org&#x2F;t&#x2F;a-tale-of-twos-complement&#x2F;106...</a> ), which is a big improvement.<p>But it&#x27;s important to not be fuzzy about the risks. There is a well established link between safety equipment and risky behavior in driving and bicycling; (<a href=\"http://en.wikipedia.org/wiki/Risk_compensation\" rel=\"nofollow\">http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Risk_compensation</a>). I don&#x27;t mean to suggest that better isn&#x27;t better and we shouldn&#x27;t use safer tools, but if our response to safer tools is to lower our vigilance, even the slightest, we may get worse results.",
      "num_comments": null,
      "story_id": 8856717,
      "story_title": "OpenSSL Security Advisory",
      "story_url": "https://www.openssl.org/news/secadv_20150108.txt",
      "parent_id": 8858860,
      "created_at_i": 1420752030,
      "_tags": [
        "comment",
        "author_nullc",
        "story_8856717"
      ],
      "objectID": "8859089",
      "_highlightResult": {
        "author": {
          "value": "nullc",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&quot;these bugs, as a class&quot;<p>It absolutely would not eliminate CVE-2014-3570 or many other of the cryptographic bugs that show up in OpenSSL and other TLS implementations.<p>This kind of axiomatic thinking that memory safety equals all safety almost resulted in Rust being less safe (IMO) than C in these other respects: the normal types in rust are all defined to overflow even though overflow is almost always a bug, and so you couldn't use <em>static</em> <em>analysis</em> on arbitrary rust codebases to warn you about these issues (where you can in C because signed overflow is undefined, so an <em>analysis</em> tool can always flag that as an error without it being a false positive).  Fortunately, it sounds like Rust is moving to fix this ( <a href=\"http://discuss.rust-lang.org/t/a-tale-of-twos-complement/1062\" rel=\"nofollow\">http://discuss.rust-lang.org/t/a-tale-of-twos-complement/106...</a> ), which is a big improvement.<p>But it's important to not be fuzzy about the risks. There is a well established link between safety equipment and risky behavior in driving and bicycling; (<a href=\"http://en.wikipedia.org/wiki/Risk_compensation\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Risk_compensation</a>). I don't mean to suggest that better isn't better and we shouldn't use safer <em>tools</em>, but if our response to safer <em>tools</em> is to lower our vigilance, even the slightest, we may get worse results.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "OpenSSL Security Advisory",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.openssl.org/news/secadv_20150108.txt",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-08T16:54:52.000Z",
      "title": null,
      "url": null,
      "author": "fat0wl",
      "points": null,
      "story_text": null,
      "comment_text": "yeah I agree #8 in particular should elicit a lot more debate in the js community. Back when I used to be into RoR I would get a ton of flack in interviews for writing pure js rather than Coffeescript, pure css rather than Sass.<p>There are legitimate cases where a pre-processor is useful (Coffeescript demos show several cases where a lot of code can be simplified) but unless you are writing a math&#x2F;list-heavy app, I feel these advantages don&#x27;t apply so much. I don&#x27;t perceive a need for these tools in most projects that are about dom manipulation, it can instead be achieved through pure libs (jQuery) which will eliminate a build step and should allow for some easier testing.<p>This is a fundamental programming debate that I don&#x27;t see a lot of discussion of... since I like CLojure I see some talk of how &quot;transparent&quot; it is as a wrapper over JVM types but a lot of the pre-processor style of transcompilers gloss over this idea (I guess just preferring 2 independent stages of static&#x2F;lint analysis?).",
      "num_comments": null,
      "story_id": 8856226,
      "story_title": "Applying NASA coding standards to JavaScript",
      "story_url": "http://pixelscommander.com/en/javascript/nasa-coding-standarts-for-javascript-performance/",
      "parent_id": 8856696,
      "created_at_i": 1420736092,
      "_tags": [
        "comment",
        "author_fat0wl",
        "story_8856226"
      ],
      "objectID": "8857247",
      "_highlightResult": {
        "author": {
          "value": "fat0wl",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "yeah I agree #8 in particular should elicit a lot more debate in the js community. Back when I used to be into RoR I would get a ton of flack in interviews for writing pure js rather than Coffeescript, pure css rather than Sass.<p>There are legitimate cases where a pre-processor is useful (Coffeescript demos show several cases where a lot of code can be simplified) but unless you are writing a math/list-heavy app, I feel these advantages don't apply so much. I don't perceive a need for these <em>tools</em> in most projects that are about dom manipulation, it can instead be achieved through pure libs (jQuery) which will eliminate a build step and should allow for some easier testing.<p>This is a fundamental programming debate that I don't see a lot of discussion of... since I like CLojure I see some talk of how &quot;transparent&quot; it is as a wrapper over JVM types but a lot of the pre-processor style of transcompilers gloss over this idea (I guess just preferring 2 independent stages of <em>static</em>/lint <em>analysis</em>?).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Applying NASA coding standards to JavaScript",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pixelscommander.com/en/javascript/nasa-coding-standarts-for-javascript-performance/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-15T21:21:38.000Z",
      "title": null,
      "url": null,
      "author": "lnanek2",
      "points": null,
      "story_text": null,
      "comment_text": "That&#x27;s pretty cool. There are a <i>lot</i> of tools, both public and private at companies kept as trade secrets to do static analysis of code to pin point potential errors, memory leaks, etc.. This is the first analysis I&#x27;ve seen that actually looks at more than one revision of a project in source control, though. Every other tool basically just analyzes one revision at a time.",
      "num_comments": null,
      "story_id": 8753174,
      "story_title": "Evolutionary couplings between files reveal poor software design choices",
      "story_url": "http://ergoso.me/computer/science/github/software/evolutionary/couplings/2014/12/10/evsrc-evolutionary-couplings-reveal-poor-software-design.html",
      "parent_id": 8753174,
      "created_at_i": 1418678498,
      "_tags": [
        "comment",
        "author_lnanek2",
        "story_8753174"
      ],
      "objectID": "8754540",
      "_highlightResult": {
        "author": {
          "value": "lnanek2",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's pretty cool. There are a <i>lot</i> of <em>tools</em>, both public and private at companies kept as trade secrets to do <em>static</em> <em>analysis</em> of code to pin point potential errors, memory leaks, etc.. This is the first <em>analysis</em> I've seen that actually looks at more than one revision of a project in source control, though. Every other tool basically just analyzes one revision at a time.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Evolutionary couplings between files reveal poor software design choices",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://ergoso.me/computer/science/github/software/evolutionary/couplings/2014/12/10/evsrc-evolutionary-couplings-reveal-poor-software-design.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-11T15:17:06.000Z",
      "title": null,
      "url": null,
      "author": "couchand",
      "points": null,
      "story_text": null,
      "comment_text": "My attitude towards developer tooling tends to be: build the tools first for the experts, and second make sure the are learnable.  I can&#x27;t stand professional tools that are built primarily for new users.  Englebart&#x27;s violin [0] and all that.<p>That said, it might be the case that removing the responsibility of versioning from experts would make them less concerned about the ramifications, and less likely to notice when they make a change like this one (well not this one exactly, but one similar but more reasonable).<p>You really do need tests in addition to static analysis to be sure of these things.<p>[0]: <a href=\"http://www.loper-os.org/?p=861\" rel=\"nofollow\">http:&#x2F;&#x2F;www.loper-os.org&#x2F;?p=861</a>",
      "num_comments": null,
      "story_id": 8729714,
      "story_title": "Elm 0.14 – Simpler Core, Better Tools",
      "story_url": "http://elm-lang.org/blog/announce/0.14.elm",
      "parent_id": 8734174,
      "created_at_i": 1418311026,
      "_tags": [
        "comment",
        "author_couchand",
        "story_8729714"
      ],
      "objectID": "8735151",
      "_highlightResult": {
        "author": {
          "value": "couchand",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "My attitude towards developer tooling tends to be: build the <em>tools</em> first for the experts, and second make sure the are learnable.  I can't stand professional <em>tools</em> that are built primarily for new users.  Englebart's violin [0] and all that.<p>That said, it might be the case that removing the responsibility of versioning from experts would make them less concerned about the ramifications, and less likely to notice when they make a change like this one (well not this one exactly, but one similar but more reasonable).<p>You really do need tests in addition to <em>static</em> <em>analysis</em> to be sure of these things.<p>[0]: <a href=\"http://www.loper-os.org/?p=861\" rel=\"nofollow\">http://www.loper-os.org/?p=861</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Elm 0.14 – Simpler Core, Better <em>Tools</em>",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "http://elm-lang.org/blog/announce/0.14.elm",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-05T16:45:19.000Z",
      "title": null,
      "url": null,
      "author": "nwah1",
      "points": null,
      "story_text": null,
      "comment_text": "Silverlight, from a development standpoint, was actually pretty great. You could write code in .NET with an infinitely customizable vector-based user interface, defined in a clean and consistent XML-based markup language. It could run in a browser, and even on a Mac.<p>You could develop using all the powerful Visual Studio tooling. It didn&#x27;t crash all the time like Flash.<p>Using Silverlight and XAML was sort of like what I imagine web programming will be like in about 10 years. Except that you could do it back in 2007.<p>You have a high level language (C#) with reusable components (UserControls) and fantastic debugging, profiling, static analysis, and automatic refactoring.<p>Incidentally, that is where the web is just now heading. Higher level and strongly-typed languages (AtScript, Typescript, Flow, ES6+) with reusable components (Web Components) and better tooling (Firefox and Chrome dev tools)",
      "num_comments": null,
      "story_id": 8701852,
      "story_title": "Introducing .NET Core",
      "story_url": "http://blogs.msdn.com/b/dotnet/archive/2014/12/04/introducing-net-core.aspx",
      "parent_id": 8703095,
      "created_at_i": 1417797919,
      "_tags": [
        "comment",
        "author_nwah1",
        "story_8701852"
      ],
      "objectID": "8705388",
      "_highlightResult": {
        "author": {
          "value": "nwah1",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Silverlight, from a development standpoint, was actually pretty great. You could write code in .NET with an infinitely customizable vector-based user interface, defined in a clean and consistent XML-based markup language. It could run in a browser, and even on a Mac.<p>You could develop using all the powerful Visual Studio tooling. It didn't crash all the time like Flash.<p>Using Silverlight and XAML was sort of like what I imagine web programming will be like in about 10 years. Except that you could do it back in 2007.<p>You have a high level language (C#) with reusable components (UserControls) and fantastic debugging, profiling, <em>static</em> <em>analysis</em>, and automatic refactoring.<p>Incidentally, that is where the web is just now heading. Higher level and strongly-typed languages (AtScript, Typescript, Flow, ES6+) with reusable components (Web Components) and better tooling (Firefox and Chrome dev <em>tools</em>)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Introducing .NET Core",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.msdn.com/b/dotnet/archive/2014/12/04/introducing-net-core.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-19T19:06:51.000Z",
      "title": null,
      "url": null,
      "author": "Animats",
      "points": null,
      "story_text": null,
      "comment_text": "That&#x27;s kind of what compilers are for. One of their jobs is static analysis. They have the graphs needed for hoisting. Libraries don&#x27;t.<p>This may be a problem with the existing compiler, if the Rust implementation is mostly a front-end to LLVM.  I&#x27;d hate to see &quot;unsafe&quot; code baked into the language standard, though.  C++ tried to fix the mess underneath with template libraries.  That didn&#x27;t end well.<p>&quot;Giving programmers low-level tools when they need them&quot; as an excuse for abandoning language safety is a recipe for bad code.  There&#x27;s a long, long history of that not working.  &quot;Unsafe&quot; code should be very, very rare, used for dealing with device registers and such.<p>This sounds like designing buffer overflows into Rust.",
      "num_comments": null,
      "story_id": 8629789,
      "story_title": "Rust, Lifetimes, and Collections",
      "story_url": "http://cglab.ca/~abeinges/blah/rust-lifetimes-and-collections/",
      "parent_id": 8631831,
      "created_at_i": 1416424011,
      "_tags": [
        "comment",
        "author_Animats",
        "story_8629789"
      ],
      "objectID": "8631940",
      "_highlightResult": {
        "author": {
          "value": "Animats",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's kind of what compilers are for. One of their jobs is <em>static</em> <em>analysis.</em> They have the graphs needed for hoisting. Libraries don't.<p>This may be a problem with the existing compiler, if the Rust implementation is mostly a front-end to LLVM.  I'd hate to see &quot;unsafe&quot; code baked into the language standard, though.  C++ tried to fix the mess underneath with template libraries.  That didn't end well.<p>&quot;Giving programmers low-level <em>tools</em> when they need them&quot; as an excuse for abandoning language safety is a recipe for bad code.  There's a long, long history of that not working.  &quot;Unsafe&quot; code should be very, very rare, used for dealing with device registers and such.<p>This sounds like designing buffer overflows into Rust.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Rust, Lifetimes, and Collections",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cglab.ca/~abeinges/blah/rust-lifetimes-and-collections/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-06T16:22:41.000Z",
      "title": null,
      "url": null,
      "author": "carlio",
      "points": null,
      "story_text": null,
      "comment_text": "I think you can get a long way with &quot;automated code reviews&quot; - basically, linting and static analysis. There are various ones out there for your language - disclaimer: I wrote one for Python called <a href=\"https://landscape.io\" rel=\"nofollow\">https:&#x2F;&#x2F;landscape.io</a><p>They can take a little while to get set up exactly how you like them, but once you do, run them on your CI server after every commit and it&#x27;ll output the warnings about style violations and so on. That&#x27;s basically what you&#x27;re after. It&#x27;s not a replacement for a manual code review but it&#x27;s certainly closer to what you want than nothing!<p>As other have said though, this only works if you and your team treat code quality as important and actually take the time to understand the output of the analysis tools. That&#x27;s why I like the CI approach, so that you can see if the number of warnings is going up or down over time and react accordingly. That metric is a useful one to keep an eye on to get a view on the quality of your code, and if it gets too high you can schedule some time.<p>(PS if you are interested in learning more about &quot;Automatic Code Reviews&quot; for Python, here&#x27;s a talk I did at EuroPython14: <a href=\"http://carlcrowder.com/pages/europython-2014-automatic-code-reviews.html\" rel=\"nofollow\">http:&#x2F;&#x2F;carlcrowder.com&#x2F;pages&#x2F;europython-2014-automatic-code-...</a> )",
      "num_comments": null,
      "story_id": 8567134,
      "story_title": "Ask HN: How do I get my coders to write better code?",
      "story_url": "",
      "parent_id": 8567134,
      "created_at_i": 1415290961,
      "_tags": [
        "comment",
        "author_carlio",
        "story_8567134"
      ],
      "objectID": "8567731",
      "_highlightResult": {
        "author": {
          "value": "carlio",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I think you can get a long way with &quot;automated code reviews&quot; - basically, linting and <em>static</em> <em>analysis.</em> There are various ones out there for your language - disclaimer: I wrote one for Python called <a href=\"https://landscape.io\" rel=\"nofollow\">https://landscape.io</a><p>They can take a little while to get set up exactly how you like them, but once you do, run them on your CI server after every commit and it'll output the warnings about style violations and so on. That's basically what you're after. It's not a replacement for a manual code review but it's certainly closer to what you want than nothing!<p>As other have said though, this only works if you and your team treat code quality as important and actually take the time to understand the output of the <em>analysis</em> <em>tools</em>. That's why I like the CI approach, so that you can see if the number of warnings is going up or down over time and react accordingly. That metric is a useful one to keep an eye on to get a view on the quality of your code, and if it gets too high you can schedule some time.<p>(PS if you are interested in learning more about &quot;Automatic Code Reviews&quot; for Python, here's a talk I did at EuroPython14: <a href=\"http://carlcrowder.com/pages/europython-2014-automatic-code-reviews.html\" rel=\"nofollow\">http://carlcrowder.com/pages/europython-2014-automatic-code-...</a> )",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: How do I get my coders to write better code?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-06T15:31:23.000Z",
      "title": null,
      "url": null,
      "author": "StevePerkins",
      "points": null,
      "story_text": null,
      "comment_text": "What I&#x27;ve seen work is a combination of code reviews and ongoing continuing education.<p>----- CODE REVIEW SIDE -----<p>This can include automated tools, human interaction, and computer-assisted human interaction.  To start with, pick a set of command code standards and style guidelines.  Google has nice ones for many languages that you can use as a starting point (<a href=\"https://google-styleguide.googlecode.com/svn/trunk/\" rel=\"nofollow\">https:&#x2F;&#x2F;google-styleguide.googlecode.com&#x2F;svn&#x2F;trunk&#x2F;</a>).<p>Secondly, enforce them through automated tools (e.g. in a Java shop, these might include PMD, FindBugs, Checkstyle, etc).  Have everyone install the IDE plugins for those tools (along with your common config).  Incorporate them into your continuous integration build process.  Perhaps put in place a static analysis tool like Sonar to send regular reports on code issues.<p>The human element would start by having someone review committed code before it&#x27;s allowed to be merged downstream.  Git&#x27;s pull requests, along with diff view systems like GitHub&#x27;s, make this easy... but you can use workable practices with Subversion or whatever also.<p>There are limits to &quot;pull request&quot;-based code reviews, though.  When change sets grow too large, it&#x27;s difficult for the reviewer to understand the high-level vision for the changes.  You start reviewing the trees, rather than the forest.  So I think you still need periodic in-person code reviews, to walk through the state of a codebase at certain milestones and discuss higher-level issues.<p>----- CONTINUING EDUCATION SIDE -----<p>The thing that I&#x27;ve seen work best here is a regular, ongoing lunch-and-learn type series.  Take any of the standard code quality treatises (e.g. &quot;Pragmatic Programmer&quot;, &quot;Code Complete&quot;, &quot;Clean Code&quot;, etc), and tackle a chapter per week.  Better yet, split up the chapters and have the team members themselves present a chapter.  It&#x27;s great experience for them (if they&#x27;re not TOO freaked out by public speaking), and you&#x27;ll never learn something as deeply as you do through the process of teaching it to others.<p>The problem with lunch-n-learns is that you MUST have buy-in from management to make them a serious and ongoing part of your team culture.  When deadlines are tight and there are fires to put out (and when are there not?), a lot of companies are quick to cancel that week&#x27;s lunch-n-learn.  When that happens, they lose traction and fall apart.",
      "num_comments": null,
      "story_id": 8567134,
      "story_title": "Ask HN: How do I get my coders to write better code?",
      "story_url": "",
      "parent_id": 8567134,
      "created_at_i": 1415287883,
      "_tags": [
        "comment",
        "author_StevePerkins",
        "story_8567134"
      ],
      "objectID": "8567424",
      "_highlightResult": {
        "author": {
          "value": "StevePerkins",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "What I've seen work is a combination of code reviews and ongoing continuing education.<p>----- CODE REVIEW SIDE -----<p>This can include automated <em>tools</em>, human interaction, and computer-assisted human interaction.  To start with, pick a set of command code standards and style guidelines.  Google has nice ones for many languages that you can use as a starting point (<a href=\"https://google-styleguide.googlecode.com/svn/trunk/\" rel=\"nofollow\">https://google-styleguide.googlecode.com/svn/trunk/</a>).<p>Secondly, enforce them through automated <em>tools</em> (e.g. in a Java shop, these might include PMD, FindBugs, Checkstyle, etc).  Have everyone install the IDE plugins for those <em>tools</em> (along with your common config).  Incorporate them into your continuous integration build process.  Perhaps put in place a <em>static</em> <em>analysis</em> tool like Sonar to send regular reports on code issues.<p>The human element would start by having someone review committed code before it's allowed to be merged downstream.  Git's pull requests, along with diff view systems like GitHub's, make this easy... but you can use workable practices with Subversion or whatever also.<p>There are limits to &quot;pull request&quot;-based code reviews, though.  When change sets grow too large, it's difficult for the reviewer to understand the high-level vision for the changes.  You start reviewing the trees, rather than the forest.  So I think you still need periodic in-person code reviews, to walk through the state of a codebase at certain milestones and discuss higher-level issues.<p>----- CONTINUING EDUCATION SIDE -----<p>The thing that I've seen work best here is a regular, ongoing lunch-and-learn type series.  Take any of the standard code quality treatises (e.g. &quot;Pragmatic Programmer&quot;, &quot;Code Complete&quot;, &quot;Clean Code&quot;, etc), and tackle a chapter per week.  Better yet, split up the chapters and have the team members themselves present a chapter.  It's great experience for them (if they're not TOO freaked out by public speaking), and you'll never learn something as deeply as you do through the process of teaching it to others.<p>The problem with lunch-n-learns is that you MUST have buy-in from management to make them a serious and ongoing part of your team culture.  When deadlines are tight and there are fires to put out (and when are there not?), a lot of companies are quick to cancel that week's lunch-n-learn.  When that happens, they lose traction and fall apart.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: How do I get my coders to write better code?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-10-01T16:58:13.000Z",
      "title": null,
      "url": null,
      "author": "gtani",
      "points": null,
      "story_text": null,
      "comment_text": "The language and development tools have exploded the last 4 years, both inside and outside Ericsson and especially after Armstrong's book and work on R12 started. I have a blog post brewing on all the improvements, here's an outline<p>===================<p>string, regex handlers, faster file I/O:<p>- \"re\" module replaces \"regex\"<p>- faster iteration over large binaries, R13A<p>- avoid io:get_line using raw access<p>-----------------------------<p>metaprogramming/\"DSL\"<p>- deep exploring parse_transform<p>----------------------<p>frameworks, database, middleware<p>- couchdb, nitrogen, mochiweb, erlyweb,and now the boss!<p>- thrift, ejabberd, rabbitMQ,<p>----------------------------<p>debug, trace, static code analysis; verify program behavior<p>- dialyzer, tidier (Sagonas and Avgerinos)<p>- mcErlang model checker<p>- quick check application vs. specification<p>-------------------------<p>data structures<p>- destructive / mutable byte arrays (HiPE BIF)<p>- shared immutable data structure<p>----------------------<p>tail recursion<p>- Ericsson expanding as fast as they can (e.g. \"andalso\",<p>-------------<p>SMP, run queues,<p>----------<p>build systems, distribute your app<p>- rake\n- faxien, sinan (erlware)<p>==============<p>Yah, this could be a <i>long</i> post, take a while to draft too.<p>Dunno the state of scala, clojure and haskell /GHC docs these days, but to explore the dark corners of erlang dev, you ahve to do a lot of mailing list and google digging.<p>(and read Cesarini/Thompson book, which is equal to best software books ever, modulo fair number of typo's)",
      "num_comments": null,
      "story_id": 854916,
      "story_title": "Rails Idioms + Django Templates + Erlang Power = Chicago Boss",
      "story_url": "http://www.chicagoboss.org/",
      "parent_id": 855134,
      "created_at_i": 1254416293,
      "_tags": [
        "comment",
        "author_gtani",
        "story_854916"
      ],
      "objectID": "855290",
      "_highlightResult": {
        "author": {
          "value": "gtani",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The language and development <em>tools</em> have exploded the last 4 years, both inside and outside Ericsson and especially after Armstrong's book and work on R12 started. I have a blog post brewing on all the improvements, here's an outline<p>===================<p>string, regex handlers, faster file I/O:<p>- \"re\" module replaces \"regex\"<p>- faster iteration over large binaries, R13A<p>- avoid io:get_line using raw access<p>-----------------------------<p>metaprogramming/\"DSL\"<p>- deep exploring parse_transform<p>----------------------<p>frameworks, database, middleware<p>- couchdb, nitrogen, mochiweb, erlyweb,and now the boss!<p>- thrift, ejabberd, rabbitMQ,<p>----------------------------<p>debug, trace, <em>static</em> code <em>analysis</em>; verify program behavior<p>- dialyzer, tidier (Sagonas and Avgerinos)<p>- mcErlang model checker<p>- quick check application vs. specification<p>-------------------------<p>data structures<p>- destructive / mutable byte arrays (HiPE BIF)<p>- shared immutable data structure<p>----------------------<p>tail recursion<p>- Ericsson expanding as fast as they can (e.g. \"andalso\",<p>-------------<p>SMP, run queues,<p>----------<p>build systems, distribute your app<p>- rake\n- faxien, sinan (erlware)<p>==============<p>Yah, this could be a <i>long</i> post, take a while to draft too.<p>Dunno the state of scala, clojure and haskell /GHC docs these days, but to explore the dark corners of erlang dev, you ahve to do a lot of mailing list and google digging.<p>(and read Cesarini/Thompson book, which is equal to best software books ever, modulo fair number of typo's)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Rails Idioms + Django Templates + Erlang Power = Chicago Boss",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.chicagoboss.org/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-25T20:12:33.000Z",
      "title": null,
      "url": null,
      "author": "vezzy-fnord",
      "points": null,
      "story_text": null,
      "comment_text": "1. &quot;Just&quot; safety is hardly peanuts given the status quo. In fact, &quot;just&quot; safety would be much more practical. It&#x27;d be much easier to port all the existing code to a C dialect (like Cyclone) than rewrite from scratch in something like Rust.<p>2. I find compiler instrumentation (think AddressSanitizer and Mudflap) to be more promising than static analysis. Much of the latter is still stuck in the lint era and give out too much noise. That said, tools like Coverity have come a long way and I know a lot of FOSS projects use them frequently. I personally haven&#x27;t.<p>3. Capsicum is quite promising, indeed. I like that it extends the existing file descriptor metaphor and offers sandboxing based on namespaces instead of system calls (unlike seccomp), as opposed to the crufty POSIX 1003.1e capabilities which are underdeveloped and still limited to executable processes, AFAIK. That said, we shouldn&#x27;t just rely on sandboxing, jailing and capability-based security. We need to fix underlying application bugs, as well (the applications that implement the capabilities and sandboxing themselves, particularly so!)",
      "num_comments": null,
      "story_id": 8508478,
      "story_title": "Don't run 'strings' on untrusted files",
      "story_url": "http://lcamtuf.blogspot.com/2014/10/psa-dont-run-strings-on-untrusted-files.html",
      "parent_id": 8509180,
      "created_at_i": 1414267953,
      "_tags": [
        "comment",
        "author_vezzy-fnord",
        "story_8508478"
      ],
      "objectID": "8509255",
      "_highlightResult": {
        "author": {
          "value": "vezzy-fnord",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "1. &quot;Just&quot; safety is hardly peanuts given the status quo. In fact, &quot;just&quot; safety would be much more practical. It'd be much easier to port all the existing code to a C dialect (like Cyclone) than rewrite from scratch in something like Rust.<p>2. I find compiler instrumentation (think AddressSanitizer and Mudflap) to be more promising than <em>static</em> <em>analysis.</em> Much of the latter is still stuck in the lint era and give out too much noise. That said, <em>tools</em> like Coverity have come a long way and I know a lot of FOSS projects use them frequently. I personally haven't.<p>3. Capsicum is quite promising, indeed. I like that it extends the existing file descriptor metaphor and offers sandboxing based on namespaces instead of system calls (unlike seccomp), as opposed to the crufty POSIX 1003.1e capabilities which are underdeveloped and still limited to executable processes, AFAIK. That said, we shouldn't just rely on sandboxing, jailing and capability-based security. We need to fix underlying application bugs, as well (the applications that implement the capabilities and sandboxing themselves, particularly so!)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Don't run 'strings' on untrusted files",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lcamtuf.blogspot.com/2014/10/psa-dont-run-strings-on-untrusted-files.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-09-29T07:08:44.000Z",
      "title": null,
      "url": null,
      "author": "ubernostrum",
      "points": null,
      "story_text": null,
      "comment_text": "Unfortunately, the author seems to be on the verge of falling into one of the fallacies he rightly points out: assuming that one of the main purposes of unit testing is to act as a surrogate for static analysis. I've seen code written in dynamically-typed languages which tries to do this, and such code pretty much universally falls into the category of \"using dynamically-typed languages poorly\"  (particularly since pretty much every popular dynamically-typed language has lint tools which will catch the sorts of things paranoid static-typing aficionados try to test for).<p>What unit tests are good at, and what they should be used for, is verifying behavior and integration, something that static type systems notably still aren't particularly good at (and likely will never be good enough at for practical purposes -- I believe quite firmly that there's a diminishing-returns effect from ever-more-powerful type systems).<p>In general, though, I like to think of static type systems existing in relation to their programming languages in much the same way that metalanguages exist in relation to object languages in logic: the type system is essentially a separate language in which you can express and then verify statements about the program, just as a metalanguage allows you to express and verify statements about its object language.<p>This carries with it, of course, various implications for the limits of type systems (particularly since metalanguages are notoriously prone to infinite regress -- eventually you need a metametalanguage to make statements about the metalanguage, then a metametametalanguage and so on); I'm fairly certain that any sufficiently powerful type system would need to end up being a Turing-complete programming model in its own right, and since I've already got one of those (I'm writing my program in it) I generally pass on that and just write the unit tests :)",
      "num_comments": null,
      "story_id": 849726,
      "story_title": "What to know before debating type systems",
      "story_url": "http://www.pphsg.org/cdsmith/types.html",
      "parent_id": 849726,
      "created_at_i": 1254208124,
      "_tags": [
        "comment",
        "author_ubernostrum",
        "story_849726"
      ],
      "objectID": "849975",
      "_highlightResult": {
        "author": {
          "value": "ubernostrum",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Unfortunately, the author seems to be on the verge of falling into one of the fallacies he rightly points out: assuming that one of the main purposes of unit testing is to act as a surrogate for <em>static</em> <em>analysis.</em> I've seen code written in dynamically-typed languages which tries to do this, and such code pretty much universally falls into the category of \"using dynamically-typed languages poorly\"  (particularly since pretty much every popular dynamically-typed language has lint <em>tools</em> which will catch the sorts of things paranoid <em>static</em>-typing aficionados try to test for).<p>What unit tests are good at, and what they should be used for, is verifying behavior and integration, something that <em>static</em> type systems notably still aren't particularly good at (and likely will never be good enough at for practical purposes -- I believe quite firmly that there's a diminishing-returns effect from ever-more-powerful type systems).<p>In general, though, I like to think of <em>static</em> type systems existing in relation to their programming languages in much the same way that metalanguages exist in relation to object languages in logic: the type system is essentially a separate language in which you can express and then verify statements about the program, just as a metalanguage allows you to express and verify statements about its object language.<p>This carries with it, of course, various implications for the limits of type systems (particularly since metalanguages are notoriously prone to infinite regress -- eventually you need a metametalanguage to make statements about the metalanguage, then a metametametalanguage and so on); I'm fairly certain that any sufficiently powerful type system would need to end up being a Turing-complete programming model in its own right, and since I've already got one of those (I'm writing my program in it) I generally pass on that and just write the unit tests :)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What to know before debating type systems",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.pphsg.org/cdsmith/types.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-23T11:33:38.000Z",
      "title": null,
      "url": null,
      "author": "klibertp",
      "points": null,
      "story_text": null,
      "comment_text": "Do you know how &quot;image based&quot; environments work? In short you live in the same space as your code, so when you write some new method you have access to all the &quot;dynamically and non deterministically&quot; code artifacts. With Smalltalk the code is <i>always</i> being run and you get many useful tools for querying the state of a running system. I know it&#x27;s hard to believe, but you can get much better completion (not to mention refactoring support) with this approach than you get from static analysis.",
      "num_comments": null,
      "story_id": 8496581,
      "story_title": "“Did you mean?” Experience in Ruby",
      "story_url": "http://www.yukinishijima.net/2014/10/21/did-you-mean-experience-in-ruby.html",
      "parent_id": 8497437,
      "created_at_i": 1414064018,
      "_tags": [
        "comment",
        "author_klibertp",
        "story_8496581"
      ],
      "objectID": "8497625",
      "_highlightResult": {
        "author": {
          "value": "klibertp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Do you know how &quot;image based&quot; environments work? In short you live in the same space as your code, so when you write some new method you have access to all the &quot;dynamically and non deterministically&quot; code artifacts. With Smalltalk the code is <i>always</i> being run and you get many useful <em>tools</em> for querying the state of a running system. I know it's hard to believe, but you can get much better completion (not to mention refactoring support) with this approach than you get from <em>static</em> <em>analysis.</em>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "“Did you mean?” Experience in Ruby",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.yukinishijima.net/2014/10/21/did-you-mean-experience-in-ruby.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-07-13T12:14:44.000Z",
      "title": null,
      "url": null,
      "author": "profquail",
      "points": null,
      "story_text": null,
      "comment_text": "Having the ability to do more system programming on .NET (without having to P/Invoke all over the place) would (should?) make a lot of it significantly easier and faster. Also, the security issue is not to be overlooked -- with managed drivers and lower-level libraries, there'd be a much lower chance of fatal security bugs (e.g. buffer overflows). Also, writing this code in .NET allows developers to take advantage of a great number of new testing tools like Pex and Code Contracts (for fuzzing and static analysis, respectively).<p>Also, .NET 4.0 includes some additions for doing parallel processing to help developers take advantage of multi-core processors. I've been playing around with it for about a month now (I'm writing an open-source managed numerics library in C#) and the new parallel stuff is really quite good.",
      "num_comments": null,
      "story_id": 700920,
      "story_title": "Microsoft Has Turned The Corner",
      "story_url": "http://minimsft.blogspot.com/2009/07/microsoft-has-turned-corner.html",
      "parent_id": 701342,
      "created_at_i": 1247487284,
      "_tags": [
        "comment",
        "author_profquail",
        "story_700920"
      ],
      "objectID": "701532",
      "_highlightResult": {
        "author": {
          "value": "profquail",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Having the ability to do more system programming on .NET (without having to P/Invoke all over the place) would (should?) make a lot of it significantly easier and faster. Also, the security issue is not to be overlooked -- with managed drivers and lower-level libraries, there'd be a much lower chance of fatal security bugs (e.g. buffer overflows). Also, writing this code in .NET allows developers to take advantage of a great number of new testing <em>tools</em> like Pex and Code Contracts (for fuzzing and <em>static</em> <em>analysis</em>, respectively).<p>Also, .NET 4.0 includes some additions for doing parallel processing to help developers take advantage of multi-core processors. I've been playing around with it for about a month now (I'm writing an open-source managed numerics library in C#) and the new parallel stuff is really quite good.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Microsoft Has Turned The Corner",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://minimsft.blogspot.com/2009/07/microsoft-has-turned-corner.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-05-30T05:41:14.000Z",
      "title": null,
      "url": null,
      "author": "gregwebs",
      "points": null,
      "story_text": null,
      "comment_text": "This is really a very small subset of static analysis- GCC compiler warnings. I am sure the developers appreciate when their program fails to compile because the compiler statically notices a bug that would cause a runtime error in a more dynamic language. They might be able to productively use more sophisticated static analyses tools.",
      "num_comments": null,
      "story_id": 633151,
      "story_title": "How SQLite Is Tested",
      "story_url": "http://www.sqlite.org/testing.html",
      "parent_id": 633155,
      "created_at_i": 1243662074,
      "_tags": [
        "comment",
        "author_gregwebs",
        "story_633151"
      ],
      "objectID": "633296",
      "_highlightResult": {
        "author": {
          "value": "gregwebs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is really a very small subset of <em>static</em> <em>analysis</em>- GCC compiler warnings. I am sure the developers appreciate when their program fails to compile because the compiler statically notices a bug that would cause a runtime error in a more dynamic language. They might be able to productively use more sophisticated <em>static</em> analyses <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How SQLite Is Tested",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.sqlite.org/testing.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-23T18:25:00.000Z",
      "title": null,
      "url": null,
      "author": "RogerL",
      "points": null,
      "story_text": null,
      "comment_text": "Thank you for providing an example.<p>I look at that and I see a couple of things. First, this is procedural programming straight out of my old, old COBOL books. Batch processing - read some files, process the data, output it. That graph is pretty, but no different from the structured analysis and design that was forced on me in the mid 80s.<p>That stuff was a nightmare to work with. No real search, endless 2D layout issues, no way to reuse, a very little bit of information conveyed in a lot of space, no way to debug, and so on. And, if your program is anything but batch&#x2F;data flow oriented, good luck.<p>I see maybe 100-300 lines of JSON in the image. Or Lua. Whatever. A modest amount of paste code to tie already written components together in in&#x2F;out chains. Now, I get that your diagram is more easily &#x27;groked&#x27; than JSON, and that is a benefit. But what if I want to search for things? Use awesome tools like sed to batch change stuff? Perform static analysis? All that graphical stuff just falls apart. Oh, perhaps there is some DOM, and I access that, but then I&#x27;m right back into the incredible power and expressiveness of text.<p>More importantly, I&#x27;d like to see the flow diagrams of all those nodes you are connecting together. I am prepared for egg on my face here, but are those written in NoFlo, or text? I&#x27;m guessing the latter.<p>So, how is this different than LabView? I completely understand the value of being able to quickly plug together pre-existing components when you have a tiny interface (you just have in&#x2F;out nodes, basically, in that diagram). A small solution for a small problem, and I don&#x27;t mean that dismissively.<p>Despite the article&#x27;s claim, and as many have already said, this stuff has been around for decades. There are definitely places for it. But having lived through it, I tell you SA&#x2F;SD died a very deserved death.<p>Sorry, this isn&#x27;t directed at you, you were just the person kind enough to provide an asked for example.<p>The other major thing that sticks out for me is that that graph is just a high level, block diagram of the program. Well, &quot;just&quot; not meant to be dismissive. The original article talks about the horrors of programming where changing one thing means changing 10 other components. They are not describing programming, they are describing hacking spaghetti code with no design. If that is the way you program, or the way the code base you are working on is coded, then I can see why these flow diagrams seem so revolutionary - a design is being done, and software is broken up into discrete components. That&#x27;s pretty fundamental SW engineering. But the magic is not in the 2D visual display, but in the idea of small components that do one thing and that are not intimately tied to other components. So hey, if the tool helps you learn or use that method, good, I guess. How you reasonably scale it up to anything large is beyond me (I&#x27;ve done entire avionics systems in data flow diagrams, and it ain&#x27;t pretty at that scale, believe me).",
      "num_comments": null,
      "story_id": 6264657,
      "story_title": "How Flow-Based Programming Could Save The Sanity Of Web Developers",
      "story_url": "http://www.fastcolabs.com/3016289/how-an-arcane-coding-method-from-1970s-banking-software-could-save-the-sanity-of-web-develop",
      "parent_id": 6264898,
      "created_at_i": 1377282300,
      "_tags": [
        "comment",
        "author_RogerL",
        "story_6264657"
      ],
      "objectID": "6265364",
      "_highlightResult": {
        "author": {
          "value": "RogerL",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Thank you for providing an example.<p>I look at that and I see a couple of things. First, this is procedural programming straight out of my old, old COBOL books. Batch processing - read some files, process the data, output it. That graph is pretty, but no different from the structured <em>analysis</em> and design that was forced on me in the mid 80s.<p>That stuff was a nightmare to work with. No real search, endless 2D layout issues, no way to reuse, a very little bit of information conveyed in a lot of space, no way to debug, and so on. And, if your program is anything but batch/data flow oriented, good luck.<p>I see maybe 100-300 lines of JSON in the image. Or Lua. Whatever. A modest amount of paste code to tie already written components together in in/out chains. Now, I get that your diagram is more easily 'groked' than JSON, and that is a benefit. But what if I want to search for things? Use awesome <em>tools</em> like sed to batch change stuff? Perform <em>static</em> <em>analysis</em>? All that graphical stuff just falls apart. Oh, perhaps there is some DOM, and I access that, but then I'm right back into the incredible power and expressiveness of text.<p>More importantly, I'd like to see the flow diagrams of all those nodes you are connecting together. I am prepared for egg on my face here, but are those written in NoFlo, or text? I'm guessing the latter.<p>So, how is this different than LabView? I completely understand the value of being able to quickly plug together pre-existing components when you have a tiny interface (you just have in/out nodes, basically, in that diagram). A small solution for a small problem, and I don't mean that dismissively.<p>Despite the article's claim, and as many have already said, this stuff has been around for decades. There are definitely places for it. But having lived through it, I tell you SA/SD died a very deserved death.<p>Sorry, this isn't directed at you, you were just the person kind enough to provide an asked for example.<p>The other major thing that sticks out for me is that that graph is just a high level, block diagram of the program. Well, &quot;just&quot; not meant to be dismissive. The original article talks about the horrors of programming where changing one thing means changing 10 other components. They are not describing programming, they are describing hacking spaghetti code with no design. If that is the way you program, or the way the code base you are working on is coded, then I can see why these flow diagrams seem so revolutionary - a design is being done, and software is broken up into discrete components. That's pretty fundamental SW engineering. But the magic is not in the 2D visual display, but in the idea of small components that do one thing and that are not intimately tied to other components. So hey, if the tool helps you learn or use that method, good, I guess. How you reasonably scale it up to anything large is beyond me (I've done entire avionics systems in data flow diagrams, and it ain't pretty at that scale, believe me).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How Flow-Based Programming Could Save The Sanity Of Web Developers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.fastcolabs.com/3016289/how-an-arcane-coding-method-from-1970s-banking-software-could-save-the-sanity-of-web-develop",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-03-10T21:02:06.000Z",
      "title": null,
      "url": null,
      "author": "Zak",
      "points": null,
      "story_text": null,
      "comment_text": "Without getting in to what those preferences are, that being a different can of worms, I think it's likely that there are trends in the language preferences of great hackers. The existence of these trends means that tools that work well with the languages great hackers prefer will be more popular with great hackers.<p>The static analysis done by heavy IDEs isn't the only way to have large amounts of information about code available in the editor. Using Emacs with Slime, the editor has a huge amount of information about your code because it's communicating with the Lisp runtime that's evaluating it.",
      "num_comments": null,
      "story_id": 510087,
      "story_title": "Core competencies of great hackers",
      "story_url": "http://giraffesoft.ca/blog/2009/03/10/4-core-competencies-of-great-hackers.html",
      "parent_id": 510298,
      "created_at_i": 1236718926,
      "_tags": [
        "comment",
        "author_Zak",
        "story_510087"
      ],
      "objectID": "510651",
      "_highlightResult": {
        "author": {
          "value": "Zak",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Without getting in to what those preferences are, that being a different can of worms, I think it's likely that there are trends in the language preferences of great hackers. The existence of these trends means that <em>tools</em> that work well with the languages great hackers prefer will be more popular with great hackers.<p>The <em>static</em> <em>analysis</em> done by heavy IDEs isn't the only way to have large amounts of information about code available in the editor. Using Emacs with Slime, the editor has a huge amount of information about your code because it's communicating with the Lisp runtime that's evaluating it.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Core competencies of great hackers",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://giraffesoft.ca/blog/2009/03/10/4-core-competencies-of-great-hackers.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2008-09-16T06:25:37.000Z",
      "title": null,
      "url": null,
      "author": "rcoder",
      "points": null,
      "story_text": null,
      "comment_text": "You're right, of course, that systems security encompasses more than a formally-verified system can encompass. I say this having worked for a group that pitched the DoD and private vendors on \"provably correct\" systems that relied on commodity operating systems and compilers, so I <i>really</i> do get it, and know just how horribly limited formal methods are in the real world.<p>My point is, as I originally suggested, that <i>any</i> static analysis would likely be an improvement over what currently happens in the LAMP world. Most compiled languages have at least some tools available which developers can use to perform basic sanity checks -- the compiler itself being of course the first and most oft-overlooked of these. Dynamic language users lack even that basic safety net, which is the reason for my primary argument about the benefits of type safety and static analysis.<p>Basically, we're in furious agreement, and if you had caught me at a different time of day or mood, I could just as easily be standing on your side of the fence, arguing against someone who was trying to tell me that theory could solve all my security problems.",
      "num_comments": null,
      "story_id": 305349,
      "story_title": "Ask YC: if Haskell is the hammer, what should be the nail?",
      "story_url": "",
      "parent_id": 305484,
      "created_at_i": 1221546337,
      "_tags": [
        "comment",
        "author_rcoder",
        "story_305349"
      ],
      "objectID": "305509",
      "_highlightResult": {
        "author": {
          "value": "rcoder",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You're right, of course, that systems security encompasses more than a formally-verified system can encompass. I say this having worked for a group that pitched the DoD and private vendors on \"provably correct\" systems that relied on commodity operating systems and compilers, so I <i>really</i> do get it, and know just how horribly limited formal methods are in the real world.<p>My point is, as I originally suggested, that <i>any</i> <em>static</em> <em>analysis</em> would likely be an improvement over what currently happens in the LAMP world. Most compiled languages have at least some <em>tools</em> available which developers can use to perform basic sanity checks -- the compiler itself being of course the first and most oft-overlooked of these. Dynamic language users lack even that basic safety net, which is the reason for my primary argument about the benefits of type safety and <em>static</em> <em>analysis.</em><p>Basically, we're in furious agreement, and if you had caught me at a different time of day or mood, I could just as easily be standing on your side of the fence, arguing against someone who was trying to tell me that theory could solve all my security problems.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask YC: if Haskell is the hammer, what should be the nail?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2008-09-16T04:10:48.000Z",
      "title": null,
      "url": null,
      "author": "tptacek",
      "points": null,
      "story_text": null,
      "comment_text": "Well, just so we're clear: I buy the idea of using Haskell or OCaml for static code analysis (in fact, one of the better known static analyzer tools, which operates on binary control flow graphs, is written in OCaml).<p>What I don't buy is the idea that the Haskell runtime actually improves SQL or HTML security. By all means, write a Haskell source analyzer. It will help. But a web app stack written in Haskell will presumably have the same problems (or lack thereof) that Rails does.<p>Mathematical reasoning, for what it's worth, doesn't have a great track record in systems security. ;)",
      "num_comments": null,
      "story_id": 305349,
      "story_title": "Ask YC: if Haskell is the hammer, what should be the nail?",
      "story_url": "",
      "parent_id": 305395,
      "created_at_i": 1221538248,
      "_tags": [
        "comment",
        "author_tptacek",
        "story_305349"
      ],
      "objectID": "305406",
      "_highlightResult": {
        "author": {
          "value": "tptacek",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Well, just so we're clear: I buy the idea of using Haskell or OCaml for <em>static</em> code <em>analysis</em> (in fact, one of the better known <em>static</em> analyzer <em>tools</em>, which operates on binary control flow graphs, is written in OCaml).<p>What I don't buy is the idea that the Haskell runtime actually improves SQL or HTML security. By all means, write a Haskell source analyzer. It will help. But a web app stack written in Haskell will presumably have the same problems (or lack thereof) that Rails does.<p>Mathematical reasoning, for what it's worth, doesn't have a great track record in systems security. ;)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask YC: if Haskell is the hammer, what should be the nail?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-02-20T08:59:15.000Z",
      "title": null,
      "url": null,
      "author": "ollysb",
      "points": null,
      "story_text": null,
      "comment_text": "I love developing in rails but let's be clear, refactoring ruby is just painful at the moment. Yesterday I decided to rename a model, it took over an hour to get the tests passing again. Ok there's rubymine but it's only partially effective, it misses things like renaming relationships and references in templates. Given the difficulty of static analysis I've been wondering if a refactoring tool might look a little different with a dynamic language. Given that refactorings are effectively replacement patterns perhaps a find/replace workflow tool would be the way to go. The workflow might go something like: specify broad regex which matches all potential changes. View matches and then partition them with further rules like file type and tighter regexes. Once you've grouped the matches provide appropriate replacements. Run tests. Refine if required. Obviously you could follow this workflow using command line tools but the refinement process is difficult because you don't retain any of the context.  Having said that it wouldn't be too hard to use existing commands to put something like this together. Looks I've got a project for this afternoon.",
      "num_comments": null,
      "story_id": 2240595,
      "story_title": "Ask HN: Is TDD/BDD hampering your startup's agility?",
      "story_url": "",
      "parent_id": 2241356,
      "created_at_i": 1298192355,
      "_tags": [
        "comment",
        "author_ollysb",
        "story_2240595"
      ],
      "objectID": "2241462",
      "_highlightResult": {
        "author": {
          "value": "ollysb",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I love developing in rails but let's be clear, refactoring ruby is just painful at the moment. Yesterday I decided to rename a model, it took over an hour to get the tests passing again. Ok there's rubymine but it's only partially effective, it misses things like renaming relationships and references in templates. Given the difficulty of <em>static</em> <em>analysis</em> I've been wondering if a refactoring tool might look a little different with a dynamic language. Given that refactorings are effectively replacement patterns perhaps a find/replace workflow tool would be the way to go. The workflow might go something like: specify broad regex which matches all potential changes. View matches and then partition them with further rules like file type and tighter regexes. Once you've grouped the matches provide appropriate replacements. Run tests. Refine if required. Obviously you could follow this workflow using command line <em>tools</em> but the refinement process is difficult because you don't retain any of the context.  Having said that it wouldn't be too hard to use existing commands to put something like this together. Looks I've got a project for this afternoon.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Is TDD/BDD hampering your startup's agility?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-02-05T18:52:21.000Z",
      "title": null,
      "url": null,
      "author": "ShabbyDoo",
      "points": null,
      "story_text": null,
      "comment_text": "In general, why has static analysis not been more popular?  When I first ran FindBugs on a 50 KLOC codebase I inherited, it identified several real, non-trivial bugs which likely hurt many users.  Perhaps the average Java developer's skill level is too low to make sense of these tools' results?  But, one would think that most teams have at least one \"adult\" who would love more visibility into a codebase.",
      "num_comments": null,
      "story_id": 2182127,
      "story_title": "Google open sources \"Contracts for Java\"",
      "story_url": "http://google-opensource.blogspot.com/2011/02/contracts-for-java.html",
      "parent_id": 2182127,
      "created_at_i": 1296931941,
      "_tags": [
        "comment",
        "author_ShabbyDoo",
        "story_2182127"
      ],
      "objectID": "2183698",
      "_highlightResult": {
        "author": {
          "value": "ShabbyDoo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In general, why has <em>static</em> <em>analysis</em> not been more popular?  When I first ran FindBugs on a 50 KLOC codebase I inherited, it identified several real, non-trivial bugs which likely hurt many users.  Perhaps the average Java developer's skill level is too low to make sense of these <em>tools</em>' results?  But, one would think that most teams have at least one \"adult\" who would love more visibility into a codebase.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Google open sources \"Contracts for Java\"",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://google-opensource.blogspot.com/2011/02/contracts-for-java.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-01-01T14:10:33.000Z",
      "title": null,
      "url": null,
      "author": "rbanffy",
      "points": null,
      "story_text": null,
      "comment_text": "&#62; JavaScript JITs are already compiling JavaScript to machine code<p>The details of how the interpreter works and of what it interprets are irrelevant to this discussion. It's JavaScript code that's being <i>transported</i>, not the compiled binary. While I agree tools like Closure somewhat obscure the resulting JavaScript, it's still source code that's being downloaded to my environment and it's my browser's job to decide how it should be executed.<p>I would have nothing against a site that sends me source code to be compiled within my computer so it could run inside a sandbox, but I won't like when Facebook starts pushing binaries I should trust won't break out of the sandbox they should respect. You can't easily do static analysis on binaries.<p>And I would love to be able to browse the web on my SPARC, POWER and MIPS boxes.<p>One good reason for JavaScript being slower than C is its typing. If we could write type-strict JavaScript code, it should not compile to less efficient binaries than corresponding C. BTW, incremental compiling has been around since the 80's - code can be compiled as quickly as it can be transferred through HTTP.",
      "num_comments": null,
      "story_id": 2057415,
      "story_title": "Mozilla’s Rejection of NativeClient Hurts the Open Web",
      "story_url": "http://chadaustin.me/2011/01/mozillas-rejection-of-nativeclient-hurts-the-open-web/",
      "parent_id": 2057443,
      "created_at_i": 1293891033,
      "_tags": [
        "comment",
        "author_rbanffy",
        "story_2057415"
      ],
      "objectID": "2057643",
      "_highlightResult": {
        "author": {
          "value": "rbanffy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> JavaScript JITs are already compiling JavaScript to machine code<p>The details of how the interpreter works and of what it interprets are irrelevant to this discussion. It's JavaScript code that's being <i>transported</i>, not the compiled binary. While I agree <em>tools</em> like Closure somewhat obscure the resulting JavaScript, it's still source code that's being downloaded to my environment and it's my browser's job to decide how it should be executed.<p>I would have nothing against a site that sends me source code to be compiled within my computer so it could run inside a sandbox, but I won't like when Facebook starts pushing binaries I should trust won't break out of the sandbox they should respect. You can't easily do <em>static</em> <em>analysis</em> on binaries.<p>And I would love to be able to browse the web on my SPARC, POWER and MIPS boxes.<p>One good reason for JavaScript being slower than C is its typing. If we could write type-strict JavaScript code, it should not compile to less efficient binaries than corresponding C. BTW, incremental compiling has been around since the 80's - code can be compiled as quickly as it can be transferred through HTTP.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mozilla’s Rejection of NativeClient Hurts the Open Web",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://chadaustin.me/2011/01/mozillas-rejection-of-nativeclient-hurts-the-open-web/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-12-23T00:00:30.000Z",
      "title": null,
      "url": null,
      "author": "paperclip",
      "points": null,
      "story_text": null,
      "comment_text": "I will try to ignore the shallow (but horrifying) issue of identifiers including spaces.<p>The real question to be asked here is what is wrong with the current portable assembler (C) ? C has occupied this niche for a long time and quite successfully - I believe all current mainstream kernels are written in C (or possibly a limited subset of C++).<p>If you want a 'portable assembler', a modern C compiler is in my opinion, a good choice:<p><pre><code>  - a solid specification: detailing the behaviour of operations, what is defined, implementation, or undefined behaviour.\n\n  - access to platform specific features through builtins and intrinsics\n\n  - ability to use inline asm if you really want to (or need to)\n\n  - easy integration with existing libraries\n\n  - minimal dependencies on a runtime library (pretty much none in freestanding implementations)\n\n  - most compliers give have ways to get good control of both what code is generated and structure layout.\n</code></pre>\nThe modern C ecosystem provides (mostly good) tools for:<p><pre><code>  - tracking memory leaks/invalid memory accesses (valgrind)\n\n  - static analysis (clang static analyser, sparse, coverity, ...)\n\n  - debuggers (gdb ...)\n\n  - solid optimizing compilers (icc, gcc, llvm)\n\n  - profilers (oprofile, perf, vtune, ...)\n</code></pre>\nAdmittedly, most of these tools don't depend on the code being written in C, but I suspect any new language would take a while to get properly integrated. If you want to use a low level language, you really want to have access to these tools or equivalent.<p>A new language trying to compete in this space would have to offer something fairly substantial to get me to switch - and a strange syntax like zinc is not going to help. From the documentation at least, zinc seems to currently be missing: an equivalent to volatile; asm; anyway to access a CAS like instruction; 64bit types; floats; a way to interface to C code; clear documentation about behaviour in corner cases (what happens if you a left shift a 32bit value by 40?). The only thing seems to bring to the table to compensate is the ability to inherit structures",
      "num_comments": null,
      "story_id": 2031586,
      "story_title": "Zinc: a low level language between assembler, C and C++ with Ruby-like syntax",
      "story_url": "http://tibleiz.net/zinc/",
      "parent_id": 2031586,
      "created_at_i": 1293062430,
      "_tags": [
        "comment",
        "author_paperclip",
        "story_2031586"
      ],
      "objectID": "2033000",
      "_highlightResult": {
        "author": {
          "value": "paperclip",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I will try to ignore the shallow (but horrifying) issue of identifiers including spaces.<p>The real question to be asked here is what is wrong with the current portable assembler (C) ? C has occupied this niche for a long time and quite successfully - I believe all current mainstream kernels are written in C (or possibly a limited subset of C++).<p>If you want a 'portable assembler', a modern C compiler is in my opinion, a good choice:<p><pre><code>  - a solid specification: detailing the behaviour of operations, what is defined, implementation, or undefined behaviour.\n\n  - access to platform specific features through builtins and intrinsics\n\n  - ability to use inline asm if you really want to (or need to)\n\n  - easy integration with existing libraries\n\n  - minimal dependencies on a runtime library (pretty much none in freestanding implementations)\n\n  - most compliers give have ways to get good control of both what code is generated and structure layout.\n</code></pre>\nThe modern C ecosystem provides (mostly good) <em>tools</em> for:<p><pre><code>  - tracking memory leaks/invalid memory accesses (valgrind)\n\n  - <em>static</em> <em>analysis</em> (clang <em>static</em> analyser, sparse, coverity, ...)\n\n  - debuggers (gdb ...)\n\n  - solid optimizing compilers (icc, gcc, llvm)\n\n  - profilers (oprofile, perf, vtune, ...)\n</code></pre>\nAdmittedly, most of these <em>tools</em> don't depend on the code being written in C, but I suspect any new language would take a while to get properly integrated. If you want to use a low level language, you really want to have access to these <em>tools</em> or equivalent.<p>A new language trying to compete in this space would have to offer something fairly substantial to get me to switch - and a strange syntax like zinc is not going to help. From the documentation at least, zinc seems to currently be missing: an equivalent to volatile; asm; anyway to access a CAS like instruction; 64bit types; floats; a way to interface to C code; clear documentation about behaviour in corner cases (what happens if you a left shift a 32bit value by 40?). The only thing seems to bring to the table to compensate is the ability to inherit structures",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Zinc: a low level language between assembler, C and C++ with Ruby-like syntax",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://tibleiz.net/zinc/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-11-02T13:50:18.000Z",
      "title": null,
      "url": null,
      "author": "stephen",
      "points": null,
      "story_text": null,
      "comment_text": "Several paragraphs in the article read like they were written by a 2nd grader:<p>\"Conversely, Adobe AIR and Silverlight allow Web-style applications to run on the desktop. Android, Adobe AIR, Google Chrome, Safari, and iPhone all use WebKit for rendering. One problem with GWT is that it does not allow you to write applications that run as desktop applications (even though GWT's development toolset for rendering is based on WebKit).\"<p>And:<p>\"When you're ready to deploy your application to the Web, you need to be a bit more careful about what library you include. It is common to use JavaScript Object Notation (JSON)-RPC services from a Pyjamas application running in the browser.\"<p>I'd give a blog post a pass, but this is a web property that I assume has an editor and pays authors for their submissions.<p>Also, pyjamas confuses me because two of GWT's rationales for existence are:<p>1. Using static analysis of your code to heavily optimize the resulting Javascript.<p>2. Using static language tools (Eclipse, etc.) to maintain order in large codebases<p>For 1), at Java-&#62;Javascript compile time, GWT will inline code, prune dead code, make calls un-polymorphic, and other fancy optimizations driven by the static typing. The goal is to make your Javascript as fast, or likely faster, than it'd be if written by hand.<p>Similar optimizations can be done these days at runtime by good VMs, e.g. the JVM and V8 (probably?), but the point with GWT is that crappy browsers (IE6-8) don't optimize at runtime, so GWT helps them out and does it at compile time.<p>For 2), whether or not you buy the assertion that IDEs/static typing make larger codebases easier to maintain, that is nonetheless the GWT team's assertion and something people using GWT generally agree with.<p>So, if you forgo static typing, and so give up static analysis, and a static tool chain/IDE, why are you not just using Javascript itself?<p>(Edit: formatting.)",
      "num_comments": null,
      "story_id": 1859240,
      "story_title": "Introduction to Pyjamas",
      "story_url": "http://www.ibm.com/developerworks/web/library/wa-aj-pyjamas/?ca=drs-",
      "parent_id": 1859240,
      "created_at_i": 1288705818,
      "_tags": [
        "comment",
        "author_stephen",
        "story_1859240"
      ],
      "objectID": "1860377",
      "_highlightResult": {
        "author": {
          "value": "stephen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Several paragraphs in the article read like they were written by a 2nd grader:<p>\"Conversely, Adobe AIR and Silverlight allow Web-style applications to run on the desktop. Android, Adobe AIR, Google Chrome, Safari, and iPhone all use WebKit for rendering. One problem with GWT is that it does not allow you to write applications that run as desktop applications (even though GWT's development <em>tools</em>et for rendering is based on WebKit).\"<p>And:<p>\"When you're ready to deploy your application to the Web, you need to be a bit more careful about what library you include. It is common to use JavaScript Object Notation (JSON)-RPC services from a Pyjamas application running in the browser.\"<p>I'd give a blog post a pass, but this is a web property that I assume has an editor and pays authors for their submissions.<p>Also, pyjamas confuses me because two of GWT's rationales for existence are:<p>1. Using <em>static</em> <em>analysis</em> of your code to heavily optimize the resulting Javascript.<p>2. Using <em>static</em> language <em>tools</em> (Eclipse, etc.) to maintain order in large codebases<p>For 1), at Java->Javascript compile time, GWT will inline code, prune dead code, make calls un-polymorphic, and other fancy optimizations driven by the <em>static</em> typing. The goal is to make your Javascript as fast, or likely faster, than it'd be if written by hand.<p>Similar optimizations can be done these days at runtime by good VMs, e.g. the JVM and V8 (probably?), but the point with GWT is that crappy browsers (IE6-8) don't optimize at runtime, so GWT helps them out and does it at compile time.<p>For 2), whether or not you buy the assertion that IDEs/<em>static</em> typing make larger codebases easier to maintain, that is nonetheless the GWT team's assertion and something people using GWT generally agree with.<p>So, if you forgo <em>static</em> typing, and so give up <em>static</em> <em>analysis</em>, and a <em>static</em> tool chain/IDE, why are you not just using Javascript itself?<p>(Edit: formatting.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Introduction to Pyjamas",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.ibm.com/developerworks/web/library/wa-aj-pyjamas/?ca=drs-",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-10-26T05:56:10.000Z",
      "title": null,
      "url": null,
      "author": "wash",
      "points": null,
      "story_text": null,
      "comment_text": "Clang's diagnostics and static analysis? Take, for example, <a href=\"https://patchwork.kernel.org/patch/36060/\" rel=\"nofollow\">https://patchwork.kernel.org/patch/36060/</a>, a serious problem in the kernel that was recently discovered. Given the size of Linux, it would be highly inefficient to manually find and fix every instances of this issue.<p>Currently, Clang doesn't support the work-around option that GCC provides to prevent the aforementioned issue. I could just implement the GNU work-around, but with Clang, it's far easier to write a scanner which will identify every place in the Linux source code where those dangerous semantics appear.<p>Clang might not be mature enough to compile Linux for distribution. The difference between GCC and Clang is that Clang is not a compiler. Clang is a modular API that provides the tools to build C language front-ends to the LLVM compiler infrastructure. The Clang compiler driver is just one implementation of an application built using the Clang libraries.<p>Why would one want to do this? Well...<p><pre><code>   http://sourceforge.net/mailarchive/message.php?msg_name=2010http://sourceforge.net/mailarchive/message.php?msg_name=20101007001758.6bcd3d3b%40Pegasus1007001758.6bcd3d3b%40Pegasus\n\n   http://clang-analyzer.llvm.org/\n\n   http://clang.llvm.org/docs/libIndex.html\n\n   http://llvm.org/ProjectsWithLLVM/#LENS\n\n   http://llvm.org/ProjectsWithLLVM/#spedi\n</code></pre>\nThink outside of the box :)",
      "num_comments": null,
      "story_id": 1832712,
      "story_title": "Clang (LLVM C compiler) builds a working Linux kernel",
      "story_url": "http://article.gmane.org/gmane.comp.compilers.clang.devel/11432",
      "parent_id": 1832915,
      "created_at_i": 1288072570,
      "_tags": [
        "comment",
        "author_wash",
        "story_1832712"
      ],
      "objectID": "1833213",
      "_highlightResult": {
        "author": {
          "value": "wash",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Clang's diagnostics and <em>static</em> <em>analysis</em>? Take, for example, <a href=\"https://patchwork.kernel.org/patch/36060/\" rel=\"nofollow\">https://patchwork.kernel.org/patch/36060/</a>, a serious problem in the kernel that was recently discovered. Given the size of Linux, it would be highly inefficient to manually find and fix every instances of this issue.<p>Currently, Clang doesn't support the work-around option that GCC provides to prevent the aforementioned issue. I could just implement the GNU work-around, but with Clang, it's far easier to write a scanner which will identify every place in the Linux source code where those dangerous semantics appear.<p>Clang might not be mature enough to compile Linux for distribution. The difference between GCC and Clang is that Clang is not a compiler. Clang is a modular API that provides the <em>tools</em> to build C language front-ends to the LLVM compiler infrastructure. The Clang compiler driver is just one implementation of an application built using the Clang libraries.<p>Why would one want to do this? Well...<p><pre><code>   http://sourceforge.net/mailarchive/message.php?msg_name=2010http://sourceforge.net/mailarchive/message.php?msg_name=20101007001758.6bcd3d3b%40Pegasus1007001758.6bcd3d3b%40Pegasus\n\n   http://clang-analyzer.llvm.org/\n\n   http://clang.llvm.org/docs/libIndex.html\n\n   http://llvm.org/ProjectsWithLLVM/#LENS\n\n   http://llvm.org/ProjectsWithLLVM/#spedi\n</code></pre>\nThink outside of the box :)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Clang (LLVM C compiler) builds a working Linux kernel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://article.gmane.org/gmane.comp.compilers.clang.devel/11432",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-10-19T14:22:40.000Z",
      "title": null,
      "url": null,
      "author": "alextgordon",
      "points": null,
      "story_text": null,
      "comment_text": "I was talking in terms of transformations, such as the clone tool. Clone takes a set of pixels, applies some math, and gives you a new set of pixels that look a bit like what you want. After you've applied clone, you're done (although you might need to apply some finishing touches).<p>There is just no room for such tools in programming. You can't have a tool that applies some transformation to the code but leaves half of it in a broken state. That would be worse than useless. No, a tool has to be 100% correct or introduce errors that are caught by the compiler, otherwise it'll take longer to find and fix its mistakes than it would to apply the transformation manually. And it turns out that making such perfect tools is incredibly hard.<p><i>How do I know my program is not broken? I run it. If it produces the answers I want, I can generally assume it is not broken (with a dose of skepticism).</i><p>But notice how much effort is put into making sure code is correct. We have unit testing, integration testing, fuzz testing, static analysis, formal verification, ... Games studios pay scores of people to sit around playing games all day. This is not seen in any other creative art.",
      "num_comments": null,
      "story_id": 1806844,
      "story_title": "IDE WTF",
      "story_url": "http://lukepalmer.wordpress.com/2010/10/18/idewtf/",
      "parent_id": 1807103,
      "created_at_i": 1287498160,
      "_tags": [
        "comment",
        "author_alextgordon",
        "story_1806844"
      ],
      "objectID": "1807194",
      "_highlightResult": {
        "author": {
          "value": "alextgordon",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I was talking in terms of transformations, such as the clone tool. Clone takes a set of pixels, applies some math, and gives you a new set of pixels that look a bit like what you want. After you've applied clone, you're done (although you might need to apply some finishing touches).<p>There is just no room for such <em>tools</em> in programming. You can't have a tool that applies some transformation to the code but leaves half of it in a broken state. That would be worse than useless. No, a tool has to be 100% correct or introduce errors that are caught by the compiler, otherwise it'll take longer to find and fix its mistakes than it would to apply the transformation manually. And it turns out that making such perfect <em>tools</em> is incredibly hard.<p><i>How do I know my program is not broken? I run it. If it produces the answers I want, I can generally assume it is not broken (with a dose of skepticism).</i><p>But notice how much effort is put into making sure code is correct. We have unit testing, integration testing, fuzz testing, <em>static</em> <em>analysis</em>, formal verification, ... Games studios pay scores of people to sit around playing games all day. This is not seen in any other creative art.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "IDE WTF",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lukepalmer.wordpress.com/2010/10/18/idewtf/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-10-03T21:45:16.000Z",
      "title": null,
      "url": null,
      "author": "silentbicycle",
      "points": null,
      "story_text": null,
      "comment_text": "That's because many of the people who build those tools have coupled them to an IDE, rather than making a standalone tool that could be made to work with any editor with a little effort. And while it would be changing files without the IDE knowing, version control systems run standalone and modify file currently being edited, too - it's not a problem when you expect it.<p>A standalone tool can either do static analysis (like a tag index, but more so) or communicate with the language runtime, and just leave the UI to the editor/IDE. Either way, it doesn't need to be in sed &#38; awk.",
      "num_comments": null,
      "story_id": 1752554,
      "story_title": "Ask HN: I'm done with the IDE. What's a good alternative?",
      "story_url": "",
      "parent_id": 1753078,
      "created_at_i": 1286142316,
      "_tags": [
        "comment",
        "author_silentbicycle",
        "story_1752554"
      ],
      "objectID": "1753703",
      "_highlightResult": {
        "author": {
          "value": "silentbicycle",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's because many of the people who build those <em>tools</em> have coupled them to an IDE, rather than making a standalone tool that could be made to work with any editor with a little effort. And while it would be changing files without the IDE knowing, version control systems run standalone and modify file currently being edited, too - it's not a problem when you expect it.<p>A standalone tool can either do <em>static</em> <em>analysis</em> (like a tag index, but more so) or communicate with the language runtime, and just leave the UI to the editor/IDE. Either way, it doesn't need to be in sed & awk.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: I'm done with the IDE. What's a good alternative?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-07-07T16:56:15.000Z",
      "title": null,
      "url": null,
      "author": "kenjackson",
      "points": null,
      "story_text": null,
      "comment_text": "What kitchen sink was thrown in C++?  The STL?  That's the main reason I first fell in love with C++.  Templates?  Exceptions?  RTTI?<p>IMO the problem with C++ is its C legacy (things like macros).  These things make it harder to read code and make it harder to write great tools for it (ever seen really good code completion or static analysis for C++ code?).",
      "num_comments": null,
      "story_id": 1494277,
      "story_title": "C# 4.0: The industrial response to Lisp?",
      "story_url": "http://axisofeval.blogspot.com/2010/07/c-40-industrial-response-to-lisp.html",
      "parent_id": 1494611,
      "created_at_i": 1278521775,
      "_tags": [
        "comment",
        "author_kenjackson",
        "story_1494277"
      ],
      "objectID": "1494684",
      "_highlightResult": {
        "author": {
          "value": "kenjackson",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "What kitchen sink was thrown in C++?  The STL?  That's the main reason I first fell in love with C++.  Templates?  Exceptions?  RTTI?<p>IMO the problem with C++ is its C legacy (things like macros).  These things make it harder to read code and make it harder to write great <em>tools</em> for it (ever seen really good code completion or <em>static</em> <em>analysis</em> for C++ code?).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "C# 4.0: The industrial response to Lisp?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://axisofeval.blogspot.com/2010/07/c-40-industrial-response-to-lisp.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-06-02T08:49:35.000Z",
      "title": null,
      "url": null,
      "author": "blasdel",
      "points": null,
      "story_text": null,
      "comment_text": "Just having builds go way faster would be awesome. Shove some static analysis in there for warnings, and maybe collect user feedback to feed into a statistical model of the likelihood that the warning was indicative of an error. Take real advantage of being a webapp.<p>I think you should run far away from emphasizing the matching of a core to it's most cost-effective target -- it's not something you need to do until you actually have something nearing the need to buy a shitload of parts and ship. You generally develop on one of several overpowered dev boards that you already owned. Pitch the multi-hardware parallel build as <i>testing</i>, not chip selection: 'what targets is my build not totally broken on'.<p>When I was doing some rather oddball FPGA development (trying to do Alan Kay style pedagogical CPU dev) I would have killed for this. I was attempting to build stuff with as little HDL as possible for clarity purposes, and would frequently fuck myself over when the Xilinx tools couldn't synthesize or place-and-route it anymore for my Spartan-3 hardware. Some of it was just their incompetence, where a hand-laid design could fit easily, but a lot of it was just classic traveling salesman problem woes. It would have been a lot easier to see what the real constraints I was hitting if I knew which chips it didn't work on anymore.<p>The vendor compiler toolchains are fucking dogshit. Just having that hosted and guaranteed not to collapse in on itself would be golden. You should also develop simple desktop software for flashing the builds for at least Linux and Mac OS X. At one point <i>I wrote my own flasher from scratch</i> that sucked but Xilinx's Windows flasher had shat itself on me and I couldn't get it to work again (the Linux stuff never worked at all, ever). Make a simple drag-and-drop flasher. You could even sell a rebranded USB-JTAG that's guaranteed not to suck.<p>Simulators are ridiculously awful, but you're not going to come anywhere near fixing that.<p>\"that the user ends up buying and using the most suitable hardware\" is a side effect of some of your features, not the real use case you should be selling. It feels somewhat greasy, because at some level you're just marketing hardware to me. Even if you do try to monetize that through some kind of affiliate thing, don't put it up front. You'll spook the engineers.",
      "num_comments": null,
      "story_id": 1397336,
      "story_title": "Ask HN's FPGA users: FPGA tool woes & wants?",
      "story_url": "",
      "parent_id": 1397336,
      "created_at_i": 1275468575,
      "_tags": [
        "comment",
        "author_blasdel",
        "story_1397336"
      ],
      "objectID": "1397456",
      "_highlightResult": {
        "author": {
          "value": "blasdel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Just having builds go way faster would be awesome. Shove some <em>static</em> <em>analysis</em> in there for warnings, and maybe collect user feedback to feed into a statistical model of the likelihood that the warning was indicative of an error. Take real advantage of being a webapp.<p>I think you should run far away from emphasizing the matching of a core to it's most cost-effective target -- it's not something you need to do until you actually have something nearing the need to buy a shitload of parts and ship. You generally develop on one of several overpowered dev boards that you already owned. Pitch the multi-hardware parallel build as <i>testing</i>, not chip selection: 'what targets is my build not totally broken on'.<p>When I was doing some rather oddball FPGA development (trying to do Alan Kay style pedagogical CPU dev) I would have killed for this. I was attempting to build stuff with as little HDL as possible for clarity purposes, and would frequently fuck myself over when the Xilinx <em>tools</em> couldn't synthesize or place-and-route it anymore for my Spartan-3 hardware. Some of it was just their incompetence, where a hand-laid design could fit easily, but a lot of it was just classic traveling salesman problem woes. It would have been a lot easier to see what the real constraints I was hitting if I knew which chips it didn't work on anymore.<p>The vendor compiler toolchains are fucking dogshit. Just having that hosted and guaranteed not to collapse in on itself would be golden. You should also develop simple desktop software for flashing the builds for at least Linux and Mac OS X. At one point <i>I wrote my own flasher from scratch</i> that sucked but Xilinx's Windows flasher had shat itself on me and I couldn't get it to work again (the Linux stuff never worked at all, ever). Make a simple drag-and-drop flasher. You could even sell a rebranded USB-JTAG that's guaranteed not to suck.<p>Simulators are ridiculously awful, but you're not going to come anywhere near fixing that.<p>\"that the user ends up buying and using the most suitable hardware\" is a side effect of some of your features, not the real use case you should be selling. It feels somewhat greasy, because at some level you're just marketing hardware to me. Even if you do try to monetize that through some kind of affiliate thing, don't put it up front. You'll spook the engineers.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN's FPGA users: FPGA tool woes & wants?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-03-11T03:04:38.000Z",
      "title": null,
      "url": null,
      "author": "jrockway",
      "points": null,
      "story_text": null,
      "comment_text": "geocar's response is pretty good, but I am going to disagree on some points.<p>Hyperlinked call graphs: nope.  Never needed it, don't know how to generate them for any language I use.  Emacs can't do it, but neither can anything else.  Write the code to do the work, and Emacs will support it in about 30 seconds.<p>All use of a given symbol: same problem.  The static analysis for this is Really Hard, and it would provide me with near-zero value.<p>Background compilation: yup.  Supported by pretty much every mode.<p>Refactoring: I've used Eclipse, but I've never had good luck with its refactoring tools.  The automated refactorings are <i>almost</i> what I want, but since exactly what I want is so simple, I just do it manually.  If you are renaming your classes everyday and you have to change the name in 1000 files, you have two problems that can't be solved by an IDE.<p>Keyword completion: excellent.  I was using Eclipse today, and there is a noticeable delay between when I press M-/ and when the keyword was completed.  I eventually learned  to not use that feature, because I can type faster than the auto-completion can \"intelligently select\" the right keyword.<p>Emacs is instantaneous, and right as often as anything else.  And I can expand things other than symbols, like long words in the documentation, or filenames in string literals, etc.<p>As for integration, I find Emacs to be quite well integrated for the work I do.  A few weeks ago, I was writing a Haskell app for use on Windows.  I was really not looking forward to it, until I realized that all the Haskell functionality works perfectly on Windows.  I never needed to leave Emacs; I could test my code (interactively or automatically) from the GHCi REPL and I could build binaries and docs with M-x compile.  Of course, it's just one keystroke to move to compilation errors (in both cases). If I needed to poke around in a shell, I just used Eshell, which works the same on every platform.  Everything you need to do is tightly integrated and very fast.<p>Working with Perl is just as nice; one keystroke runs the test suite in a nearby eshell, another just runs the tests that pertain to the current file.  Anything I want to do is usually one or two keys away, and a shell to do something complicated is just as easy to get to.  (For me, C-x C-x switches between the shell and the most-recently-used buffer.  Fast!)<p><i>Their UI's tend to be a lot more powerful because they are not designed to be run on windowless environments.</i><p>Not true.  But one thing that's nice about Emacs is that you can run Emacs in the background and connect to it multiple times.  If your X session dies, no information is lost.  If you are poking around in a shell, you just \"emacsclient -t file\" (which I alias to \"ec file\") and you are instantly working with that file in your normal Emacs session.<p><i>for large projects I use an IDE with a Vim emulation plugin</i><p>That means you are probably unaware of about 90% of Vim's features.  I've watched many experienced Vim users try to use various vi emulation plugins for Eclipse, and there is always a lot of cursing involved.  They eventually just invoke Eclipse functions from vim instead.<p>The underlying theme here is that IDEs make tasks that you perform once or twice a week really simple.  The \"traditional editors\" don't do much about that; instead they make the things you do 10,000 times a day really really simple.<p>(One other thing I notice is that IDE users tend to ignore features that Vim and Emacs have and dismiss them as unnecessary, while Emacs/Vim users steal the good features from IDEs as often as possible.)<p>In conclusion, you don't know much about Emacs.",
      "num_comments": null,
      "story_id": 1181742,
      "story_title": "New IDE: code bubbles",
      "story_url": "http://www.cs.brown.edu/people/acb/codebubbles_site.htm",
      "parent_id": 1182386,
      "created_at_i": 1268276678,
      "_tags": [
        "comment",
        "author_jrockway",
        "story_1181742"
      ],
      "objectID": "1182755",
      "_highlightResult": {
        "author": {
          "value": "jrockway",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "geocar's response is pretty good, but I am going to disagree on some points.<p>Hyperlinked call graphs: nope.  Never needed it, don't know how to generate them for any language I use.  Emacs can't do it, but neither can anything else.  Write the code to do the work, and Emacs will support it in about 30 seconds.<p>All use of a given symbol: same problem.  The <em>static</em> <em>analysis</em> for this is Really Hard, and it would provide me with near-zero value.<p>Background compilation: yup.  Supported by pretty much every mode.<p>Refactoring: I've used Eclipse, but I've never had good luck with its refactoring <em>tools</em>.  The automated refactorings are <i>almost</i> what I want, but since exactly what I want is so simple, I just do it manually.  If you are renaming your classes everyday and you have to change the name in 1000 files, you have two problems that can't be solved by an IDE.<p>Keyword completion: excellent.  I was using Eclipse today, and there is a noticeable delay between when I press M-/ and when the keyword was completed.  I eventually learned  to not use that feature, because I can type faster than the auto-completion can \"intelligently select\" the right keyword.<p>Emacs is instantaneous, and right as often as anything else.  And I can expand things other than symbols, like long words in the documentation, or filenames in string literals, etc.<p>As for integration, I find Emacs to be quite well integrated for the work I do.  A few weeks ago, I was writing a Haskell app for use on Windows.  I was really not looking forward to it, until I realized that all the Haskell functionality works perfectly on Windows.  I never needed to leave Emacs; I could test my code (interactively or automatically) from the GHCi REPL and I could build binaries and docs with M-x compile.  Of course, it's just one keystroke to move to compilation errors (in both cases). If I needed to poke around in a shell, I just used Eshell, which works the same on every platform.  Everything you need to do is tightly integrated and very fast.<p>Working with Perl is just as nice; one keystroke runs the test suite in a nearby eshell, another just runs the tests that pertain to the current file.  Anything I want to do is usually one or two keys away, and a shell to do something complicated is just as easy to get to.  (For me, C-x C-x switches between the shell and the most-recently-used buffer.  Fast!)<p><i>Their UI's tend to be a lot more powerful because they are not designed to be run on windowless environments.</i><p>Not true.  But one thing that's nice about Emacs is that you can run Emacs in the background and connect to it multiple times.  If your X session dies, no information is lost.  If you are poking around in a shell, you just \"emacsclient -t file\" (which I alias to \"ec file\") and you are instantly working with that file in your normal Emacs session.<p><i>for large projects I use an IDE with a Vim emulation plugin</i><p>That means you are probably unaware of about 90% of Vim's features.  I've watched many experienced Vim users try to use various vi emulation plugins for Eclipse, and there is always a lot of cursing involved.  They eventually just invoke Eclipse functions from vim instead.<p>The underlying theme here is that IDEs make tasks that you perform once or twice a week really simple.  The \"traditional editors\" don't do much about that; instead they make the things you do 10,000 times a day really really simple.<p>(One other thing I notice is that IDE users tend to ignore features that Vim and Emacs have and dismiss them as unnecessary, while Emacs/Vim users steal the good features from IDEs as often as possible.)<p>In conclusion, you don't know much about Emacs.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "New IDE: code bubbles",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.cs.brown.edu/people/acb/codebubbles_site.htm",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-03-07T05:31:20.000Z",
      "title": null,
      "url": null,
      "author": "megaduck",
      "points": null,
      "story_text": null,
      "comment_text": "As a dynamic language guy, I can't help but look at the static analysis here and feel a twinge of jealousy.  There really isn't anything like this in the Ruby world.<p>Some stuff is starting to emerge, but we're still largely dependent on tests to catch stupid mistakes.  When I'm chasing down a bug, it would be nice to have a variety of tools to throw at the problem.",
      "num_comments": null,
      "story_id": 1172765,
      "story_title": "How to convince any C developer to dump gcc and use clang",
      "story_url": "http://fseek.me/2010/03/how-to-convince-any-c-developer-to-dump-gcc-and-use-clang/",
      "parent_id": 1172765,
      "created_at_i": 1267939880,
      "_tags": [
        "comment",
        "author_megaduck",
        "story_1172765"
      ],
      "objectID": "1172935",
      "_highlightResult": {
        "author": {
          "value": "megaduck",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "As a dynamic language guy, I can't help but look at the <em>static</em> <em>analysis</em> here and feel a twinge of jealousy.  There really isn't anything like this in the Ruby world.<p>Some stuff is starting to emerge, but we're still largely dependent on tests to catch stupid mistakes.  When I'm chasing down a bug, it would be nice to have a variety of <em>tools</em> to throw at the problem.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How to convince any C developer to dump gcc and use clang",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://fseek.me/2010/03/how-to-convince-any-c-developer-to-dump-gcc-and-use-clang/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-07T07:32:21.000Z",
      "title": "",
      "url": "",
      "author": "maaku",
      "points": 15,
      "story_text": null,
      "comment_text": "Except that software is written by machines these days. I stopped writing in assembly language after it stopped being cool in the 90's. Even still, you'd have to be hand-crafting machine code in a hex editor to really get all the machines out of the loop.<p>These days I write in an interpreted language using complex libraries that handle a multitude of protocol choices for me. Even if you argue that each of those tools were at one point hand-crafted, even down to the compiler, there are now development tools that help me write code, from basic code completion and tooltips to the most complex static and runtime analysis. That is machines writing software, with a human in the loop.",
      "num_comments": null,
      "story_id": 3937871,
      "story_title": "Why do web sites and software take so long to build? And why is it so hard?",
      "story_url": "http://www.scottporad.com/2012/05/06/why-do-web-sites-and-software-take-so-long-to-build-and-why-is-it-so-hard/",
      "parent_id": 3937871,
      "created_at_i": 1336375941,
      "_tags": [
        "comment",
        "author_maaku",
        "story_3937871"
      ],
      "objectID": "3938047",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "maaku",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Except that software is written by machines these days. I stopped writing in assembly language after it stopped being cool in the 90's. Even still, you'd have to be hand-crafting machine code in a hex editor to really get all the machines out of the loop.<p>These days I write in an interpreted language using complex libraries that handle a multitude of protocol choices for me. Even if you argue that each of those <em>tools</em> were at one point hand-crafted, even down to the compiler, there are now development <em>tools</em> that help me write code, from basic code completion and tooltips to the most complex <em>static</em> and runtime <em>analysis.</em> That is machines writing software, with a human in the loop.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why do web sites and software take so long to build? And why is it so hard?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.scottporad.com/2012/05/06/why-do-web-sites-and-software-take-so-long-to-build-and-why-is-it-so-hard/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-05T18:26:44.000Z",
      "title": null,
      "url": null,
      "author": "seanmcdirmid",
      "points": 1,
      "story_text": null,
      "comment_text": "Static typing is definitely useful, but like humans and chimps, the so called static languages share much of their DNA with their dynamic counterparts; and static typing doesn&#x27;t necessarily account for more than a few percentage points of productivity increases (though those percents are definitely noticeable). More to the point, you still need to test non trivial Haskell code and the lack of a decent debugger is a tragedy.<p>Safety critical systems are generally real tine so Haskell is off the table. I&#x27;ll also spend a lot of tine manually verifying the code, and using alot of external analysis and verification tools, so restricted C++ is fine in that case. Now, if you told me that the system was safety critical and nit real time, and the system wasn&#x27;t important enough to merit lots of manual verification, then Haskell would be a great choice because its static type system is better than nothing.",
      "num_comments": null,
      "story_id": 8408452,
      "story_title": "Haskell, Monads and Purity",
      "story_url": "http://jelv.is/blog/Haskell-Monads-and-Purity/",
      "parent_id": 8412393,
      "created_at_i": 1412533604,
      "_tags": [
        "comment",
        "author_seanmcdirmid",
        "story_8408452"
      ],
      "objectID": "8412976",
      "_highlightResult": {
        "author": {
          "value": "seanmcdirmid",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<em>Static</em> typing is definitely useful, but like humans and chimps, the so called <em>static</em> languages share much of their DNA with their dynamic counterparts; and <em>static</em> typing doesn't necessarily account for more than a few percentage points of productivity increases (though those percents are definitely noticeable). More to the point, you still need to test non trivial Haskell code and the lack of a decent debugger is a tragedy.<p>Safety critical systems are generally real tine so Haskell is off the table. I'll also spend a lot of tine manually verifying the code, and using alot of external <em>analysis</em> and verification <em>tools</em>, so restricted C++ is fine in that case. Now, if you told me that the system was safety critical and nit real time, and the system wasn't important enough to merit lots of manual verification, then Haskell would be a great choice because its <em>static</em> type system is better than nothing.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Haskell, Monads and Purity",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://jelv.is/blog/Haskell-Monads-and-Purity/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-20T03:31:23.000Z",
      "title": null,
      "url": null,
      "author": "csense",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt; I don&#x27;t know of legitimate websites that obfuscate their JS. (Minification doesn&#x27;t count.)<p>What exactly is the difference between obfuscation and minimization?  Could you write a program to tell the difference between a JS file that&#x27;s been benevolently minified versus maliciously obfuscated?  For that matter, how do <i>humans</i> tell the difference between minification and obfuscation?<p>I think that, if you define &quot;obfuscation&quot; as &quot;transforming source code into a less readable form,&quot; then most automatic program transformations -- <i>especially</i> those specifically intended to reduce the size of the resulting code -- will also be obfuscations.<p>Of course, if only malware authors would make their products comply with RFC 3514, these problems would go away; security sandboxes and antimalware programs could simply and effectively filter based on the intent of a program&#x27;s author, rather than static or dynamic analysis of the program&#x27;s code [1].<p>[1] <a href=\"http://tools.ietf.org/html/rfc3514\" rel=\"nofollow\">http:&#x2F;&#x2F;tools.ietf.org&#x2F;html&#x2F;rfc3514</a>",
      "num_comments": null,
      "story_id": 7082862,
      "story_title": "Java Primary Cause of 91 Percent of Attacks: Cisco",
      "story_url": "http://www.eweek.com/security/java-primary-cause-of-91-percent-of-attacks-cisco.html",
      "parent_id": 7083285,
      "created_at_i": 1390188683,
      "_tags": [
        "comment",
        "author_csense",
        "story_7082862"
      ],
      "objectID": "7087374",
      "_highlightResult": {
        "author": {
          "value": "csense",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; I don't know of legitimate websites that obfuscate their JS. (Minification doesn't count.)<p>What exactly is the difference between obfuscation and minimization?  Could you write a program to tell the difference between a JS file that's been benevolently minified versus maliciously obfuscated?  For that matter, how do <i>humans</i> tell the difference between minification and obfuscation?<p>I think that, if you define &quot;obfuscation&quot; as &quot;transforming source code into a less readable form,&quot; then most automatic program transformations -- <i>especially</i> those specifically intended to reduce the size of the resulting code -- will also be obfuscations.<p>Of course, if only malware authors would make their products comply with RFC 3514, these problems would go away; security sandboxes and antimalware programs could simply and effectively filter based on the intent of a program's author, rather than <em>static</em> or dynamic <em>analysis</em> of the program's code [1].<p>[1] <a href=\"http://tools.ietf.org/html/rfc3514\" rel=\"nofollow\">http://<em>tools</em>.ietf.org/html/rfc3514</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Java Primary Cause of 91 Percent of Attacks: Cisco",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.eweek.com/security/java-primary-cause-of-91-percent-of-attacks-cisco.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-29T01:17:26.000Z",
      "title": null,
      "url": null,
      "author": "dietrichepp",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; If the tooling for verifying C is really so good, why not verify the C parts of the JRE? Then they&#x27;d be proven once and for all, and lots of systems would benefit.<p>I&#x27;m going to quote the article again...<p>&gt; You&#x27;re more dependent on the decisions made by the language implementers than you think.<p>When you use Java, you don&#x27;t have the opportunity to second-guess the choices that produced the JRE.  And I think you&#x27;re not quite getting what I&#x27;m saying: I&#x27;m not saying that &quot;we should switch to systems which are written more in C&quot;, I&#x27;m saying that writing systems in C protects you from mistakes in the JRE (which you have no control over) in exchange for exposing you to your own mistakes (which you can control).  You can then spend a large amount of time and money developing and verifying your system.  The goals and constraints of your project will determine whether this is a good trade-off.  I&#x27;m certain that Java is preferable for writing the vast majority of web apps, but the web is not everything.<p>&gt; If the tooling for verifying C is really so good, why not verify the C parts of the JRE?<p>First, I&#x27;m going to guess that an enormous amount of static and dynamic analysis has been done on the JRE.  Bugs in it are rather rare these days, given its size and complexity.<p>However, verification tools are generally not suited to this particular task.  Verification tools are better at verifying typical application code, and the JRE needs to do a lot of very unusual operations in order to work.  In cases where you&#x27;d use verification, you&#x27;d also typically use a &quot;safe&quot; subset of C.  Some of these subsets don&#x27;t even permit dynamic memory allocation, or if so, only permit it at program startup.<p>So, it may actually be more straightforward to deliver a working Mars rover in C than it would be to deliver a verified JRE.  Neither task is easy.",
      "num_comments": null,
      "story_id": 8804153,
      "story_title": "Would You Bet $100M on Your Pet Programming Language? (2007)",
      "story_url": "http://prog21.dadgum.com/13.html?",
      "parent_id": 8806260,
      "created_at_i": 1419815846,
      "_tags": [
        "comment",
        "author_dietrichepp",
        "story_8804153"
      ],
      "objectID": "8808160",
      "_highlightResult": {
        "author": {
          "value": "dietrichepp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; If the tooling for verifying C is really so good, why not verify the C parts of the JRE? Then they'd be proven once and for all, and lots of systems would benefit.<p>I'm going to quote the article again...<p>&gt; You're more dependent on the decisions made by the language implementers than you think.<p>When you use Java, you don't have the opportunity to second-guess the choices that produced the JRE.  And I think you're not quite getting what I'm saying: I'm not saying that &quot;we should switch to systems which are written more in C&quot;, I'm saying that writing systems in C protects you from mistakes in the JRE (which you have no control over) in exchange for exposing you to your own mistakes (which you can control).  You can then spend a large amount of time and money developing and verifying your system.  The goals and constraints of your project will determine whether this is a good trade-off.  I'm certain that Java is preferable for writing the vast majority of web apps, but the web is not everything.<p>&gt; If the tooling for verifying C is really so good, why not verify the C parts of the JRE?<p>First, I'm going to guess that an enormous amount of <em>static</em> and dynamic <em>analysis</em> has been done on the JRE.  Bugs in it are rather rare these days, given its size and complexity.<p>However, verification <em>tools</em> are generally not suited to this particular task.  Verification <em>tools</em> are better at verifying typical application code, and the JRE needs to do a lot of very unusual operations in order to work.  In cases where you'd use verification, you'd also typically use a &quot;safe&quot; subset of C.  Some of these subsets don't even permit dynamic memory allocation, or if so, only permit it at program startup.<p>So, it may actually be more straightforward to deliver a working Mars rover in C than it would be to deliver a verified JRE.  Neither task is easy.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Would You Bet $100M on Your Pet Programming Language? (2007)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://prog21.dadgum.com/13.html?",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-03-06T08:47:45.000Z",
      "title": null,
      "url": null,
      "author": "russell_h",
      "points": null,
      "story_text": null,
      "comment_text": "<i>We are adding a number of measures to help prevent additional malicious applications using similar exploits from being distributed through Android Market</i><p>Am I the only one thinking they might be planning to leverage their recent acquisition of zynamics on this front? In particular, zynamics seems to have developed some tools[1] for classifying malware based on (as I understand it) some sort of static control-flow analysis. I'm far from an expert on the matter, but that sounds like it has some potential with regards to keeping malicious apps out of the Android Market.<p>[1] <a href=\"http://www.zynamics.com/vxclass.html\" rel=\"nofollow\">http://www.zynamics.com/vxclass.html</a>",
      "num_comments": null,
      "story_id": 2293615,
      "story_title": "An Update on Android Market Security",
      "story_url": "http://googlemobile.blogspot.com/2011/03/update-on-android-market-security.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+OfficialGoogleMobileBlog+%28Official+Google+Mobile+Blog%29",
      "parent_id": 2293615,
      "created_at_i": 1299401265,
      "_tags": [
        "comment",
        "author_russell_h",
        "story_2293615"
      ],
      "objectID": "2293823",
      "_highlightResult": {
        "author": {
          "value": "russell_h",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>We are adding a number of measures to help prevent additional malicious applications using similar exploits from being distributed through Android Market</i><p>Am I the only one thinking they might be planning to leverage their recent acquisition of zynamics on this front? In particular, zynamics seems to have developed some <em>tools</em>[1] for classifying malware based on (as I understand it) some sort of <em>static</em> control-flow <em>analysis.</em> I'm far from an expert on the matter, but that sounds like it has some potential with regards to keeping malicious apps out of the Android Market.<p>[1] <a href=\"http://www.zynamics.com/vxclass.html\" rel=\"nofollow\">http://www.zynamics.com/vxclass.html</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "An Update on Android Market Security",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://googlemobile.blogspot.com/2011/03/update-on-android-market-security.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+OfficialGoogleMobileBlog+%28Official+Google+Mobile+Blog%29",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-03-10T22:08:24.000Z",
      "title": null,
      "url": null,
      "author": "InclinedPlane",
      "points": null,
      "story_text": null,
      "comment_text": "Regardless of anyone's opinions of this particular IDE / workflow it's been clear for a while that the future of developer tools will almost certainly include:<p>- IDEs that take advantage of greater knowledge of code than just a simple organization of text files (e.g. reflection, call stacks, static and dynamic analysis, etc.)<p>- Tying bug-tracking, automated testing, and source control together in a coherent way.<p>- Generally merging the developer workflow into a seamless experience instead of a disjoint series of steps across N sets of distinct tools.<p>Already we're seeing plenty of movement in this direction, with things like visual studio's intellisense, more in-IDE unit test tools, and the plethora of refactoring tools out there.<p>The days of IDEs that do little more than compile and keep track of collections of files for you are numbered.",
      "num_comments": null,
      "story_id": 1181742,
      "story_title": "New IDE: code bubbles",
      "story_url": "http://www.cs.brown.edu/people/acb/codebubbles_site.htm",
      "parent_id": 1181742,
      "created_at_i": 1268258904,
      "_tags": [
        "comment",
        "author_InclinedPlane",
        "story_1181742"
      ],
      "objectID": "1182137",
      "_highlightResult": {
        "author": {
          "value": "InclinedPlane",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Regardless of anyone's opinions of this particular IDE / workflow it's been clear for a while that the future of developer <em>tools</em> will almost certainly include:<p>- IDEs that take advantage of greater knowledge of code than just a simple organization of text files (e.g. reflection, call stacks, <em>static</em> and dynamic <em>analysis</em>, etc.)<p>- Tying bug-tracking, automated testing, and source control together in a coherent way.<p>- Generally merging the developer workflow into a seamless experience instead of a disjoint series of steps across N sets of distinct <em>tools</em>.<p>Already we're seeing plenty of movement in this direction, with things like visual studio's intellisense, more in-IDE unit test <em>tools</em>, and the plethora of refactoring <em>tools</em> out there.<p>The days of IDEs that do little more than compile and keep track of collections of files for you are numbered.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "New IDE: code bubbles",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.cs.brown.edu/people/acb/codebubbles_site.htm",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-02T19:30:26.000Z",
      "title": null,
      "url": null,
      "author": "bbncyber",
      "points": 1,
      "story_text": null,
      "comment_text": "Raytheon BBN Technologies Cyber Security Department is hiring (Cambridge, MA and Columbia, MD). I currently work here in a technical position.<p>What You Could Do<p>&quot;As part of the Cyber Security team at BBN, you might write Android apps and inject them with malware to test malware detection tools, devise creative ways to graphically represent data about the lineage of malware, reverse engineer an embedded device looking for vulnerabilities that a hacker could exploit, or create and implement algorithms and code to prevent data exfiltration from military networks.&quot;<p>I know that is copied from the req. I don&#x27;t want to post details that might get me in trouble. That being said, it is an accurate description of what you could do.<p>What We Are Looking For<p>We are looking for developers, reverse engineers, cyber researchers, etc., BS to PhD, 0-6 years experience. US citizenship required, willingness to obtain clearance preferred but not required. Offices in Columbia, MD and Cambridge, MA.<p>Job Requirements:\\n* Great imagination\\n* Strong written and oral communication skills\\n* Solid programming skills, particularly in C&#x2F;C++ or Java but also x86 (or other) assembly language, Python or Perl\\n* Some experience in designing and developing software systems, as well as performing system test and integration<p>Experience or interest in any of the following is desirable:\\n* Networking code development\\n* Operating system internals and&#x2F;or kernel development\\n* Network protocol analysis techniques\\n* Virtualization and sandboxing\\n* Reverse engineering\\n* System analysis and engineering\\n* Static and dynamic binary analysis\\n* Low-level knowledge of consumer electronics (e.g., mobile phones, ARM processors, etc.)\\n* Embedded systems\\n* Other security topics like fuzzing, memory analysis, malware techniques, cryptography, etc.<p>Shoot me an email at ebarnes@bbn.com if interested. I&#x27;m happy to answer questions.",
      "num_comments": null,
      "story_id": 7970366,
      "story_title": "Ask HN: Who is hiring? (July 2014)",
      "story_url": "",
      "parent_id": 7970366,
      "created_at_i": 1404329426,
      "_tags": [
        "comment",
        "author_bbncyber",
        "story_7970366"
      ],
      "objectID": "7979113",
      "_highlightResult": {
        "author": {
          "value": "bbncyber",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Raytheon BBN Technologies Cyber Security Department is hiring (Cambridge, MA and Columbia, MD). I currently work here in a technical position.<p>What You Could Do<p>&quot;As part of the Cyber Security team at BBN, you might write Android apps and inject them with malware to test malware detection <em>tools</em>, devise creative ways to graphically represent data about the lineage of malware, reverse engineer an embedded device looking for vulnerabilities that a hacker could exploit, or create and implement algorithms and code to prevent data exfiltration from military networks.&quot;<p>I know that is copied from the req. I don't want to post details that might get me in trouble. That being said, it is an accurate description of what you could do.<p>What We Are Looking For<p>We are looking for developers, reverse engineers, cyber researchers, etc., BS to PhD, 0-6 years experience. US citizenship required, willingness to obtain clearance preferred but not required. Offices in Columbia, MD and Cambridge, MA.<p>Job Requirements:\\n* Great imagination\\n* Strong written and oral communication skills\\n* Solid programming skills, particularly in C/C++ or Java but also x86 (or other) assembly language, Python or Perl\\n* Some experience in designing and developing software systems, as well as performing system test and integration<p>Experience or interest in any of the following is desirable:\\n* Networking code development\\n* Operating system internals and/or kernel development\\n* Network protocol <em>analysis</em> techniques\\n* Virtualization and sandboxing\\n* Reverse engineering\\n* System <em>analysis</em> and engineering\\n* <em>Static</em> and dynamic binary <em>analysis</em>\\n* Low-level knowledge of consumer electronics (e.g., mobile phones, ARM processors, etc.)\\n* Embedded systems\\n* Other security topics like fuzzing, memory <em>analysis</em>, malware techniques, cryptography, etc.<p>Shoot me an email at ebarnes@bbn.com if interested. I'm happy to answer questions.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (July 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-12-01T17:46:01.000Z",
      "title": null,
      "url": null,
      "author": "erex78",
      "points": null,
      "story_text": null,
      "comment_text": "Mapsense Position: Backend Engineer<p>Keywords: INTERN, VISA, FULLTIME.\nMinimum education: Bachelor&#x27;s degree in CS&#x2F;EECS.\nMinimum experience: 2 years.\nUseful to know: Java, Maven, ZooKeeper, MongoDB, Lucene, Git.<p>Tone A (professional):<p>The backend team at Mapsense is a small but highly motivated group building scalable tools for geodata analysis. We&#x27;re looking for an independent, experienced backend engineer to join our team and and contribute while learning the infrastructure. An ideal candidate would be comfortable with designing and implementing web APIs; building and testing autoscaled services; and being productive, professional, and personable on a daily basis.<p>Tone B (nerdy):<p>There&#x27;s a word to describe the freezing of a machine that executes billions of electronic instructions per second, then examining its memory&#x27;s contents bit, by, bit: debugging. If hitting breakpoints sends chills down your spine, you&#x27;re probably cut out for backend engineering at Mapsense. Hack away at the backend of a complex but intuitive geodata analysis API, implemented as a distributed, autoscaled nexus of modern open source technologies. And in case joining a team of intelligent, highly motivated code ninjas isn&#x27;t enough, we have one more guarantee: consider boredom a thing of the past.<p>Tone C (cute):<p>The one thing that sets Mapsense apart from all the other geodata startups is the sheer popularity of our cute office dog, Amos. To be honest, our backend engineering team is a little jealous of all that attention. They&#x27;ve already developed a versatile but highly intuitive API for geodata ingestion and analysis, all while placing massive emphasis on documentation, testing, and teamwork. But to really shine, they need some help! Will you be the next independent, experienced engineer to join the backend ranks and help surpass Amos&#x27; renown once and for all?<p>Tone D (challenging):<p>Tired of companies living off of boring CRUD APIs with a single, static database? So are we. The backend engineering team at Mapsense is building a distributed, scalable backend architecture to support the ingestion and analysis of massive amounts of geodata, but writing well-designed, documented, and fully tested code isn&#x27;t easy. That&#x27;s why we&#x27;re only hiring highly motivated, independent engineers to join a tiny backend team always willing to commit to quality. It won&#x27;t be easy, but nothing worth doing ever is.<p>Tone E (meaningful):<p>Help Mapsense revolutionize the process of geodata analysis by joining our backend engineering team in developing an incredibly versatile tool with use cases in a variety of industries, from climate to marketing to military. You&#x27;ll have the opportunity to jump into a robust, scalable system built on the latest open source backend technologies, and work with a motivated group of engineers. Expect to grow from interesting engineering problems every day while transforming the world one data set at a time.",
      "num_comments": null,
      "story_id": 8681040,
      "story_title": "Ask HN: Who is hiring? (December 2014)",
      "story_url": "",
      "parent_id": 8681040,
      "created_at_i": 1417455961,
      "_tags": [
        "comment",
        "author_erex78",
        "story_8681040"
      ],
      "objectID": "8682438",
      "_highlightResult": {
        "author": {
          "value": "erex78",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Mapsense Position: Backend Engineer<p>Keywords: INTERN, VISA, FULLTIME.\nMinimum education: Bachelor's degree in CS/EECS.\nMinimum experience: 2 years.\nUseful to know: Java, Maven, ZooKeeper, MongoDB, Lucene, Git.<p>Tone A (professional):<p>The backend team at Mapsense is a small but highly motivated group building scalable <em>tools</em> for geodata <em>analysis.</em> We're looking for an independent, experienced backend engineer to join our team and and contribute while learning the infrastructure. An ideal candidate would be comfortable with designing and implementing web APIs; building and testing autoscaled services; and being productive, professional, and personable on a daily basis.<p>Tone B (nerdy):<p>There's a word to describe the freezing of a machine that executes billions of electronic instructions per second, then examining its memory's contents bit, by, bit: debugging. If hitting breakpoints sends chills down your spine, you're probably cut out for backend engineering at Mapsense. Hack away at the backend of a complex but intuitive geodata <em>analysis</em> API, implemented as a distributed, autoscaled nexus of modern open source technologies. And in case joining a team of intelligent, highly motivated code ninjas isn't enough, we have one more guarantee: consider boredom a thing of the past.<p>Tone C (cute):<p>The one thing that sets Mapsense apart from all the other geodata startups is the sheer popularity of our cute office dog, Amos. To be honest, our backend engineering team is a little jealous of all that attention. They've already developed a versatile but highly intuitive API for geodata ingestion and <em>analysis</em>, all while placing massive emphasis on documentation, testing, and teamwork. But to really shine, they need some help! Will you be the next independent, experienced engineer to join the backend ranks and help surpass Amos' renown once and for all?<p>Tone D (challenging):<p>Tired of companies living off of boring CRUD APIs with a single, <em>static</em> database? So are we. The backend engineering team at Mapsense is building a distributed, scalable backend architecture to support the ingestion and <em>analysis</em> of massive amounts of geodata, but writing well-designed, documented, and fully tested code isn't easy. That's why we're only hiring highly motivated, independent engineers to join a tiny backend team always willing to commit to quality. It won't be easy, but nothing worth doing ever is.<p>Tone E (meaningful):<p>Help Mapsense revolutionize the process of geodata <em>analysis</em> by joining our backend engineering team in developing an incredibly versatile tool with use cases in a variety of industries, from climate to marketing to military. You'll have the opportunity to jump into a robust, scalable system built on the latest open source backend technologies, and work with a motivated group of engineers. Expect to grow from interesting engineering problems every day while transforming the world one data set at a time.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is hiring? (December 2014)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-08T18:42:10.000Z",
      "title": null,
      "url": null,
      "author": "fat0wl",
      "points": null,
      "story_text": null,
      "comment_text": "good points, but yeah the reason i lump them together (even though I agree that C preprocessors vs. css vs. js vs. jvm abstraction are obviously very different technologies) is that in the context of this discussion, i see them as a layer of abstraction that basically mangles the ability for code analysis (whether it be static or in debugging) to happen in a way that feels comprehensive<p>for some technologies this is being alleviated with source maps, but it still feels like over-complication when there are library alternatives available (Underscore, as you point out). Because when it comes down to it you will need to debug &amp; understand some language paradigms&#x2F;quirks of the language you are transcompiling to, so it would behoove the developer to be as fluent in the target language as possible (&amp; of course, coding natively in it to begin with promotes fluency...)<p>as the tools become stronger the danger disappears, yet the base language has simultaneously matured to the point where this extra technology may be nearing obsolescence... i understand in js there is some lag with web standards boards etc., but taking Java as an example, annotations and other language functions were added while simultaneously the libraries&#x2F;containers (web frameworks, Spring, EE) got more powerful. It is a pretty strong &amp; mature toolset probably mainly due to the language evolution always being forced back toward the core.<p>From the limited amount I know, the other JVM languages are implemented against the JVM spec which is matured in a similar way, thus facilitating easier implementation of language features &amp; interoperability.",
      "num_comments": null,
      "story_id": 8856226,
      "story_title": "Applying NASA coding standards to JavaScript",
      "story_url": "http://pixelscommander.com/en/javascript/nasa-coding-standarts-for-javascript-performance/",
      "parent_id": 8857360,
      "created_at_i": 1420742530,
      "_tags": [
        "comment",
        "author_fat0wl",
        "story_8856226"
      ],
      "objectID": "8858030",
      "_highlightResult": {
        "author": {
          "value": "fat0wl",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "good points, but yeah the reason i lump them together (even though I agree that C preprocessors vs. css vs. js vs. jvm abstraction are obviously very different technologies) is that in the context of this discussion, i see them as a layer of abstraction that basically mangles the ability for code <em>analysis</em> (whether it be <em>static</em> or in debugging) to happen in a way that feels comprehensive<p>for some technologies this is being alleviated with source maps, but it still feels like over-complication when there are library alternatives available (Underscore, as you point out). Because when it comes down to it you will need to debug &amp; understand some language paradigms/quirks of the language you are transcompiling to, so it would behoove the developer to be as fluent in the target language as possible (&amp; of course, coding natively in it to begin with promotes fluency...)<p>as the <em>tools</em> become stronger the danger disappears, yet the base language has simultaneously matured to the point where this extra technology may be nearing obsolescence... i understand in js there is some lag with web standards boards etc., but taking Java as an example, annotations and other language functions were added while simultaneously the libraries/containers (web frameworks, Spring, EE) got more powerful. It is a pretty strong &amp; mature <em>tools</em>et probably mainly due to the language evolution always being forced back toward the core.<p>From the limited amount I know, the other JVM languages are implemented against the JVM spec which is matured in a similar way, thus facilitating easier implementation of language features &amp; interoperability.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Applying NASA coding standards to JavaScript",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pixelscommander.com/en/javascript/nasa-coding-standarts-for-javascript-performance/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-08T21:45:38.000Z",
      "title": null,
      "url": null,
      "author": "nanolith",
      "points": null,
      "story_text": null,
      "comment_text": "I agree with this assessment.  There is nothing inherently wrong with C.  While alternative languages have certain advantages, there are clear reasons why core foundational libraries like OpenSSL are written in C: portability, age of the code base, knowledge of the contributors, etc.<p>While I would personally like to see a pragmatic move towards C++ in many of these low level libraries for some of the additional type safety and mechanics the language provides, this is a normative idea only, and I am under no delusion that it would necessarily result in better code.  Good software transcends language.<p>I would, however, like to see enhancements to the style of code being written in this library so that tools like static analyzers and contract verifiers can provide meaningful results.  A craftsman is only as good as how well he&#x2F;she can make use of the available tools.  Much of OpenSSL defies analysis, which is why the more bone-headed of these vulnerabilities, such as Heartbleed, are so hard to find.<p>It&#x27;s impossible to eliminate all bugs.  But, it is possible to build code in such a way that when there is the suspicion of a bug, one has a fairly good idea of how and why it is occurring.  It is also possible to structure code -- even C and assembler -- so that it&#x27;s easier to read and analyze, be this by eye or using tools.  Finally, it&#x27;s possible to structure code so that automated unit testing provides meaningful results regarding boundary conditions and contracts between functions.  This latter point isn&#x27;t meant to find bugs on its own, but rather to codify the more subtle bits of contracts between functions and data structures in a defensive way to ensure that future patches -- like the one that caused Heartbleed -- don&#x27;t stomp on assumptions made in software.",
      "num_comments": null,
      "story_id": 8856717,
      "story_title": "OpenSSL Security Advisory",
      "story_url": "https://www.openssl.org/news/secadv_20150108.txt",
      "parent_id": 8859089,
      "created_at_i": 1420753538,
      "_tags": [
        "comment",
        "author_nanolith",
        "story_8856717"
      ],
      "objectID": "8859222",
      "_highlightResult": {
        "author": {
          "value": "nanolith",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I agree with this assessment.  There is nothing inherently wrong with C.  While alternative languages have certain advantages, there are clear reasons why core foundational libraries like OpenSSL are written in C: portability, age of the code base, knowledge of the contributors, etc.<p>While I would personally like to see a pragmatic move towards C++ in many of these low level libraries for some of the additional type safety and mechanics the language provides, this is a normative idea only, and I am under no delusion that it would necessarily result in better code.  Good software transcends language.<p>I would, however, like to see enhancements to the style of code being written in this library so that <em>tools</em> like <em>static</em> analyzers and contract verifiers can provide meaningful results.  A craftsman is only as good as how well he/she can make use of the available <em>tools</em>.  Much of OpenSSL defies <em>analysis</em>, which is why the more bone-headed of these vulnerabilities, such as Heartbleed, are so hard to find.<p>It's impossible to eliminate all bugs.  But, it is possible to build code in such a way that when there is the suspicion of a bug, one has a fairly good idea of how and why it is occurring.  It is also possible to structure code -- even C and assembler -- so that it's easier to read and analyze, be this by eye or using <em>tools</em>.  Finally, it's possible to structure code so that automated unit testing provides meaningful results regarding boundary conditions and contracts between functions.  This latter point isn't meant to find bugs on its own, but rather to codify the more subtle bits of contracts between functions and data structures in a defensive way to ensure that future patches -- like the one that caused Heartbleed -- don't stomp on assumptions made in software.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "OpenSSL Security Advisory",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.openssl.org/news/secadv_20150108.txt",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-01-03T07:19:06.000Z",
      "title": null,
      "url": null,
      "author": "heyitsnick",
      "points": null,
      "story_text": null,
      "comment_text": "Certainly possible, and teams can utilise off-the-shelf analytics tools to aid in the analysis (if that's allowed); however using this information beyond very simple adjustments (such as preflop) is very difficult. Also any deviation from a balanced strategy will open up the bot to counter-exploitation.<p>As I say if dummy players are in there (playing easily exploitable passive or maniacal strategy) then I think there's good reason to implement an exploitive strat; otherwise the effort probably won't have the payoff amongst other static-strategy players.",
      "num_comments": null,
      "story_id": 2062336,
      "story_title": "6.912 - MIT Pokerbot Competition",
      "story_url": "http://pokerbots.mit.edu/",
      "parent_id": 2062439,
      "created_at_i": 1294039146,
      "_tags": [
        "comment",
        "author_heyitsnick",
        "story_2062336"
      ],
      "objectID": "2062461",
      "_highlightResult": {
        "author": {
          "value": "heyitsnick",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Certainly possible, and teams can utilise off-the-shelf analytics <em>tools</em> to aid in the <em>analysis</em> (if that's allowed); however using this information beyond very simple adjustments (such as preflop) is very difficult. Also any deviation from a balanced strategy will open up the bot to counter-exploitation.<p>As I say if dummy players are in there (playing easily exploitable passive or maniacal strategy) then I think there's good reason to implement an exploitive strat; otherwise the effort probably won't have the payoff amongst other <em>static</em>-strategy players.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "6.912 - MIT Pokerbot Competition",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pokerbots.mit.edu/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-10-10T11:43:53.000Z",
      "title": "",
      "url": "",
      "author": "jules",
      "points": 6,
      "story_text": null,
      "comment_text": "Please make the language a nice target for other languages to compile to. Better yet, make a lower level bytecode language that Dart can compile down to as well as other languages.<p>For example value types would be excellent. Even better would be explicit regions, but I'm sure that's not going to happen.<p>Also, please fix this:<p><i>The type system is unsound, due to the covariance of generic types. This is\na deliberate choice (and undoubtedly controversial). Experience has shown that sound type rules for generics fly in the face of programmer intuition. It is easy for tools to provide a sound type analysis if they choose, which may be useful for tasks like refactoring.</i><p>And add proper generics. If sound type rules fly in the face of programmer intuition, that means that the programmer's intuition is wrong. The proper response is to inform the programmer of his mistake at compile time, and not to silently ignore it and add dynamic type checks on every contravariant use of generics including array access! That is worse on both programmer productivity because the programmer expects that his program is type safe when he is using static types and on runtime speed because the dynamic checks slow down all programs needlessly. Dart already has dynamic typing; use that when you want it, not something that looks like static typing but really is dynamic typing.<p>Another thing that would be awesome is if you provide a compact binary format for code.",
      "num_comments": null,
      "story_id": 3092558,
      "story_title": "Dart language",
      "story_url": "http://www.dartlang.org/",
      "parent_id": 3092726,
      "created_at_i": 1318247033,
      "_tags": [
        "comment",
        "author_jules",
        "story_3092558"
      ],
      "objectID": "3093339",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jules",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Please make the language a nice target for other languages to compile to. Better yet, make a lower level bytecode language that Dart can compile down to as well as other languages.<p>For example value types would be excellent. Even better would be explicit regions, but I'm sure that's not going to happen.<p>Also, please fix this:<p><i>The type system is unsound, due to the covariance of generic types. This is\na deliberate choice (and undoubtedly controversial). Experience has shown that sound type rules for generics fly in the face of programmer intuition. It is easy for <em>tools</em> to provide a sound type <em>analysis</em> if they choose, which may be useful for tasks like refactoring.</i><p>And add proper generics. If sound type rules fly in the face of programmer intuition, that means that the programmer's intuition is wrong. The proper response is to inform the programmer of his mistake at compile time, and not to silently ignore it and add dynamic type checks on every contravariant use of generics including array access! That is worse on both programmer productivity because the programmer expects that his program is type safe when he is using <em>static</em> types and on runtime speed because the dynamic checks slow down all programs needlessly. Dart already has dynamic typing; use that when you want it, not something that looks like <em>static</em> typing but really is dynamic typing.<p>Another thing that would be awesome is if you provide a compact binary format for code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Dart language",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.dartlang.org/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-17T22:40:27.000Z",
      "title": null,
      "url": null,
      "author": "rwallace",
      "points": 15,
      "story_text": null,
      "comment_text": "When you&#x27;re writing safety-critical code, what you want above all else is <i>lack of surprises</i>. Sure, C has pitfalls, what language doesn&#x27;t? But we know what the pitfalls are. We have decades of experience in avoiding them. The toolchains are mature and very well tested. The source code maps fairly directly to the hardware. You don&#x27;t have to put your trust in esoterica like trying to find a garbage collector that claims to be able to meet real-time constraints and then trying to understand the edge cases in the analysis on which that claim is based.<p>It&#x27;s okay to have bleeding edge technology in the ancillary tools like the static analyzer. But for safety-critical work, you don&#x27;t want bleeding edge technology in the language in which you&#x27;re writing the actual code.",
      "num_comments": null,
      "story_id": 7252940,
      "story_title": "How Airbus is debugging the A350",
      "story_url": "http://www.businessweek.com/articles/2014-02-13/how-airbus-is-debugging-the-a350#p1",
      "parent_id": 7254378,
      "created_at_i": 1392676827,
      "_tags": [
        "comment",
        "author_rwallace",
        "story_7252940"
      ],
      "objectID": "7255014",
      "_highlightResult": {
        "author": {
          "value": "rwallace",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "When you're writing safety-critical code, what you want above all else is <i>lack of surprises</i>. Sure, C has pitfalls, what language doesn't? But we know what the pitfalls are. We have decades of experience in avoiding them. The toolchains are mature and very well tested. The source code maps fairly directly to the hardware. You don't have to put your trust in esoterica like trying to find a garbage collector that claims to be able to meet real-time constraints and then trying to understand the edge cases in the <em>analysis</em> on which that claim is based.<p>It's okay to have bleeding edge technology in the ancillary <em>tools</em> like the <em>static</em> analyzer. But for safety-critical work, you don't want bleeding edge technology in the language in which you're writing the actual code.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How Airbus is debugging the A350",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.businessweek.com/articles/2014-02-13/how-airbus-is-debugging-the-a350#p1",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-01-07T19:32:53.000Z",
      "title": "",
      "url": "",
      "author": "dalke",
      "points": 11,
      "story_text": null,
      "comment_text": "I looked at <a href=\"http://www.chessvibes.com/plaatjes/rybkaevidence/ZW_Rybka_Fruit.pdf\" rel=\"nofollow\">http://www.chessvibes.com/plaatjes/rybkaevidence/ZW_Rybka_Fr...</a> . It happens to be the one mentioned as biased evidence in this chessbase article, though I picked it because it was a PDF and not an RTF file.<p>This is the the one which has a side-by-side comparison of what appears to be two pieces of code. One of which is \"static const int KnightBackRankOpening = 0;\"<p><pre><code>    for (sq = 0; sq &#60; 64; sq++) {\n        P(piece,sq,Opening) += KnightRank[square_rank(sq)] * KnightBackRankOpening;\n    }\n</code></pre>\nThat appears to damning, but as the chessbase article points out, there's no source for the Rybka case, only reverse engineering. Since KnightBackRankOpening is \"static const int 0\" (can you really reverse engineer a \"const\" from machine code?), you would expect any half-decent optimizing compiler to remove that whole chunk of code.<p>In other words, this seemingly indicting code is a faade; a functionally equivalent implementation constructed to maximize similarity. Granted, the PDF does say \"The code shown here is simply the functional equivalent\" and \"Fruit and Rybka have functionally identical code here too,\" I looked at the code and the biggest similarity is that both code snippets are rendered in the same style. I don't see any copying. I see different tunings (eg, different weight parameters), and even though both tools are working in the same data representation and algorithm space, I see different implementations of those algorithms.<p>I find the chessbase article to be much more convincing than the results of the original investigation.<p>What would convince me otherwise is the same analysis of other modern chess programs, to show that they don't use the same approach.",
      "num_comments": null,
      "story_id": 3437028,
      "story_title": "Debunking a Computer Chess Scandal",
      "story_url": "http://www.chessbase.com/newsdetail.asp?newsid=7791",
      "parent_id": 3437698,
      "created_at_i": 1325964773,
      "_tags": [
        "comment",
        "author_dalke",
        "story_3437028"
      ],
      "objectID": "3437852",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "dalke",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I looked at <a href=\"http://www.chessvibes.com/plaatjes/rybkaevidence/ZW_Rybka_Fruit.pdf\" rel=\"nofollow\">http://www.chessvibes.com/plaatjes/rybkaevidence/ZW_Rybka_Fr...</a> . It happens to be the one mentioned as biased evidence in this chessbase article, though I picked it because it was a PDF and not an RTF file.<p>This is the the one which has a side-by-side comparison of what appears to be two pieces of code. One of which is \"<em>static</em> const int KnightBackRankOpening = 0;\"<p><pre><code>    for (sq = 0; sq < 64; sq++) {\n        P(piece,sq,Opening) += KnightRank[square_rank(sq)] * KnightBackRankOpening;\n    }\n</code></pre>\nThat appears to damning, but as the chessbase article points out, there's no source for the Rybka case, only reverse engineering. Since KnightBackRankOpening is \"<em>static</em> const int 0\" (can you really reverse engineer a \"const\" from machine code?), you would expect any half-decent optimizing compiler to remove that whole chunk of code.<p>In other words, this seemingly indicting code is a faade; a functionally equivalent implementation constructed to maximize similarity. Granted, the PDF does say \"The code shown here is simply the functional equivalent\" and \"Fruit and Rybka have functionally identical code here too,\" I looked at the code and the biggest similarity is that both code snippets are rendered in the same style. I don't see any copying. I see different tunings (eg, different weight parameters), and even though both <em>tools</em> are working in the same data representation and algorithm space, I see different implementations of those algorithms.<p>I find the chessbase article to be much more convincing than the results of the original investigation.<p>What would convince me otherwise is the same <em>analysis</em> of other modern chess programs, to show that they don't use the same approach.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Debunking a Computer Chess Scandal",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.chessbase.com/newsdetail.asp?newsid=7791",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-03-06T08:14:44.000Z",
      "title": null,
      "url": null,
      "author": "thescrewdriver",
      "points": 9,
      "story_text": null,
      "comment_text": "From the article:<p>New features in the 2.11 series<p>This release contains all of the bug fixes and improvements made in the 2.10 series, as well as:<p>Collections<p>Immutable HashMaps and HashSets perform faster filters, unions, and the like, with improved structural sharing (lower memory usage or churn).<p>Mutable LongMap and AnyRefMap have been added to provide improved performance when keys are Long or AnyRef (performance enhancement of up to 4x or 2x respectively).\\n        BigDecimal is more explicit about rounding and numeric representations, and better handles very large values without exhausting memory (by avoiding unnecessary conversions to BigInt).<p>List has improved performance on map, flatMap, and collect.<p>See also Deprecation above: we have slated many classes and methods to become final, to clarify which classes are not meant to be subclassed and to facilitate future maintenance and performance improvements.<p>Modularization<p>The core Scala standard library jar has shed 20% of its bytecode. The modules for xml, parsing, swing as well as the (unsupported) continuations plugin and library are available individually or via scala-library-all. Note that this artifact has weaker binary compatibility guarantees than scala-library – as explained above.<p>The compiler has been modularized internally, to separate the presentation compiler, scaladoc and the REPL. We hope this will make it easier to contribute. In this release, all of these modules are still packaged in scala-compiler.jar. We plan to ship them in separate JARs in 2.12.x.<p>Reflection, macros and quasiquotes<p>Please see this detailed changelog that lists all significant changes and provides advice on forward and backward compatibility.<p>See also this summary of the experimental side of the 2.11 development cycle.\\n        #3321 introduced Sprinter, a new AST pretty-printing library! Very useful for tools that deal with source code.<p>Back-end<p>The GenBCode back-end (experimental in 2.11). See @magarciaepfl’s extensive documentation.<p>A new experimental way of compiling closures, implemented by @JamesIry. With -Ydelambdafy:method anonymous functions are compiled faster, with a smaller bytecode footprint. This works by keeping the function body as a private (static, if no this reference is needed) method of the enclosing class, and at the last moment during compilation emitting a small anonymous class that extends FunctionN and delegates to it. This sets the scene for a smooth migration to Java 8-style lambdas (not yet implemented).<p>Branch elimination through constant analysis #2214<p>Compiler Performance<p>Incremental compilation has been improved significantly. To try it out, upgrade to sbt 0.13.2-M2 and add incOptions := incOptions.value.withNameHashing(true) to your build! Other build tools are also supported. More info at this sbt issue – that’s where most of the work happened. More features are planned, e.g. class-based tracking.<p>We’ve been optimizing the batch compiler’s performance as well, and will continue to work on this during the 2.11.x cycle.<p>Improve performance of reflection SI-6638<p>IDE * Numerous bug fixes and improvements!<p>REPL<p>The bytecode decompiler command, :javap, now works with Java 7 SI-4936 and has sprouted new options SI-6894 (Thanks, @som-snytt!)<p>Added command :kind to help to tell ground types from type constructors. #2340 (Thanks, George Leontiev and Eugene Yokota!)<p>The interpreter can now be embedded as a JSR-166 Scripting Engine SI-874. (Thanks, Raphael Jolly!)<p>Warnings * Warn about unused private &#x2F; local terms and types, and unused imports, under -Xlint. This will even tell you when a local var could be a val.<p>Slimming down the compiler<p>The experimental .NET backend has been removed from the compiler.<p>Scala 2.10 shipped with new implementations of the Pattern Matcher and the Bytecode Emitter. We have removed the old implementations.<p>Search and destroy mission for ~5000 chunks of dead code. #1648",
      "num_comments": null,
      "story_id": 7352372,
      "story_title": "Scala 2.11.0-RC1 is now available",
      "story_url": "http://www.scala-lang.org/news/2014/03/06/release-notes-2.11.0-RC1.html",
      "parent_id": 7352372,
      "created_at_i": 1394093684,
      "_tags": [
        "comment",
        "author_thescrewdriver",
        "story_7352372"
      ],
      "objectID": "7352516",
      "_highlightResult": {
        "author": {
          "value": "thescrewdriver",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "From the article:<p>New features in the 2.11 series<p>This release contains all of the bug fixes and improvements made in the 2.10 series, as well as:<p>Collections<p>Immutable HashMaps and HashSets perform faster filters, unions, and the like, with improved structural sharing (lower memory usage or churn).<p>Mutable LongMap and AnyRefMap have been added to provide improved performance when keys are Long or AnyRef (performance enhancement of up to 4x or 2x respectively).\\n        BigDecimal is more explicit about rounding and numeric representations, and better handles very large values without exhausting memory (by avoiding unnecessary conversions to BigInt).<p>List has improved performance on map, flatMap, and collect.<p>See also Deprecation above: we have slated many classes and methods to become final, to clarify which classes are not meant to be subclassed and to facilitate future maintenance and performance improvements.<p>Modularization<p>The core Scala standard library jar has shed 20% of its bytecode. The modules for xml, parsing, swing as well as the (unsupported) continuations plugin and library are available individually or via scala-library-all. Note that this artifact has weaker binary compatibility guarantees than scala-library – as explained above.<p>The compiler has been modularized internally, to separate the presentation compiler, scaladoc and the REPL. We hope this will make it easier to contribute. In this release, all of these modules are still packaged in scala-compiler.jar. We plan to ship them in separate JARs in 2.12.x.<p>Reflection, macros and quasiquotes<p>Please see this detailed changelog that lists all significant changes and provides advice on forward and backward compatibility.<p>See also this summary of the experimental side of the 2.11 development cycle.\\n        #3321 introduced Sprinter, a new AST pretty-printing library! Very useful for <em>tools</em> that deal with source code.<p>Back-end<p>The GenBCode back-end (experimental in 2.11). See @magarciaepfl’s extensive documentation.<p>A new experimental way of compiling closures, implemented by @JamesIry. With -Ydelambdafy:method anonymous functions are compiled faster, with a smaller bytecode footprint. This works by keeping the function body as a private (<em>static</em>, if no this reference is needed) method of the enclosing class, and at the last moment during compilation emitting a small anonymous class that extends FunctionN and delegates to it. This sets the scene for a smooth migration to Java 8-style lambdas (not yet implemented).<p>Branch elimination through constant <em>analysis</em> #2214<p>Compiler Performance<p>Incremental compilation has been improved significantly. To try it out, upgrade to sbt 0.13.2-M2 and add incOptions := incOptions.value.withNameHashing(true) to your build! Other build <em>tools</em> are also supported. More info at this sbt issue – that’s where most of the work happened. More features are planned, e.g. class-based tracking.<p>We’ve been optimizing the batch compiler’s performance as well, and will continue to work on this during the 2.11.x cycle.<p>Improve performance of reflection SI-6638<p>IDE * Numerous bug fixes and improvements!<p>REPL<p>The bytecode decompiler command, :javap, now works with Java 7 SI-4936 and has sprouted new options SI-6894 (Thanks, @som-snytt!)<p>Added command :kind to help to tell ground types from type constructors. #2340 (Thanks, George Leontiev and Eugene Yokota!)<p>The interpreter can now be embedded as a JSR-166 Scripting Engine SI-874. (Thanks, Raphael Jolly!)<p>Warnings * Warn about unused private / local terms and types, and unused imports, under -Xlint. This will even tell you when a local var could be a val.<p>Slimming down the compiler<p>The experimental .NET backend has been removed from the compiler.<p>Scala 2.10 shipped with new implementations of the Pattern Matcher and the Bytecode Emitter. We have removed the old implementations.<p>Search and destroy mission for ~5000 chunks of dead code. #1648",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Scala 2.11.0-RC1 is now available",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.scala-lang.org/news/2014/03/06/release-notes-2.11.0-RC1.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-05-13T03:31:52.000Z",
      "title": "",
      "url": "",
      "author": "hermanhermitage",
      "points": 5,
      "story_text": null,
      "comment_text": "There is still a lot of performance slippage out there in high level languages (eg look at the need for assembly when people write raw codecs in C - x264 etc).  We are rapidly approaching the battery wall on mobile devices and the clock wall is already here.  ISA's may be extended to support dynamic languages more efficiently (tags, direct uop translation from user specified instructions) - but right now at a given TDP static execution is greener for many applications than dynamic, and history has shown us cpu vendors are unwilling to go down this path.<p>Javascript is anything but efficient right now - some code paths are fast but with a high startup cost.  Look at the startup problem with Chrome/V8 for instance, or watch a nodejs application hit the GC wall with 800MB of live data.<p>There are times when static is faster than dynamic and vice-versa.  Times when heavy upfront compilation is better than incremental run time analysis and vice-versa.  As the clock wall, TDP wall and process communication wall hits we need all the tools available to exploit maximum performance.",
      "num_comments": null,
      "story_id": 3965713,
      "story_title": "*JS : Low-Level JavaScript",
      "story_url": "http://mbebenita.github.com/Mvm/",
      "parent_id": 3965886,
      "created_at_i": 1336879912,
      "_tags": [
        "comment",
        "author_hermanhermitage",
        "story_3965713"
      ],
      "objectID": "3965941",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "hermanhermitage",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "There is still a lot of performance slippage out there in high level languages (eg look at the need for assembly when people write raw codecs in C - x264 etc).  We are rapidly approaching the battery wall on mobile devices and the clock wall is already here.  ISA's may be extended to support dynamic languages more efficiently (tags, direct uop translation from user specified instructions) - but right now at a given TDP <em>static</em> execution is greener for many applications than dynamic, and history has shown us cpu vendors are unwilling to go down this path.<p>Javascript is anything but efficient right now - some code paths are fast but with a high startup cost.  Look at the startup problem with Chrome/V8 for instance, or watch a nodejs application hit the GC wall with 800MB of live data.<p>There are times when <em>static</em> is faster than dynamic and vice-versa.  Times when heavy upfront compilation is better than incremental run time <em>analysis</em> and vice-versa.  As the clock wall, TDP wall and process communication wall hits we need all the <em>tools</em> available to exploit maximum performance.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "*JS : Low-Level JavaScript",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://mbebenita.github.com/Mvm/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-06-03T19:54:41.000Z",
      "title": null,
      "url": null,
      "author": "dredmorbius",
      "points": 4,
      "story_text": null,
      "comment_text": "I think the disruption will emerge out of new replacement tools, probably emerging from some of the existing systems, though not from the current major players in browser space (Firefox, Gnome, Safari, IE), which I&#x27;m increasingly seeing as dead ends.  This is reflected both in history and in the present situation.<p>In the past, revolutions in browser models didn&#x27;t happen through evolution of existing browsers so much as their <i>wholesale replacement</i>.<p>The Web itself supplanted a whole set of proprietary document formats, both static and hypertext, of which Tim O&#x27;Reilly has written and spoken about this in talking about the origins of O&#x27;Reilly &amp; Associates.  His <i>Open Sources</i> essay covers this tangentially, though I think there are better examples I&#x27;m not finding at present:\\n<a href=\"http://oreilly.com/catalog/opensources/book/tim.html\" rel=\"nofollow\">http:&#x2F;&#x2F;oreilly.com&#x2F;catalog&#x2F;opensources&#x2F;book&#x2F;tim.html</a><p><i>In this regard, it&#x27;s interesting to point out that the software industry&#x27;s first attempts to improve on the web interface for active content--technologies like browser-side Java applets and Microsoft ActiveX controls--failed because they were aimed at professional programmers and could not easily be copied and implemented by the amateurs who were building the Web. Vendors viewed the Web in software terms, and didn&#x27;t understand that the Web was changing not only what applications were being built but what tools their builders needed.</i><p>The upshot:  HTML wasn&#x27;t pay-to-play, you weren&#x27;t locked within a proprietary &quot;ecosystem&quot;.  It also wasn&#x27;t subject to the format limitations of postscript and PDF.  It&#x27;s even been backwards-bolted onto existing information infrastructures such as manpages and GNU Info documents via tools such as Debian&#x27;s dwww:<p><a href=\"https://packages.debian.org/wheezy/dwww\" rel=\"nofollow\">https:&#x2F;&#x2F;packages.debian.org&#x2F;wheezy&#x2F;dwww</a><p>And so proprietary doc formats gave way to HTML.  Lynx begat Mosaic, which added graphics, then Netscape, which extended graphics and a number of other capabilities, until it fell over under its own bloated mass of bugs and technical debt and birthed Mozilla.<p>Tabbed browsing came by way of ... um, whatever it was that graced HN a week or so back, in 1997&#x2F;98, though didn&#x27;t reach high visibility until around 2000 by way of Opera, Skipstone, and Galeon, from which it was rapidly adopted by Mozilla, which itself grew emphasizing Xul (remember that) until <i>it</i> collapsed and was replaced by a user&#x27;s one-off, Firefox.  Google got into the game with Chrome which seems headed in the apps engine direction (and from which I suspect it will similarly collapse as a Web browser).<p>For the lightweight document reading <i>and</i> management interface, I suspect we&#x27;ll see emergence from some of the existing eBook reader &#x2F; bibliography &#x2F; online simplification tools.  I suspect that sites will start publishing in a simplified format (ePub, Markdown, LaTeX, DocBook, possibly even strict HTML5), which can be rendered <i>to client preferences</i> and in a device- and format-independent manner.  Our problem isn&#x27;t a want of semantic markups, it&#x27;s running QC over the ones we&#x27;ve got and ensuring people are using them properly.  Absent some sort of publishing authority (think along the lines of Debian&#x27;s package management system) I don&#x27;t know how this could be enforced.  Perhaps adding smarts at the webserver level:  &quot;Hey, that document you just loaded, those tags you use, I do not think they mean what you think they mean.&quot;  A validation step integrated as part of the publishing process.<p>Or maybe a nudge from search engines (though Google&#x27;s own craptacular markup in its G+ pages makes me suspect this is wishful thinking).  A well-formed, semantically-correct page gets a higher SERP ranking than one that&#x27;s a clusterfuck.  And hey, the SEOs will love me because this gives them yet another contracting&#x2F;consulting service opportunity.  Sigh.<p>Candidates to grow into this niche on the client side include Calibre, Zotero, Moon+Reader (and other ePub readers), and perhaps some of the generalized reader tools such as Evince and Okular (the GNOME and KDE readers).  I&#x27;d like to explore the Internet Archive&#x27;s BookReader as a _local_ client (it&#x27;s presently oriented at Web content) -- ironically it&#x27;s actually got <i>vastly</i> better presentation performance than most <i>local</i> readers I&#x27;ve seen.  I expect dedicated PDF readers to go the way of the dodo.  Pandoc is another tool to keep you eye on.  I&#x27;ve played with that recently, with some script glue, to convert an ePub to LaTeX source and then PDF output (still somewhat preferred for local viewing, ePubs still annoy me on Linux desktop).  <i>Nothing</i> makes me happy at present, but I&#x27;m seeing some glimmers of light.<p>The apps platform space:  some sort of sandbox in which remote apps can play but only in a limited sense.  Effectively creating a mobile device environment within the desktop (on mobile, the apps already have their space).  Key elements of this will be standardizing on widget sets, state preservation (apps should be immune to having the rug pulled out from under them), and <i>user-controlled</i> privacy controls (lacking in present app and browser models).  A data liberation standard would also be very useful, so long as I&#x27;m compiling my ideal wishlist.  I&#x27;ve got less experience here than elsewhere, and I&#x27;m probably missing a lot.<p>Seeing apps which are <i>functionally</i> oriented rather than <i>site</i> oriented would be a huge plus.  The &quot;download our app&quot; annoyance must die yesterday.<p>On the commercial space, we&#x27;re already seeing proprietary dedicated ecommerce platforms -- that&#x27;s what the mobile shopping apps from Apple (iTunes), Google (Play Store), and Amazon (Amazon Marketplace) are, effectively.  Each is, of course, a silo.  The next step is going to be for someone to come up with a <i>generalized</i> shopping interface which can access any of the back-ends.  Google&#x27;s doing some interesting work here with its Google Shopping Express, and the <i>really</i> interesting element of this would be, IMO, to integrate a few different areas of shopping:<p>• Information gathering.  Essentially, reviews of both merchants and products.  A cross between Yelp, Google Reviews, Wikipedia, and Amazon&#x27;s reviews.<p>• Merchant info.  Often I simply want to go to a physical location and get standard information (hours, available merchandise, service availability for, say, a barbarshop or restaurant or auto shop).<p>• Stock info.  Is X product in stock?  This is actually where I think the most interesting aspects may happen, as it could see a tie-in of merchant systems with the rest of the supply chain.  As with what I&#x27;ve discussed recently on disintermediating of search, providing local merchants the access to global supply-chain and inventory management which is presently only available to big box stores could be a huge disruptor.  It&#x27;s not an easy problem to solve, but it could be immensely profitable.  There&#x27;s actually a name for this, &quot;Federated Retail&quot;:  <a href=\"http://instagov.com/wiki/Federated_retail\" rel=\"nofollow\">http:&#x2F;&#x2F;instagov.com&#x2F;wiki&#x2F;Federated_retail</a><p>• Ordering.  Requesting a specific item.<p>• Payment.  <i>Note that ordering and payment are separate.</i>  I may well want to <i>order</i> online but pay in person.<p>• Fulfillment &#x2F; shipping &#x2F; delivery &#x2F; pickup.  The act of actually getting the thing you want.  Note that while delivery to the home <i>may</i> be convenient, it often <i>isn&#x27;t</i>, and one really useful function a merchant can provide is for warehousing of orders.  I actually <i>do</i> special-order products frequently <i>from local merchants</i> (bookstores, hardware stores, clothing stores), especially <i>where seeing, handling, getting fitted, or browsing products</i> is a significant part of the experience.  So long as the pick-up location is convenient to my daily habits, walking a few blocks really isn&#x27;t a big deal.  And it&#x27;s often <i>far</i> more convenient <i>than arranging to be at home at a specific time.</i>  At least until such time as homes and residences are constructed with package delivery as a consideration.<p>• Authentication <i>if necessary</i>.  Note that often this <i>isn&#x27;t</i> a requirement, and, frankly, authenticated deep behavior tracking is a massive turn-off for me on virtually any online shopping experience, <i>and is among the key reasons I avoid online shopping where possible.</i>  I&#x27;m one of those reverse show-roomers:  I&#x27;ll often research a product on Amazon, then buy it locally.<p>One of the things I find most interesting about online shopping isn&#x27;t its size or growth, but the <i>lack</i> of these.  For the past several years, online retail has been <i>underperforming</i> growth estimates:  <a href=\"http://redd.it/243in1\" rel=\"nofollow\">http:&#x2F;&#x2F;redd.it&#x2F;243in1</a><p>In 2010, TechCrunch cited Forrester Research predicting 8% of all retail sales by 2014.<p>From the US Small Business Administration we have &quot;An Analysis of Internet Sales Taxation and the Small Seller Exemption[5] &quot; giving surprisingly low numbers in November, 2013:  &quot;According to the U.S. Census Bureau, online sales accounted for approximately 5.3 percent of total retail sales in the second quarter of 2013. While online sales still represent a small share of total sales, they are expected to grow significantly in the future.&quot;<p><a href=\"http://techcrunch.com/2010/03/08/forrester-forecast-online-retail-sales-will-grow-to-250-billion-by-2014/\" rel=\"nofollow\">http:&#x2F;&#x2F;techcrunch.com&#x2F;2010&#x2F;03&#x2F;08&#x2F;forrester-forecast-online-r...</a><p><a href=\"http://www.sba.gov/advocacy/7540/758295\" rel=\"nofollow\">http:&#x2F;&#x2F;www.sba.gov&#x2F;advocacy&#x2F;7540&#x2F;758295</a><p>For media, as noted, there are a number of existing tools which provide a superior playback experience to browser-embedded players.  My main complaint with, e.g., VLC, is that it&#x27;s unstable (tends to crash), loses playlists, and if playing, say, YouTube content, seems to establish a link to the present instance of the content URL which changes, so that if you&#x27;re playing with interruptions, you&#x27;ll lose the source and have to re-queue the original YouTube link to your playlist, which is a bit of a PITA.",
      "num_comments": null,
      "story_id": 7835566,
      "story_title": "Top Web Design Mistakes of 1999",
      "story_url": "http://www.nngroup.com/articles/the-top-ten-web-design-mistakes-of-1999/",
      "parent_id": 7838420,
      "created_at_i": 1401825281,
      "_tags": [
        "comment",
        "author_dredmorbius",
        "story_7835566"
      ],
      "objectID": "7842356",
      "_highlightResult": {
        "author": {
          "value": "dredmorbius",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I think the disruption will emerge out of new replacement <em>tools</em>, probably emerging from some of the existing systems, though not from the current major players in browser space (Firefox, Gnome, Safari, IE), which I'm increasingly seeing as dead ends.  This is reflected both in history and in the present situation.<p>In the past, revolutions in browser models didn't happen through evolution of existing browsers so much as their <i>wholesale replacement</i>.<p>The Web itself supplanted a whole set of proprietary document formats, both <em>static</em> and hypertext, of which Tim O'Reilly has written and spoken about this in talking about the origins of O'Reilly &amp; Associates.  His <i>Open Sources</i> essay covers this tangentially, though I think there are better examples I'm not finding at present:\\n<a href=\"http://oreilly.com/catalog/opensources/book/tim.html\" rel=\"nofollow\">http://oreilly.com/catalog/opensources/book/tim.html</a><p><i>In this regard, it's interesting to point out that the software industry's first attempts to improve on the web interface for active content--technologies like browser-side Java applets and Microsoft ActiveX controls--failed because they were aimed at professional programmers and could not easily be copied and implemented by the amateurs who were building the Web. Vendors viewed the Web in software terms, and didn't understand that the Web was changing not only what applications were being built but what <em>tools</em> their builders needed.</i><p>The upshot:  HTML wasn't pay-to-play, you weren't locked within a proprietary &quot;ecosystem&quot;.  It also wasn't subject to the format limitations of postscript and PDF.  It's even been backwards-bolted onto existing information infrastructures such as manpages and GNU Info documents via <em>tools</em> such as Debian's dwww:<p><a href=\"https://packages.debian.org/wheezy/dwww\" rel=\"nofollow\">https://packages.debian.org/wheezy/dwww</a><p>And so proprietary doc formats gave way to HTML.  Lynx begat Mosaic, which added graphics, then Netscape, which extended graphics and a number of other capabilities, until it fell over under its own bloated mass of bugs and technical debt and birthed Mozilla.<p>Tabbed browsing came by way of ... um, whatever it was that graced HN a week or so back, in 1997/98, though didn't reach high visibility until around 2000 by way of Opera, Skipstone, and Galeon, from which it was rapidly adopted by Mozilla, which itself grew emphasizing Xul (remember that) until <i>it</i> collapsed and was replaced by a user's one-off, Firefox.  Google got into the game with Chrome which seems headed in the apps engine direction (and from which I suspect it will similarly collapse as a Web browser).<p>For the lightweight document reading <i>and</i> management interface, I suspect we'll see emergence from some of the existing eBook reader / bibliography / online simplification <em>tools</em>.  I suspect that sites will start publishing in a simplified format (ePub, Markdown, LaTeX, DocBook, possibly even strict HTML5), which can be rendered <i>to client preferences</i> and in a device- and format-independent manner.  Our problem isn't a want of semantic markups, it's running QC over the ones we've got and ensuring people are using them properly.  Absent some sort of publishing authority (think along the lines of Debian's package management system) I don't know how this could be enforced.  Perhaps adding smarts at the webserver level:  &quot;Hey, that document you just loaded, those tags you use, I do not think they mean what you think they mean.&quot;  A validation step integrated as part of the publishing process.<p>Or maybe a nudge from search engines (though Google's own craptacular markup in its G+ pages makes me suspect this is wishful thinking).  A well-formed, semantically-correct page gets a higher SERP ranking than one that's a clusterfuck.  And hey, the SEOs will love me because this gives them yet another contracting/consulting service opportunity.  Sigh.<p>Candidates to grow into this niche on the client side include Calibre, Zotero, Moon+Reader (and other ePub readers), and perhaps some of the generalized reader <em>tools</em> such as Evince and Okular (the GNOME and KDE readers).  I'd like to explore the Internet Archive's BookReader as a _local_ client (it's presently oriented at Web content) -- ironically it's actually got <i>vastly</i> better presentation performance than most <i>local</i> readers I've seen.  I expect dedicated PDF readers to go the way of the dodo.  Pandoc is another tool to keep you eye on.  I've played with that recently, with some script glue, to convert an ePub to LaTeX source and then PDF output (still somewhat preferred for local viewing, ePubs still annoy me on Linux desktop).  <i>Nothing</i> makes me happy at present, but I'm seeing some glimmers of light.<p>The apps platform space:  some sort of sandbox in which remote apps can play but only in a limited sense.  Effectively creating a mobile device environment within the desktop (on mobile, the apps already have their space).  Key elements of this will be standardizing on widget sets, state preservation (apps should be immune to having the rug pulled out from under them), and <i>user-controlled</i> privacy controls (lacking in present app and browser models).  A data liberation standard would also be very useful, so long as I'm compiling my ideal wishlist.  I've got less experience here than elsewhere, and I'm probably missing a lot.<p>Seeing apps which are <i>functionally</i> oriented rather than <i>site</i> oriented would be a huge plus.  The &quot;download our app&quot; annoyance must die yesterday.<p>On the commercial space, we're already seeing proprietary dedicated ecommerce platforms -- that's what the mobile shopping apps from Apple (iTunes), Google (Play Store), and Amazon (Amazon Marketplace) are, effectively.  Each is, of course, a silo.  The next step is going to be for someone to come up with a <i>generalized</i> shopping interface which can access any of the back-ends.  Google's doing some interesting work here with its Google Shopping Express, and the <i>really</i> interesting element of this would be, IMO, to integrate a few different areas of shopping:<p>• Information gathering.  Essentially, reviews of both merchants and products.  A cross between Yelp, Google Reviews, Wikipedia, and Amazon's reviews.<p>• Merchant info.  Often I simply want to go to a physical location and get standard information (hours, available merchandise, service availability for, say, a barbarshop or restaurant or auto shop).<p>• Stock info.  Is X product in stock?  This is actually where I think the most interesting aspects may happen, as it could see a tie-in of merchant systems with the rest of the supply chain.  As with what I've discussed recently on disintermediating of search, providing local merchants the access to global supply-chain and inventory management which is presently only available to big box stores could be a huge disruptor.  It's not an easy problem to solve, but it could be immensely profitable.  There's actually a name for this, &quot;Federated Retail&quot;:  <a href=\"http://instagov.com/wiki/Federated_retail\" rel=\"nofollow\">http://instagov.com/wiki/Federated_retail</a><p>• Ordering.  Requesting a specific item.<p>• Payment.  <i>Note that ordering and payment are separate.</i>  I may well want to <i>order</i> online but pay in person.<p>• Fulfillment / shipping / delivery / pickup.  The act of actually getting the thing you want.  Note that while delivery to the home <i>may</i> be convenient, it often <i>isn't</i>, and one really useful function a merchant can provide is for warehousing of orders.  I actually <i>do</i> special-order products frequently <i>from local merchants</i> (bookstores, hardware stores, clothing stores), especially <i>where seeing, handling, getting fitted, or browsing products</i> is a significant part of the experience.  So long as the pick-up location is convenient to my daily habits, walking a few blocks really isn't a big deal.  And it's often <i>far</i> more convenient <i>than arranging to be at home at a specific time.</i>  At least until such time as homes and residences are constructed with package delivery as a consideration.<p>• Authentication <i>if necessary</i>.  Note that often this <i>isn't</i> a requirement, and, frankly, authenticated deep behavior tracking is a massive turn-off for me on virtually any online shopping experience, <i>and is among the key reasons I avoid online shopping where possible.</i>  I'm one of those reverse show-roomers:  I'll often research a product on Amazon, then buy it locally.<p>One of the things I find most interesting about online shopping isn't its size or growth, but the <i>lack</i> of these.  For the past several years, online retail has been <i>underperforming</i> growth estimates:  <a href=\"http://redd.it/243in1\" rel=\"nofollow\">http://redd.it/243in1</a><p>In 2010, TechCrunch cited Forrester Research predicting 8% of all retail sales by 2014.<p>From the US Small Business Administration we have &quot;An <em>Analysis</em> of Internet Sales Taxation and the Small Seller Exemption[5] &quot; giving surprisingly low numbers in November, 2013:  &quot;According to the U.S. Census Bureau, online sales accounted for approximately 5.3 percent of total retail sales in the second quarter of 2013. While online sales still represent a small share of total sales, they are expected to grow significantly in the future.&quot;<p><a href=\"http://techcrunch.com/2010/03/08/forrester-forecast-online-retail-sales-will-grow-to-250-billion-by-2014/\" rel=\"nofollow\">http://techcrunch.com/2010/03/08/forrester-forecast-online-r...</a><p><a href=\"http://www.sba.gov/advocacy/7540/758295\" rel=\"nofollow\">http://www.sba.gov/advocacy/7540/758295</a><p>For media, as noted, there are a number of existing <em>tools</em> which provide a superior playback experience to browser-embedded players.  My main complaint with, e.g., VLC, is that it's unstable (tends to crash), loses playlists, and if playing, say, YouTube content, seems to establish a link to the present instance of the content URL which changes, so that if you're playing with interruptions, you'll lose the source and have to re-queue the original YouTube link to your playlist, which is a bit of a PITA.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Top Web Design Mistakes of 1999",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.nngroup.com/articles/the-top-ten-web-design-mistakes-of-1999/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-25T04:04:15.000Z",
      "title": "",
      "url": "",
      "author": "zmmmmm",
      "points": 4,
      "story_text": null,
      "comment_text": "Heh, all the bioinformaticians come out of the woodwork :-)<p>Here's yet-another-project for bioinformatics workflows that I've been involved in. This one based on Groovy:<p><a href=\"http://bpipe.org\" rel=\"nofollow\">http://bpipe.org</a><p>I agree with your sentiments about the nature of pipelines vs build system a la make. Many many people start down the path of putting the classic DAG dependency analysis as the foundation of their needs when in fact, this isn't so much of a problem in real situations, and is even somewhat counterproductive because it forces you to declare a lot of things in a static way that actually aren't static at all. I've found tools like this completely break down when your data starts determining your workflow (eg: if the file is bigger than X I will break it in n parts and run them in parallel, otherwise I will continue on and do it using a different command entirely in memory).<p>In my experience the problems in big data analysis are more about the complexity of managing the process, achieving as much parallelization with as little effort and craziness as possible (don't see any mention of that in Drake), documenting what actually happened when something ran so you can figure it out later, and most of all, flexibility in modifying it since it changes every day of the week.<p>One mistake that Drake appears to make (again, from my quick skim), is interweaving the declaration of the \"stages\" of the pipeline (what they do) and the dependencies between them (the order they run in). This makes your pipeline stages less reusable and the pipeline harder to maintain. Bpipe completely separates these things out, which is something I like about it.",
      "num_comments": null,
      "story_id": 5110921,
      "story_title": "Introducing Drake, a kind of make for data",
      "story_url": "http://blog.factual.com/introducing-drake-a-kind-of-make-for-data",
      "parent_id": 5111696,
      "created_at_i": 1359086655,
      "_tags": [
        "comment",
        "author_zmmmmm",
        "story_5110921"
      ],
      "objectID": "5113879",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "zmmmmm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Heh, all the bioinformaticians come out of the woodwork :-)<p>Here's yet-another-project for bioinformatics workflows that I've been involved in. This one based on Groovy:<p><a href=\"http://bpipe.org\" rel=\"nofollow\">http://bpipe.org</a><p>I agree with your sentiments about the nature of pipelines vs build system a la make. Many many people start down the path of putting the classic DAG dependency <em>analysis</em> as the foundation of their needs when in fact, this isn't so much of a problem in real situations, and is even somewhat counterproductive because it forces you to declare a lot of things in a <em>static</em> way that actually aren't <em>static</em> at all. I've found <em>tools</em> like this completely break down when your data starts determining your workflow (eg: if the file is bigger than X I will break it in n parts and run them in parallel, otherwise I will continue on and do it using a different command entirely in memory).<p>In my experience the problems in big data <em>analysis</em> are more about the complexity of managing the process, achieving as much parallelization with as little effort and craziness as possible (don't see any mention of that in Drake), documenting what actually happened when something ran so you can figure it out later, and most of all, flexibility in modifying it since it changes every day of the week.<p>One mistake that Drake appears to make (again, from my quick skim), is interweaving the declaration of the \"stages\" of the pipeline (what they do) and the dependencies between them (the order they run in). This makes your pipeline stages less reusable and the pipeline harder to maintain. Bpipe completely separates these things out, which is something I like about it.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Introducing Drake, a kind of make for data",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.factual.com/introducing-drake-a-kind-of-make-for-data",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-28T18:29:13.000Z",
      "title": "",
      "url": "",
      "author": "compumike",
      "points": 3,
      "story_text": null,
      "comment_text": "We've been building a SPICE-like mixed-mode circuit simulator plus a SVG-based schematic editor, HTML5/Canvas-based plotting, in about 20K lines of CoffeeScript.  No browser plugins required -- runs directly in the browser's JavaScript engine, and all simulation is client-side.  (We generate and factor big matrices on the client side.)  We currently do DC, time-domain simulations, and frequency-domain analysis (small signal, \"Bode plots\" if you're familiar with the lingo).  Circuit analysis results compare well to \"real\" desktop SPICEs.  We evaluate real and complex electrical quantities.  In fact, we have a graphing calculator essentially embedded in our tool.  Since it's browser-based, it's immediately Windows/Mac/Linux cross-platform, unlike most software EDA tools which are Windows-only.  Check out the cross-tab copy-paste functionality as well!<p>If you look at any electronics forum online, it's normal to see scanned hand-drawn schematics, or static screenshots from various desktop tools. There's no reason why we shouldn't instead be sharing useful URLs that enable editing and simulation.  If someone uses CircuitLab and posts a public URL, they enable the entire community to easily open their circuit, make a few changes, simulate / iterate, and share the new version.<p>Looking forward to hearing your feedback!",
      "num_comments": null,
      "story_id": 3644160,
      "story_title": "Show HN: CircuitLab, an in-browser schematic editor and circuit simulator",
      "story_url": "http://www.circuitlab.com/",
      "parent_id": 3644160,
      "created_at_i": 1330453753,
      "_tags": [
        "comment",
        "author_compumike",
        "story_3644160"
      ],
      "objectID": "3644225",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "compumike",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "We've been building a SPICE-like mixed-mode circuit simulator plus a SVG-based schematic editor, HTML5/Canvas-based plotting, in about 20K lines of CoffeeScript.  No browser plugins required -- runs directly in the browser's JavaScript engine, and all simulation is client-side.  (We generate and factor big matrices on the client side.)  We currently do DC, time-domain simulations, and frequency-domain <em>analysis</em> (small signal, \"Bode plots\" if you're familiar with the lingo).  Circuit <em>analysis</em> results compare well to \"real\" desktop SPICEs.  We evaluate real and complex electrical quantities.  In fact, we have a graphing calculator essentially embedded in our tool.  Since it's browser-based, it's immediately Windows/Mac/Linux cross-platform, unlike most software EDA <em>tools</em> which are Windows-only.  Check out the cross-tab copy-paste functionality as well!<p>If you look at any electronics forum online, it's normal to see scanned hand-drawn schematics, or <em>static</em> screenshots from various desktop <em>tools</em>. There's no reason why we shouldn't instead be sharing useful URLs that enable editing and simulation.  If someone uses CircuitLab and posts a public URL, they enable the entire community to easily open their circuit, make a few changes, simulate / iterate, and share the new version.<p>Looking forward to hearing your feedback!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Show HN: CircuitLab, an in-browser schematic editor and circuit simulator",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.circuitlab.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-29T05:15:02.000Z",
      "title": null,
      "url": null,
      "author": "shostack",
      "points": 2,
      "story_text": null,
      "comment_text": "I would agree with quite a bit of this.<p>However I would disagree with your statement that it is a de factor admission of failure of monetizing all that data.  If anything, it is Facebook laying the foundations for a very powerful data asset once it gets the other pieces of the puzzle in place.  Let&#x27;s not forget that Google&#x27;s own GDN was once the red headed step-child of the display space only a handful of years ago due to quality issues (and the Search Partner Network still suffers from quite a bit of this as covered in a recent article on Search Engine Land[1]).<p>In any event, all of this data that they have, and that Google has, etc. are largely wasted because of both of their failures to leverage it to the fullest capacity and solve the issue of cross-channel attribution analysis and optimization.<p>Perfect example...it is 2014--why the heck can&#x27;t I get view-through revenue data in the AdWords UI when using the AdWords conversion tag and&#x2F;or syncing with GA? You most certainly have the data.  Why should that be limited to advertisers who pay for DFA to get the exposure-to-conversion reporting capabilities?<p>More importantly, why has nobody tackled the truly large scale, cross-industry problem of true global frequency capping and tracking?  I realize it is in part because there is little incentive to play nice with others, but that seems like a problem Google should try to solve as it would provide tremendous value in the form of a drastic reduction in wasted impressions (and thus higher-performance display campaigns).  In the end, it is the users that suffer from being bombarded by ads from multiple networks&#x2F;DSPs&#x2F;etc. because of the few options to limit exposure across initiatives without setting up complex audience segmentation and negative lists.<p>Getting all of this data under one roof&#x2F;GUID is only useful if there are tools to optimize against it at that scale and level of complexity.  That means making data-driven attribution a priority and proving the incremental value of impressions and view-throughs.  Letting advertisers view their data through multiple attribution lenses or define their own is still falling short because attribution should not be based on static values.  This is a problem that Google has the chops to solve, and that the average advertiser lacks the resources, expertise, and technology for. I&#x27;ve been pretty disappointed in your solution thus far.  This is data you should expose to the masses in an actionable manner that would dramatically help them sell Google display solutions. Admittedly I haven&#x27;t had a chance to try GA Premium&#x27;s data-driven attribution features, and I&#x27;m dying to know how Adometry will be incorporated into your products, but it can&#x27;t come soon enough.<p>As it stands right now though, I still can&#x27;t easily show with data that view-throughs are worth a damn--even if I did have said revenue data.  Oh, and don&#x27;t get me started on video display units...why has AdWords for Video still not been fully merged with the main AdWords platform?  It is ridiculous that I need to use a separate platform and split my budgets&#x2F;data&#x2F;reporting if I want to run Trueview ads for a retargeting campaign.<p>Anyway, thanks for bearing the brunt of my unloading on Google&#x27;s display efforts.  I&#x27;ve been particularly frustrated with them as of late, and now that I&#x27;m client-side without the massive collective budgets I sat on top of as a senior-level individual at a top agency partner, I don&#x27;t get as many opportunities to share my candid thoughts to Googlers about how to improve things. I actually live&#x2F;work in Mountain View though if you or any display Googlers want to grab a drink and discuss further.<p>[1] <a href=\"http://searchengineland.com/will-ask-com-google-arbitrage-ever-stop-203565\" rel=\"nofollow\">http:&#x2F;&#x2F;searchengineland.com&#x2F;will-ask-com-google-arbitrage-ev...</a>",
      "num_comments": null,
      "story_id": 8381493,
      "story_title": "With New Ad Platform, Facebook Opens Gates to Its Vault of User Data",
      "story_url": "http://www.nytimes.com/2014/09/29/business/with-new-ad-platform-facebook-opens-the-gates-to-its-vault-of-consumer-data.html",
      "parent_id": 8381692,
      "created_at_i": 1411967702,
      "_tags": [
        "comment",
        "author_shostack",
        "story_8381493"
      ],
      "objectID": "8381780",
      "_highlightResult": {
        "author": {
          "value": "shostack",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I would agree with quite a bit of this.<p>However I would disagree with your statement that it is a de factor admission of failure of monetizing all that data.  If anything, it is Facebook laying the foundations for a very powerful data asset once it gets the other pieces of the puzzle in place.  Let's not forget that Google's own GDN was once the red headed step-child of the display space only a handful of years ago due to quality issues (and the Search Partner Network still suffers from quite a bit of this as covered in a recent article on Search Engine Land[1]).<p>In any event, all of this data that they have, and that Google has, etc. are largely wasted because of both of their failures to leverage it to the fullest capacity and solve the issue of cross-channel attribution <em>analysis</em> and optimization.<p>Perfect example...it is 2014--why the heck can't I get view-through revenue data in the AdWords UI when using the AdWords conversion tag and/or syncing with GA? You most certainly have the data.  Why should that be limited to advertisers who pay for DFA to get the exposure-to-conversion reporting capabilities?<p>More importantly, why has nobody tackled the truly large scale, cross-industry problem of true global frequency capping and tracking?  I realize it is in part because there is little incentive to play nice with others, but that seems like a problem Google should try to solve as it would provide tremendous value in the form of a drastic reduction in wasted impressions (and thus higher-performance display campaigns).  In the end, it is the users that suffer from being bombarded by ads from multiple networks/DSPs/etc. because of the few options to limit exposure across initiatives without setting up complex audience segmentation and negative lists.<p>Getting all of this data under one roof/GUID is only useful if there are <em>tools</em> to optimize against it at that scale and level of complexity.  That means making data-driven attribution a priority and proving the incremental value of impressions and view-throughs.  Letting advertisers view their data through multiple attribution lenses or define their own is still falling short because attribution should not be based on <em>static</em> values.  This is a problem that Google has the chops to solve, and that the average advertiser lacks the resources, expertise, and technology for. I've been pretty disappointed in your solution thus far.  This is data you should expose to the masses in an actionable manner that would dramatically help them sell Google display solutions. Admittedly I haven't had a chance to try GA Premium's data-driven attribution features, and I'm dying to know how Adometry will be incorporated into your products, but it can't come soon enough.<p>As it stands right now though, I still can't easily show with data that view-throughs are worth a damn--even if I did have said revenue data.  Oh, and don't get me started on video display units...why has AdWords for Video still not been fully merged with the main AdWords platform?  It is ridiculous that I need to use a separate platform and split my budgets/data/reporting if I want to run Trueview ads for a retargeting campaign.<p>Anyway, thanks for bearing the brunt of my unloading on Google's display efforts.  I've been particularly frustrated with them as of late, and now that I'm client-side without the massive collective budgets I sat on top of as a senior-level individual at a top agency partner, I don't get as many opportunities to share my candid thoughts to Googlers about how to improve things. I actually live/work in Mountain View though if you or any display Googlers want to grab a drink and discuss further.<p>[1] <a href=\"http://searchengineland.com/will-ask-com-google-arbitrage-ever-stop-203565\" rel=\"nofollow\">http://searchengineland.com/will-ask-com-google-arbitrage-ev...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "With New Ad Platform, Facebook Opens Gates to Its Vault of User Data",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.nytimes.com/2014/09/29/business/with-new-ad-platform-facebook-opens-the-gates-to-its-vault-of-consumer-data.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-18T19:33:51.000Z",
      "title": null,
      "url": null,
      "author": "mcgwiz",
      "points": 2,
      "story_text": null,
      "comment_text": "This is perplexing to me.<p>&gt; 1. Bad search ranking and Twitter&#x2F;Facebook previews<p>This problem is patently obvious to the most cursory examination of single-page applications. If SEO is important, and you want to do an SPA, then you must be willing to bear the cost of addressing HTML requests. For my startup, I wanted to keep things DRY, which lead me early on to the Nustache engine for ASP.NET, allowing me to use the same Mustache templates on server and client. This doesn&#x27;t have anything like the complexity described in the article.<p>&gt; 2. Flaky stats and monitoring<p>Simply not true. Using Google Analytics and Backbone, you simply listen to the Backbone.history:route event and fire off a pageview using the Google Analytics API.<p>&gt; 3. Slow, complex build tools<p>Complex, yes. Slow? Using r.js, no slower than a typical static language build.<p>&gt; 4. Slow, flaky tests<p>Slow, yes, but no more so than desktop app test automation. I&#x27;ve found PhantomJS with QUnit (unit-testing), and CasperJS for integration testing to be quite reliable. It took a few days to get everything connected (scripting IIS Express to start and end in the background being the trickiest bit), but that was it.<p>&gt; 5. Slowness is swept under the rug, not addressed<p>This is a UX challenge that is known and obvious up-front. Failing to address it is a design problem, not a technological one.<p>Overall, this seems the result of the ineptitude prevalent in inexperienced, &quot;move fast, break things&quot; teams. Rather than owning up to moving too fast and foregoing due analysis&#x2F;research, they blame technology. Or, the article is a marketing ploy.",
      "num_comments": null,
      "story_id": 7255227,
      "story_title": "Why we left AngularJS",
      "story_url": "https://sourcegraph.com/blog/switching-from-angularjs-to-server-side-html",
      "parent_id": 7255227,
      "created_at_i": 1392752031,
      "_tags": [
        "comment",
        "author_mcgwiz",
        "story_7255227"
      ],
      "objectID": "7260487",
      "_highlightResult": {
        "author": {
          "value": "mcgwiz",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is perplexing to me.<p>&gt; 1. Bad search ranking and Twitter/Facebook previews<p>This problem is patently obvious to the most cursory examination of single-page applications. If SEO is important, and you want to do an SPA, then you must be willing to bear the cost of addressing HTML requests. For my startup, I wanted to keep things DRY, which lead me early on to the Nustache engine for ASP.NET, allowing me to use the same Mustache templates on server and client. This doesn't have anything like the complexity described in the article.<p>&gt; 2. Flaky stats and monitoring<p>Simply not true. Using Google Analytics and Backbone, you simply listen to the Backbone.history:route event and fire off a pageview using the Google Analytics API.<p>&gt; 3. Slow, complex build <em>tools</em><p>Complex, yes. Slow? Using r.js, no slower than a typical <em>static</em> language build.<p>&gt; 4. Slow, flaky tests<p>Slow, yes, but no more so than desktop app test automation. I've found PhantomJS with QUnit (unit-testing), and CasperJS for integration testing to be quite reliable. It took a few days to get everything connected (scripting IIS Express to start and end in the background being the trickiest bit), but that was it.<p>&gt; 5. Slowness is swept under the rug, not addressed<p>This is a UX challenge that is known and obvious up-front. Failing to address it is a design problem, not a technological one.<p>Overall, this seems the result of the ineptitude prevalent in inexperienced, &quot;move fast, break things&quot; teams. Rather than owning up to moving too fast and foregoing due <em>analysis</em>/research, they blame technology. Or, the article is a marketing ploy.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why we left AngularJS",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://sourcegraph.com/blog/switching-from-angularjs-to-server-side-html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-09-20T12:02:44.000Z",
      "title": null,
      "url": null,
      "author": "johan_larson",
      "points": 1,
      "story_text": null,
      "comment_text": "There&#x27;s a lot to be said for keeping things as simple as possible. Although what qualifies as simple varies from application to application.<p>I was doing some preliminary analysis for a small project recently, and considering various frameworks and tools. Eventually I realized I could implement what was needed using four JSPs producing static html, with a bit of styling in CSS. No AOP, no injection framework, no JavaScript. And no explicit differentiation between device types.<p>The resulting application will start up quickly -- which is important when running in a PaaS environment -- and should work on any browser, including weird old stuff like Lynx. Less butterfly. More rat.",
      "num_comments": null,
      "story_id": 8342755,
      "story_title": "“The Mess We're In” by Joe Armstrong at Strange Loop [video]",
      "story_url": "https://www.youtube.com/watch?v=lKXe3HUG2l4",
      "parent_id": 8343926,
      "created_at_i": 1411214564,
      "_tags": [
        "comment",
        "author_johan_larson",
        "story_8342755"
      ],
      "objectID": "8344326",
      "_highlightResult": {
        "author": {
          "value": "johan_larson",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "There's a lot to be said for keeping things as simple as possible. Although what qualifies as simple varies from application to application.<p>I was doing some preliminary <em>analysis</em> for a small project recently, and considering various frameworks and <em>tools</em>. Eventually I realized I could implement what was needed using four JSPs producing <em>static</em> html, with a bit of styling in CSS. No AOP, no injection framework, no JavaScript. And no explicit differentiation between device types.<p>The resulting application will start up quickly -- which is important when running in a PaaS environment -- and should work on any browser, including weird old stuff like Lynx. Less butterfly. More rat.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "“The Mess We're In” by Joe Armstrong at Strange Loop [video]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.youtube.com/watch?v=lKXe3HUG2l4",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-12-23T04:41:20.000Z",
      "title": null,
      "url": null,
      "author": "coolsunglasses",
      "points": 1,
      "story_text": null,
      "comment_text": "You&#x27;re focusing on a different part than I was.<p>My point was that super fancy IDEs and plain old text editors alike could reuse the same tooling and not have to reimplement things like language parsing, analysis, and refactoring tooling.<p>Libraries like haskell-suite and command-line tooling like ghc-mod have succeeded in that. That ghc-mod happens to be a command-line application is <i>utterly irrelevant</i> to the end-user unless they want to go poking around.<p>And uh, you know, some people do sometimes.<p>Want to go poking around that is. Some people like owning and operating their tools.<p>I&#x27;m not saying &quot;Hail Unix&quot;, I&#x27;m saying, &quot;Hail IDE, Emacs, and Vim hackers not needing to write the same libraries over and over&quot;. The specific implementation is irrelevant.<p>Also if you refuse, on account of bias, to understand why people might find such a design (command-line application invoked from different programming environments to augment functionality) then you are <i>damning</i> yourself to be ignorant of how other people think and work.<p>This reminds a <i>lot</i> of the hatred some people have for the Twilight series. It&#x27;s not a product designed to appeal to somebody like me, but clearly there&#x27;s <i>something</i> to it because it has resonated with <i>millions</i> of people.<p>Is it really worth it to say &quot;ugh yuck&quot; and not even pause to reflect on what it is about this thing you dislike (Unix-style tooling) that so many other people have stuck with for decades? Are you feeling insecure because the average hacker these days is using a Mac or Linux machine?<p>&gt;I frankly don&#x27;t buy the entire interop premise,<p>I guess you can be that way if you want, but Emacs, Vim, Sublime Text and Eclipse all have Scion integration. Scion isn&#x27;t quite like ghc-mod, note that I was talking about a general attitude that all IDE tooling should be reusable across multiple environments in Haskell, not just command-line applications.<p>Scion in this case is:<p><a href=\\\"https://github.com/nominolo/scion\\\" rel=\\\"nofollow\\\">https:&#x2F;&#x2F;github.com&#x2F;nominolo&#x2F;scion</a><p>Scion is a Haskell library that aims to implement those parts of a Haskell IDE which are independent of the particular front-end. Scion is based on the GHC API and Cabal. It provides both a Haskell API and a server for non-Haskell clients such as Emacs and Vim.<p>You&#x27;ll note that it&#x27;s not actually a command-line app like ghc-mod. I use ghc-mod because it&#x27;s &quot;simple&quot; and easily inspectable&#x2F;dumpable for it&#x27;s output at the terminal.<p>I know Emacs and vim users to both use ghc-mod.<p>buildwrapper mostly replaced Scion and is used by Leksah, Yi, EclipseFP (all IDEs). Buildwrapper provides its functionality via JSON.<p>Leksah, Yi, and EclipseFP are the primary IDEs Haskell users use, <i>IF</i> they&#x27;re not using FPComplete&#x27;s dilly which is web-based and is using the same Haskell IDE tooling as everybody else.<p>&gt; Haskell has no popular IDE as far as I can tell<p>I don&#x27;t really know that &quot;IDEs are popular in Haskell&quot;<p>but &quot;Haskell has popular IDEs&quot; is true.<p>Further, while I can&#x27;t speak for vim users, the way most advanced Emacs users interact with their programming languages, especially Haskell, is an interactive hybrid IDE environment usually built on a REPL.<p>&gt; How much do C and Haskell share in common?<p>The fuck are you talking about? I&#x27;ve only been talking about tool-sharing in the Haskell community this whole time.<p>&gt; so why worry if IntelliJ doesn&#x27;t share an architecture with Eclipse?<p>It&#x27;s troubling because it means labor is wasted writing the same tooling (IDE) for the same language (Java). Hackers should be bothered when their colleagues are writing redundant code.<p>Maybe that&#x27;s not an ethos at Microsoft or MSR, but it is in the various open source communities I&#x27;ve been in.<p>&gt;But as someone who works on IDEs full time, this rosy-tinted glasses belief that we were doing it the right way 30 years ago quickly annoys me.<p>You clearly have not used Emacs or any of the Haskell tooling I use.<p>While some Emacs users still use things like etags&#x2F;ctags, I do not. I have language-aware search&#x2F;go-to-definition faculties just like any IDE in Emacs. The same goes for most other things I give a damn about. We have the same faculties as anybody else, we simply refuse to give up control over our tools because we don&#x27;t buy into Microsoft&#x27;s dystopian digital neo-feudalism.<p>I don&#x27;t let that difference of vision cause me to act like a fucking prick to a perfect stranger on HN though. You are representing Microsoft and MSR - and all I&#x27;ve gotten from this experience is that Microsoft employees are totally out of touch with the work anybody else is doing. Unprovocatedly unpleasant to boot.<p>&gt;...has no popular IDE as far as I can tell; the community just isn&#x27;t into them (though some exist, like Leksah), which is quite odd to me, as they have all that static type information sitting around!<p>Haskell users aggressively leverage the types for secondary purposes, you&#x27;re just not a Haskell user and are therefore ignorant to it. You&#x27;re still wrong about Haskell users not using IDE-esque workflows, you just don&#x27;t understand how that can manifest in a different form than being a Visual Studio customer.<p>&gt;I frankly don&#x27;t buy the entire interop premise,<p>I&#x27;ve conclusively demonstrated aggressive tool-sharing across different toolsets in Haskell, even with most people upgrading from Scion to buildwrapper when it became mature. It&#x27;s rare for open source communities to keep up with each other that well.<p>&gt; Unix was a great C dev environment, you had ed (later vi and emacs)<p>The proximity of mentioning ed and vi&#x2F;emacs in the same sentence is not as clever as you think it is and really just shows how ignorant you are to how vimmers and Emacs users work these days.<p>My Emacs environment of today would be utterly alien to myself-10-years-ago. Or even 3-5 years ago. Or even 2 years ago. A lot of evolution can happen when you&#x27;ve been improving the same tooling over and over for multiple decades.<p>Emacs is nearly as old as Bill Gates&#x27;s DUI arrest (1976 and &#x27;75). Do you really think people are using it the same way now as they were then?<p>I mean, for one thing, it starts up quickly now &gt;:)<p>You should really try immersing yourself in how Emacs users work these days, you really have no idea at all. It could use a lot of work, so could everything, and there are some things that some IDEs for some languages will do better...but it bears more resemblance to those IDEs than to ed of all things.<p>The interactive REPL oriented workflow is something IDEs still haven&#x27;t gotten right though. Pity that.",
      "num_comments": null,
      "story_id": 6942905,
      "story_title": "IDEas: Tools for Coders",
      "story_url": "http://omegaortega.com/ideas-tools-for-coders/",
      "parent_id": 6949924,
      "created_at_i": 1387773680,
      "_tags": [
        "comment",
        "author_coolsunglasses",
        "story_6942905"
      ],
      "objectID": "6953124",
      "_highlightResult": {
        "author": {
          "value": "coolsunglasses",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You're focusing on a different part than I was.<p>My point was that super fancy IDEs and plain old text editors alike could reuse the same tooling and not have to reimplement things like language parsing, <em>analysis</em>, and refactoring tooling.<p>Libraries like haskell-suite and command-line tooling like ghc-mod have succeeded in that. That ghc-mod happens to be a command-line application is <i>utterly irrelevant</i> to the end-user unless they want to go poking around.<p>And uh, you know, some people do sometimes.<p>Want to go poking around that is. Some people like owning and operating their <em>tools</em>.<p>I'm not saying &quot;Hail Unix&quot;, I'm saying, &quot;Hail IDE, Emacs, and Vim hackers not needing to write the same libraries over and over&quot;. The specific implementation is irrelevant.<p>Also if you refuse, on account of bias, to understand why people might find such a design (command-line application invoked from different programming environments to augment functionality) then you are <i>damning</i> yourself to be ignorant of how other people think and work.<p>This reminds a <i>lot</i> of the hatred some people have for the Twilight series. It's not a product designed to appeal to somebody like me, but clearly there's <i>something</i> to it because it has resonated with <i>millions</i> of people.<p>Is it really worth it to say &quot;ugh yuck&quot; and not even pause to reflect on what it is about this thing you dislike (Unix-style tooling) that so many other people have stuck with for decades? Are you feeling insecure because the average hacker these days is using a Mac or Linux machine?<p>&gt;I frankly don't buy the entire interop premise,<p>I guess you can be that way if you want, but Emacs, Vim, Sublime Text and Eclipse all have Scion integration. Scion isn't quite like ghc-mod, note that I was talking about a general attitude that all IDE tooling should be reusable across multiple environments in Haskell, not just command-line applications.<p>Scion in this case is:<p><a href=\\\"https://github.com/nominolo/scion\\\" rel=\\\"nofollow\\\">https://github.com/nominolo/scion</a><p>Scion is a Haskell library that aims to implement those parts of a Haskell IDE which are independent of the particular front-end. Scion is based on the GHC API and Cabal. It provides both a Haskell API and a server for non-Haskell clients such as Emacs and Vim.<p>You'll note that it's not actually a command-line app like ghc-mod. I use ghc-mod because it's &quot;simple&quot; and easily inspectable/dumpable for it's output at the terminal.<p>I know Emacs and vim users to both use ghc-mod.<p>buildwrapper mostly replaced Scion and is used by Leksah, Yi, EclipseFP (all IDEs). Buildwrapper provides its functionality via JSON.<p>Leksah, Yi, and EclipseFP are the primary IDEs Haskell users use, <i>IF</i> they're not using FPComplete's dilly which is web-based and is using the same Haskell IDE tooling as everybody else.<p>&gt; Haskell has no popular IDE as far as I can tell<p>I don't really know that &quot;IDEs are popular in Haskell&quot;<p>but &quot;Haskell has popular IDEs&quot; is true.<p>Further, while I can't speak for vim users, the way most advanced Emacs users interact with their programming languages, especially Haskell, is an interactive hybrid IDE environment usually built on a REPL.<p>&gt; How much do C and Haskell share in common?<p>The fuck are you talking about? I've only been talking about tool-sharing in the Haskell community this whole time.<p>&gt; so why worry if IntelliJ doesn't share an architecture with Eclipse?<p>It's troubling because it means labor is wasted writing the same tooling (IDE) for the same language (Java). Hackers should be bothered when their colleagues are writing redundant code.<p>Maybe that's not an ethos at Microsoft or MSR, but it is in the various open source communities I've been in.<p>&gt;But as someone who works on IDEs full time, this rosy-tinted glasses belief that we were doing it the right way 30 years ago quickly annoys me.<p>You clearly have not used Emacs or any of the Haskell tooling I use.<p>While some Emacs users still use things like etags/ctags, I do not. I have language-aware search/go-to-definition faculties just like any IDE in Emacs. The same goes for most other things I give a damn about. We have the same faculties as anybody else, we simply refuse to give up control over our <em>tools</em> because we don't buy into Microsoft's dystopian digital neo-feudalism.<p>I don't let that difference of vision cause me to act like a fucking prick to a perfect stranger on HN though. You are representing Microsoft and MSR - and all I've gotten from this experience is that Microsoft employees are totally out of touch with the work anybody else is doing. Unprovocatedly unpleasant to boot.<p>&gt;...has no popular IDE as far as I can tell; the community just isn't into them (though some exist, like Leksah), which is quite odd to me, as they have all that <em>static</em> type information sitting around!<p>Haskell users aggressively leverage the types for secondary purposes, you're just not a Haskell user and are therefore ignorant to it. You're still wrong about Haskell users not using IDE-esque workflows, you just don't understand how that can manifest in a different form than being a Visual Studio customer.<p>&gt;I frankly don't buy the entire interop premise,<p>I've conclusively demonstrated aggressive tool-sharing across different <em>tools</em>ets in Haskell, even with most people upgrading from Scion to buildwrapper when it became mature. It's rare for open source communities to keep up with each other that well.<p>&gt; Unix was a great C dev environment, you had ed (later vi and emacs)<p>The proximity of mentioning ed and vi/emacs in the same sentence is not as clever as you think it is and really just shows how ignorant you are to how vimmers and Emacs users work these days.<p>My Emacs environment of today would be utterly alien to myself-10-years-ago. Or even 3-5 years ago. Or even 2 years ago. A lot of evolution can happen when you've been improving the same tooling over and over for multiple decades.<p>Emacs is nearly as old as Bill Gates's DUI arrest (1976 and '75). Do you really think people are using it the same way now as they were then?<p>I mean, for one thing, it starts up quickly now &gt;:)<p>You should really try immersing yourself in how Emacs users work these days, you really have no idea at all. It could use a lot of work, so could everything, and there are some things that some IDEs for some languages will do better...but it bears more resemblance to those IDEs than to ed of all things.<p>The interactive REPL oriented workflow is something IDEs still haven't gotten right though. Pity that.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "IDEas: <em>Tools</em> for Coders",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "http://omegaortega.com/ideas-<em>tools</em>-for-coders/",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        }
      }
    },
    {
      "created_at": "2013-07-19T23:19:06.000Z",
      "title": "",
      "url": "",
      "author": "chewxy",
      "points": 1,
      "story_text": null,
      "comment_text": "If by graphs you mean charts, these are the tools I use:<p>- d3js + nvd3 [0] - if the charts have to be online for consumption of people outside the company. Not so much a fan of using this because I have to do extra work to convert the data into json, and then write the scripts to generate the chart.<p>- ggplot2 [1] - if the charts are static and need to somewhat be shown (internal analysis, internal reports, client-facing presentation, etc). Of late, I&#x27;ve been using ggplot2 for xkcd-style charts and nobody seem to mind :P - so I don&#x27;t think people are actually looking closely into the charts<p>- plot (from R) - if the chart is only for my consumption - I don&#x27;t need a fancy beautiful chart to read a PCA output for example.<p>As for high quality, the charts are only as high quality as the way you use them. If you use the wrong charts for the wrong data, it&#x27;s not going to be high quality.<p>[0] - <a href=\"http://nvd3.org/\" rel=\"nofollow\">http:&#x2F;&#x2F;nvd3.org&#x2F;</a><p>[1] - <a href=\"http://ggplot2.org\" rel=\"nofollow\">http:&#x2F;&#x2F;ggplot2.org</a>",
      "num_comments": null,
      "story_id": 6072862,
      "story_title": "Ask HN: What is the best program to produce graphs?",
      "story_url": "",
      "parent_id": 6072862,
      "created_at_i": 1374275946,
      "_tags": [
        "comment",
        "author_chewxy",
        "story_6072862"
      ],
      "objectID": "6073568",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "chewxy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "If by graphs you mean charts, these are the <em>tools</em> I use:<p>- d3js + nvd3 [0] - if the charts have to be online for consumption of people outside the company. Not so much a fan of using this because I have to do extra work to convert the data into json, and then write the scripts to generate the chart.<p>- ggplot2 [1] - if the charts are <em>static</em> and need to somewhat be shown (internal <em>analysis</em>, internal reports, client-facing presentation, etc). Of late, I've been using ggplot2 for xkcd-style charts and nobody seem to mind :P - so I don't think people are actually looking closely into the charts<p>- plot (from R) - if the chart is only for my consumption - I don't need a fancy beautiful chart to read a PCA output for example.<p>As for high quality, the charts are only as high quality as the way you use them. If you use the wrong charts for the wrong data, it's not going to be high quality.<p>[0] - <a href=\"http://nvd3.org/\" rel=\"nofollow\">http://nvd3.org/</a><p>[1] - <a href=\"http://ggplot2.org\" rel=\"nofollow\">http://ggplot2.org</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: What is the best program to produce graphs?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-15T23:31:10.000Z",
      "title": "",
      "url": "",
      "author": "happy_dino",
      "points": 1,
      "story_text": null,
      "comment_text": "That's not an IDE. What's the value of static typing if you have you don't have any tools which make use of it to provide code analysis, completion and refactoring options?",
      "num_comments": null,
      "story_id": 5710542,
      "story_title": "Why I chose to write Nuuton in Go",
      "story_url": "http://nuuton.com/blog/why_i_chose_go.html",
      "parent_id": 5715649,
      "created_at_i": 1368660670,
      "_tags": [
        "comment",
        "author_happy_dino",
        "story_5710542"
      ],
      "objectID": "5715827",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "happy_dino",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "That's not an IDE. What's the value of <em>static</em> typing if you have you don't have any <em>tools</em> which make use of it to provide code <em>analysis</em>, completion and refactoring options?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why I chose to write Nuuton in Go",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://nuuton.com/blog/why_i_chose_go.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-15T04:23:01.000Z",
      "title": "",
      "url": "",
      "author": "mspecter",
      "points": 1,
      "story_text": null,
      "comment_text": "So, this might be naive, but for static information like the shared libs it's using, you might want to check out otool, and then pick up a good disassembler (I'm a fan of hopper, which is relatively cheap). For dynamic analysis you might want to check out the standard osx tools like netstat, and instrumentation tools like valgrind or gdb. gdb + breakpoints on choice system calls works pretty well on non-obfuscated binaries!",
      "num_comments": null,
      "story_id": 5548066,
      "story_title": "Pin - A Dynamic Binary Instrumentation Tool",
      "story_url": "http://pintool.org/",
      "parent_id": 5549611,
      "created_at_i": 1365999781,
      "_tags": [
        "comment",
        "author_mspecter",
        "story_5548066"
      ],
      "objectID": "5549724",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "mspecter",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "So, this might be naive, but for <em>static</em> information like the shared libs it's using, you might want to check out otool, and then pick up a good disassembler (I'm a fan of hopper, which is relatively cheap). For dynamic <em>analysis</em> you might want to check out the standard osx <em>tools</em> like netstat, and instrumentation <em>tools</em> like valgrind or gdb. gdb + breakpoints on choice system calls works pretty well on non-obfuscated binaries!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Pin - A Dynamic Binary Instrumentation Tool",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pintool.org/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-06-04T19:38:06.000Z",
      "title": null,
      "url": null,
      "author": "spankalee",
      "points": null,
      "story_text": null,
      "comment_text": "I know this might be an unpopular view here, but declarative(ish) constructs like class give a little hope that programs will be more statically analyzable so that we can get nice things like static type checking and warnings, code completion, optimizing compilers, etc.<p>These types of imperative patterns make life extremely hard on tools, which now need to add in unreliable things like escape analysis to be able determine which classes are visible. Modules will help a little with explicit exports, so that the importing modules have some hope of tooling, but analysis within a module would suffer.",
      "num_comments": null,
      "story_id": 9660658,
      "story_title": "Classes are Expressions",
      "story_url": "http://raganwald.com/2015/06/04/classes-are-expressions.html",
      "parent_id": 9660658,
      "created_at_i": 1433446686,
      "_tags": [
        "comment",
        "author_spankalee",
        "story_9660658"
      ],
      "objectID": "9661550",
      "_highlightResult": {
        "author": {
          "value": "spankalee",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I know this might be an unpopular view here, but declarative(ish) constructs like class give a little hope that programs will be more statically analyzable so that we can get nice things like <em>static</em> type checking and warnings, code completion, optimizing compilers, etc.<p>These types of imperative patterns make life extremely hard on <em>tools</em>, which now need to add in unreliable things like escape <em>analysis</em> to be able determine which classes are visible. Modules will help a little with explicit exports, so that the importing modules have some hope of tooling, but <em>analysis</em> within a module would suffer.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Classes are Expressions",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://raganwald.com/2015/06/04/classes-are-expressions.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-27T02:01:21.000Z",
      "title": null,
      "url": null,
      "author": "stephenr",
      "points": null,
      "story_text": null,
      "comment_text": "Even without static types tools like PHPStorm have offered that type of analysis and error reporting.",
      "num_comments": null,
      "story_id": 9443241,
      "story_title": "Comparing the PHP 7 and Hack Type Systems",
      "story_url": "http://www.dmiller.io/blog/2015/4/26/comparing-the-php7-and-hack-type-systems",
      "parent_id": 9443705,
      "created_at_i": 1430100081,
      "_tags": [
        "comment",
        "author_stephenr",
        "story_9443241"
      ],
      "objectID": "9444071",
      "_highlightResult": {
        "author": {
          "value": "stephenr",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Even without <em>static</em> types <em>tools</em> like PHPStorm have offered that type of <em>analysis</em> and error reporting.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Comparing the PHP 7 and Hack Type Systems",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.dmiller.io/blog/2015/4/26/comparing-the-php7-and-hack-type-systems",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-10T21:04:09.000Z",
      "title": null,
      "url": null,
      "author": "gorohoroh",
      "points": null,
      "story_text": null,
      "comment_text": "First of all ReSharper C++ offers ~60 real-time code inspections. Things like unreachable code, hiding local declarations, dependent type without &#x27;typename&#x27; keyword, non-inline function definition in a header file, boost::format with too many or too few arguments, invalid printf format specifiers, redundant keywords (&#x27;else&#x27;, &#x27;static&#x27;, &#x27;template&#x27; etc).<p>Quick-fixes are provided for many of the inspections so that if you want to act on an inspection, you can have R# C++ do the editing for you.<p>AFAIK Visual Assist has very limited code analysis capabilities.<p>Refactorings&#x2F;transformations such as &quot;Substitute macro call&quot;, &quot;Initialize field from constructor parameter&quot;, &quot;Merge nested if statements&quot;, &quot;Replace redundant parentheses&quot;, &quot;Move method implementation out of class scope&quot; or &quot;Replace &#x27;auto&#x27; with explicit type&quot; are also unique to ReSharper C++ AFAIK.<p>Also I don&#x27;t think VAX has navigation to derived&#x2F;base symbols or specializations.<p>Some of the things that VAX has but R# C++ doesn&#x27;t include Document method, auto-inserting underscores after &#x27;m&#x27; and Header hierarchy view.<p>Here&#x27;s how a dev on the R# C++ team has summarized differences between the tools in a comment last year: <a href=\"http:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;cpp&#x2F;comments&#x2F;29k4fb&#x2F;resharper_for_c_eap_goes_on_jetbrains_net_tools&#x2F;cim0d3p\" rel=\"nofollow\">http:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;cpp&#x2F;comments&#x2F;29k4fb&#x2F;resharper_for_c_...</a><p>(Disclaimer: I&#x27;m with JetBrains, the company behind ReSharper C++. If you want to take the above with a grain of salt, feel free to.)",
      "num_comments": null,
      "story_id": 9354650,
      "story_title": "Introducing ReSharper C++",
      "story_url": "http://blog.jetbrains.com/dotnet/2015/04/10/introducing-resharper-cpp/",
      "parent_id": 9356893,
      "created_at_i": 1428699849,
      "_tags": [
        "comment",
        "author_gorohoroh",
        "story_9354650"
      ],
      "objectID": "9357103",
      "_highlightResult": {
        "author": {
          "value": "gorohoroh",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "First of all ReSharper C++ offers ~60 real-time code inspections. Things like unreachable code, hiding local declarations, dependent type without 'typename' keyword, non-inline function definition in a header file, boost::format with too many or too few arguments, invalid printf format specifiers, redundant keywords ('else', '<em>static'</em>, 'template' etc).<p>Quick-fixes are provided for many of the inspections so that if you want to act on an inspection, you can have R# C++ do the editing for you.<p>AFAIK Visual Assist has very limited code <em>analysis</em> capabilities.<p>Refactorings/transformations such as &quot;Substitute macro call&quot;, &quot;Initialize field from constructor parameter&quot;, &quot;Merge nested if statements&quot;, &quot;Replace redundant parentheses&quot;, &quot;Move method implementation out of class scope&quot; or &quot;Replace 'auto' with explicit type&quot; are also unique to ReSharper C++ AFAIK.<p>Also I don't think VAX has navigation to derived/base symbols or specializations.<p>Some of the things that VAX has but R# C++ doesn't include Document method, auto-inserting underscores after 'm' and Header hierarchy view.<p>Here's how a dev on the R# C++ team has summarized differences between the <em>tools</em> in a comment last year: <a href=\"http://www.reddit.com/r/cpp/comments/29k4fb/resharper_for_c_eap_goes_on_jetbrains_net_tools/cim0d3p\" rel=\"nofollow\">http://www.reddit.com/r/cpp/comments/29k4fb/resharper_for_c_...</a><p>(Disclaimer: I'm with JetBrains, the company behind ReSharper C++. If you want to take the above with a grain of salt, feel free to.)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Introducing ReSharper C++",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.jetbrains.com/dotnet/2015/04/10/introducing-resharper-cpp/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-10T17:59:37.000Z",
      "title": null,
      "url": null,
      "author": "rajesh88",
      "points": null,
      "story_text": null,
      "comment_text": "Location : Bangalore\nRemote : YES\nWilling to relocate : YES\nTechnologies : C&#x2F;C++,Objective C, XCode , iOS , SQLite, Webservices- XML, JSON ,REST ,SOAP  \nResume :\n\t\t\t  90&#x2F;5 Anthony Complex,\n\t\t\t  25th Main 3rd Cross BTM 2nd Stage,  \t\t  Bangalore -560076.\n\t\t\t  E-mail: raj.vishwakarma08@gmail.com\n\t\t\t  Mobile: +91- 99 16 420 914\nRajesh Vishwakarma<p>Experience Summary:<p>•\tOver 3 years of experience in iOS application development.\n•\tKnowledge and understanding in iOS SDKs, Objective-C and Xcode.\n•\tInsightful knowledge in iOS application analysis, design and development.\n•\tExpertise in enterprise iOS application development.\n•\tExpertise in iOS Static Library development.\n•\tExperience in third party iOS plug-in integration.\n•\tFluent in C++ with strong OOPs concepts.\n•\tExperience in C++ development on iOS.\n•\tGood experience in implementing design changes, resolving performance issues, memory issues and optimizing the code.\n•\tProficient in game development using Cocos2d, Cocos2d-x, Box2d and Xcode.\n•\tExperience with Unity3d for 2d games.\n•\tKnowledge of common data structures and algorithmic solutions.\n•\tStrong debugging skill.\n•\tAbility and desire to learn new skills and take on new tasks.<p>Technical Skill:\n•\tProgramming Language : Objective C , C&#x2F;C++ , Java\n•\tiOS SDKs : iOS 5.0 (on words)\n•\tIDE : Xcode 4.3 (on words)\n•\tUI Design Tools : Interface Builder, Storyboard.\n•\tWeb Services : SOAP, REST, JSON, XML\n•\tGame Development: Unity 3d, Cocos2d, Cocos2d-x, Box2d.\n•\tDatabase : SQLite\n•\tOperating System: Mac-OS<p>Employment Details :<p>•\tConsultant (iOS) Cignex Datamatics Technologies Pvt. Ltd., Bangalore from November 2014\n•\tSoftware Engineer,  Celstream Technologies Pvt. Ltd., Bangalore from November 2013 - October 2014.\n•\t¬¬iOS Game Developer,  Dumadu Games Pvt. Ltd., Bangalore from February 2012 - October 2013.<p>Educational Qualification:\nS. No.\tExamination\tCollege&#x2F;School\tUniversity&#x2F;Board\tYear\tPercentage\n1\tMCA  \tGovt. Engineering College, Jabalpur\tR.G.P.V Bhopal\t2011\t77.05\n2\tB.Sc.\tGovt. Model Science College, Jabalpur\tR.D.V.V Jabalpur\t2007\t71.08 \n3\tH.S.C\tGovt. B.I.C Balua, Varanasi\tU.P Board\t2004\t75.40 \n4\tS.S.C\tJ.J.I.C Marufpur Chandauli, Varanasi\tU.P Board\t2002\t57.00<p>Project Details:\nProject #1\tRS iDemo                                                                                   \nDescription\tiDemo, as an iOS App, is conceptualized to provide for an always connected sales\ncommunity by providing\n- The demo brokers a tool to simplify the managing , tracking of the deployed\n  demo units and recalling them when needed.\n- The sales team a tool to easily locate demo units, reserve , determine pricing\n  and arrange for shipment from&#x2F;to their home office.\n- The regional managers a tool to look up the demo units assigned to them, team \n  and perform necessary follow up activities.\nTools &amp; Technologies\tXcode 5.1, iOS 7.1, Objective C, SQLite, REST, JSON, Web Services\nTeam Size \t3\nRole &amp; Responsibilities\tRequirement Analysis, Prototype Modeling, UI design, Development and Profiling.<p>Project #2\tRS SiteSeller \nDescription\tRSA could like to create an internal tool for their sales forces to provide easy and effective access to various sales materials. The needed sales materials are intended to be available on the sales person&#x27;s Apple iPad device.\nContent should be available on the device offline without needing network access and\nthe content is expected to be synchronized with the source on a regular basis.\nSome content such as video may not be available offline.\nTools &amp; Technologies\tXcode 4.6&#x2F;5.0, iOS 6.1&#x2F;7.0, Objective C, Core Data, SOAP,XML, Web Services\nRole &amp; Responsibilities\tFeatures Enhancement, Support for iOS6&#x2F;iOS7, code and performance optimization.<p>Project #4\tSmart Wallet\nDescription\tThe app provides every individual the facility to record and categorize their daily expenses. The app also allows the user to see reports based on various filters based on time durations or categories. The report can also be emailed to the user in appropriate format so that he can use it elsewhere.<p>Besides, the app also allows the user to set the budget, and when the expenses reaches the budget threshold, it can give alerts and notifications.<p>Tools &amp; Technologies\tXcode 4.5, iOS 6.0, Objective C, Core Data\nTeam Size\t3\nRole &amp; Responsibilities\tClient requirement analysis , UI design,  Application Coding<p>Project#3\tBlue Lion\nDescription\tThis app discover one of the most enchanting spots in Paris: the Palais-Royal. Our guide, Ulrike Kasper, an artists and professor of history of arts, will guide you through a fascinating walk. She talks about the history and people, kings, philosophers and revolutionaries, who haunt this monument and the surrounding galleries. The guides is includes an original text, practical information, modern and historic illustrations, as well as a captivating audio version by a storyteller, which, we are sure, will make your visit even more agreeable.\nTools &amp; Technologies\tXcode 4.2 , iPhone SDK5.0, Sqlite\nRole &amp; Responsibilities\tUI design. Code development\nApp Link\t<a href=\"https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;blue-lion-guides-palais-royal&#x2F;id574847756?ls=1&amp;mt=8\" rel=\"nofollow\">https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;blue-lion-guides-palais-roya...</a><p>Project#5\tWar Of Eternity\nTools &amp; Technologies\tXcode 4.3, iOS 5.0, C++,Cocos2d-x,  Cocoa Touch\nTeam Size \t2\nRole &amp; Responsibility\tRequirement analysis , UI designed and  Game Play Coding For Enemy Module\nApp Link\t <a href=\"https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;war-eternity-fort-defense&#x2F;id666188944?mt=8\" rel=\"nofollow\">https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;war-eternity-fort-defense&#x2F;id...</a><p>Project#6\tSlotMania (SlotMachine)\nTools &amp; Technologies\tXcode 4.3, iOS 5.0, Cocos2d-X, C++, Cocoa Touch\nRole &amp; Responsibility\tRequirement analysis, UI Designed, Game Programming\nApp Link\t<a href=\"https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;slot-mania-hd&#x2F;id633841176?mt=8\" rel=\"nofollow\">https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;slot-mania-hd&#x2F;id633841176?mt...</a><p>Project#7\tSensei’s Puzzle                                                                \nTools &amp; Technologies\tXcode 4.3, iOS 5.0,C++, Cocos2d-x, Cocoa Touch\nRole &amp; Responsibility\tDesigned Level Editor, Game Play Coding \nApp Link\t<a href=\"https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;senseis-puzzle-hd&#x2F;id572486774?mt=8\" rel=\"nofollow\">https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;senseis-puzzle-hd&#x2F;id57248677...</a><p>Project#8\tDoodle Car Plush\nTools &amp; Technologies\tXcode 4.2, iOS5.0, Objective C,Cocos2d, Cocoa Touch,  Box2d \nRole &amp; Responsibility\tDesigned Level Editor, UI Designed and Game Play Coding\nApp Link\t<a href=\"https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;doodle-car-plus&#x2F;id448860353?mt=8\" rel=\"nofollow\">https:&#x2F;&#x2F;itunes.apple.com&#x2F;us&#x2F;app&#x2F;doodle-car-plus&#x2F;id448860353?...</a><p>Awards and Achievements:\n•\tBest Practices Award for Process Improvement by Celstream Technologies Pvt. Ltd. Bangalore.\n•\tObtained  3nd position  in MCA.\n•\tObtained  2nd position in 12th class.<p>Interest and Hobbies:\n•\tExploring knowledge in mobile related technologies&#x2F;frameworks.\n•\tListening music.\n•\tCooking.\n•\tPlaying badminton and computer games.<p>Personal Profile:\nFull Name\t\t: Rajesh Kumar Vishwakarma\nDate of Birth\t\t: 15th November, 1988\nGender\t\t\t: Male\nPermanent Address\t: 572 East Belbag Road, Jabalpur (M.P)\nLanguages Known\t: English, Hindi",
      "num_comments": null,
      "story_id": 9303599,
      "story_title": "Ask HN: Who wants to be hired? (April 2015)",
      "story_url": "",
      "parent_id": 9303599,
      "created_at_i": 1428688777,
      "_tags": [
        "comment",
        "author_rajesh88",
        "story_9303599"
      ],
      "objectID": "9356004",
      "_highlightResult": {
        "author": {
          "value": "rajesh88",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Location : Bangalore\nRemote : YES\nWilling to relocate : YES\nTechnologies : C/C++,Objective C, XCode , iOS , SQLite, Webservices- XML, JSON ,REST ,SOAP  \nResume :\n\t\t\t  90/5 Anthony Complex,\n\t\t\t  25th Main 3rd Cross BTM 2nd Stage,  \t\t  Bangalore -560076.\n\t\t\t  E-mail: raj.vishwakarma08@gmail.com\n\t\t\t  Mobile: +91- 99 16 420 914\nRajesh Vishwakarma<p>Experience Summary:<p>•\tOver 3 years of experience in iOS application development.\n•\tKnowledge and understanding in iOS SDKs, Objective-C and Xcode.\n•\tInsightful knowledge in iOS application <em>analysis</em>, design and development.\n•\tExpertise in enterprise iOS application development.\n•\tExpertise in iOS <em>Static</em> Library development.\n•\tExperience in third party iOS plug-in integration.\n•\tFluent in C++ with strong OOPs concepts.\n•\tExperience in C++ development on iOS.\n•\tGood experience in implementing design changes, resolving performance issues, memory issues and optimizing the code.\n•\tProficient in game development using Cocos2d, Cocos2d-x, Box2d and Xcode.\n•\tExperience with Unity3d for 2d games.\n•\tKnowledge of common data structures and algorithmic solutions.\n•\tStrong debugging skill.\n•\tAbility and desire to learn new skills and take on new tasks.<p>Technical Skill:\n•\tProgramming Language : Objective C , C/C++ , Java\n•\tiOS SDKs : iOS 5.0 (on words)\n•\tIDE : Xcode 4.3 (on words)\n•\tUI Design <em>Tools</em> : Interface Builder, Storyboard.\n•\tWeb Services : SOAP, REST, JSON, XML\n•\tGame Development: Unity 3d, Cocos2d, Cocos2d-x, Box2d.\n•\tDatabase : SQLite\n•\tOperating System: Mac-OS<p>Employment Details :<p>•\tConsultant (iOS) Cignex Datamatics Technologies Pvt. Ltd., Bangalore from November 2014\n•\tSoftware Engineer,  Celstream Technologies Pvt. Ltd., Bangalore from November 2013 - October 2014.\n•\t¬¬iOS Game Developer,  Dumadu Games Pvt. Ltd., Bangalore from February 2012 - October 2013.<p>Educational Qualification:\nS. No.\tExamination\tCollege/School\tUniversity/Board\tYear\tPercentage\n1\tMCA  \tGovt. Engineering College, Jabalpur\tR.G.P.V Bhopal\t2011\t77.05\n2\tB.Sc.\tGovt. Model Science College, Jabalpur\tR.D.V.V Jabalpur\t2007\t71.08 \n3\tH.S.C\tGovt. B.I.C Balua, Varanasi\tU.P Board\t2004\t75.40 \n4\tS.S.C\tJ.J.I.C Marufpur Chandauli, Varanasi\tU.P Board\t2002\t57.00<p>Project Details:\nProject #1\tRS iDemo                                                                                   \nDescription\tiDemo, as an iOS App, is conceptualized to provide for an always connected sales\ncommunity by providing\n- The demo brokers a tool to simplify the managing , tracking of the deployed\n  demo units and recalling them when needed.\n- The sales team a tool to easily locate demo units, reserve , determine pricing\n  and arrange for shipment from/to their home office.\n- The regional managers a tool to look up the demo units assigned to them, team \n  and perform necessary follow up activities.\n<em>Tools</em> &amp; Technologies\tXcode 5.1, iOS 7.1, Objective C, SQLite, REST, JSON, Web Services\nTeam Size \t3\nRole &amp; Responsibilities\tRequirement <em>Analysis</em>, Prototype Modeling, UI design, Development and Profiling.<p>Project #2\tRS SiteSeller \nDescription\tRSA could like to create an internal tool for their sales forces to provide easy and effective access to various sales materials. The needed sales materials are intended to be available on the sales person's Apple iPad device.\nContent should be available on the device offline without needing network access and\nthe content is expected to be synchronized with the source on a regular basis.\nSome content such as video may not be available offline.\n<em>Tools</em> &amp; Technologies\tXcode 4.6/5.0, iOS 6.1/7.0, Objective C, Core Data, SOAP,XML, Web Services\nRole &amp; Responsibilities\tFeatures Enhancement, Support for iOS6/iOS7, code and performance optimization.<p>Project #4\tSmart Wallet\nDescription\tThe app provides every individual the facility to record and categorize their daily expenses. The app also allows the user to see reports based on various filters based on time durations or categories. The report can also be emailed to the user in appropriate format so that he can use it elsewhere.<p>Besides, the app also allows the user to set the budget, and when the expenses reaches the budget threshold, it can give alerts and notifications.<p><em>Tools</em> &amp; Technologies\tXcode 4.5, iOS 6.0, Objective C, Core Data\nTeam Size\t3\nRole &amp; Responsibilities\tClient requirement <em>analysis</em> , UI design,  Application Coding<p>Project#3\tBlue Lion\nDescription\tThis app discover one of the most enchanting spots in Paris: the Palais-Royal. Our guide, Ulrike Kasper, an artists and professor of history of arts, will guide you through a fascinating walk. She talks about the history and people, kings, philosophers and revolutionaries, who haunt this monument and the surrounding galleries. The guides is includes an original text, practical information, modern and historic illustrations, as well as a captivating audio version by a storyteller, which, we are sure, will make your visit even more agreeable.\n<em>Tools</em> &amp; Technologies\tXcode 4.2 , iPhone SDK5.0, Sqlite\nRole &amp; Responsibilities\tUI design. Code development\nApp Link\t<a href=\"https://itunes.apple.com/us/app/blue-lion-guides-palais-royal/id574847756?ls=1&amp;mt=8\" rel=\"nofollow\">https://itunes.apple.com/us/app/blue-lion-guides-palais-roya...</a><p>Project#5\tWar Of Eternity\n<em>Tools</em> &amp; Technologies\tXcode 4.3, iOS 5.0, C++,Cocos2d-x,  Cocoa Touch\nTeam Size \t2\nRole &amp; Responsibility\tRequirement <em>analysis</em> , UI designed and  Game Play Coding For Enemy Module\nApp Link\t <a href=\"https://itunes.apple.com/us/app/war-eternity-fort-defense/id666188944?mt=8\" rel=\"nofollow\">https://itunes.apple.com/us/app/war-eternity-fort-defense/id...</a><p>Project#6\tSlotMania (SlotMachine)\n<em>Tools</em> &amp; Technologies\tXcode 4.3, iOS 5.0, Cocos2d-X, C++, Cocoa Touch\nRole &amp; Responsibility\tRequirement <em>analysis</em>, UI Designed, Game Programming\nApp Link\t<a href=\"https://itunes.apple.com/us/app/slot-mania-hd/id633841176?mt=8\" rel=\"nofollow\">https://itunes.apple.com/us/app/slot-mania-hd/id633841176?mt...</a><p>Project#7\tSensei’s Puzzle                                                                \n<em>Tools</em> &amp; Technologies\tXcode 4.3, iOS 5.0,C++, Cocos2d-x, Cocoa Touch\nRole &amp; Responsibility\tDesigned Level Editor, Game Play Coding \nApp Link\t<a href=\"https://itunes.apple.com/us/app/senseis-puzzle-hd/id572486774?mt=8\" rel=\"nofollow\">https://itunes.apple.com/us/app/senseis-puzzle-hd/id57248677...</a><p>Project#8\tDoodle Car Plush\n<em>Tools</em> &amp; Technologies\tXcode 4.2, iOS5.0, Objective C,Cocos2d, Cocoa Touch,  Box2d \nRole &amp; Responsibility\tDesigned Level Editor, UI Designed and Game Play Coding\nApp Link\t<a href=\"https://itunes.apple.com/us/app/doodle-car-plus/id448860353?mt=8\" rel=\"nofollow\">https://itunes.apple.com/us/app/doodle-car-plus/id448860353?...</a><p>Awards and Achievements:\n•\tBest Practices Award for Process Improvement by Celstream Technologies Pvt. Ltd. Bangalore.\n•\tObtained  3nd position  in MCA.\n•\tObtained  2nd position in 12th class.<p>Interest and Hobbies:\n•\tExploring knowledge in mobile related technologies/frameworks.\n•\tListening music.\n•\tCooking.\n•\tPlaying badminton and computer games.<p>Personal Profile:\nFull Name\t\t: Rajesh Kumar Vishwakarma\nDate of Birth\t\t: 15th November, 1988\nGender\t\t\t: Male\nPermanent Address\t: 572 East Belbag Road, Jabalpur (M.P)\nLanguages Known\t: English, Hindi",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who wants to be hired? (April 2015)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-06T19:48:29.000Z",
      "title": null,
      "url": null,
      "author": "squeaky-clean",
      "points": null,
      "story_text": null,
      "comment_text": "Off topic from the article, but this is something I literally just spent my morning wrestling with and fixing, so I&#x27;d like to talk&#x2F;rant about it a little. My apologies in advance for rambling.<p>You can use doc comments to signify types. You mention you use PyCharm in your article, and it supports doc comments in it&#x27;s autocomplete and code analysis, I find most popular libraries are commented well enough that PyCharm can understand them.<p>I also always try (and encourage others) to use names that are declarative for both purpose and type. Of course, you can&#x27;t always rely on third party libraries (or even colleagues) to be so nice, but I find a good name (almost) always removes all the confusion that normally comes from a lack of static typing.<p>For example, one of Codecademy&#x27;s very first Python lessons includes some code like this:<p><pre><code>    meal = 44.50\n    tax = 0.0675\n    tip = 0.15\n</code></pre>\nWhich I think is unclear. Imagine these were function arguments. calc_total(meal, tax, tip) is vague. Is meal an object, or a numeric value? (I could possibly see it containing a list of all items in the meal with prices). Tax is almost always a percentage, but what about tip? Judging by the the above values, we can assume a 15% tip, but we don&#x27;t know if the customer was stingy and tipped $0.15, and by just name alone, we can&#x27;t tell at all.<p><pre><code>    calc_total(meal_cost, tax_percent, tip_percent)\n</code></pre>\nIt&#x27;s now immediately clear to me the type and range of values it accepts. The tip_percent is also an example of when a good name can provide info that even static typing could not, because in either case it is a floating point (please let&#x27;s not get into a debate about Decimal or currency types :P ). This is a very basic example, but it applies at all levels. Don&#x27;t call the parameter &quot;users&quot; if the function is not expecting an iterable of User objects. Maybe &quot;usernames&quot; would be better. Etc.<p>But of course, this only helps if the code you&#x27;re working with is named well. In something like Java, you have better protection and tools when working alongside lower quality code. I also completely agree with you on point #2 about No Static Types. Navigating through my editor is so much easier in a static language than it is in PyCharm with large projects. And the most annoying thing is that autocomplete breaks with ORMs, and most ORM usage is actually flagged as a warning or error. Ugh.<p>I also feel very confident in the automated refactoring in something such as an IntelliJ Java project, or ReSharper, but am apprehensive about using PyCharm to refactor anything with usages spanning more than one file. Same goes for Javascript (or any other dynamic language, I suppose. Those are just the two I use).<p>Enjoyed the posts by the way, adding your blog to my reading list.",
      "num_comments": null,
      "story_id": 9328518,
      "story_title": "Ten Years of Git: An Interview with Linus Torvalds",
      "story_url": "http://www.linux.com/news/featured-blogs/185-jennifer-cloer/821541-10-years-of-git-an-interview-with-git-creator-linus-torvalds",
      "parent_id": 9329872,
      "created_at_i": 1428349709,
      "_tags": [
        "comment",
        "author_squeaky-clean",
        "story_9328518"
      ],
      "objectID": "9330297",
      "_highlightResult": {
        "author": {
          "value": "squeaky-clean",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Off topic from the article, but this is something I literally just spent my morning wrestling with and fixing, so I'd like to talk/rant about it a little. My apologies in advance for rambling.<p>You can use doc comments to signify types. You mention you use PyCharm in your article, and it supports doc comments in it's autocomplete and code <em>analysis</em>, I find most popular libraries are commented well enough that PyCharm can understand them.<p>I also always try (and encourage others) to use names that are declarative for both purpose and type. Of course, you can't always rely on third party libraries (or even colleagues) to be so nice, but I find a good name (almost) always removes all the confusion that normally comes from a lack of <em>static</em> typing.<p>For example, one of Codecademy's very first Python lessons includes some code like this:<p><pre><code>    meal = 44.50\n    tax = 0.0675\n    tip = 0.15\n</code></pre>\nWhich I think is unclear. Imagine these were function arguments. calc_total(meal, tax, tip) is vague. Is meal an object, or a numeric value? (I could possibly see it containing a list of all items in the meal with prices). Tax is almost always a percentage, but what about tip? Judging by the the above values, we can assume a 15% tip, but we don't know if the customer was stingy and tipped $0.15, and by just name alone, we can't tell at all.<p><pre><code>    calc_total(meal_cost, tax_percent, tip_percent)\n</code></pre>\nIt's now immediately clear to me the type and range of values it accepts. The tip_percent is also an example of when a good name can provide info that even <em>static</em> typing could not, because in either case it is a floating point (please let's not get into a debate about Decimal or currency types :P ). This is a very basic example, but it applies at all levels. Don't call the parameter &quot;users&quot; if the function is not expecting an iterable of User objects. Maybe &quot;usernames&quot; would be better. Etc.<p>But of course, this only helps if the code you're working with is named well. In something like Java, you have better protection and <em>tools</em> when working alongside lower quality code. I also completely agree with you on point #2 about No <em>Static</em> Types. Navigating through my editor is so much easier in a <em>static</em> language than it is in PyCharm with large projects. And the most annoying thing is that autocomplete breaks with ORMs, and most ORM usage is actually flagged as a warning or error. Ugh.<p>I also feel very confident in the automated refactoring in something such as an IntelliJ Java project, or ReSharper, but am apprehensive about using PyCharm to refactor anything with usages spanning more than one file. Same goes for Javascript (or any other dynamic language, I suppose. Those are just the two I use).<p>Enjoyed the posts by the way, adding your blog to my reading list.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ten Years of Git: An Interview with Linus Torvalds",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.linux.com/news/featured-blogs/185-jennifer-cloer/821541-10-years-of-git-an-interview-with-git-creator-linus-torvalds",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-12T13:18:28.000Z",
      "title": null,
      "url": null,
      "author": "cabinpark",
      "points": null,
      "story_text": null,
      "comment_text": "&gt;I&#x27;m amazed that you say that calculus has had a much greater impact on society when virtually every database, graphics manipulation or economic analysis uses principles of linear algebra.<p>I&#x27;m not. Consider all of physics. Physics is written down in terms of differential equations. You need calculus to get these equations. In terms of graphics, for example, are you magically creating only static images that never change in time? How do you think people came up with the algorithms to do things like refraction or reflection? These all involve calculus. Calculus is the most important tool in applying mathematics to the real world. It is how we derive the models for pretty much everything I can think of. Any time you want to model something where anything changes, that is calculus. Any time you want to find an optimal solutions, that is calculus. I can&#x27;t think of a single area of applied mathematics that doesn&#x27;t use calculus in some form. Even mathematics in general, calculus is used  in some form pretty much everywhere in some form, except maybe in the foundations of mathematics like set theory or logic.<p>Solving them, on the other hand, is a different problem. This is where linear algebra is important. When solving an ODE or PDE, when I discretise it, all I am doing is re-writing it as a giant linear algebra problem. Quantum mechanics, for example, is dedicated to finding the eigenvalues and eigenvectors of the Hamiltonian. Linear algebra provides the tools to solve the problems posed by calculus. But it isn&#x27;t always required.<p>In fact, if you look at the history of linear algebra, it only really became wide-spread when quantum mechanics was developing since there is a deep connection between linear algebra and quantum mechanics. Heisenberg had never heard of a matrix before despite discovering Heisenberg matrix mechanics.  He was told by Max Born that what he had been doing is actually this thing mathematicians called &quot;matrices&quot;. Now linear algebra is a required course for physicists (incidentally, linear algebra was the first lecture I ever attended at university).<p>So I would argue that learning calculus is the most important thing someone should know mathematically, since it is the tool we use to build models. The second most is linear algebra since it provides us the tools to solve these problems. But in my mind, knowing how to derive these models is a lot more important than being able to solve them. That and linear algebra doesn&#x27;t give you any insight into why we are solving the problem that way, it is just a tool to solve the problem.<p>Also in Calculus 1,2,3 and so on, you learn increasingly more complicated techniques of calculus to solve more problems. But when you start numerically solving them, linear algebra doesn&#x27;t care. It doesn&#x27;t care if your equation came from the Einstein field equations or Newton&#x27;s second law. It&#x27;s all the same to it. So in a sense, I can teach you everything you&#x27;ll need to know about linear algebra in a single course but the same is not true of calculus, which requires multiple courses.",
      "num_comments": null,
      "story_id": 9189553,
      "story_title": "Too Much Calculus – Gilbert Strang (2001) [pdf]",
      "story_url": "http://www-math.mit.edu/~gs/papers/essay.pdf",
      "parent_id": 9189940,
      "created_at_i": 1426166308,
      "_tags": [
        "comment",
        "author_cabinpark",
        "story_9189553"
      ],
      "objectID": "9190537",
      "_highlightResult": {
        "author": {
          "value": "cabinpark",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt;I'm amazed that you say that calculus has had a much greater impact on society when virtually every database, graphics manipulation or economic <em>analysis</em> uses principles of linear algebra.<p>I'm not. Consider all of physics. Physics is written down in terms of differential equations. You need calculus to get these equations. In terms of graphics, for example, are you magically creating only <em>static</em> images that never change in time? How do you think people came up with the algorithms to do things like refraction or reflection? These all involve calculus. Calculus is the most important tool in applying mathematics to the real world. It is how we derive the models for pretty much everything I can think of. Any time you want to model something where anything changes, that is calculus. Any time you want to find an optimal solutions, that is calculus. I can't think of a single area of applied mathematics that doesn't use calculus in some form. Even mathematics in general, calculus is used  in some form pretty much everywhere in some form, except maybe in the foundations of mathematics like set theory or logic.<p>Solving them, on the other hand, is a different problem. This is where linear algebra is important. When solving an ODE or PDE, when I discretise it, all I am doing is re-writing it as a giant linear algebra problem. Quantum mechanics, for example, is dedicated to finding the eigenvalues and eigenvectors of the Hamiltonian. Linear algebra provides the <em>tools</em> to solve the problems posed by calculus. But it isn't always required.<p>In fact, if you look at the history of linear algebra, it only really became wide-spread when quantum mechanics was developing since there is a deep connection between linear algebra and quantum mechanics. Heisenberg had never heard of a matrix before despite discovering Heisenberg matrix mechanics.  He was told by Max Born that what he had been doing is actually this thing mathematicians called &quot;matrices&quot;. Now linear algebra is a required course for physicists (incidentally, linear algebra was the first lecture I ever attended at university).<p>So I would argue that learning calculus is the most important thing someone should know mathematically, since it is the tool we use to build models. The second most is linear algebra since it provides us the <em>tools</em> to solve these problems. But in my mind, knowing how to derive these models is a lot more important than being able to solve them. That and linear algebra doesn't give you any insight into why we are solving the problem that way, it is just a tool to solve the problem.<p>Also in Calculus 1,2,3 and so on, you learn increasingly more complicated techniques of calculus to solve more problems. But when you start numerically solving them, linear algebra doesn't care. It doesn't care if your equation came from the Einstein field equations or Newton's second law. It's all the same to it. So in a sense, I can teach you everything you'll need to know about linear algebra in a single course but the same is not true of calculus, which requires multiple courses.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Too Much Calculus – Gilbert Strang (2001) [pdf]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www-math.mit.edu/~gs/papers/essay.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-08T16:16:24.000Z",
      "title": null,
      "url": null,
      "author": "DannyBee",
      "points": null,
      "story_text": null,
      "comment_text": "&quot;but what is wrong with recursion? Why NASA guidelines prescribe to avoid simple technique we were studying as early as in school? The reason for that is static code analyzers NASA use to reduce the chance for error. Recursions make code less predictable for them. JavaScript tools do not have such a precept so what we can take out of this rule?&quot;<p>This is of course, wrong. Javascript has not solved the problem of making recursion easy or sane to analyze.  It is quite literally the same problem you have with C.<p>In fact, most javascript tools are <i>way</i> less useful at recursion analysis (IE they produce a much higher rate of false positives) than C tools.<p>&quot;9.The use of pointers should be restricted. Specifically, no more than one level of dereferencing is allowed. Function pointers are not permitted.<p>This is the rule JavaScript developer can not get anything from.\n&quot;<p>Except that javascript developers use function pointers like they were going out of style ...",
      "num_comments": null,
      "story_id": 8856226,
      "story_title": "Applying NASA coding standards to JavaScript",
      "story_url": "http://pixelscommander.com/en/javascript/nasa-coding-standarts-for-javascript-performance/",
      "parent_id": 8856226,
      "created_at_i": 1420733784,
      "_tags": [
        "comment",
        "author_DannyBee",
        "story_8856226"
      ],
      "objectID": "8857019",
      "_highlightResult": {
        "author": {
          "value": "DannyBee",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&quot;but what is wrong with recursion? Why NASA guidelines prescribe to avoid simple technique we were studying as early as in school? The reason for that is <em>static</em> code analyzers NASA use to reduce the chance for error. Recursions make code less predictable for them. JavaScript <em>tools</em> do not have such a precept so what we can take out of this rule?&quot;<p>This is of course, wrong. Javascript has not solved the problem of making recursion easy or sane to analyze.  It is quite literally the same problem you have with C.<p>In fact, most javascript <em>tools</em> are <i>way</i> less useful at recursion <em>analysis</em> (IE they produce a much higher rate of false positives) than C <em>tools</em>.<p>&quot;9.The use of pointers should be restricted. Specifically, no more than one level of dereferencing is allowed. Function pointers are not permitted.<p>This is the rule JavaScript developer can not get anything from.\n&quot;<p>Except that javascript developers use function pointers like they were going out of style ...",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Applying NASA coding standards to JavaScript",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pixelscommander.com/en/javascript/nasa-coding-standarts-for-javascript-performance/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-07-06T16:20:04.000Z",
      "title": null,
      "url": null,
      "author": "jacquesm",
      "points": null,
      "story_text": null,
      "comment_text": "The reasons 1 by 1:<p>1) you don't need to edit HTML code to include scripts<p>The authors assert that you'd have do this by hand if you had a lot of static html. This is incorrect (you could easily insert the code using some script), but it also doesn't make sense, most larger sites (if not all these days) are dynamically constructed and adding a bit of .js is as easy as changing a footer.<p>2) scripts take additional time to load<p>This is true, but it only matters if you place your little bit of javascript in the wrong place on the page (say in the header). When positioned correctly it does not need to take more time to make the connection.<p>3) 'if website exists, log files exist too' (...)<p>This is really not always the case. Plenty of very high volume sites rely almost entirely on 3rd party analysis simply because storing and processing the logs becomes a major operation by itself.<p>4) 'server log files contain hits to all files, not just pages'<p>That's true, but for almost every practical purpose that I can think of that is a very good reason to use a tag based analysis tool rather than to go through your logs. The embedding argument the author makes is fairly easily taken care of by some cookie magic and / or a referrer check.<p>5) you can investigate and control bandwidth usage<p>Bot detection and blocking is a reason to spool your log files to a ramdisk and to analyze them in real time, to do it the next day is totally pointless. Interactive log analysis (such as the product sold by this company does) can help there, but a simple 50 line script will do the same thing just as well and can run in the background instead of requiring 'interaction'.<p>6) see 5<p>7) log files record all traffic, even if javascript is disabled<p>yes, but trust me on this one, almost everybody has javascript enabled these days because more and more of the web stops working if you don't have it. The biggest source of missing traffic is not people that have javascript turned off but bots.<p>8) you can find out about hacker attacks<p>True, but your sysadmin probably has a whole bunch of tools looking at the regular logs already to monitor this. Basically when all the 'regular' traffic is discarded from your logs the remainder is bots and bad guys. A real attack (such as a ddos) is actually going to work much better if you are writing log files because you're going to be writing all that totally useless logging information to the disk. Also, in my book a 'hacker' is going to go after other ports than port 80.<p>9) log files contain error information<p>This is very true, and should not be taken lightly, your server should log errors and you should poll those error logs periodically to make sure they're blank (or nearly so) in case you've got a problem on your site.<p>10) by using (a) log file analyzer, you don't give away your business data<p>well, you're not exactly giving away your business data, but the point is well taken. For most sites however the benefits of having access to fairly detailed site statistics in real time for $0 vs 'giving away of business data' is clearly in favor of giving away that data.<p>Google and plenty of others of course have their own agenda on what they do with 'your' data, but as long as they don't get too evil with it it looks like the number of sites that analyse via tags is going to continue to expand.",
      "num_comments": null,
      "story_id": 689746,
      "story_title": "Why web log analyzers are better than JavaScript based analytics",
      "story_url": "http://www.datalandsoftware.com/blog/2009/07/06/10-reasons-why-web-log-analyzers-are-better-than-javascript-based-analytics/",
      "parent_id": 689746,
      "created_at_i": 1246897204,
      "_tags": [
        "comment",
        "author_jacquesm",
        "story_689746"
      ],
      "objectID": "689882",
      "_highlightResult": {
        "author": {
          "value": "jacquesm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The reasons 1 by 1:<p>1) you don't need to edit HTML code to include scripts<p>The authors assert that you'd have do this by hand if you had a lot of <em>static</em> html. This is incorrect (you could easily insert the code using some script), but it also doesn't make sense, most larger sites (if not all these days) are dynamically constructed and adding a bit of .js is as easy as changing a footer.<p>2) scripts take additional time to load<p>This is true, but it only matters if you place your little bit of javascript in the wrong place on the page (say in the header). When positioned correctly it does not need to take more time to make the connection.<p>3) 'if website exists, log files exist too' (...)<p>This is really not always the case. Plenty of very high volume sites rely almost entirely on 3rd party <em>analysis</em> simply because storing and processing the logs becomes a major operation by itself.<p>4) 'server log files contain hits to all files, not just pages'<p>That's true, but for almost every practical purpose that I can think of that is a very good reason to use a tag based <em>analysis</em> tool rather than to go through your logs. The embedding argument the author makes is fairly easily taken care of by some cookie magic and / or a referrer check.<p>5) you can investigate and control bandwidth usage<p>Bot detection and blocking is a reason to spool your log files to a ramdisk and to analyze them in real time, to do it the next day is totally pointless. Interactive log <em>analysis</em> (such as the product sold by this company does) can help there, but a simple 50 line script will do the same thing just as well and can run in the background instead of requiring 'interaction'.<p>6) see 5<p>7) log files record all traffic, even if javascript is disabled<p>yes, but trust me on this one, almost everybody has javascript enabled these days because more and more of the web stops working if you don't have it. The biggest source of missing traffic is not people that have javascript turned off but bots.<p>8) you can find out about hacker attacks<p>True, but your sysadmin probably has a whole bunch of <em>tools</em> looking at the regular logs already to monitor this. Basically when all the 'regular' traffic is discarded from your logs the remainder is bots and bad guys. A real attack (such as a ddos) is actually going to work much better if you are writing log files because you're going to be writing all that totally useless logging information to the disk. Also, in my book a 'hacker' is going to go after other ports than port 80.<p>9) log files contain error information<p>This is very true, and should not be taken lightly, your server should log errors and you should poll those error logs periodically to make sure they're blank (or nearly so) in case you've got a problem on your site.<p>10) by using (a) log file analyzer, you don't give away your business data<p>well, you're not exactly giving away your business data, but the point is well taken. For most sites however the benefits of having access to fairly detailed site statistics in real time for $0 vs 'giving away of business data' is clearly in favor of giving away that data.<p>Google and plenty of others of course have their own agenda on what they do with 'your' data, but as long as they don't get too evil with it it looks like the number of sites that analyse via tags is going to continue to expand.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why web log analyzers are better than JavaScript based analytics",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.datalandsoftware.com/blog/2009/07/06/10-reasons-why-web-log-analyzers-are-better-than-javascript-based-analytics/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-04T00:56:51.000Z",
      "title": null,
      "url": null,
      "author": "siddboots",
      "points": null,
      "story_text": null,
      "comment_text": "I&#x27;m a data analyst &#x2F; data application developer for a large humanitarian NGO.<p>What: Lots of small data analysis projects, some large web projects. All projects are in git repos or in our division&#x27;s SVN. My work tends to involve ETL data flows, statistical analysis, web development and data visualisation. I&#x27;m not &quot;full stack&quot; as I never really play with hardware or do much systems administration. I do get to control a nice big, enterprisey Oracle data warehouse, with a few hundred users, but I&#x27;ve hardly played with nosql, redis, mapreduce, etc.<p>Most of my problems can be solved in-memory, and most of my data fits on a single disk.<p>How: SQL. SQL. More SQL. PL&#x2F;SQL. Python (Pandas, scipy, numpy). R (these days only when I can&#x27;t find a python lib). Javascript (just jquery, underscore and D3). Windows 7 while at work, Ubuntu + i3 wm at home. Edit in vim with very few plugins, everything else is done in zsh&#x2F;powershell. IIS for production, Pyramid&#x2F;Pylons Project for quick prototyping. A wide variety of RDBMS, but chiefly Oracle. I do lots of my templating&#x2F;css in-browser using developer tools (FF, Chrome, IE9).<p>My typical web stack is static html and javascript, with json served up out of purpose-specific database views. No need for an MV* framework, since I&#x27;m almost never dealing with transactional data.<p>I also use Excel for a) doing quick data transforms b) building interactive, distributable data analysis apps in less than an hour. I&#x27;m trying to build an excel replacement with vim bindings and LISPy worksheet formulas.",
      "num_comments": null,
      "story_id": 6153721,
      "story_title": "Ask HN: What kind of programming do you do and what tools do you use every day?",
      "story_url": "",
      "parent_id": 6153721,
      "created_at_i": 1375577811,
      "_tags": [
        "comment",
        "author_siddboots",
        "story_6153721"
      ],
      "objectID": "6154084",
      "_highlightResult": {
        "author": {
          "value": "siddboots",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm a data analyst / data application developer for a large humanitarian NGO.<p>What: Lots of small data <em>analysis</em> projects, some large web projects. All projects are in git repos or in our division's SVN. My work tends to involve ETL data flows, statistical <em>analysis</em>, web development and data visualisation. I'm not &quot;full stack&quot; as I never really play with hardware or do much systems administration. I do get to control a nice big, enterprisey Oracle data warehouse, with a few hundred users, but I've hardly played with nosql, redis, mapreduce, etc.<p>Most of my problems can be solved in-memory, and most of my data fits on a single disk.<p>How: SQL. SQL. More SQL. PL/SQL. Python (Pandas, scipy, numpy). R (these days only when I can't find a python lib). Javascript (just jquery, underscore and D3). Windows 7 while at work, Ubuntu + i3 wm at home. Edit in vim with very few plugins, everything else is done in zsh/powershell. IIS for production, Pyramid/Pylons Project for quick prototyping. A wide variety of RDBMS, but chiefly Oracle. I do lots of my templating/css in-browser using developer <em>tools</em> (FF, Chrome, IE9).<p>My typical web stack is <em>static</em> html and javascript, with json served up out of purpose-specific database views. No need for an MV* framework, since I'm almost never dealing with transactional data.<p>I also use Excel for a) doing quick data transforms b) building interactive, distributable data <em>analysis</em> apps in less than an hour. I'm trying to build an excel replacement with vim bindings and LISPy worksheet formulas.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: What kind of programming do you do and what <em>tools</em> do you use every day?",
          "matchLevel": "partial",
          "matchedWords": [
            "tools"
          ]
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-01-05T16:49:29.000Z",
      "title": null,
      "url": null,
      "author": "PaulHoule",
      "points": null,
      "story_text": null,
      "comment_text": "Well,  the advantage of a language like Java or C# is that the IDE knows the types of objects,  so,  for instance,  it can autocomplete method and property names.  Because introspection is used rarely in static languages,  IDEs can do automated refactoring operations and KNOW that they found all the (non-introspection) references that are affected.<p>It's certainly possible to parse PHP, Python or Ruby into an abstract syntax tree (OK,  Perl is a little harder) but practically very few people do metaprogramming at that level,  even when it's officially supported. (C# and VB have had \"expression trees\" for a few years now and they're barely used.)<p>Part of the appeal of LISP is that you can pretend Noam Chomsky was never born and never need to learn how to write parsers or deal with the data structures that they spit out.<p>Any kind of extreme metaprogramming is going to defeat 'reasoning-in-code'.  For instance,  in LISP I can easily implement a new kind of control structure...  Because 'understanding' a program in general (rather than running it) is an undecidable problem,  it's clear that an IDE will ultimately get bogged down.<p>I've written a lot of PHP lately in a metaprogramming-heavy framework that uses magic methods to 'create' new properties and methods.  The way this is done is systematic,  and an IDE could probably be loaded with rules that would help it 'understand' this usage,  but so far as I do this kind of code analysis,  it's going to be in command-line tools that are cheap to develop compared to GUI tools.",
      "num_comments": null,
      "story_id": 2070745,
      "story_title": "Lisp IDEs (where for art thou?)",
      "story_url": "http://www.adrianmouat.com/bit-bucket/2011/01/lisp-ides-where-for-art-thou/",
      "parent_id": 2071128,
      "created_at_i": 1294246169,
      "_tags": [
        "comment",
        "author_PaulHoule",
        "story_2070745"
      ],
      "objectID": "2071487",
      "_highlightResult": {
        "author": {
          "value": "PaulHoule",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Well,  the advantage of a language like Java or C# is that the IDE knows the types of objects,  so,  for instance,  it can autocomplete method and property names.  Because introspection is used rarely in <em>static</em> languages,  IDEs can do automated refactoring operations and KNOW that they found all the (non-introspection) references that are affected.<p>It's certainly possible to parse PHP, Python or Ruby into an abstract syntax tree (OK,  Perl is a little harder) but practically very few people do metaprogramming at that level,  even when it's officially supported. (C# and VB have had \"expression trees\" for a few years now and they're barely used.)<p>Part of the appeal of LISP is that you can pretend Noam Chomsky was never born and never need to learn how to write parsers or deal with the data structures that they spit out.<p>Any kind of extreme metaprogramming is going to defeat 'reasoning-in-code'.  For instance,  in LISP I can easily implement a new kind of control structure...  Because 'understanding' a program in general (rather than running it) is an undecidable problem,  it's clear that an IDE will ultimately get bogged down.<p>I've written a lot of PHP lately in a metaprogramming-heavy framework that uses magic methods to 'create' new properties and methods.  The way this is done is systematic,  and an IDE could probably be loaded with rules that would help it 'understand' this usage,  but so far as I do this kind of code <em>analysis</em>,  it's going to be in command-line <em>tools</em> that are cheap to develop compared to GUI <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Lisp IDEs (where for art thou?)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.adrianmouat.com/bit-bucket/2011/01/lisp-ides-where-for-art-thou/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-12-21T11:21:28.000Z",
      "title": null,
      "url": null,
      "author": "nostrademons",
      "points": null,
      "story_text": null,
      "comment_text": "I work with a bunch of them.  A UX <i>designer's</i> basic job is to figure out how a product should work: who is the user, what do they want, how should they interact with the product, and how should the product's UI be laid out to accomplish that?  They use a bunch of tools, from Macromedia Fireworks and Photoshop on the static side down to JavaScript and Python/PHP on the dynamic side.  At Google at least, it's very common for UX designers to be able to code in rapid prototyping languages, though they usually know nothing about large-scale software engineering (beyond what engineers tell them).<p>A UX <i>researcher's</i> basic job is to figure out how users behave and what they want.  This is basically applied social science.  They work directly with users - sometimes through usability studies and one-way glass, sometimes through focus groups, sometimes through going out into the community and talking with people who use the product, and sometimes through logs analysis and quantitative data.  This is not usually a technical position, but it requires someone with familiarity with the scientific method, a curiosity about people, and often good statistical/quantitative skills.<p>Since he's a UX <i>lead</i>, however, my guess is his day job came down to two things: hiring new UX people, and prioritizing requests for the skills of his reportees.",
      "num_comments": null,
      "story_id": 2026490,
      "story_title": "Googler Paul Adams Heads To Facebook",
      "story_url": "http://techcrunch.com/2010/12/20/paul-adams-googler-whose-presentation-foretold-facebook-groups-heads-to-facebook/",
      "parent_id": 2027431,
      "created_at_i": 1292930488,
      "_tags": [
        "comment",
        "author_nostrademons",
        "story_2026490"
      ],
      "objectID": "2027509",
      "_highlightResult": {
        "author": {
          "value": "nostrademons",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I work with a bunch of them.  A UX <i>designer's</i> basic job is to figure out how a product should work: who is the user, what do they want, how should they interact with the product, and how should the product's UI be laid out to accomplish that?  They use a bunch of <em>tools</em>, from Macromedia Fireworks and Photoshop on the <em>static</em> side down to JavaScript and Python/PHP on the dynamic side.  At Google at least, it's very common for UX designers to be able to code in rapid prototyping languages, though they usually know nothing about large-scale software engineering (beyond what engineers tell them).<p>A UX <i>researcher's</i> basic job is to figure out how users behave and what they want.  This is basically applied social science.  They work directly with users - sometimes through usability studies and one-way glass, sometimes through focus groups, sometimes through going out into the community and talking with people who use the product, and sometimes through logs <em>analysis</em> and quantitative data.  This is not usually a technical position, but it requires someone with familiarity with the scientific method, a curiosity about people, and often good statistical/quantitative skills.<p>Since he's a UX <i>lead</i>, however, my guess is his day job came down to two things: hiring new UX people, and prioritizing requests for the skills of his reportees.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Googler Paul Adams Heads To Facebook",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://techcrunch.com/2010/12/20/paul-adams-googler-whose-presentation-foretold-facebook-groups-heads-to-facebook/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-12-05T00:25:43.000Z",
      "title": null,
      "url": null,
      "author": "jules",
      "points": null,
      "story_text": null,
      "comment_text": "Right, I'm thinking that X will happen to Python/Ruby like Python/Ruby happened to Java.<p>A 5x improvement is a lot to ask for...I don't think that Python/Ruby offers 5x over Java, and to get 5x over Python/Ruby will be very hard. Even describing software in reasonably precise English probably doesn't offer 5x over the state of the art.<p>On the other hand, 50% is definitely feasible. The form this will take is a combination of, among other things:<p>- Moving away from the dynamicism of Python/Ruby: by sacrificing just a little bit of the dynamicism (like assigning to a variable by string name) you can gain a lot in terms of what IDEs can do and what compilers can do to optimize.<p>- New constructs that replace the dynamic metaprogramming in Ruby/Python with static metaprogramming, like Lisp's macros and F#'s type providers.<p>- Merging OOP with functional programming by unifying FP's abstract data types and pattern matching with OOP's classes and runtime dispatch. The resulting system will be something like multimethods or predicate dispatch.<p>- Testing tools will get more powerful. Randomized testing will play a more important role. We'll get statistical analysis in IDEs that can sometimes pinpoint the line that's causing a bug by running the randomized tests and computing the correlation of \"line n was executed\" with \"the test failed\".<p>- Last but not least, the days of ASCII based programming are over.<p>&#62; I dont think the shift will be programming language based because the decision makers dont pay attention to programmers. (I'm speaking the enterprise world here, not startups.) But I hope you're right, not me. :-)<p>I agree. As usual the enterprise world will lag a few years behind...around the time they adopt Python/Ruby/F#/etc, the startup world will have new languages and tools.",
      "num_comments": null,
      "story_id": 1970023,
      "story_title": "Ask HN: 2011 Predictions",
      "story_url": "",
      "parent_id": 1970545,
      "created_at_i": 1291508743,
      "_tags": [
        "comment",
        "author_jules",
        "story_1970023"
      ],
      "objectID": "1970589",
      "_highlightResult": {
        "author": {
          "value": "jules",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Right, I'm thinking that X will happen to Python/Ruby like Python/Ruby happened to Java.<p>A 5x improvement is a lot to ask for...I don't think that Python/Ruby offers 5x over Java, and to get 5x over Python/Ruby will be very hard. Even describing software in reasonably precise English probably doesn't offer 5x over the state of the art.<p>On the other hand, 50% is definitely feasible. The form this will take is a combination of, among other things:<p>- Moving away from the dynamicism of Python/Ruby: by sacrificing just a little bit of the dynamicism (like assigning to a variable by string name) you can gain a lot in terms of what IDEs can do and what compilers can do to optimize.<p>- New constructs that replace the dynamic metaprogramming in Ruby/Python with <em>static</em> metaprogramming, like Lisp's macros and F#'s type providers.<p>- Merging OOP with functional programming by unifying FP's abstract data types and pattern matching with OOP's classes and runtime dispatch. The resulting system will be something like multimethods or predicate dispatch.<p>- Testing <em>tools</em> will get more powerful. Randomized testing will play a more important role. We'll get statistical <em>analysis</em> in IDEs that can sometimes pinpoint the line that's causing a bug by running the randomized tests and computing the correlation of \"line n was executed\" with \"the test failed\".<p>- Last but not least, the days of ASCII based programming are over.<p>> I dont think the shift will be programming language based because the decision makers dont pay attention to programmers. (I'm speaking the enterprise world here, not startups.) But I hope you're right, not me. :-)<p>I agree. As usual the enterprise world will lag a few years behind...around the time they adopt Python/Ruby/F#/etc, the startup world will have new languages and <em>tools</em>.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: 2011 Predictions",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-11T15:27:42.000Z",
      "title": null,
      "url": null,
      "author": "pjmlp",
      "points": 2,
      "story_text": null,
      "comment_text": "Funny enough in a sad way, static analysis tooling was part of the original C tooling, but when developers started creating C compilers for systems other than UNIX, lint seldom came along.<p>It also did not help the way C compiler phases were split.<p>If anything, we have to thank LLVM guys for making static analysis part of clang.",
      "num_comments": null,
      "story_id": 8162259,
      "story_title": "Can We Trust the Libraries We Use?",
      "story_url": "http://www.viva64.com/en/b/0271/",
      "parent_id": 8162697,
      "created_at_i": 1407770862,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_8162259"
      ],
      "objectID": "8163641",
      "_highlightResult": {
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Funny enough in a sad way, <em>static</em> <em>analysis</em> <em>tooli</em>ng was part of the original C <em>tooli</em>ng, but when developers started creating C compilers for systems other than UNIX, lint seldom came along.<p>It also did not help the way C compiler phases were split.<p>If anything, we have to thank LLVM guys for making <em>static</em> <em>analysis</em> part of clang.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Can We Trust the Libraries We Use?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.viva64.com/en/b/0271/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-06-28T11:08:26.000Z",
      "title": "",
      "url": "",
      "author": "steve_barham",
      "points": 1,
      "story_text": null,
      "comment_text": "I&#x27;m with you on the type checking (although this particular library doesn&#x27;t seem to offer much in that space). That said, I&#x27;d argue that modern tooling (e.g. IDEA, and by association the static analysis toolchain in Teamcity) are capable of identifying and validating embedded SQL, particularly when provided with database metadata.<p>Essentially, I&#x27;m deeply uneasy about embedding translators from one language into another. As an example, not many people like using BigDecimal to describe arithmetic operations, despite it having a fluent syntax and improved type safety (e.g. around implicit conversions) compared to just writing an expression.",
      "num_comments": null,
      "story_id": 5956867,
      "story_title": "Show HN: fluent SQL  a minimalistic SQL builder for Java",
      "story_url": "https://github.com/ivanceras/fluent-sql/",
      "parent_id": 5957181,
      "created_at_i": 1372417706,
      "_tags": [
        "comment",
        "author_steve_barham",
        "story_5956867"
      ],
      "objectID": "5957282",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "steve_barham",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm with you on the type checking (although this particular library doesn't seem to offer much in that space). That said, I'd argue that modern <em>tooli</em>ng (e.g. IDEA, and by association the <em>static</em> <em>analysis</em> toolchain in Teamcity) are capable of identifying and validating embedded SQL, particularly when provided with database metadata.<p>Essentially, I'm deeply uneasy about embedding translators from one language into another. As an example, not many people like using BigDecimal to describe arithmetic operations, despite it having a fluent syntax and improved type safety (e.g. around implicit conversions) compared to just writing an expression.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Show HN: fluent SQL  a minimalistic SQL builder for Java",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/ivanceras/fluent-sql/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-27T03:40:50.000Z",
      "title": null,
      "url": null,
      "author": "welder",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; Dynamic typing allows you to quickly build and iterate but lacks the static-analysis tooling needed for larger codebases<p>Large codebases, ewww. Instead separate things into smaller projects, each easily maintainable on it&#x27;s own.",
      "num_comments": null,
      "story_id": 9608525,
      "story_title": "Why We Use Go",
      "story_url": "http://bravenewgeek.com/go-is-unapologetically-flawed-heres-why-we-use-it/",
      "parent_id": 9608525,
      "created_at_i": 1432698050,
      "_tags": [
        "comment",
        "author_welder",
        "story_9608525"
      ],
      "objectID": "9609197",
      "_highlightResult": {
        "author": {
          "value": "welder",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; Dynamic typing allows you to quickly build and iterate but lacks the <em>static</em>-<em>analysis</em> <em>tooli</em>ng needed for larger codebases<p>Large codebases, ewww. Instead separate things into smaller projects, each easily maintainable on it's own.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why We Use Go",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://bravenewgeek.com/go-is-unapologetically-flawed-heres-why-we-use-it/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-11-14T15:39:00.000Z",
      "title": null,
      "url": null,
      "author": "barrkel",
      "points": null,
      "story_text": null,
      "comment_text": "&#62; \"Programming language quality is usually inversely proportional to the number of special forms\"<p>Programming language obscurity is also usually inversely proportional to the number of special forms. Church numerals?<p>The happy place is somewhere in the middle, where there's enough language such that you don't have to build it out of other pieces - and this also helps with performance, static analysis, tooling, debugging and lots of other areas - but there isn't so much that you end up with lots of methods to do the same thing, in similar but incompatible ways.",
      "num_comments": null,
      "story_id": 941740,
      "story_title": "I'm turning into a Lisp snob",
      "story_url": "http://briancarper.net/blog/im-turning-into-a-lisp-snob",
      "parent_id": 941740,
      "created_at_i": 1258213140,
      "_tags": [
        "comment",
        "author_barrkel",
        "story_941740"
      ],
      "objectID": "941771",
      "_highlightResult": {
        "author": {
          "value": "barrkel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> \"Programming language quality is usually inversely proportional to the number of special forms\"<p>Programming language obscurity is also usually inversely proportional to the number of special forms. Church numerals?<p>The happy place is somewhere in the middle, where there's enough language such that you don't have to build it out of other pieces - and this also helps with performance, <em>static</em> <em>analysis</em>, <em>tooli</em>ng, debugging and lots of other areas - but there isn't so much that you end up with lots of methods to do the same thing, in similar but incompatible ways.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "I'm turning into a Lisp snob",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://briancarper.net/blog/im-turning-into-a-lisp-snob",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-01T13:41:32.000Z",
      "title": null,
      "url": null,
      "author": "dmytrish",
      "points": null,
      "story_text": null,
      "comment_text": "It&#x27;s not only compile time that matters: an overcomplicated language grammar&#x2F;specification hinders development of language infrastructure (static analyses tools, linters, debuggers, parsers&#x2F;code generators, IDE interaction, etc).",
      "num_comments": null,
      "story_id": 9125912,
      "story_title": "8cc: A Small C Compiler",
      "story_url": "https://github.com/rui314/8cc",
      "parent_id": 9126256,
      "created_at_i": 1425217292,
      "_tags": [
        "comment",
        "author_dmytrish",
        "story_9125912"
      ],
      "objectID": "9126996",
      "_highlightResult": {
        "author": {
          "value": "dmytrish",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It's not only compile time that matters: an overcomplicated language grammar/specification hinders development of language infrastructure (<em>static</em> <em>analyses</em> <em>tools</em>, linters, debuggers, parsers/code generators, IDE interaction, etc).",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "8cc: A Small C Compiler",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/rui314/8cc",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-14T22:01:11.000Z",
      "title": null,
      "url": null,
      "author": "dasil003",
      "points": 2,
      "story_text": null,
      "comment_text": "Why don&#x27;t you think Haskell will help with this?  If Java can&#x27;t prevent a NullPointerException I don&#x27;t see how static analysis can take the tooling where you want it to go.",
      "num_comments": null,
      "story_id": 7059063,
      "story_title": "Ditching a Language",
      "story_url": "http://blogs.perl.org/users/ovid/2014/01/ditching-a-language.html",
      "parent_id": 7059813,
      "created_at_i": 1389736871,
      "_tags": [
        "comment",
        "author_dasil003",
        "story_7059063"
      ],
      "objectID": "7060097",
      "_highlightResult": {
        "author": {
          "value": "dasil003",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Why don't you think Haskell will help with this?  If Java can't prevent a NullPointerException I don't see how <em>static</em> <em>analysis</em> can take the <em>tooli</em>ng where you want it to go.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ditching a Language",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.perl.org/users/ovid/2014/01/ditching-a-language.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-05-03T17:47:33.000Z",
      "title": null,
      "url": null,
      "author": "dozzie",
      "points": 1,
      "story_text": null,
      "comment_text": "&gt; I do not subscribe to the reasoning that Tests immediately cause a bad design<p>Me neither. But tests are given much, much more attention than they are worth. Tests mainly make up for lack of clean structure and good tooling for static analysis. Strong static typing is worth attention. Static analysers and code proof assistants are worth attention. Simple design that make whole class of errors <i>impossible</i> is worth it. Tests are not worth that much in this neighbourhood.<p>Having plenty of tests is OK when the code base is fragile <i>and</i> it&#x27;s not clear how to make it robust. Tests are a tool of last resort, if all thinking fails to produce something bug-resistant.",
      "num_comments": null,
      "story_id": 7681833,
      "story_title": "Professionalism and TDD (Reprise)",
      "story_url": "http://blog.8thlight.com/uncle-bob/2014/05/02/ProfessionalismAndTDD.html",
      "parent_id": 7690711,
      "created_at_i": 1399139253,
      "_tags": [
        "comment",
        "author_dozzie",
        "story_7681833"
      ],
      "objectID": "7691669",
      "_highlightResult": {
        "author": {
          "value": "dozzie",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; I do not subscribe to the reasoning that Tests immediately cause a bad design<p>Me neither. But tests are given much, much more attention than they are worth. Tests mainly make up for lack of clean structure and good <em>tooli</em>ng for <em>static</em> <em>analysis.</em> Strong <em>static</em> typing is worth attention. <em>Static</em> analysers and code proof assistants are worth attention. Simple design that make whole class of errors <i>impossible</i> is worth it. Tests are not worth that much in this neighbourhood.<p>Having plenty of tests is OK when the code base is fragile <i>and</i> it's not clear how to make it robust. Tests are a tool of last resort, if all thinking fails to produce something bug-resistant.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Professionalism and TDD (Reprise)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.8thlight.com/uncle-bob/2014/05/02/ProfessionalismAndTDD.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-06T16:56:33.000Z",
      "title": null,
      "url": null,
      "author": "Nitramp",
      "points": null,
      "story_text": null,
      "comment_text": "I think there is no point in trying to emulate different language semantics on top of JavaScript.<p>asm.js is a weird hack that lives in a totally different world than actual browser APIs (e.g. the DOM), and you have to emulate your entire runtime and environment to get anything useful, which means your binary is going to be huge (as in this example, but similar things apply).<p>Emulating better semantics than JS based on JS usually leaves you in this uncanny valley where you either trade off performance and size for nicer semantics (e.g. killing the null&#x2F;undefined dichotomy, or 64 bit integer math), or you end up with odd semantics that don&#x27;t quite fit the language you&#x27;re compiling from, or a mix of both, which is a usability disaster.<p>So the only real chance to improve on the state of JS is being a syntactical shim on top of JS and help users with better syntax, static analysis, and compile time tooling. That&#x27;d be TypeScript.",
      "num_comments": null,
      "story_id": 9496672,
      "story_title": "PyPy.js: A fast, compliant Python implementation for the web",
      "story_url": "http://pypyjs.org/",
      "parent_id": 9496672,
      "created_at_i": 1430931393,
      "_tags": [
        "comment",
        "author_Nitramp",
        "story_9496672"
      ],
      "objectID": "9500042",
      "_highlightResult": {
        "author": {
          "value": "Nitramp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I think there is no point in trying to emulate different language semantics on top of JavaScript.<p>asm.js is a weird hack that lives in a totally different world than actual browser APIs (e.g. the DOM), and you have to emulate your entire runtime and environment to get anything useful, which means your binary is going to be huge (as in this example, but similar things apply).<p>Emulating better semantics than JS based on JS usually leaves you in this uncanny valley where you either trade off performance and size for nicer semantics (e.g. killing the null/undefined dichotomy, or 64 bit integer math), or you end up with odd semantics that don't quite fit the language you're compiling from, or a mix of both, which is a usability disaster.<p>So the only real chance to improve on the state of JS is being a syntactical shim on top of JS and help users with better syntax, <em>static</em> <em>analysis</em>, and compile time <em>tooli</em>ng. That'd be TypeScript.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "PyPy.js: A fast, compliant Python implementation for the web",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pypyjs.org/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-31T19:38:28.000Z",
      "title": null,
      "url": null,
      "author": "the8472",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; And maybe makes static analysis easier.<p>&gt; But still not sure if it was really needed.<p>That depends on your definition of &quot;needed&quot; of course. Do we need any abstractions? Why not just write assembly, nay, machine code?<p>Static analysis enables a lot of tooling (accurate auto-completion, compile-time type checking, null-analysis, ) and can also make life easier for the JIT compilers[1].<p>On the one end of the spectrum it&#x27;s not needed because as long as a language is turing-complete it can do anything any other turing-complete language can do. \nOn the other end it is needed to make your life easier and be more productive by offloading work from your brain to the CPU.<p>[1] <a href=\"https:&#x2F;&#x2F;developers.google.com&#x2F;v8&#x2F;experiments\" rel=\"nofollow\">https:&#x2F;&#x2F;developers.google.com&#x2F;v8&#x2F;experiments</a>",
      "num_comments": null,
      "story_id": 9633870,
      "story_title": "Show HN: ES7 Decorator library adds types checking, memoization, and more to JS",
      "story_url": "https://github.com/mako-taco/DecorateThis",
      "parent_id": 9634111,
      "created_at_i": 1433101108,
      "_tags": [
        "comment",
        "author_the8472",
        "story_9633870"
      ],
      "objectID": "9635265",
      "_highlightResult": {
        "author": {
          "value": "the8472",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; And maybe makes <em>static</em> <em>analysis</em> easier.<p>&gt; But still not sure if it was really needed.<p>That depends on your definition of &quot;needed&quot; of course. Do we need any abstractions? Why not just write assembly, nay, machine code?<p><em>Static</em> <em>analysis</em> enables a lot of <em>tooli</em>ng (accurate auto-completion, compile-time type checking, null-<em>analysis</em>, ) and can also make life easier for the JIT compilers[1].<p>On the one end of the spectrum it's not needed because as long as a language is turing-complete it can do anything any other turing-complete language can do. \nOn the other end it is needed to make your life easier and be more productive by offloading work from your brain to the CPU.<p>[1] <a href=\"https://developers.google.com/v8/experiments\" rel=\"nofollow\">https://developers.google.com/v8/experiments</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Show HN: ES7 Decorator library adds types checking, memoization, and more to JS",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://github.com/mako-taco/DecorateThis",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-04-06T17:55:24.000Z",
      "title": null,
      "url": null,
      "author": "Kalium",
      "points": null,
      "story_text": null,
      "comment_text": "Static analysis can be much more difficult, and there&#x27;s a whole different toolbox for defeating static analysis. Often disassemblers can be attacked directly.",
      "num_comments": null,
      "story_id": 9327364,
      "story_title": "Stack Necromancy: Defeating Debuggers by Raising the Dead",
      "story_url": "http://spareclockcycles.org/2012/02/14/stack-necromancy-defeating-debuggers-by-raising-the-dead.html",
      "parent_id": 9329305,
      "created_at_i": 1428342924,
      "_tags": [
        "comment",
        "author_Kalium",
        "story_9327364"
      ],
      "objectID": "9329544",
      "_highlightResult": {
        "author": {
          "value": "Kalium",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<em>Static</em> <em>analysis</em> can be much more difficult, and there's a whole different <em>toolb</em>ox for defeating <em>static</em> <em>analysis.</em> Often disassemblers can be attacked directly.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Stack Necromancy: Defeating Debuggers by Raising the Dead",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://spareclockcycles.org/2012/02/14/stack-necromancy-defeating-debuggers-by-raising-the-dead.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-03T00:34:54.000Z",
      "title": null,
      "url": null,
      "author": "spion",
      "points": 2,
      "story_text": null,
      "comment_text": "The problem with jsx and sweet.js is the lack of tooling. For example, TernJS (a static analysis engine I use in emacs) will never understand either, so no auto-complete or hints.<p>Is such tooling even possible for something like sweet.js?",
      "num_comments": null,
      "story_id": 7978897,
      "story_title": "Compiling JSX with Sweet.js using Readtables",
      "story_url": "http://jlongster.com/Compiling-JSX-with-Sweet.js-using-Readtables",
      "parent_id": 7979241,
      "created_at_i": 1404347694,
      "_tags": [
        "comment",
        "author_spion",
        "story_7978897"
      ],
      "objectID": "7980761",
      "_highlightResult": {
        "author": {
          "value": "spion",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The problem with jsx and sweet.js is the lack of <em>tooli</em>ng. For example, TernJS (a <em>static</em> <em>analysis</em> engine I use in emacs) will never understand either, so no auto-complete or hints.<p>Is such <em>tooli</em>ng even possible for something like sweet.js?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Compiling JSX with Sweet.js using Readtables",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://jlongster.com/Compiling-JSX-with-Sweet.js-using-Readtables",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-31T21:13:38.000Z",
      "title": null,
      "url": null,
      "author": "rozap",
      "points": null,
      "story_text": null,
      "comment_text": "In Elixir you can annotate functions with type signatures and then use a tool like Dialyzer(1) to perform static analysis on the compiled bytecode. There is tooling that integrates with mix in Elixir called which makes this easy(2)<p>1) <a href=\"http:&#x2F;&#x2F;www.erlang.org&#x2F;doc&#x2F;apps&#x2F;dialyzer&#x2F;dialyzer_chapter.html\" rel=\"nofollow\">http:&#x2F;&#x2F;www.erlang.org&#x2F;doc&#x2F;apps&#x2F;dialyzer&#x2F;dialyzer_chapter.htm...</a>\n2) <a href=\"https:&#x2F;&#x2F;github.com&#x2F;jeremyjh&#x2F;dialyxir\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jeremyjh&#x2F;dialyxir</a>",
      "num_comments": null,
      "story_id": 9634114,
      "story_title": "Monads in Elixir",
      "story_url": "http://www.zohaib.me/monads-in-elixir-2/",
      "parent_id": 9634841,
      "created_at_i": 1433106818,
      "_tags": [
        "comment",
        "author_rozap",
        "story_9634114"
      ],
      "objectID": "9635573",
      "_highlightResult": {
        "author": {
          "value": "rozap",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "In Elixir you can annotate functions with type signatures and then use a <em>tool</em> like Dialyzer(1) to perform <em>static</em> <em>analysis</em> on the compiled bytecode. There is <em>tool</em>ing that integrates with mix in Elixir called which makes this easy(2)<p>1) <a href=\"http://www.erlang.org/doc/apps/dialyzer/dialyzer_chapter.html\" rel=\"nofollow\">http://www.erlang.org/doc/apps/dialyzer/dialyzer_chapter.htm...</a>\n2) <a href=\"https://github.com/jeremyjh/dialyxir\" rel=\"nofollow\">https://github.com/jeremyjh/dialyxir</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Monads in Elixir",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.zohaib.me/monads-in-elixir-2/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-07T18:03:25.000Z",
      "title": "",
      "url": "",
      "author": "pjmlp",
      "points": 9,
      "story_text": null,
      "comment_text": "What I find very positive about clang/llvm is:<p>- Everyone now seems to be using LLVM for language prototyping instead of JVM/.NET, clearly positive for native compilation and to show people without compiler knowledge that managed != VM<p>- The compiler as a library implementation of clang allows C, C++ and Objective-C to enjoy tooling support similar to JVM and .NET languages<p>- As someone with a sweet spot for the strong typing found in the Pascal family, the integrated static analysis are just great",
      "num_comments": null,
      "story_id": 5668421,
      "story_title": "Why IBM Now Views LLVM As Being Critical Software",
      "story_url": "http://www.phoronix.com/scan.php?page=news_item&px=MTM2NjU",
      "parent_id": 5668851,
      "created_at_i": 1367949805,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_5668421"
      ],
      "objectID": "5669657",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "What I find very positive about clang/llvm is:<p>- Everyone now seems to be using LLVM for language prototyping instead of JVM/.NET, clearly positive for native compilation and to show people without compiler knowledge that managed != VM<p>- The compiler as a library implementation of clang allows C, C++ and Objective-C to enjoy <em>tooli</em>ng support similar to JVM and .NET languages<p>- As someone with a sweet spot for the strong typing found in the Pascal family, the integrated <em>static</em> <em>analysis</em> are just great",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why IBM Now Views LLVM As Being Critical Software",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.phoronix.com/scan.php?page=news_item&px=MTM2NjU",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-08-25T03:29:03.000Z",
      "title": null,
      "url": null,
      "author": "MetaCosm",
      "points": 8,
      "story_text": null,
      "comment_text": "I agree with you on one part, writing static language INITIAL code, does generally take more time.  Depending on the language, it can vary from slightly more in something like Go (where composition is valued over type hierarchies) to a great deal longer in languages that encourage lots of castle building and type relationships.<p>That said, I have been in industry for over a decade in a half, and the most miserable, hellish experience I ever had was dealing with a large (100k+) non-trivial consumer facing Python application.  It was a special type of pain, with novel errors happening in production on a regular basis 4+ years into the project.  Refactoring was horrifically risky, and the analysis tooling stack is AWFUL... to the point that when used, it was often outright wrong.<p>I will gladly give up those cost savings on the leading edge, to have a product I can actually maintain in the long term.  I suspect this inability to maintain apps writing in certain dynamic languages is why they have culture bias towards starting over (and being proud of it, &quot;version 2.0, rewritten from scratch!&quot;)... which I found a bit shocking at first versus C, which would trend far more toward refactoring.",
      "num_comments": null,
      "story_id": 8219506,
      "story_title": "Revenge of the Types",
      "story_url": "http://lucumr.pocoo.org/2014/8/24/revenge-of-the-types/",
      "parent_id": 8220236,
      "created_at_i": 1408937343,
      "_tags": [
        "comment",
        "author_MetaCosm",
        "story_8219506"
      ],
      "objectID": "8220466",
      "_highlightResult": {
        "author": {
          "value": "MetaCosm",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I agree with you on one part, writing <em>static</em> language INITIAL code, does generally take more time.  Depending on the language, it can vary from slightly more in something like Go (where composition is valued over type hierarchies) to a great deal longer in languages that encourage lots of castle building and type relationships.<p>That said, I have been in industry for over a decade in a half, and the most miserable, hellish experience I ever had was dealing with a large (100k+) non-trivial consumer facing Python application.  It was a special type of pain, with novel errors happening in production on a regular basis 4+ years into the project.  Refactoring was horrifically risky, and the <em>analysis</em> <em>tooli</em>ng stack is AWFUL... to the point that when used, it was often outright wrong.<p>I will gladly give up those cost savings on the leading edge, to have a product I can actually maintain in the long term.  I suspect this inability to maintain apps writing in certain dynamic languages is why they have culture bias towards starting over (and being proud of it, &quot;version 2.0, rewritten from scratch!&quot;)... which I found a bit shocking at first versus C, which would trend far more toward refactoring.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Revenge of the Types",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://lucumr.pocoo.org/2014/8/24/revenge-of-the-types/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-05-23T22:17:57.000Z",
      "title": "",
      "url": "",
      "author": "chandlerc",
      "points": 7,
      "story_text": null,
      "comment_text": "I would expect many of these tools to catch these types of bugs. The challenging thing for us has been to catch <i>only</i> bugs, and to catch them very fast during normal compilation.<p>A lot of the static analyses we've looked into (and I'm hoping for more detailed blog posts about that in the future) find plenty of bugs, but also find lots of non-bugs. Combine that with being too slow to run during the normal build, and you can't break the build when such a bug is found.<p>I think one of the most interesting aspects of this is how we catch the bugs early, and force developers to fix them immediately by breaking the build.",
      "num_comments": null,
      "story_id": 2577481,
      "story_title": "C++ at Google: Here Be Dragons",
      "story_url": "http://blog.llvm.org/2011/05/c-at-google-here-be-dragons.html",
      "parent_id": 2577768,
      "created_at_i": 1306189077,
      "_tags": [
        "comment",
        "author_chandlerc",
        "story_2577481"
      ],
      "objectID": "2577821",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "chandlerc",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I would expect many of these <em>tools</em> to catch these types of bugs. The challenging thing for us has been to catch <i>only</i> bugs, and to catch them very fast during normal compilation.<p>A lot of the <em>static</em> <em>analyses</em> we've looked into (and I'm hoping for more detailed blog posts about that in the future) find plenty of bugs, but also find lots of non-bugs. Combine that with being too slow to run during the normal build, and you can't break the build when such a bug is found.<p>I think one of the most interesting aspects of this is how we catch the bugs early, and force developers to fix them immediately by breaking the build.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "C++ at Google: Here Be Dragons",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.llvm.org/2011/05/c-at-google-here-be-dragons.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-22T15:05:04.000Z",
      "title": null,
      "url": null,
      "author": "pjmlp",
      "points": 4,
      "story_text": null,
      "comment_text": "Worse, lint was part of the original C toolchain, but very few people cared to use it, because they couldn&#x27;t be bored to tune the tool to their projects.<p>This is the type of error that any static analysis tool would easily pick.",
      "num_comments": null,
      "story_id": 7282005,
      "story_title": "Apple's SSL/TLS bug",
      "story_url": "https://www.imperialviolet.org/2014/02/22/applebug.html",
      "parent_id": 7282123,
      "created_at_i": 1393081504,
      "_tags": [
        "comment",
        "author_pjmlp",
        "story_7282005"
      ],
      "objectID": "7282227",
      "_highlightResult": {
        "author": {
          "value": "pjmlp",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Worse, lint was part of the original C <em>toolc</em>hain, but very few people cared to use it, because they couldn't be bored to tune the tool to their projects.<p>This is the type of error that any <em>static</em> <em>analysis</em> tool would easily pick.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Apple's SSL/TLS bug",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.imperialviolet.org/2014/02/22/applebug.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-04-19T04:04:36.000Z",
      "title": "",
      "url": "",
      "author": "pcwalton",
      "points": 4,
      "story_text": null,
      "comment_text": "I don't disagree. The documentation needs work.<p>That said, the compiler needs a lot of work as well, as those who have used the language for any amount of time can attest to. Everyone sees the dreaded \"internal compiler error\" message. Everyone encounters borrow check and code generation bugs. Everyone misses a working package management system and pretty printer. Everyone bemoans the slowness of compilation for small programs. These are things you just didn't see for Go when it was announced--because it was Google-internal then.<p>We intend to fix the documentation before calling it 1.0. But compilers are complex, <i>especially</i> for a language with a rich type system and a nontrivial static analysis built in (the borrow check). There are many things to do, from documentation to bug fixing to feature work (macros and default methods are unfinished) to tooling work.<p>Note, however, that the code examples in the documentation are kept up to date and enforced via the test suite. So there may be inaccuracies in the prose, but we do perform automated quality control as best we can.",
      "num_comments": null,
      "story_id": 5573817,
      "story_title": "Performance of sequential Rust programs",
      "story_url": "http://pcwalton.github.io/blog/2013/04/18/performance-of-sequential-rust-programs/",
      "parent_id": 5574621,
      "created_at_i": 1366344276,
      "_tags": [
        "comment",
        "author_pcwalton",
        "story_5573817"
      ],
      "objectID": "5574741",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "pcwalton",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I don't disagree. The documentation needs work.<p>That said, the compiler needs a lot of work as well, as those who have used the language for any amount of time can attest to. Everyone sees the dreaded \"internal compiler error\" message. Everyone encounters borrow check and code generation bugs. Everyone misses a working package management system and pretty printer. Everyone bemoans the slowness of compilation for small programs. These are things you just didn't see for Go when it was announced--because it was Google-internal then.<p>We intend to fix the documentation before calling it 1.0. But compilers are complex, <i>especially</i> for a language with a rich type system and a nontrivial <em>static</em> <em>analysis</em> built in (the borrow check). There are many things to do, from documentation to bug fixing to feature work (macros and default methods are unfinished) to <em>tooli</em>ng work.<p>Note, however, that the code examples in the documentation are kept up to date and enforced via the test suite. So there may be inaccuracies in the prose, but we do perform automated quality control as best we can.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Performance of sequential Rust programs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://pcwalton.github.io/blog/2013/04/18/performance-of-sequential-rust-programs/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-23T23:04:51.000Z",
      "title": "",
      "url": "",
      "author": "bri3d",
      "points": 4,
      "story_text": null,
      "comment_text": "I answered Objective-C only because I'm considering the entire ecosystem around a language in addition to the actual language (its features, idioms, and syntax).<p>Objective-C isn't a particularly pretty language, in my opinion - but when XCode's powerful code completion, decent visual debugger, and awesome static analysis come into play, it's a lot more attractive.<p>Plus, for me, programming is about the goal, with the journey an oft-pleasant and very engrossing side effect. Objective-C hits the sweet spot where the language and toolchain gets out of my way and lets me build beautiful, functional software that people actually use.",
      "num_comments": null,
      "story_id": 3746692,
      "story_title": "Poll: What's Your Favorite Programming Language?",
      "story_url": null,
      "parent_id": 3746692,
      "created_at_i": 1332543891,
      "_tags": [
        "comment",
        "author_bri3d",
        "story_3746692"
      ],
      "objectID": "3747785",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "bri3d",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I answered Objective-C only because I'm considering the entire ecosystem around a language in addition to the actual language (its features, idioms, and syntax).<p>Objective-C isn't a particularly pretty language, in my opinion - but when XCode's powerful code completion, decent visual debugger, and awesome <em>static</em> <em>analysis</em> come into play, it's a lot more attractive.<p>Plus, for me, programming is about the goal, with the journey an oft-pleasant and very engrossing side effect. Objective-C hits the sweet spot where the language and <em>toolc</em>hain gets out of my way and lets me build beautiful, functional software that people actually use.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Poll: What's Your Favorite Programming Language?",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-27T09:01:36.000Z",
      "title": "",
      "url": "",
      "author": "taliesinb",
      "points": 3,
      "story_text": null,
      "comment_text": "Tooling should get us part of the way - it surely cannot be that difficult to interactively show which interfaces a type satisfies (and conversely, what you'd need to add to a type to have it satisfy an interface).<p>In general it would be neat if the \"go\" command supported some more advanced static analysis stuff beyond go fix, fmt, and vet.<p>A lot of this stuff could be done by reflect -- if only there was a repl!",
      "num_comments": null,
      "story_id": 5773810,
      "story_title": "Interfaces in Go make it hard to navigate code",
      "story_url": "http://www.swageroo.com/wordpress/googles-go-and-implicit-interface-declaration/?h",
      "parent_id": 5773810,
      "created_at_i": 1369645296,
      "_tags": [
        "comment",
        "author_taliesinb",
        "story_5773810"
      ],
      "objectID": "5773976",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "taliesinb",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<em>Tooli</em>ng should get us part of the way - it surely cannot be that difficult to interactively show which interfaces a type satisfies (and conversely, what you'd need to add to a type to have it satisfy an interface).<p>In general it would be neat if the \"go\" command supported some more advanced <em>static</em> <em>analysis</em> stuff beyond go fix, fmt, and vet.<p>A lot of this stuff could be done by reflect -- if only there was a repl!",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Interfaces in Go make it hard to navigate code",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.swageroo.com/wordpress/googles-go-and-implicit-interface-declaration/?h",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-02-18T18:32:55.000Z",
      "title": "",
      "url": "",
      "author": "CodeCube",
      "points": 3,
      "story_text": null,
      "comment_text": "Honestly, all of those things are still secondary to actually developing. You can write great code without doing static analysis and profiling it. And with the most recent version, NuGet is included even in Express.<p>The biggest roadblocks to .NET development/adoption are not toolchain related IMO, they are platform related. If you want to bring up a farm of windows boxes, you're gonna pay.",
      "num_comments": null,
      "story_id": 5238788,
      "story_title": "Performance-Wise, C# Trumps Java",
      "story_url": "http://www.datacenteracceleration.com/author.asp?section_id=2933",
      "parent_id": 5239346,
      "created_at_i": 1361212375,
      "_tags": [
        "comment",
        "author_CodeCube",
        "story_5238788"
      ],
      "objectID": "5239727",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "CodeCube",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Honestly, all of those things are still secondary to actually developing. You can write great code without doing <em>static</em> <em>analysis</em> and profiling it. And with the most recent version, NuGet is included even in Express.<p>The biggest roadblocks to .NET development/adoption are not <em>toolc</em>hain related IMO, they are platform related. If you want to bring up a farm of windows boxes, you're gonna pay.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Performance-Wise, C# Trumps Java",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.datacenteracceleration.com/author.asp?section_id=2933",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-01-23T14:07:42.000Z",
      "title": null,
      "url": null,
      "author": "heavi5ide",
      "points": 2,
      "story_text": null,
      "comment_text": "Hi, article author here. This was more a comment on the verbosity of Google Closure&#x27;s syntax. If you&#x27;re not familiar with it, to get the most out of the closure compiler, you have to add type annotations in javascript comments for pretty much every function parameter, return value, constant, etc. Otherwise the compiler&#x27;s static analysis doesn&#x27;t really have much to work with. This makes it kind of a pain to javascript devs who are not used to this sort of thing.<p>Coming from Java, I probably found it a little less annoying than most javascript devs. Although in Java (as I mentioned in a footnote) you have really powerful and mature tooling like Eclipse, which--whatever else you think of it--does really help with Java&#x27;s general verbosity. You&#x27;re not going to find the same sort of tool help for dealing with Closure javascript.",
      "num_comments": null,
      "story_id": 7107228,
      "story_title": "How Angular Lets Us Iterate Like Crazy",
      "story_url": "http://blog.chartbeat.com/2014/01/15/how-angular-lets-us-iterate/",
      "parent_id": 7107970,
      "created_at_i": 1390486062,
      "_tags": [
        "comment",
        "author_heavi5ide",
        "story_7107228"
      ],
      "objectID": "7108188",
      "_highlightResult": {
        "author": {
          "value": "heavi5ide",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Hi, article author here. This was more a comment on the verbosity of Google Closure's syntax. If you're not familiar with it, to get the most out of the closure compiler, you have to add type annotations in javascript comments for pretty much every function parameter, return value, constant, etc. Otherwise the compiler's <em>static</em> <em>analysis</em> doesn't really have much to work with. This makes it kind of a pain to javascript devs who are not used to this sort of thing.<p>Coming from Java, I probably found it a little less annoying than most javascript devs. Although in Java (as I mentioned in a footnote) you have really powerful and mature <em>tooli</em>ng like Eclipse, which--whatever else you think of it--does really help with Java's general verbosity. You're not going to find the same sort of tool help for dealing with Closure javascript.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How Angular Lets Us Iterate Like Crazy",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.chartbeat.com/2014/01/15/how-angular-lets-us-iterate/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-16T18:43:30.000Z",
      "title": "",
      "url": "",
      "author": "ionforce",
      "points": 2,
      "story_text": null,
      "comment_text": "For varying contexts of bad. It impedes on things like static analysis.<p>You don't want the surface area of your programming language confined to 1) runtime 2) being run by a specific binary. Where is the offline tooling? Where is the variety?<p>This handicap makes me despise Perl. And I say that as a long time professional Perl engineer.",
      "num_comments": null,
      "story_id": 5718265,
      "story_title": "Extreme syntax",
      "story_url": "http://www.johndcook.com/blog/2013/05/16/extreme-syntax/",
      "parent_id": 5720220,
      "created_at_i": 1368729810,
      "_tags": [
        "comment",
        "author_ionforce",
        "story_5718265"
      ],
      "objectID": "5720313",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "ionforce",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "For varying contexts of bad. It impedes on things like <em>static</em> <em>analysis.</em><p>You don't want the surface area of your programming language confined to 1) runtime 2) being run by a specific binary. Where is the offline <em>tooli</em>ng? Where is the variety?<p>This handicap makes me despise Perl. And I say that as a long time professional Perl engineer.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Extreme syntax",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.johndcook.com/blog/2013/05/16/extreme-syntax/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-10-02T22:46:42.000Z",
      "title": "",
      "url": "",
      "author": "giulianob",
      "points": 2,
      "story_text": null,
      "comment_text": "Actually just about every popular library out there for JS creates some sort of fake OO layer on top of JS (e.g. Backbone, jQuery, Prototype, YUI, etc..). If you are just throwing a couple of scripts together then JS is fine but if you are trying to make an actual application, you need libraries to make it more OO.<p>I've worked on large code bases in several languages and JS has to got to be one of the worst when it comes to code quality due to the flexibility. It's always an awful experience trying to refactor a large portion of JS since it's difficult to even find where objects are being used. I'd take AS3 over JS anytime of the day since it allows me to specify types (though optional) and if I do the tooling is able to do a lot of the static analysis that is important in large projects. TypeScript still gives you plain old JS while allowing you to specify some extra information in order to facilitate development. It's actually new developers that aren't aware of these things and love JS from what I've seen. They haven't worked on large code bases and love the flexibility of JS. When you actually are trying to create proper abstractions in order to architect your code, you need visibility modifiers, you need interfaces, and you need types.",
      "num_comments": null,
      "story_id": 4601654,
      "story_title": "Why does TypeScript have be the answer to anything?",
      "story_url": "http://www.hanselman.com/blog/WhyDoesTypeScriptHaveBeTheAnswerToAnything.aspx",
      "parent_id": 4603772,
      "created_at_i": 1349218002,
      "_tags": [
        "comment",
        "author_giulianob",
        "story_4601654"
      ],
      "objectID": "4604800",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "giulianob",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Actually just about every popular library out there for JS creates some sort of fake OO layer on top of JS (e.g. Backbone, jQuery, Prototype, YUI, etc..). If you are just throwing a couple of scripts together then JS is fine but if you are trying to make an actual application, you need libraries to make it more OO.<p>I've worked on large code bases in several languages and JS has to got to be one of the worst when it comes to code quality due to the flexibility. It's always an awful experience trying to refactor a large portion of JS since it's difficult to even find where objects are being used. I'd take AS3 over JS anytime of the day since it allows me to specify types (though optional) and if I do the <em>tooli</em>ng is able to do a lot of the <em>static</em> <em>analysis</em> that is important in large projects. TypeScript still gives you plain old JS while allowing you to specify some extra information in order to facilitate development. It's actually new developers that aren't aware of these things and love JS from what I've seen. They haven't worked on large code bases and love the flexibility of JS. When you actually are trying to create proper abstractions in order to architect your code, you need visibility modifiers, you need interfaces, and you need types.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why does TypeScript have be the answer to anything?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.hanselman.com/blog/WhyDoesTypeScriptHaveBeTheAnswerToAnything.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-11T00:33:11.000Z",
      "title": null,
      "url": null,
      "author": "sqs",
      "points": 1,
      "story_text": null,
      "comment_text": "This is full static analysis, with AST and type inference.<p>However, type inference on JavaScript is quite hard, and as you&#x27;ve seen, our analyzer fails on many complex libraries like d3. We have an open issue about fixing d3 support at <a href=\"https://github.com/sourcegraph/sourcegraph.com/issues/13\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sourcegraph&#x2F;sourcegraph.com&#x2F;issues&#x2F;13</a>, which you can +1 if you want to stay updated on. And we&#x27;re releasing the analysis toolkit we use as open source soon so it&#x27;s not bottlenecked on us.",
      "num_comments": null,
      "story_id": 8006309,
      "story_title": "Sourcegraph: Search code, jump around source, see real usage examples",
      "story_url": "https://sourcegraph.com",
      "parent_id": 8010486,
      "created_at_i": 1405038791,
      "_tags": [
        "comment",
        "author_sqs",
        "story_8006309"
      ],
      "objectID": "8018256",
      "_highlightResult": {
        "author": {
          "value": "sqs",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is full <em>static</em> <em>analysis</em>, with AST and type inference.<p>However, type inference on JavaScript is quite hard, and as you've seen, our analyzer fails on many complex libraries like d3. We have an open issue about fixing d3 support at <a href=\"https://github.com/sourcegraph/sourcegraph.com/issues/13\" rel=\"nofollow\">https://github.com/sourcegraph/sourcegraph.com/issues/13</a>, which you can +1 if you want to stay updated on. And we're releasing the <em>analysis</em> <em>toolk</em>it we use as open source soon so it's not bottlenecked on us.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Sourcegraph: Search code, jump around source, see real usage examples",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://sourcegraph.com",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-07-09T04:28:32.000Z",
      "title": null,
      "url": null,
      "author": "dllthomas",
      "points": 1,
      "story_text": null,
      "comment_text": "<i>&quot;Tooling can also go beyond types, though.&quot;</i><p>By &quot;tooling&quot; there, I wasn&#x27;t referring to static analysis.  I meant things like type-directed name resolution, type-directed completion, Agda&#x27;s &quot;holes&quot;, and so on.  Strictly, these do <i>not</i> rely on the type system being &quot;a part of&quot; the language, but they <i>do</i> rely on some degree of standardization on a particular type system for the tool to work (or work well).<p><i>&quot;Interleaved calls to different types, for example, can be found through tooling.&quot;</i><p>I actually don&#x27;t understand exactly what you mean here.  You might be surprised what even pretty rudimentary type systems can find if you leverage &#x27;em right, though - as I mentioned in that other thread, I track which threads access what resources, and which functions live on which threads, with C&#x27;s type system unadorned by additional checks (I <i>do</i> use additional static analysis, it just is entirely unnecessary to catch this one).<p><i>&quot;Well, I realize that is false. But the hoops all of the examples I have seen that types have to jump through to accomplish that aren&#x27;t exactly pleasant.<p>&quot;So, maybe my preference is just that tooling can give you many of the benefits of more advanced type systems, without having to have all of the boilerplate of it everywhere in the code.&quot;</i><p>Ironically, I think my C code has more annotations for my static analysis tool-of-choice than the C types.  Certainly there are a lot of poor type systems, and a lot of languages that expose particular type systems poorly.  Boilerplate type annotations are mostly unnecessary in languages with type inference.<p>As I&#x27;ve said elsewhere, though, your tooling <i>may be</i> &quot;more advanced type systems&quot;.  Splint, for instance, can enforce linear typing - something that is not a part of the type system laid out in the C standard (or that enforced by typical C compilers, even with warnings).<p><i>&quot;At any rate, I should say thank you very much for keeping this dialog going. Been a blast!&quot;</i><p>Yes, it&#x27;s turned out great :)",
      "num_comments": null,
      "story_id": 8005156,
      "story_title": "Option and Null in Dynamic Languages",
      "story_url": "http://www.rntz.net/post/2014-07-02-option-in-dynlangs.html",
      "parent_id": 8007710,
      "created_at_i": 1404880112,
      "_tags": [
        "comment",
        "author_dllthomas",
        "story_8005156"
      ],
      "objectID": "8008067",
      "_highlightResult": {
        "author": {
          "value": "dllthomas",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>&quot;<em>Tooli</em>ng can also go beyond types, though.&quot;</i><p>By &quot;<em>tooli</em>ng&quot; there, I wasn't referring to <em>static</em> <em>analysis.</em>  I meant things like type-directed name resolution, type-directed completion, Agda's &quot;holes&quot;, and so on.  Strictly, these do <i>not</i> rely on the type system being &quot;a part of&quot; the language, but they <i>do</i> rely on some degree of standardization on a particular type system for the tool to work (or work well).<p><i>&quot;Interleaved calls to different types, for example, can be found through <em>tooli</em>ng.&quot;</i><p>I actually don't understand exactly what you mean here.  You might be surprised what even pretty rudimentary type systems can find if you leverage 'em right, though - as I mentioned in that other thread, I track which threads access what resources, and which functions live on which threads, with C's type system unadorned by additional checks (I <i>do</i> use additional <em>static</em> <em>analysis</em>, it just is entirely unnecessary to catch this one).<p><i>&quot;Well, I realize that is false. But the hoops all of the examples I have seen that types have to jump through to accomplish that aren't exactly pleasant.<p>&quot;So, maybe my preference is just that <em>tooli</em>ng can give you many of the benefits of more advanced type systems, without having to have all of the boilerplate of it everywhere in the code.&quot;</i><p>Ironically, I think my C code has more annotations for my <em>static</em> <em>analysis</em> tool-of-choice than the C types.  Certainly there are a lot of poor type systems, and a lot of languages that expose particular type systems poorly.  Boilerplate type annotations are mostly unnecessary in languages with type inference.<p>As I've said elsewhere, though, your <em>tooli</em>ng <i>may be</i> &quot;more advanced type systems&quot;.  Splint, for instance, can enforce linear typing - something that is not a part of the type system laid out in the C standard (or that enforced by typical C compilers, even with warnings).<p><i>&quot;At any rate, I should say thank you very much for keeping this dialog going. Been a blast!&quot;</i><p>Yes, it's turned out great :)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Option and Null in Dynamic Languages",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.rntz.net/post/2014-07-02-option-in-dynlangs.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-04-14T07:52:01.000Z",
      "title": null,
      "url": null,
      "author": "arghnoname",
      "points": 1,
      "story_text": null,
      "comment_text": "I was once talking to someone with a lot of experience in this field and he said that false positives were one of their biggest problems. If you have too many false positives programmers end up deciding the analyzer is full of crap and either dismiss the results entirely or gloss past many ultimately useful results.<p>A static analyzer that will actually be used can&#x27;t have too many false positives, and this is the big challenge with these things. He said that allowing some false negatives (to cut down on false positives) made the tools more effective in actually solving problems.<p>That said, with something like openSSL, you do sort of just wish the programmers would deal with it. Language design should include elements to make these sorts of static analyses easier.",
      "num_comments": null,
      "story_id": 7578427,
      "story_title": "A New Development for Coverity and Heartbleed",
      "story_url": "http://blog.regehr.org/archives/1128",
      "parent_id": 7581749,
      "created_at_i": 1397461921,
      "_tags": [
        "comment",
        "author_arghnoname",
        "story_7578427"
      ],
      "objectID": "7584972",
      "_highlightResult": {
        "author": {
          "value": "arghnoname",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I was once talking to someone with a lot of experience in this field and he said that false positives were one of their biggest problems. If you have too many false positives programmers end up deciding the analyzer is full of crap and either dismiss the results entirely or gloss past many ultimately useful results.<p>A <em>static</em> analyzer that will actually be used can't have too many false positives, and this is the big challenge with these things. He said that allowing some false negatives (to cut down on false positives) made the <em>tools</em> more effective in actually solving problems.<p>That said, with something like openSSL, you do sort of just wish the programmers would deal with it. Language design should include elements to make these sorts of <em>static</em> <em>analyses</em> easier.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "A New Development for Coverity and Heartbleed",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.regehr.org/archives/1128",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-08-21T02:19:59.000Z",
      "title": "",
      "url": "",
      "author": "eru",
      "points": 1,
      "story_text": null,
      "comment_text": "Better languages _are_ better tooling.  To make it more concrete: Thanks to the difference in languages, ghc can do much more static analysis than gcc.  More refactoring support would also be possible, even if that&#x27;s not done in practice for Haskell, yet.  HLint is nice to toy around with, though.",
      "num_comments": null,
      "story_id": 6243993,
      "story_title": "John Carmack discusses the art and science of software engineering (2012)",
      "story_url": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
      "parent_id": 6247628,
      "created_at_i": 1377051599,
      "_tags": [
        "comment",
        "author_eru",
        "story_6243993"
      ],
      "objectID": "6247790",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "eru",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Better languages _are_ better <em>tooli</em>ng.  To make it more concrete: Thanks to the difference in languages, ghc can do much more <em>static</em> <em>analysis</em> than gcc.  More refactoring support would also be possible, even if that's not done in practice for Haskell, yet.  HLint is nice to toy around with, though.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "John Carmack discusses the art and science of software engineering (2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blogs.uw.edu/ajko/2012/08/22/john-carmack-discusses-the-art-and-science-of-software-engineering/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-05-27T22:39:49.000Z",
      "title": "",
      "url": "",
      "author": "solomatov",
      "points": 1,
      "story_text": null,
      "comment_text": "&#62;* Web != Desktop. Large desktop apps are the wrong paradigm on the web. You won't see a Web-based Mathematica rewritten by hand in HTML/JS/etc. You will see Emscripten-compiled 3DS Max (see my blog on OTOY for more). The reasons behind these outcomes should be clear. They have little to do with JS lacking Java's big-OO features.<p>I am actually not defending big-OO features (I think, 90s style big-OO is obsolete). I like mix of OO and functional programming and like the results which it confers to code (see for example, Reactive Extensions, it's very easy to learn, expressive, and compact). The feature which I miss in JavaScript and which platforms such as JVM and .NET have, is ease of maintaining code, mainly through sound type system and languages created with tooling in mind.<p>&#62;* Glad you brought up refactoring. It is doable in JS IDEs with modern, aggressive static analysis. See not only TypeScript but also Marijn Haverbeke's Tern and work by Ben Livshits, et al., at MSR.<p>The problem with algorithms similar to Tern's is that it works well until we use reflexive capabilities of the language. However, most of the libraries do use them, and as long as it happens, algorithms such as Tern's infer useless type Object.<p>&#62;But automated refactoring is not as much in demand among Web developers I know, who do it by hand and who in general avoid the big-OO \"Kingdom of Nouns\" approach that motivates auto-refactoring.<p>There are refactoring which can be useful in any language. My favorite one is rename, I usually can't come up with a good name from a first attempt. Others are extract/inline method (extract/inline variable is easy to implement in JavaScript).<p>Another maintainability related feature is navigation to definition and find usages. Unfortunately, language dynamism makes them imprecise and code maintenance becomes nightmare especially if you have &#62; 30 KLOCs of code. You have to recheck everything manually and it's very error prone. Tests can help, but they also require substantial effort.",
      "num_comments": null,
      "story_id": 5754848,
      "story_title": "Mozilla can produce near-native performance on the Web",
      "story_url": "http://arstechnica.com/information-technology/2013/05/native-level-performance-on-the-web-a-brief-examination-of-asm-js/",
      "parent_id": 5776673,
      "created_at_i": 1369694389,
      "_tags": [
        "comment",
        "author_solomatov",
        "story_5754848"
      ],
      "objectID": "5776992",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "solomatov",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": ">* Web != Desktop. Large desktop apps are the wrong paradigm on the web. You won't see a Web-based Mathematica rewritten by hand in HTML/JS/etc. You will see Emscripten-compiled 3DS Max (see my blog on OTOY for more). The reasons behind these outcomes should be clear. They have little to do with JS lacking Java's big-OO features.<p>I am actually not defending big-OO features (I think, 90s style big-OO is obsolete). I like mix of OO and functional programming and like the results which it confers to code (see for example, Reactive Extensions, it's very easy to learn, expressive, and compact). The feature which I miss in JavaScript and which platforms such as JVM and .NET have, is ease of maintaining code, mainly through sound type system and languages created with <em>tooli</em>ng in mind.<p>>* Glad you brought up refactoring. It is doable in JS IDEs with modern, aggressive <em>static</em> <em>analysis.</em> See not only TypeScript but also Marijn Haverbeke's Tern and work by Ben Livshits, et al., at MSR.<p>The problem with algorithms similar to Tern's is that it works well until we use reflexive capabilities of the language. However, most of the libraries do use them, and as long as it happens, algorithms such as Tern's infer useless type Object.<p>>But automated refactoring is not as much in demand among Web developers I know, who do it by hand and who in general avoid the big-OO \"Kingdom of Nouns\" approach that motivates auto-refactoring.<p>There are refactoring which can be useful in any language. My favorite one is rename, I usually can't come up with a good name from a first attempt. Others are extract/inline method (extract/inline variable is easy to implement in JavaScript).<p>Another maintainability related feature is navigation to definition and find usages. Unfortunately, language dynamism makes them imprecise and code maintenance becomes nightmare especially if you have > 30 KLOCs of code. You have to recheck everything manually and it's very error prone. Tests can help, but they also require substantial effort.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mozilla can produce near-native performance on the Web",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://arstechnica.com/information-technology/2013/05/native-level-performance-on-the-web-a-brief-examination-of-asm-js/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-10-02T19:16:28.000Z",
      "title": "",
      "url": "",
      "author": "seanmcdirmid",
      "points": 1,
      "story_text": null,
      "comment_text": "To be more specific you have to use some crazy static analysis technology (global interprocedural analysis) that is intractable unless you sacrifice accuracy. Human have similar problems as compilers/tooling, though they are a bit better at understanding nuanced conventions to make better judgements about what dynamic code is doing.",
      "num_comments": null,
      "story_id": 4601654,
      "story_title": "Why does TypeScript have be the answer to anything?",
      "story_url": "http://www.hanselman.com/blog/WhyDoesTypeScriptHaveBeTheAnswerToAnything.aspx",
      "parent_id": 4603650,
      "created_at_i": 1349205388,
      "_tags": [
        "comment",
        "author_seanmcdirmid",
        "story_4601654"
      ],
      "objectID": "4603688",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "seanmcdirmid",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "To be more specific you have to use some crazy <em>static</em> <em>analysis</em> technology (global interprocedural <em>analysis</em>) that is intractable unless you sacrifice accuracy. Human have similar problems as compilers/<em>tooli</em>ng, though they are a bit better at understanding nuanced conventions to make better judgements about what dynamic code is doing.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why does TypeScript have be the answer to anything?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.hanselman.com/blog/WhyDoesTypeScriptHaveBeTheAnswerToAnything.aspx",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-08-10T18:46:21.000Z",
      "title": "",
      "url": "",
      "author": "slurgfest",
      "points": 1,
      "story_text": null,
      "comment_text": "Mind the context: the guy said there needed to be a \"new VI\" to have \"better\" syntax highlighting (whatever specifically he meant by that). You broke in to emphasize how tough it is to parse C++, which is true, but not entirely relevant; the person you replied to was simply pointing out that it's easy to reconfigure vim's syntax highlighting to almost any requirement. Which is true, by the way.<p>It appears that you are preoccupied with hard-coded construction of ASTs for some dialect of C++ inside your editor. I never suggested it could not be done. But, this is a different issue.<p>However, I really don't think many people need that when the facilities for configuring syntax highlighting are so good. The existing system has allowed vim to support a crazy number of languages and have fresh support for languages quite quickly after they start to be used.<p>If you like vim, and you want something SPECIFIC to be fixed about its C++ highlighting (not just a general complaint that you feel it is 'woefully limited' because it isn't based on hardcoded static analysis for C++) ... then don't waste time on doubt. Just try it. Make your own highlighting script and see if it works to a usable level. If it does not, then you know, and not just because of some a priori principle that syntax highlighting is useless unless it is based on an AST generated by your compiler toolchain or something.<p>If you really did have any practical reason to believe that the existing syntax highlighting facility was totally unsuitable for more than a handful of people... maybe it would be interesting to have some way of plugging in external modules of some kind to provide ASTs for specific languages. (Because I think the idea of making my text editor totally coupled to a specific hard-coded implementation of a parser for a particular language sucks really bad; but if you don't think that, then maybe you just want to buy a C++ IDE and be done with it)",
      "num_comments": null,
      "story_id": 4366283,
      "story_title": "My biggest problem with Vim",
      "story_url": "http://haldean.org/docstore/?vim-problems",
      "parent_id": 4367360,
      "created_at_i": 1344624381,
      "_tags": [
        "comment",
        "author_slurgfest",
        "story_4366283"
      ],
      "objectID": "4367585",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "slurgfest",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Mind the context: the guy said there needed to be a \"new VI\" to have \"better\" syntax highlighting (whatever specifically he meant by that). You broke in to emphasize how tough it is to parse C++, which is true, but not entirely relevant; the person you replied to was simply pointing out that it's easy to reconfigure vim's syntax highlighting to almost any requirement. Which is true, by the way.<p>It appears that you are preoccupied with hard-coded construction of ASTs for some dialect of C++ inside your editor. I never suggested it could not be done. But, this is a different issue.<p>However, I really don't think many people need that when the facilities for configuring syntax highlighting are so good. The existing system has allowed vim to support a crazy number of languages and have fresh support for languages quite quickly after they start to be used.<p>If you like vim, and you want something SPECIFIC to be fixed about its C++ highlighting (not just a general complaint that you feel it is 'woefully limited' because it isn't based on hardcoded <em>static</em> <em>analysis</em> for C++) ... then don't waste time on doubt. Just try it. Make your own highlighting script and see if it works to a usable level. If it does not, then you know, and not just because of some a priori principle that syntax highlighting is useless unless it is based on an AST generated by your compiler <em>toolc</em>hain or something.<p>If you really did have any practical reason to believe that the existing syntax highlighting facility was totally unsuitable for more than a handful of people... maybe it would be interesting to have some way of plugging in external modules of some kind to provide ASTs for specific languages. (Because I think the idea of making my text editor totally coupled to a specific hard-coded implementation of a parser for a particular language sucks really bad; but if you don't think that, then maybe you just want to buy a C++ IDE and be done with it)",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "My biggest problem with Vim",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://haldean.org/docstore/?vim-problems",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-05-15T04:41:06.000Z",
      "title": null,
      "url": null,
      "author": "girvo",
      "points": null,
      "story_text": null,
      "comment_text": "<i>&gt; If it does anything, it is to put up an appearance of being modern, while remaining rotten on the inside, and hence all the more dangerous.</i><p>But what&#x27;s rotten that you have to use in the day-to-day? PHP still has it&#x27;s quirks, sure, but when I write modern PHP nearly all of those melt away. Also, well done Cliche, that&#x27;s pretty neat; there are some other implementations of this idea nowadays that do similar things and are very useful.[0]<p>One of the reasons I love HHVM is that Hack is basically PHP-the-good-parts-with-other-awesome-good-parts-added. Static analysis? No problem. Autocomplete? Built into the default tooling! Having to remember dirty array method parameter ordering? No need -- use Collections and use methods on the primitives!<p>[0] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;nikic&#x2F;PHP-Parser\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;nikic&#x2F;PHP-Parser</a>",
      "num_comments": null,
      "story_id": 9548323,
      "story_title": "In Defence of WordPress",
      "story_url": "https://ma.ttias.be/in-defence-of-wordpress/",
      "parent_id": 9548845,
      "created_at_i": 1431664866,
      "_tags": [
        "comment",
        "author_girvo",
        "story_9548323"
      ],
      "objectID": "9548972",
      "_highlightResult": {
        "author": {
          "value": "girvo",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "<i>&gt; If it does anything, it is to put up an appearance of being modern, while remaining rotten on the inside, and hence all the more dangerous.</i><p>But what's rotten that you have to use in the day-to-day? PHP still has it's quirks, sure, but when I write modern PHP nearly all of those melt away. Also, well done Cliche, that's pretty neat; there are some other implementations of this idea nowadays that do similar things and are very useful.[0]<p>One of the reasons I love HHVM is that Hack is basically PHP-the-good-parts-with-other-awesome-good-parts-added. <em>Static</em> <em>analysis</em>? No problem. Autocomplete? Built into the default <em>tooli</em>ng! Having to remember dirty array method parameter ordering? No need -- use Collections and use methods on the primitives!<p>[0] <a href=\"https://github.com/nikic/PHP-Parser\" rel=\"nofollow\">https://github.com/nikic/PHP-Parser</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "In Defence of WordPress",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://ma.ttias.be/in-defence-of-wordpress/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-03-14T09:47:45.000Z",
      "title": null,
      "url": null,
      "author": "xxgreg",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; Complaining about JS as a backward-compatibility-constrained language, to support the idea that JS uplift needs expensive, separate &quot;REPLACE JS&quot; alterna-language&#x2F;runtime projects such as Dart, which inevitably -- because you can&#x27;t replace JS, flamebait trigger warning LOL -- backpeddle to compile-to-JS tooling and tardy tech transfer into ECMA-262, doesn&#x27;t justify the opportunity cost.<p>Ok, let&#x27;s say JS continues to evolve over the next 5-10 years, and by this time all browsers support integers, optional types, operator overloading, less implicit conversion, and mixins. By this point compiling Dart to JS is trivial, and the cross compiled code is also completely readible. So I can take my existing Dart project and compile it to ES11, clean up a few things by hand, and then continue developing in ES11. In the meantime I&#x27;ve had 5-10 years being very productive developing in Dart with good tool support. This seems like a win to me.<p>Having a VM is also incredibly beneficial for development and debugging. These points alone justify investment in Dart.<p>But there are more benefits. Providing a testing ground for VM engineers to try out new features without legacy compatibility constraints. They haven&#x27;t really got started on performance yet, and they&#x27;re already solidly ahead of V8. This can provide insights for TC39, to see what kind of performance&#x2F;memory improvements are possible if changes are made to the language.<p>&gt; Bignums<p>I&#x27;m aware of the bignums strawman, and I&#x27;m aware the page on the wiki dates to 2010. But I repeat: even if the V8 team had implemented bignums behind a flag in 2010, do you really think that the other vendors (including MS and Apple) would have also implemented them already? I find this scenario unlikely. (But kudos to MS&#x2F;A for implementing the new ES6 features. I&#x27;m glad to see JS evolving)<p>&gt; [Snapshotting] could be added to JS if it could be done for Dart.<p>My understanding was that the V8 team actually implemented snapshotting and initially used it for loading their JS core library. They didn&#x27;t think it was possible to use it for loading cached web code. Not because of the globals object, but because javascript code must be executed to build up classes, i.e. setting prototypes etc. Because execution and structure is interleaved, top level code and initialisors could perform side effects before the static program structure exists.<p>&gt; there hasn&#x27;t been much uplift over five years.<p>It looks like Dart is a longer term bet. It will be interesting to see what kind of an influence it has over the next decade or so. Especially given the recent talk around adding optional typing to JS. The Dart team are also currently experimenting with co-operative threading, growable stacks and concurrency primitives. <a href=\"https://github.com/dart-lang/fletch/wiki/Coroutines-and-Threads\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dart-lang&#x2F;fletch&#x2F;wiki&#x2F;Coroutines-and-Thre...</a><p>&gt; My point about opportunity costs stands. We could have come a lot farther, faster.<p>I&#x27;m not convinced. I don&#x27;t see how the development resourcing on the V8 development team could have sped up the ES6 standards process. The ES6 process includes getting consesus with Apple&#x2F;Microsoft - this process isn&#x27;t time constrained by V8 development resources.<p>Consider the opportunity cost if they chose not to develop Dart. Developers have to wait a lot longer to get modern tooling, with: completions, doc hovers, code navigation and static analysis. These really make a huge difference to developer productivity. All of the experience gained here can feed back into javascript tooling (assuming optional typing makes it into ES).<p>Also consider the individual developer&#x27;s motivations. It&#x27;s great that you are excited about working on JS and spidermonkey year after year. But what were the motivations of the developers at google? If the developers are passionate about the web like yourself, then they can continue to work with the V8 team. But if what excites them, is working on a state of the art dynamically typed VM, well then removing some of the legacy JS constraints allows them freedom to innovate. If their only choice had been to work on V8, they could well leave the company and work on another VM project somewhere else. So what would the cost have been if google management said no you can&#x27;t do Dart?<p>&gt; You switched from &quot;Dart does good for the Web via (eventual) JS uplift&quot; (paraphrasing), to &quot;Dart just needs to provide good development tooling&quot; ... What&#x27;s with the goalpost moving ... ?<p>The shifted goal post was: &quot;Dart ain&#x27;t gonna replace JS in the foreseeable future&quot;. I never claimed that Dart will, or needs to, replace javascript.",
      "num_comments": null,
      "story_id": 9178765,
      "story_title": "Strengthening JavaScript",
      "story_url": "https://developers.google.com/v8/experiments",
      "parent_id": 9201747,
      "created_at_i": 1426326465,
      "_tags": [
        "comment",
        "author_xxgreg",
        "story_9178765"
      ],
      "objectID": "9202053",
      "_highlightResult": {
        "author": {
          "value": "xxgreg",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; Complaining about JS as a backward-compatibility-constrained language, to support the idea that JS uplift needs expensive, separate &quot;REPLACE JS&quot; alterna-language/runtime projects such as Dart, which inevitably -- because you can't replace JS, flamebait trigger warning LOL -- backpeddle to compile-to-JS <em>tooli</em>ng and tardy tech transfer into ECMA-262, doesn't justify the opportunity cost.<p>Ok, let's say JS continues to evolve over the next 5-10 years, and by this time all browsers support integers, optional types, operator overloading, less implicit conversion, and mixins. By this point compiling Dart to JS is trivial, and the cross compiled code is also completely readible. So I can take my existing Dart project and compile it to ES11, clean up a few things by hand, and then continue developing in ES11. In the meantime I've had 5-10 years being very productive developing in Dart with good tool support. This seems like a win to me.<p>Having a VM is also incredibly beneficial for development and debugging. These points alone justify investment in Dart.<p>But there are more benefits. Providing a testing ground for VM engineers to try out new features without legacy compatibility constraints. They haven't really got started on performance yet, and they're already solidly ahead of V8. This can provide insights for TC39, to see what kind of performance/memory improvements are possible if changes are made to the language.<p>&gt; Bignums<p>I'm aware of the bignums strawman, and I'm aware the page on the wiki dates to 2010. But I repeat: even if the V8 team had implemented bignums behind a flag in 2010, do you really think that the other vendors (including MS and Apple) would have also implemented them already? I find this scenario unlikely. (But kudos to MS/A for implementing the new ES6 features. I'm glad to see JS evolving)<p>&gt; [Snapshotting] could be added to JS if it could be done for Dart.<p>My understanding was that the V8 team actually implemented snapshotting and initially used it for loading their JS core library. They didn't think it was possible to use it for loading cached web code. Not because of the globals object, but because javascript code must be executed to build up classes, i.e. setting prototypes etc. Because execution and structure is interleaved, top level code and initialisors could perform side effects before the <em>static</em> program structure exists.<p>&gt; there hasn't been much uplift over five years.<p>It looks like Dart is a longer term bet. It will be interesting to see what kind of an influence it has over the next decade or so. Especially given the recent talk around adding optional typing to JS. The Dart team are also currently experimenting with co-operative threading, growable stacks and concurrency primitives. <a href=\"https://github.com/dart-lang/fletch/wiki/Coroutines-and-Threads\" rel=\"nofollow\">https://github.com/dart-lang/fletch/wiki/Coroutines-and-Thre...</a><p>&gt; My point about opportunity costs stands. We could have come a lot farther, faster.<p>I'm not convinced. I don't see how the development resourcing on the V8 development team could have sped up the ES6 standards process. The ES6 process includes getting consesus with Apple/Microsoft - this process isn't time constrained by V8 development resources.<p>Consider the opportunity cost if they chose not to develop Dart. Developers have to wait a lot longer to get modern <em>tooli</em>ng, with: completions, doc hovers, code navigation and <em>static</em> <em>analysis.</em> These really make a huge difference to developer productivity. All of the experience gained here can feed back into javascript <em>tooli</em>ng (assuming optional typing makes it into ES).<p>Also consider the individual developer's motivations. It's great that you are excited about working on JS and spidermonkey year after year. But what were the motivations of the developers at google? If the developers are passionate about the web like yourself, then they can continue to work with the V8 team. But if what excites them, is working on a state of the art dynamically typed VM, well then removing some of the legacy JS constraints allows them freedom to innovate. If their only choice had been to work on V8, they could well leave the company and work on another VM project somewhere else. So what would the cost have been if google management said no you can't do Dart?<p>&gt; You switched from &quot;Dart does good for the Web via (eventual) JS uplift&quot; (paraphrasing), to &quot;Dart just needs to provide good development <em>tooli</em>ng&quot; ... What's with the goalpost moving ... ?<p>The shifted goal post was: &quot;Dart ain't gonna replace JS in the foreseeable future&quot;. I never claimed that Dart will, or needs to, replace javascript.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Strengthening JavaScript",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://developers.google.com/v8/experiments",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-26T16:20:53.000Z",
      "title": null,
      "url": null,
      "author": "twerquie",
      "points": null,
      "story_text": null,
      "comment_text": "I&#x27;m no zealot, and don&#x27;t think these are absolute truths by any means but I&#x27;ve worked extensively on enterprise solutions in both C#&#x2F;.Net and Node.js and can respond to your points below.<p>1. It turns out the reactor pattern is a good way to build network servers that scale reasonably well with minimal developer effort. In my experience developers tend to avoid writing threaded code in synchronous languages, and threads don&#x27;t show up very often in run-of-the-mill solutions. To be sure, JavaScript&#x27;s lack of threads is a blemish, but oddly it forced the community to focus heavily on distributed architectures, and as a result most of the tooling encourages distributed systems, which is a win for some common use cases.<p>2. Type safety is a hotly debated topic and I don&#x27;t think you can find resolution on this one. For some people, &quot;weakest of weak typing&quot; is a benefit.<p>3. Static vs. dynamic, see #2.<p>4. Do you mean that everything must be enforced by convention instead of static code analysis, compile-time checks and type safety? If so, I think you&#x27;re making the same point three times.<p>Erlang is a beautiful language and may be the most correct in some sense, but doesn&#x27;t look nearly as attractive to the kinds of teams I work on when you start to consider developer availability, library ecosystem, tooling, ISP support, documentation and community.",
      "num_comments": null,
      "story_id": 8662348,
      "story_title": "Yahoo Mail moving to React",
      "story_url": "http://www.slideshare.net/rmsguhan/react-meetup-mailonreact",
      "parent_id": 8662605,
      "created_at_i": 1417018853,
      "_tags": [
        "comment",
        "author_twerquie",
        "story_8662348"
      ],
      "objectID": "8663005",
      "_highlightResult": {
        "author": {
          "value": "twerquie",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm no zealot, and don't think these are absolute truths by any means but I've worked extensively on enterprise solutions in both C#/.Net and Node.js and can respond to your points below.<p>1. It turns out the reactor pattern is a good way to build network servers that scale reasonably well with minimal developer effort. In my experience developers tend to avoid writing threaded code in synchronous languages, and threads don't show up very often in run-of-the-mill solutions. To be sure, JavaScript's lack of threads is a blemish, but oddly it forced the community to focus heavily on distributed architectures, and as a result most of the <em>tooli</em>ng encourages distributed systems, which is a win for some common use cases.<p>2. Type safety is a hotly debated topic and I don't think you can find resolution on this one. For some people, &quot;weakest of weak typing&quot; is a benefit.<p>3. <em>Static</em> vs. dynamic, see #2.<p>4. Do you mean that everything must be enforced by convention instead of <em>static</em> code <em>analysis</em>, compile-time checks and type safety? If so, I think you're making the same point three times.<p>Erlang is a beautiful language and may be the most correct in some sense, but doesn't look nearly as attractive to the kinds of teams I work on when you start to consider developer availability, library ecosystem, <em>tooli</em>ng, ISP support, documentation and community.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Yahoo Mail moving to React",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.slideshare.net/rmsguhan/react-meetup-mailonreact",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-24T10:27:31.000Z",
      "title": null,
      "url": null,
      "author": "BonsaiDen",
      "points": null,
      "story_text": null,
      "comment_text": "Vanilla JS is perfectly fine and there are a ton of people out there who are using it every day on a highly professional level.<p>There is a huge amount of tooling these days and specially the Node.js community and ecosystem are flourishing. Code coverage, static analysis, test frameworks for every use case imaginable, you name it.<p>Coffeescript and its brethren are a &quot;solution&quot; for people who are not interested in JavaScript and don&#x27;t care about performance &#x2F; maintainability in the long term. The additional compile step and the resulting problems with not being able to know exactly what it ends up generating become a huge burden in the long run. If you&#x27;re really good in JS, you know what we&#x27;ll be JIT&#x27;ted and what not, just like a really good C++ developer knows what the compiler will eventually optimize away and what not.<p>Seriously, building your cool, new library in &lt;Insert Fancy New Compile to JS Language here&gt; is like writing the latest addition to Boost in C89. Nobody wants to depend on it in the long run.<p>From what I have seen, the people who are mainly using things like Coffeescript are coming from Ruby or Python and want their cool-aid back.<p>If you don&#x27;t want to learn a language, don&#x27;t use it and if that means you won&#x27;t be able to do stuff on the web, well I&#x27;m totally fine with that. I&#x27;ve seen enough code that looked like a J2EE developer just started coding C the other day.",
      "num_comments": null,
      "story_id": 8502134,
      "story_title": "How to become a programmer, or the art of Googling well",
      "story_url": "http://okepi.wordpress.com/2014/08/21/how-to-become-a-programmer-or-the-art-of-googling-well/",
      "parent_id": 8502397,
      "created_at_i": 1414146451,
      "_tags": [
        "comment",
        "author_BonsaiDen",
        "story_8502134"
      ],
      "objectID": "8502969",
      "_highlightResult": {
        "author": {
          "value": "BonsaiDen",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Vanilla JS is perfectly fine and there are a ton of people out there who are using it every day on a highly professional level.<p>There is a huge amount of <em>tooli</em>ng these days and specially the Node.js community and ecosystem are flourishing. Code coverage, <em>static</em> <em>analysis</em>, test frameworks for every use case imaginable, you name it.<p>Coffeescript and its brethren are a &quot;solution&quot; for people who are not interested in JavaScript and don't care about performance / maintainability in the long term. The additional compile step and the resulting problems with not being able to know exactly what it ends up generating become a huge burden in the long run. If you're really good in JS, you know what we'll be JIT'ted and what not, just like a really good C++ developer knows what the compiler will eventually optimize away and what not.<p>Seriously, building your cool, new library in &lt;Insert Fancy New Compile to JS Language here&gt; is like writing the latest addition to Boost in C89. Nobody wants to depend on it in the long run.<p>From what I have seen, the people who are mainly using things like Coffeescript are coming from Ruby or Python and want their cool-aid back.<p>If you don't want to learn a language, don't use it and if that means you won't be able to do stuff on the web, well I'm totally fine with that. I've seen enough code that looked like a J2EE developer just started coding C the other day.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How to become a programmer, or the art of Googling well",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://okepi.wordpress.com/2014/08/21/how-to-become-a-programmer-or-the-art-of-googling-well/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-23T06:15:47.000Z",
      "title": null,
      "url": null,
      "author": "derefr",
      "points": null,
      "story_text": null,
      "comment_text": "A lot of people are recommending IDE-like tooling--but in truly dynamic language (one with a &quot;living image&quot; with path-dependent monkey-patched behavior that can&#x27;t be replicated during static analysis, like Smalltalk--or, sometimes, Ruby) there&#x27;s a more idiomatic way.<p>In a dynamic language, if you&#x27;re at all unsure of what code you need to write, then you <i>don&#x27;t write it in your editor in the first place.</i> Instead, you build the expression you need, interactively, at the REPL—and then, once it works, you paste that <i>into</i> your editor.<p>In dynamic languages, the &quot;dead&quot; code in modules is effectively a coagulation of previously &quot;live&quot; REPL incantations; to trust code that was written &quot;dead&quot; to work correctly &quot;live&quot; is madness (or just a recipe for really long iterations involving unit tests.)<p>If you take this approach far enough, though, you do get a sort of IDE—something that manages your expression experiments and the context harnesses they need, and re-runs experiments when you edit their dependent formulae. I am, of course, talking about &quot;notebook&quot; interfaces like IPython&#x27;s.",
      "num_comments": null,
      "story_id": 8496581,
      "story_title": "“Did you mean?” Experience in Ruby",
      "story_url": "http://www.yukinishijima.net/2014/10/21/did-you-mean-experience-in-ruby.html",
      "parent_id": 8496581,
      "created_at_i": 1414044947,
      "_tags": [
        "comment",
        "author_derefr",
        "story_8496581"
      ],
      "objectID": "8496910",
      "_highlightResult": {
        "author": {
          "value": "derefr",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "A lot of people are recommending IDE-like <em>tooli</em>ng--but in truly dynamic language (one with a &quot;living image&quot; with path-dependent monkey-patched behavior that can't be replicated during <em>static</em> <em>analysis</em>, like Smalltalk--or, sometimes, Ruby) there's a more idiomatic way.<p>In a dynamic language, if you're at all unsure of what code you need to write, then you <i>don't write it in your editor in the first place.</i> Instead, you build the expression you need, interactively, at the REPL—and then, once it works, you paste that <i>into</i> your editor.<p>In dynamic languages, the &quot;dead&quot; code in modules is effectively a coagulation of previously &quot;live&quot; REPL incantations; to trust code that was written &quot;dead&quot; to work correctly &quot;live&quot; is madness (or just a recipe for really long iterations involving unit tests.)<p>If you take this approach far enough, though, you do get a sort of IDE—something that manages your expression experiments and the context harnesses they need, and re-runs experiments when you edit their dependent formulae. I am, of course, talking about &quot;notebook&quot; interfaces like IPython's.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "“Did you mean?” Experience in Ruby",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.yukinishijima.net/2014/10/21/did-you-mean-experience-in-ruby.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-10-09T15:39:59.000Z",
      "title": null,
      "url": null,
      "author": "dllthomas",
      "points": null,
      "story_text": null,
      "comment_text": "If you use static analysis, defensively initializing to a wrong value may mean that your tooling doesn&#x27;t tell you when you fail to correctly set it <i>from</i> that wrong value.",
      "num_comments": null,
      "story_id": 8427852,
      "story_title": "Fixing a 37-year-old bug by merging a 22-year-old fix",
      "story_url": "http://cvsweb.openbsd.org/cgi-bin/cvsweb/src/usr.bin/head/head.c?rev=1.18&content-type=text/x-cvsweb-markup",
      "parent_id": 8432816,
      "created_at_i": 1412869199,
      "_tags": [
        "comment",
        "author_dllthomas",
        "story_8427852"
      ],
      "objectID": "8433023",
      "_highlightResult": {
        "author": {
          "value": "dllthomas",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "If you use <em>static</em> <em>analysis</em>, defensively initializing to a wrong value may mean that your <em>tooli</em>ng doesn't tell you when you fail to correctly set it <i>from</i> that wrong value.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Fixing a 37-year-old bug by merging a 22-year-old fix",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://cvsweb.openbsd.org/cgi-bin/cvsweb/src/usr.bin/head/head.c?rev=1.18&content-type=text/x-cvsweb-markup",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-01-26T21:28:00.000Z",
      "title": null,
      "url": null,
      "author": "sedachv",
      "points": null,
      "story_text": null,
      "comment_text": "The C preprocessor can't do metaprogramming, by definition - there's no way to take apart and examine the arguments passed to macros.<p>The reason you can't statically analyze C code that uses macros has to do with the preprocessor's broken design - it is a separate stage from the compiler, and there's no way for the two to communicate.<p>All this actually means that Lisp macros can be used for static analysis (via macroexpand), in a user-extensible way, without needing to add extensions to the compiler or stages to the compilation process.<p>I don't understand why you cite C# as a good example of something that doesn't have code preprocessors. Visual Studio has T4 (Text Template Transformation Toolkit), which is a dumb joke.",
      "num_comments": null,
      "story_id": 2143752,
      "story_title": "How Lisp macros differ from static code-generation and metaprogramming",
      "story_url": "http://brandonbyars.com/2008/02/12/understanding-syntactic-macros/",
      "parent_id": 2144965,
      "created_at_i": 1296077280,
      "_tags": [
        "comment",
        "author_sedachv",
        "story_2143752"
      ],
      "objectID": "2145220",
      "_highlightResult": {
        "author": {
          "value": "sedachv",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The C preprocessor can't do metaprogramming, by definition - there's no way to take apart and examine the arguments passed to macros.<p>The reason you can't statically analyze C code that uses macros has to do with the preprocessor's broken design - it is a separate stage from the compiler, and there's no way for the two to communicate.<p>All this actually means that Lisp macros can be used for <em>static</em> <em>analysis</em> (via macroexpand), in a user-extensible way, without needing to add extensions to the compiler or stages to the compilation process.<p>I don't understand why you cite C# as a good example of something that doesn't have code preprocessors. Visual Studio has T4 (Text Template Transformation <em>Toolk</em>it), which is a dumb joke.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "How Lisp macros differ from <em>static</em> code-generation and metaprogramming",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "http://brandonbyars.com/2008/02/12/understanding-syntactic-macros/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-12-13T04:22:48.000Z",
      "title": null,
      "url": null,
      "author": "jdp23",
      "points": null,
      "story_text": null,
      "comment_text": "Javascript is a really difficult language from a static analysis perspective, and they're still special-casing a lot to get to something useful -- for example, in the Prototype toolkit, they had to change about 5% of the code to get it to analyze well.",
      "num_comments": null,
      "story_id": 1999275,
      "story_title": "Using Static Analysis for Ajax Intrusion Detection",
      "story_url": "http://cs.brown.edu/people/sk/Publications/Papers/Published/gkj-stat-anal-ajax-id/paper.pdf",
      "parent_id": 1999275,
      "created_at_i": 1292214168,
      "_tags": [
        "comment",
        "author_jdp23",
        "story_1999275"
      ],
      "objectID": "1999309",
      "_highlightResult": {
        "author": {
          "value": "jdp23",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Javascript is a really difficult language from a <em>static</em> <em>analysis</em> perspective, and they're still special-casing a lot to get to something useful -- for example, in the Prototype <em>toolk</em>it, they had to change about 5% of the code to get it to analyze well.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Using <em>Static</em> <em>Analysis</em> for Ajax Intrusion Detection",
          "matchLevel": "partial",
          "matchedWords": [
            "static",
            "analysis"
          ]
        },
        "story_url": {
          "value": "http://cs.brown.edu/people/sk/Publications/Papers/Published/gkj-stat-anal-ajax-id/paper.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2009-12-18T17:28:08.000Z",
      "title": null,
      "url": null,
      "author": "mmastrac",
      "points": null,
      "story_text": null,
      "comment_text": "This is exactly what the Google Web Toolkit compiler does, but outputs Java bytecode rather than taking it into JS.<p>The HotSpot compiler does some of this static analysis at runtime (various forms of devirtualization and type-tightening), but it's far more effective if you feed it into a big vat and keep running optimizations on it until you can eke out anything more.",
      "num_comments": null,
      "story_id": 1003065,
      "story_title": "Java code optimization project",
      "story_url": "http://www.supercompilers.com/",
      "parent_id": 1003065,
      "created_at_i": 1261157288,
      "_tags": [
        "comment",
        "author_mmastrac",
        "story_1003065"
      ],
      "objectID": "1003500",
      "_highlightResult": {
        "author": {
          "value": "mmastrac",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "This is exactly what the Google Web <em>Toolk</em>it compiler does, but outputs Java bytecode rather than taking it into JS.<p>The HotSpot compiler does some of this <em>static</em> <em>analysis</em> at runtime (various forms of devirtualization and type-tightening), but it's far more effective if you feed it into a big vat and keep running optimizations on it until you can eke out anything more.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Java code optimization project",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.supercompilers.com/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-06-08T09:48:05.000Z",
      "title": "",
      "url": "",
      "author": "Superpig",
      "points": 1,
      "story_text": null,
      "comment_text": "\"According to the known guidelines for empirical research in software engineering (see for example [16, 17]), it is necessary to make explicit all elements that potentially threaten the validity of an experiment.\"<p>Or, y'know, according to <i>any basic understanding of science whatsoever.</i> Jesus.<p>They're essentially trying to test whether static typing optimises development time, and as with any optimisation, you only see a substantial increase if you're optimising the bottleneck. Static typing <i>won't</i> show any speed benefits if your coders are being slowed down by weird abstractions, poor tooling, or analysis of the problem.<p>The experiment didn't focus on use of the type system, but nor did it actually test anything close to a real-world scenario. All in all, it seems worthless to me.",
      "num_comments": null,
      "story_id": 4082775,
      "story_title": "Study of 49 programmers: static type system had no effect on development time",
      "story_url": "http://www.cs.washington.edu/education/courses/cse590n/10au/hanenberg-oopsla2010.pdf",
      "parent_id": 4082775,
      "created_at_i": 1339148885,
      "_tags": [
        "comment",
        "author_Superpig",
        "story_4082775"
      ],
      "objectID": "4083487",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "Superpig",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "\"According to the known guidelines for empirical research in software engineering (see for example [16, 17]), it is necessary to make explicit all elements that potentially threaten the validity of an experiment.\"<p>Or, y'know, according to <i>any basic understanding of science whatsoever.</i> Jesus.<p>They're essentially trying to test whether <em>static</em> typing optimises development time, and as with any optimisation, you only see a substantial increase if you're optimising the bottleneck. <em>Static</em> typing <i>won't</i> show any speed benefits if your coders are being slowed down by weird abstractions, poor <em>tooli</em>ng, or <em>analysis</em> of the problem.<p>The experiment didn't focus on use of the type system, but nor did it actually test anything close to a real-world scenario. All in all, it seems worthless to me.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Study of 49 programmers: <em>static</em> type system had no effect on development time",
          "matchLevel": "partial",
          "matchedWords": [
            "static"
          ]
        },
        "story_url": {
          "value": "http://www.cs.washington.edu/education/courses/cse590n/10au/hanenberg-oopsla2010.pdf",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-02-04T23:55:23.000Z",
      "title": null,
      "url": null,
      "author": "tel",
      "points": 9,
      "story_text": null,
      "comment_text": "The word on the street in the Haskell community is that what you say is definitely true in many places, but Haskell makes inroads by being pretty fast if not C fast, grabbing Excel interaction [1], and building banking-related DSLs [2]. The typical story is that the Haskell shop builds advanced tools atop Excel, analysts get excited and want more, then the Haskell shop teaches them just enough Haskell to run a pricing DSL. Static types make it so that relatively untrained programmers can still manipulate the DSL adroitly.<p>All that to say not that Haskell is going to beat Java&#x2F;C++ in any visible time frame but instead to compare its use favorably with something like Python.<p>[1] See Paradise, Credit Suisse&#x27;s Excel interop library (<a href=\"http://www.icfpconference.org/icfp2008/accepted/37.html\" rel=\"nofollow\">http:&#x2F;&#x2F;www.icfpconference.org&#x2F;icfp2008&#x2F;accepted&#x2F;37.html</a>)<p>[2] <a href=\"http://research.microsoft.com/en-us/um/people/simonpj/Papers/financial-contracts/contracts-icfp.htm\" rel=\"nofollow\">http:&#x2F;&#x2F;research.microsoft.com&#x2F;en-us&#x2F;um&#x2F;people&#x2F;simonpj&#x2F;Papers...</a>",
      "num_comments": null,
      "story_id": 7180035,
      "story_title": " We are moving into the quantitative finance industry",
      "story_url": "https://www.fpcomplete.com/business/blog/moving-quantitative-finance-industry/",
      "parent_id": 7180504,
      "created_at_i": 1391558123,
      "_tags": [
        "comment",
        "author_tel",
        "story_7180035"
      ],
      "objectID": "7181056",
      "_highlightResult": {
        "author": {
          "value": "tel",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "The word on the street in the Haskell community is that what you say is definitely true in many places, but Haskell makes inroads by being pretty fast if not C fast, grabbing Excel interaction [1], and building banking-related DSLs [2]. The typical story is that the Haskell shop builds advanced <em>tools</em> atop Excel, <em>analysts</em> get excited and want more, then the Haskell shop teaches them just enough Haskell to run a pricing DSL. <em>Static</em> types make it so that relatively untrained programmers can still manipulate the DSL adroitly.<p>All that to say not that Haskell is going to beat Java/C++ in any visible time frame but instead to compare its use favorably with something like Python.<p>[1] See Paradise, Credit Suisse's Excel interop library (<a href=\"http://www.icfpconference.org/icfp2008/accepted/37.html\" rel=\"nofollow\">http://www.icfpconference.org/icfp2008/accepted/37.html</a>)<p>[2] <a href=\"http://research.microsoft.com/en-us/um/people/simonpj/Papers/financial-contracts/contracts-icfp.htm\" rel=\"nofollow\">http://research.microsoft.com/en-us/um/people/simonpj/Papers...</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": " We are moving into the quantitative finance industry",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://www.fpcomplete.com/business/blog/moving-quantitative-finance-industry/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-09-17T23:40:07.000Z",
      "title": "",
      "url": "",
      "author": "saurik",
      "points": 2,
      "story_text": null,
      "comment_text": "You seem to be assuming that optimizations are only of value if they can be depended on happening consistently as a defined property of the language on every single platform for which there exists a compiler: in practice, compilers perform numerous optimizations (such as static branch prediction) that only work probabilistically even for the case of a specific version of a specific compiler on a specific operating system; I know of very few people (maybe you are one of them, however) who consider this to be a detriment. For a more obvious comparison: yes, I could sit around constructing object pools in my Java program to avoid heap allocations and their associated garbage collection penalty, but if rudimentary escape analysis manages to pick up a lot of the value, even if &quot;fragile&quot; or nondeterministic, I might not need to spend the time anymore to worry about that kind of detail in my software as the cost benefit analysis shows that the toolchain is now a more efficient usage of resources towards that issue (I could be spending my energy working on algorithm design, for example, instead of object pools). As long as the semantics of the language support the optimization, and as it doesn&#x27;t seem to be difficult to implement, it would be useful to have the compiler perform this optimization for the developer, and one would expect such an optimization to either already be there or be &quot;in the works&quot;.",
      "num_comments": null,
      "story_id": 6398147,
      "story_title": "Bjarne Stroustrup – The Essence of C++ [video]",
      "story_url": "http://channel9.msdn.com/Events/GoingNative/2013/Opening-Keynote-Bjarne-Stroustrup",
      "parent_id": 6401948,
      "created_at_i": 1379461207,
      "_tags": [
        "comment",
        "author_saurik",
        "story_6398147"
      ],
      "objectID": "6402584",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "saurik",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "You seem to be assuming that optimizations are only of value if they can be depended on happening consistently as a defined property of the language on every single platform for which there exists a compiler: in practice, compilers perform numerous optimizations (such as <em>static</em> branch prediction) that only work probabilistically even for the case of a specific version of a specific compiler on a specific operating system; I know of very few people (maybe you are one of them, however) who consider this to be a detriment. For a more obvious comparison: yes, I could sit around constructing object pools in my Java program to avoid heap allocations and their associated garbage collection penalty, but if rudimentary escape <em>analysis</em> manages to pick up a lot of the value, even if &quot;fragile&quot; or nondeterministic, I might not need to spend the time anymore to worry about that kind of detail in my software as the cost benefit <em>analysis</em> shows that the <em>toolc</em>hain is now a more efficient usage of resources towards that issue (I could be spending my energy working on algorithm design, for example, instead of object pools). As long as the semantics of the language support the optimization, and as it doesn't seem to be difficult to implement, it would be useful to have the compiler perform this optimization for the developer, and one would expect such an optimization to either already be there or be &quot;in the works&quot;.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Bjarne Stroustrup – The Essence of C++ [video]",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://channel9.msdn.com/Events/GoingNative/2013/Opening-Keynote-Bjarne-Stroustrup",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-06-28T13:18:17.000Z",
      "title": "",
      "url": "",
      "author": "jamii",
      "points": 15,
      "story_text": null,
      "comment_text": "I didn&#x27;t find that comparison very useful&#x2F;accurate (having used clojure heavily for a year or two and scala full-time for the past month). The main differences I find are:<p>When evaluating language tradeoffs the scala community values power more and the clojure community values simplicity more.<p>Scala wants to provide you with the most powerful language possible. Clojure wants to make it easy for you to mold your own language.<p>Scala language tooling works at compile-time and analyses the language statically. Clojure language tooling connects to a running environment and uses introspection. Scala has much better static checking and clojure has much better introspection. While both languages have a repl, the clojure community puts much more emphasis on live, interactive programming.<p>Clojures syntactic extension mechanisms are much simpler, being based on sexps. Scalas are powerful (eg can access the lexical environment) but much more heavy-weight.<p>Clojure has run-time eval. This makes it possible to do eg domain-specific jit (eg compiling DSLs -&gt; clojure code -&gt; java bytecode on the fly). Scala has a run-time interpreter which I haven&#x27;t used but is reputed to be slow.<p>I haven&#x27;t yet explored non-jvm backends for scala but I suspect that clojure will eventually dominate on that front for two reasons: 1) when clojure-in-clojure is finished porting clojure to a new platform will be far easier than scala and 2) clojure was designed from the beginning to be a parasitic language and delegates many features to the underlying platform.<p>Scala breaks backwards compatibility much more often than clojure. Whether this is a pro or con is up for debate. There are lots of small niggling things in clojure I would like to change but on the other hand maintaining scala code across compiler updates is a pain in the ass.<p>Personally, I believe that the number one problem a language needs to address is managing complexity. The clojure community largely seems to get that and is driving for simple, orthogonal language features and libraries to an extent that I&#x27;ve not seen in any other community (eg <a href=\"http://blog.getprismatic.com/blog/2012/10/1/prismatics-graph-at-strange-loop.html\" rel=\"nofollow\">http:&#x2F;&#x2F;blog.getprismatic.com&#x2F;blog&#x2F;2012&#x2F;10&#x2F;1&#x2F;prismatics-graph...</a>). In addition, the most exciting research I&#x27;ve seen on that front (eg  <a href=\"http://www.vpri.org/pdf/tr2011004_steps11.pdf\" rel=\"nofollow\">http:&#x2F;&#x2F;www.vpri.org&#x2F;pdf&#x2F;tr2011004_steps11.pdf</a>  <a href=\"http://boom.cs.berkeley.edu/\" rel=\"nofollow\">http:&#x2F;&#x2F;boom.cs.berkeley.edu&#x2F;</a> ) and most of my favorite tools rely on powerful introspection and runtime code generation. I think Yegge describes this better than I can - <a href=\"http://steve-yegge.blogspot.co.uk/2007/01/pinocchio-problem.html\" rel=\"nofollow\">http:&#x2F;&#x2F;steve-yegge.blogspot.co.uk&#x2F;2007&#x2F;01&#x2F;pinocchio-problem....</a>",
      "num_comments": null,
      "story_id": 5956926,
      "story_title": "Horses for courses: choosing Scala or Clojure",
      "story_url": "http://rrees.me/2013/03/19/horses-for-courses-choosing-scala-or-clojure",
      "parent_id": 5956926,
      "created_at_i": 1372425497,
      "_tags": [
        "comment",
        "author_jamii",
        "story_5956926"
      ],
      "objectID": "5957774",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "jamii",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I didn't find that comparison very useful/accurate (having used clojure heavily for a year or two and scala full-time for the past month). The main differences I find are:<p>When evaluating language tradeoffs the scala community values power more and the clojure community values simplicity more.<p>Scala wants to provide you with the most powerful language possible. Clojure wants to make it easy for you to mold your own language.<p>Scala language tooling works at compile-time and <em>analyses</em> the language statically. Clojure language tooling connects to a running environment and uses introspection. Scala has much better <em>static</em> checking and clojure has much better introspection. While both languages have a repl, the clojure community puts much more emphasis on live, interactive programming.<p>Clojures syntactic extension mechanisms are much simpler, being based on sexps. Scalas are powerful (eg can access the lexical environment) but much more heavy-weight.<p>Clojure has run-time eval. This makes it possible to do eg domain-specific jit (eg compiling DSLs -&gt; clojure code -&gt; java bytecode on the fly). Scala has a run-time interpreter which I haven't used but is reputed to be slow.<p>I haven't yet explored non-jvm backends for scala but I suspect that clojure will eventually dominate on that front for two reasons: 1) when clojure-in-clojure is finished porting clojure to a new platform will be far easier than scala and 2) clojure was designed from the beginning to be a parasitic language and delegates many features to the underlying platform.<p>Scala breaks backwards compatibility much more often than clojure. Whether this is a pro or con is up for debate. There are lots of small niggling things in clojure I would like to change but on the other hand maintaining scala code across compiler updates is a pain in the ass.<p>Personally, I believe that the number one problem a language needs to address is managing complexity. The clojure community largely seems to get that and is driving for simple, orthogonal language features and libraries to an extent that I've not seen in any other community (eg <a href=\"http://blog.getprismatic.com/blog/2012/10/1/prismatics-graph-at-strange-loop.html\" rel=\"nofollow\">http://blog.getprismatic.com/blog/2012/10/1/prismatics-graph...</a>). In addition, the most exciting research I've seen on that front (eg  <a href=\"http://www.vpri.org/pdf/tr2011004_steps11.pdf\" rel=\"nofollow\">http://www.vpri.org/pdf/tr2011004_steps11.pdf</a>  <a href=\"http://boom.cs.berkeley.edu/\" rel=\"nofollow\">http://boom.cs.berkeley.edu/</a> ) and most of my favorite <em>tools</em> rely on powerful introspection and runtime code generation. I think Yegge describes this better than I can - <a href=\"http://steve-yegge.blogspot.co.uk/2007/01/pinocchio-problem.html\" rel=\"nofollow\">http://steve-yegge.blogspot.co.uk/2007/01/pinocchio-problem....</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Horses for courses: choosing Scala or Clojure",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://rrees.me/2013/03/19/horses-for-courses-choosing-scala-or-clojure",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-11-28T10:57:41.000Z",
      "title": null,
      "url": null,
      "author": "jamii",
      "points": 6,
      "story_text": null,
      "comment_text": "I&#x27;m just going to copy-and-paste this old comment:<p>When evaluating language tradeoffs the scala community values power more and the clojure community values simplicity more.<p>Scala wants to provide you with the most powerful language possible. Clojure wants to make it easy for you to mold your own language.<p>Scala language tooling works at compile-time and analyses the language statically. Clojure language tooling connects to a running environment and uses introspection. Scala has much better static checking and clojure has much better introspection. While both languages have a repl, the clojure community puts much more emphasis on live, interactive programming.<p>Clojures syntactic extension mechanisms are much simpler, being based on sexps. Scalas are powerful (eg can access the lexical environment) but much more heavy-weight.<p>Clojure has run-time eval. This makes it possible to do eg domain-specific jit (eg compiling DSLs -&gt; clojure code -&gt; java bytecode on the fly). Scala has a run-time interpreter which I haven&#x27;t used but is reputed to be slow.<p>I haven&#x27;t yet explored non-jvm backends for scala but I suspect that clojure will eventually dominate on that front for two reasons: 1) when clojure-in-clojure is finished porting clojure to a new platform will be far easier than scala and 2) clojure was designed from the beginning to be a parasitic language and delegates many features to the underlying platform.<p>Scala breaks backwards compatibility much more often than clojure. Whether this is a pro or con is up for debate. There are lots of small niggling things in clojure I would like to change but on the other hand maintaining scala code across compiler updates is a pain in the ass.<p>Personally, I believe that the number one problem a language needs to address is managing complexity. The clojure community largely seems to get that and is driving for simple, orthogonal language features and libraries to an extent that I&#x27;ve not seen in any other community (eg <a href=\"http://blog.getprismatic.com/blog/2012/10/1/prismatics-graph-at-strange-loop.html\" rel=\"nofollow\">http:&#x2F;&#x2F;blog.getprismatic.com&#x2F;blog&#x2F;2012&#x2F;10&#x2F;1&#x2F;prismatics-graph...</a>). In addition, the most exciting research I&#x27;ve seen on that front (eg <a href=\"http://www.vpri.org/pdf/tr2011004_steps11.pdf\" rel=\"nofollow\">http:&#x2F;&#x2F;www.vpri.org&#x2F;pdf&#x2F;tr2011004_steps11.pdf</a> <a href=\"http://boom.cs.berkeley.edu/\" rel=\"nofollow\">http:&#x2F;&#x2F;boom.cs.berkeley.edu&#x2F;</a> ) and most of my favorite tools rely on powerful introspection and runtime code generation. I think Yegge describes this better than I can - <a href=\"http://steve-yegge.blogspot.co.uk/2007/01/pinocchio-problem.html\" rel=\"nofollow\">http:&#x2F;&#x2F;steve-yegge.blogspot.co.uk&#x2F;2007&#x2F;01&#x2F;pinocchio-problem....</a>",
      "num_comments": null,
      "story_id": 6812499,
      "story_title": "Clojure: The JFDI language",
      "story_url": "https://docs.google.com/presentation/d/15-7qFy6URdE7Owi2LitkQI_OHBu1AFWPUwHxgBc-O4E/edit?usp=sharing",
      "parent_id": 6813217,
      "created_at_i": 1385636261,
      "_tags": [
        "comment",
        "author_jamii",
        "story_6812499"
      ],
      "objectID": "6814016",
      "_highlightResult": {
        "author": {
          "value": "jamii",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'm just going to copy-and-paste this old comment:<p>When evaluating language tradeoffs the scala community values power more and the clojure community values simplicity more.<p>Scala wants to provide you with the most powerful language possible. Clojure wants to make it easy for you to mold your own language.<p>Scala language tooling works at compile-time and <em>analyses</em> the language statically. Clojure language tooling connects to a running environment and uses introspection. Scala has much better <em>static</em> checking and clojure has much better introspection. While both languages have a repl, the clojure community puts much more emphasis on live, interactive programming.<p>Clojures syntactic extension mechanisms are much simpler, being based on sexps. Scalas are powerful (eg can access the lexical environment) but much more heavy-weight.<p>Clojure has run-time eval. This makes it possible to do eg domain-specific jit (eg compiling DSLs -&gt; clojure code -&gt; java bytecode on the fly). Scala has a run-time interpreter which I haven't used but is reputed to be slow.<p>I haven't yet explored non-jvm backends for scala but I suspect that clojure will eventually dominate on that front for two reasons: 1) when clojure-in-clojure is finished porting clojure to a new platform will be far easier than scala and 2) clojure was designed from the beginning to be a parasitic language and delegates many features to the underlying platform.<p>Scala breaks backwards compatibility much more often than clojure. Whether this is a pro or con is up for debate. There are lots of small niggling things in clojure I would like to change but on the other hand maintaining scala code across compiler updates is a pain in the ass.<p>Personally, I believe that the number one problem a language needs to address is managing complexity. The clojure community largely seems to get that and is driving for simple, orthogonal language features and libraries to an extent that I've not seen in any other community (eg <a href=\"http://blog.getprismatic.com/blog/2012/10/1/prismatics-graph-at-strange-loop.html\" rel=\"nofollow\">http://blog.getprismatic.com/blog/2012/10/1/prismatics-graph...</a>). In addition, the most exciting research I've seen on that front (eg <a href=\"http://www.vpri.org/pdf/tr2011004_steps11.pdf\" rel=\"nofollow\">http://www.vpri.org/pdf/tr2011004_steps11.pdf</a> <a href=\"http://boom.cs.berkeley.edu/\" rel=\"nofollow\">http://boom.cs.berkeley.edu/</a> ) and most of my favorite <em>tools</em> rely on powerful introspection and runtime code generation. I think Yegge describes this better than I can - <a href=\"http://steve-yegge.blogspot.co.uk/2007/01/pinocchio-problem.html\" rel=\"nofollow\">http://steve-yegge.blogspot.co.uk/2007/01/pinocchio-problem....</a>",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Clojure: The JFDI language",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "https://docs.google.com/presentation/d/15-7qFy6URdE7Owi2LitkQI_OHBu1AFWPUwHxgBc-O4E/edit?usp=sharing",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-01-09T13:51:42.000Z",
      "title": "",
      "url": "",
      "author": "xyzzy123",
      "points": 5,
      "story_text": null,
      "comment_text": "Hi!<p>&#62; I doubt I can do such thorough debugging. Are there any useful guides/resources one can use to understand and debug the various hardware architectures?<p>I'm not aware of any good asm or CPU arch books which cover avx more accessibly than the Intel manuals but I imagine someone will correct me if a good reference is available. I'd never heard of avx until today since those instructions are new since the last time I had to look at x86 SIMD.<p>I would actually just recommend a general text like \"Debugging: The 9 Indispensable Rules for Finding Even the Most Elusive Software and Hardware Problems\" as a first shot. I can't really answer your question in the way you want :(  There is no \"magic book\" which will explain everything you need to know.<p>I'm an \"intermediate level\" debugger. I've spent perhaps a few hours a week doing low-level debugging for the last couple of years on x86/x64 Windows and Linux plus maybe 2 embedded archs. I can give some general advice as to what might be a good use of your time if you want to get good at low-level debugging. Obviously, anyone doing stuff like this as their career will need to go a little bit further.<p>Mainly I am writing this because I think I can answer your question better than saying \"Read several thousand pages here: <a href=\"http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html\" rel=\"nofollow\">http://www.intel.com/content/www/us/en/processors/architectu...</a>. It's not really a good use of time for most people. It is not an entirely wasted investment in your early 20's, but 5 years down the track you won't remember much of it unless you live in the debugger or work on a code generator.<p>The way everyone I know does it is to have a good handle on the general case and research (google :) everything else as needed. You can learn the basics in about 40 hours. I know many people who are talented at reversing and debugging, and I can tell you that they do not have (or need) detailed mental models of the SIMD extensions or (speaking for myself) even the FPU. It's cool to know, but with the exception of domain-specific work (codecs, fast math) it is not necessary to keep that information \"swapped in\". When you are working low-level you will find there is an enormous amount of detail to the world. That's the whole problem, and I can explain this with an analogy: imagine trying to diagnose a cracked engine block with an electron microscope.<p>The general idea is to step back, know the basics and be prepared to apply detailed analysis as neccesary.<p>Priorities:<p><pre><code>  0. Determination, patience and \"can do\". Common sense and knowlege of general debugging strategies.\n  1. How to operate the debugger\n  2. Top 50 mnemonics and references on hand for the rest\n  3. Calling conventions and ABI (http://en.wikipedia.org/wiki/X86_calling_conventions)\n  4. Basic OS internals (location of key data structures, heap layout, syscall conventions)\n\n  ... (everything else)\n</code></pre>\n0. The number one predictor of success is to have a kind of \"I can do this\" attitude even though you might not necessarily know what you are doing. The confidence that you can figure it out and the willingness to spend the time to do it. You won't always be right, but you won't get far without it. You also need the general principles of divide and conquer, basic logic and how not to fool yourself.<p>1. Knowing your way around the debugger really well is more useful than knowing reams about, say, the specifics of CPU architecture. So, how to set up symbols and sources, inspect the state of your process/threads. Most crashes can be resolved with a backtrace and looking at a few locals (assuming you have source).<p>2. If you need to read asm, you only need to know the top 50 or 100 mnemonics (if that). If you look at instruction frequencies you'll find the top 50 mnemonics make up more than 95% of all code by frequency, so you can work quickly knowing just these and look up the remainder as required.  I had a reference for that (which I can't find) but a quick-and-dirty analysis (I did this on x64 Ubuntu 10.04) goes:<p><pre><code>  $ find /usr/bin -type f | xargs file | grep ELF | cut -d: -f1 | xargs -n1 objdump --no-show-raw-insn -d &#62; /var/tmp/allops.lst   # dump all instructions from binaries in /usr/bin/ to /var/tmp\n  $ egrep -i '  [0-9a-f]+:' /var/tmp/allops.lst | awk '{ print $2 }' | sort | uniq -c | sort -rn &#62; /tmp/opfreq.list               # get sorted list of mnemonic frequency (highest at the top)\n  $ head -100 /tmp/opfreq.list | awk '{sum += $0} END {print sum}'                                                                # accumulate frequency of top 100 mnemonics\n  30229337     \n  $  awk '{sum += $0} END {print sum}' /tmp/opfreq.list                                                                           # accumulate frequency of all mnemonics\n  30356097\n    </code></pre>\nTop 50 is 97%. Top 100 is 99.6%. If you do a more granular analysis (involving addressing forms etc) you'll find a similar conclusion holds.<p>3. The ABI comes next; basically because you're not going to be able to make sense of function prolog/epilog or the state of your stack without it.<p>4. Knowing your memory map and OS specifics really help too (so e.g. on Windows how to read the PEB/TIB, syscall convention for your OS, roughly how the heap is laid out, whether a pointer is pointing towards a local, a heap address or a library function). Again, only to a high level really.<p>---<p>The normal way to debug something like this (after googling your error, of course) would be to repro the crash, check the call stack, look at the source code for the library and figure out what path takes you to where you crashed. In this case you would work out reasonably quickly out that the crashing eip is in some AVX-optimised LAPACK code and that LAPACK chooses this code at runtime based on the advertised CPU capabilities. Then you would be confused for a bit. Eventually you would figure out you're faulting because AVX instructions don't work but only reach there because they're advertised. Hence Amazon's bug. The whole process is pretty slow, but it's the standard and obvious way of doing it.<p>However in this case the problem they had <i>really</i> was that the crash was intermittent.<p>Based on the narrative given, the picloud guys took a more \"cloud-like\" approach to diagnosing the issue: they ran the \"unreliable\" code (plus some environment scraping, I'm guessing) across a whole bunch of instances and worked out by google and eyeball what was different about the crashy instances. This is a practical way of doing it :)  It's almost a kind of \"statistical debugging\", if you want to put things into buckets. Most major software vendors now get minidumps when their apps crash and this (statistical debugging) is actually an interesting field of study in it's own right. It could use some more postgrad. See e.g. <a href=\"https://crash-stats.mozilla.com/topcrasher/byversion/Firefox/18.0\" rel=\"nofollow\">https://crash-stats.mozilla.com/topcrasher/byversion/Firefox...</a><p>---<p>I'm going to finish this off by explaining what would be better than reading books and references: finding excuses to do it. It turns out that debugging is mostly thankless and only buys you credit in a very limited social circle. Truthfully it's not a good use of your life unless you're the kind of person who enjoys it. Think of it like chess or go problems. If you want to be good at it, you have to find an excuse. Some motivating activities people find for doing low-level work (in no particular order) are:<p><pre><code>  1) Cracking commercial software, writing game trainers, hacking online games (Download trials, or your game of choice)\n  2) Writing exploits (Say, check CVEs, figure out if you can repro, debug until your eyes bleed, write an exploit) \n  3) Improving open source software (find a bug tracker, repro crashes, isolate the bugs)\n  4) Doing crackmes (see e.g. http://crackmes.de/)\n  5) Commercial reasons (work on a toolchain, compiler, embedded system ports, your $software)\n</code></pre>\n---<p>P.S: your complete problem solving breakfast should include repro first, understanding your target, a bit of reasoning and guessing, dynamic analysis (tracing first: Process Monitor/strace/ltrace, debuggers: gdb/ddd/WinDbg/Immunity/OllyDbg, instrumentation: dynamorio/pin), static analysis (objdump/IDA pro) and copious amounts of whatever will make your life easier.<p>---<p>If you are interested I can tell you some war stories about debugging problems in distributed systems but this post is already too long.",
      "num_comments": null,
      "story_id": 5030511,
      "story_title": "When EC2 Hardware Changes Underneath You",
      "story_url": "http://blog.picloud.com/2013/01/08/when-ec2-hardware-changes-underneath-you/",
      "parent_id": 5030706,
      "created_at_i": 1357739502,
      "_tags": [
        "comment",
        "author_xyzzy123",
        "story_5030511"
      ],
      "objectID": "5031439",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "xyzzy123",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Hi!<p>> I doubt I can do such thorough debugging. Are there any useful guides/resources one can use to understand and debug the various hardware architectures?<p>I'm not aware of any good asm or CPU arch books which cover avx more accessibly than the Intel manuals but I imagine someone will correct me if a good reference is available. I'd never heard of avx until today since those instructions are new since the last time I had to look at x86 SIMD.<p>I would actually just recommend a general text like \"Debugging: The 9 Indispensable Rules for Finding Even the Most Elusive Software and Hardware Problems\" as a first shot. I can't really answer your question in the way you want :(  There is no \"magic book\" which will explain everything you need to know.<p>I'm an \"intermediate level\" debugger. I've spent perhaps a few hours a week doing low-level debugging for the last couple of years on x86/x64 Windows and Linux plus maybe 2 embedded archs. I can give some general advice as to what might be a good use of your time if you want to get good at low-level debugging. Obviously, anyone doing stuff like this as their career will need to go a little bit further.<p>Mainly I am writing this because I think I can answer your question better than saying \"Read several thousand pages here: <a href=\"http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html\" rel=\"nofollow\">http://www.intel.com/content/www/us/en/processors/architectu...</a>. It's not really a good use of time for most people. It is not an entirely wasted investment in your early 20's, but 5 years down the track you won't remember much of it unless you live in the debugger or work on a code generator.<p>The way everyone I know does it is to have a good handle on the general case and research (google :) everything else as needed. You can learn the basics in about 40 hours. I know many people who are talented at reversing and debugging, and I can tell you that they do not have (or need) detailed mental models of the SIMD extensions or (speaking for myself) even the FPU. It's cool to know, but with the exception of domain-specific work (codecs, fast math) it is not necessary to keep that information \"swapped in\". When you are working low-level you will find there is an enormous amount of detail to the world. That's the whole problem, and I can explain this with an analogy: imagine trying to diagnose a cracked engine block with an electron microscope.<p>The general idea is to step back, know the basics and be prepared to apply detailed <em>analysis</em> as neccesary.<p>Priorities:<p><pre><code>  0. Determination, patience and \"can do\". Common sense and knowlege of general debugging strategies.\n  1. How to operate the debugger\n  2. Top 50 mnemonics and references on hand for the rest\n  3. Calling conventions and ABI (http://en.wikipedia.org/wiki/X86_calling_conventions)\n  4. Basic OS internals (location of key data structures, heap layout, syscall conventions)\n\n  ... (everything else)\n</code></pre>\n0. The number one predictor of success is to have a kind of \"I can do this\" attitude even though you might not necessarily know what you are doing. The confidence that you can figure it out and the willingness to spend the time to do it. You won't always be right, but you won't get far without it. You also need the general principles of divide and conquer, basic logic and how not to fool yourself.<p>1. Knowing your way around the debugger really well is more useful than knowing reams about, say, the specifics of CPU architecture. So, how to set up symbols and sources, inspect the state of your process/threads. Most crashes can be resolved with a backtrace and looking at a few locals (assuming you have source).<p>2. If you need to read asm, you only need to know the top 50 or 100 mnemonics (if that). If you look at instruction frequencies you'll find the top 50 mnemonics make up more than 95% of all code by frequency, so you can work quickly knowing just these and look up the remainder as required.  I had a reference for that (which I can't find) but a quick-and-dirty <em>analysis</em> (I did this on x64 Ubuntu 10.04) goes:<p><pre><code>  $ find /usr/bin -type f | xargs file | grep ELF | cut -d: -f1 | xargs -n1 objdump --no-show-raw-insn -d > /var/tmp/allops.lst   # dump all instructions from binaries in /usr/bin/ to /var/tmp\n  $ egrep -i '  [0-9a-f]+:' /var/tmp/allops.lst | awk '{ print $2 }' | sort | uniq -c | sort -rn > /tmp/opfreq.list               # get sorted list of mnemonic frequency (highest at the top)\n  $ head -100 /tmp/opfreq.list | awk '{sum += $0} END {print sum}'                                                                # accumulate frequency of top 100 mnemonics\n  30229337     \n  $  awk '{sum += $0} END {print sum}' /tmp/opfreq.list                                                                           # accumulate frequency of all mnemonics\n  30356097\n    </code></pre>\nTop 50 is 97%. Top 100 is 99.6%. If you do a more granular <em>analysis</em> (involving addressing forms etc) you'll find a similar conclusion holds.<p>3. The ABI comes next; basically because you're not going to be able to make sense of function prolog/epilog or the state of your stack without it.<p>4. Knowing your memory map and OS specifics really help too (so e.g. on Windows how to read the PEB/TIB, syscall convention for your OS, roughly how the heap is laid out, whether a pointer is pointing towards a local, a heap address or a library function). Again, only to a high level really.<p>---<p>The normal way to debug something like this (after googling your error, of course) would be to repro the crash, check the call stack, look at the source code for the library and figure out what path takes you to where you crashed. In this case you would work out reasonably quickly out that the crashing eip is in some AVX-optimised LAPACK code and that LAPACK chooses this code at runtime based on the advertised CPU capabilities. Then you would be confused for a bit. Eventually you would figure out you're faulting because AVX instructions don't work but only reach there because they're advertised. Hence Amazon's bug. The whole process is pretty slow, but it's the standard and obvious way of doing it.<p>However in this case the problem they had <i>really</i> was that the crash was intermittent.<p>Based on the narrative given, the picloud guys took a more \"cloud-like\" approach to diagnosing the issue: they ran the \"unreliable\" code (plus some environment scraping, I'm guessing) across a whole bunch of instances and worked out by google and eyeball what was different about the crashy instances. This is a practical way of doing it :)  It's almost a kind of \"statistical debugging\", if you want to put things into buckets. Most major software vendors now get minidumps when their apps crash and this (statistical debugging) is actually an interesting field of study in it's own right. It could use some more postgrad. See e.g. <a href=\"https://crash-stats.mozilla.com/topcrasher/byversion/Firefox/18.0\" rel=\"nofollow\">https://crash-stats.mozilla.com/topcrasher/byversion/Firefox...</a><p>---<p>I'm going to finish this off by explaining what would be better than reading books and references: finding excuses to do it. It turns out that debugging is mostly thankless and only buys you credit in a very limited social circle. Truthfully it's not a good use of your life unless you're the kind of person who enjoys it. Think of it like chess or go problems. If you want to be good at it, you have to find an excuse. Some motivating activities people find for doing low-level work (in no particular order) are:<p><pre><code>  1) Cracking commercial software, writing game trainers, hacking online games (Download trials, or your game of choice)\n  2) Writing exploits (Say, check CVEs, figure out if you can repro, debug until your eyes bleed, write an exploit) \n  3) Improving open source software (find a bug tracker, repro crashes, isolate the bugs)\n  4) Doing crackmes (see e.g. http://crackmes.de/)\n  5) Commercial reasons (work on a <em>toolc</em>hain, compiler, embedded system ports, your $software)\n</code></pre>\n---<p>P.S: your complete problem solving breakfast should include repro first, understanding your target, a bit of reasoning and guessing, dynamic <em>analysis</em> (tracing first: Process Monitor/strace/ltrace, debuggers: gdb/ddd/WinDbg/Immunity/OllyDbg, instrumentation: dynamorio/pin), <em>static</em> <em>analysis</em> (objdump/IDA pro) and copious amounts of whatever will make your life easier.<p>---<p>If you are interested I can tell you some war stories about debugging problems in distributed systems but this post is already too long.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "When EC2 Hardware Changes Underneath You",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.picloud.com/2013/01/08/when-ec2-hardware-changes-underneath-you/",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2015-01-15T18:50:16.000Z",
      "title": null,
      "url": null,
      "author": "bad_user",
      "points": null,
      "story_text": null,
      "comment_text": "&gt; <i>There is a trade-off being verbosity and maintainability, IMGO Go hits that.</i><p>This is where we&#x27;ll always disagree, because if you like Go, it&#x27;s natural for you to come up with this argument, however the line you&#x27;re drawing is completely arbitrary. I have yet to hear an argument about what makes Go strike a fine balance between verbosity and maintainability, when my feelings are the opposite - I find Go code to not be very maintainable in comparison with other static languages, because Go is not very statically type-safe.<p>&gt; <i>LOL. Said no person who has actually distributed a multiplatofrm Java application ever</i><p>Yet it happens all the time and a LOL is not an argument that disproves that. From my own experience, I have built stuff on top of Java &#x2F; the JVM on OS X &#x2F; Linux and deployed on Linux, Windows and OS X, without encountering any issues, ever, without worrying that Java&#x27;s NIO will work or not, without worrying on whether the memory model will suddenly be different, without worrying on whether my app will leak on 32 bits platforms ;-)<p>Android is the only ugly duckling, but that&#x27;s only because Android doesn&#x27;t have a JVM on it. It still works out well though.<p>But if you have examples, I&#x27;d love to hear them out.<p>&gt; <i>The key word here was dependency, specifically, external dependency. If Go&#x27;d runtime ships with the binary its not really a external dependency is it.</i><p>Now that&#x27;s an arbitrary distinction, isn&#x27;t it? What stops one from bundling the VM in the same deployed binary? If you want this distinction, the only valid argument is one of size, but then again for the server-side (where most of the Go stuff is used) that&#x27;s completely meaningless.<p>&gt; <i>Yes. It comes baked into the stdlib, its &quot;http&#x2F;pprof&quot;</i><p>Are you seriously comparing something like YourKit&#x27;s Profiler and Java&#x27;s remote attach and debugging capabilities to http&#x2F;pprof? IMHO, that&#x27;s not a comparison you can make.<p>&gt; <i>Biggest plus ever, goes native simple tooling doesn&#x27;t need an external life support system.</i><p>There are many issues wrong with this line of thinking - the simple tooling you&#x27;re talking about doesn&#x27;t do what I and many others want it to do. Also if you look throughout history, all the languages that came with batteries included have suffered once the people finally reached the conclusion that the included batteries have been shitty. Which is what happens when you don&#x27;t let evolution pick a winner with the community acting as the fitness function. But we&#x27;ll talk in about 5 years.<p>&gt; <i>You are wrong, all the the stuff you are are talking about is library based, Go has channels&#x2F;select&#x2F;go build into the language as primitives. I wasn&#x27;t talking about bolt on libraries.</i><p>But that&#x27;s the point mate, the JVM is capable enough to build anything you want on top of it as libraries, there&#x27;s no point for something to be hard-coded in the language. Which is a good thing, because when speaking of concurrency and parallelism, there isn&#x27;t a one size fits all.<p>For example, speaking of Go&#x27;s channels - they are strictly about managing concurrency, they are not about parallelizing a workload and they do not work across address spaces &#x2F; asynchronous boundaries. And if you think that Go&#x27;s channels are the answer to everything, well, you would have been better off with Erlang, as there you might have had a valid argument.<p>&gt; <i>IMHO This is not the case, if you think it is, explain.</i><p>Can you take an arbitrary memory location and cast it to anything you want? Can you override how heap allocation happens? Can you allocate an array on the stack? Can you do RAII? Do you have the union type from C?<p>In practice you have no control on where Golang allocates stuff - the compiler decides that based on really simple rules for escape analysis and as a general rule of thumb AFAIK anything that is allocated with &quot;new&quot; goes on the heap.  What you can do with Golang is to use the &quot;unsafe&quot; package. But that&#x27;s not different than using Java&#x27;s sun.misc.unsafe ;-)<p>The only real difference with Golang is that you can have stack allocated structs, as otherwise Java also does escape analysis. But besides this coming to Java 9, the real kicker is that .NET&#x2F;C# has had stack allocated values since inception, in addition to much more potent &quot;unsafe&quot; constructs - in C# you can even do pointers and pointer arithmetic and the runtime will pin those memory addresses during execution for avoiding GC interference.",
      "num_comments": null,
      "story_id": 8892632,
      "story_title": "Why Tech Startups Should Look at Go",
      "story_url": "http://startupedmonton.tumblr.com/post/107921476571/why-tech-startups-should-look-at-go",
      "parent_id": 8893401,
      "created_at_i": 1421347816,
      "_tags": [
        "comment",
        "author_bad_user",
        "story_8892632"
      ],
      "objectID": "8894510",
      "_highlightResult": {
        "author": {
          "value": "bad_user",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&gt; <i>There is a trade-off being verbosity and maintainability, IMGO Go hits that.</i><p>This is where we'll always disagree, because if you like Go, it's natural for you to come up with this argument, however the line you're drawing is completely arbitrary. I have yet to hear an argument about what makes Go strike a fine balance between verbosity and maintainability, when my feelings are the opposite - I find Go code to not be very maintainable in comparison with other <em>static</em> languages, because Go is not very statically type-safe.<p>&gt; <i>LOL. Said no person who has actually distributed a multiplatofrm Java application ever</i><p>Yet it happens all the time and a LOL is not an argument that disproves that. From my own experience, I have built stuff on top of Java / the JVM on OS X / Linux and deployed on Linux, Windows and OS X, without encountering any issues, ever, without worrying that Java's NIO will work or not, without worrying on whether the memory model will suddenly be different, without worrying on whether my app will leak on 32 bits platforms ;-)<p>Android is the only ugly duckling, but that's only because Android doesn't have a JVM on it. It still works out well though.<p>But if you have examples, I'd love to hear them out.<p>&gt; <i>The key word here was dependency, specifically, external dependency. If Go'd runtime ships with the binary its not really a external dependency is it.</i><p>Now that's an arbitrary distinction, isn't it? What stops one from bundling the VM in the same deployed binary? If you want this distinction, the only valid argument is one of size, but then again for the server-side (where most of the Go stuff is used) that's completely meaningless.<p>&gt; <i>Yes. It comes baked into the stdlib, its &quot;http/pprof&quot;</i><p>Are you seriously comparing something like YourKit's Profiler and Java's remote attach and debugging capabilities to http/pprof? IMHO, that's not a comparison you can make.<p>&gt; <i>Biggest plus ever, goes native simple <em>tooli</em>ng doesn't need an external life support system.</i><p>There are many issues wrong with this line of thinking - the simple <em>tooli</em>ng you're talking about doesn't do what I and many others want it to do. Also if you look throughout history, all the languages that came with batteries included have suffered once the people finally reached the conclusion that the included batteries have been shitty. Which is what happens when you don't let evolution pick a winner with the community acting as the fitness function. But we'll talk in about 5 years.<p>&gt; <i>You are wrong, all the the stuff you are are talking about is library based, Go has channels/select/go build into the language as primitives. I wasn't talking about bolt on libraries.</i><p>But that's the point mate, the JVM is capable enough to build anything you want on top of it as libraries, there's no point for something to be hard-coded in the language. Which is a good thing, because when speaking of concurrency and parallelism, there isn't a one size fits all.<p>For example, speaking of Go's channels - they are strictly about managing concurrency, they are not about parallelizing a workload and they do not work across address spaces / asynchronous boundaries. And if you think that Go's channels are the answer to everything, well, you would have been better off with Erlang, as there you might have had a valid argument.<p>&gt; <i>IMHO This is not the case, if you think it is, explain.</i><p>Can you take an arbitrary memory location and cast it to anything you want? Can you override how heap allocation happens? Can you allocate an array on the stack? Can you do RAII? Do you have the union type from C?<p>In practice you have no control on where Golang allocates stuff - the compiler decides that based on really simple rules for escape <em>analysis</em> and as a general rule of thumb AFAIK anything that is allocated with &quot;new&quot; goes on the heap.  What you can do with Golang is to use the &quot;unsafe&quot; package. But that's not different than using Java's sun.misc.unsafe ;-)<p>The only real difference with Golang is that you can have stack allocated structs, as otherwise Java also does escape <em>analysis.</em> But besides this coming to Java 9, the real kicker is that .NET/C# has had stack allocated values since inception, in addition to much more potent &quot;unsafe&quot; constructs - in C# you can even do pointers and pointer arithmetic and the runtime will pin those memory addresses during execution for avoiding GC interference.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Why Tech Startups Should Look at Go",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://startupedmonton.tumblr.com/post/107921476571/why-tech-startups-should-look-at-go",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-11-30T07:04:44.000Z",
      "title": null,
      "url": null,
      "author": "jamii",
      "points": null,
      "story_text": null,
      "comment_text": "Ocaml hits most of the points on your list, if you can bring yourself to use a statically typed language.<p>&#62; Support OO, imperative and functional paradigms<p>Yep. Objects aren't used all that often but they are fully supported and can do some things that are difficult in Java or C++ eg <a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/manual007.html#toc39\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/manual007.html#to...</a><p>&#62; Compile to fully optimized machine code with efficiency comparable to that of C<p>Not quite, but ocamlopt generates pretty damn fast code and, more importantly, has very predictable performance. Ocaml makes a pretty good systems language as demonstrated by the recent Mirage paper: <a href=\"http://anil.recoil.org/papers/2010-hotcloud-lamp.pdf\" rel=\"nofollow\">http://anil.recoil.org/papers/2010-hotcloud-lamp.pdf</a><p>&#62; Provide language support for numerical multidimensional arrays and linear algebra with a syntax comparable to Matlab<p>No, but this would make a good Jane Street summer project. Ocaml has extensible syntax via camlp4 and bindings to R, GSL and Matlab (no octave bindings for some reason).<p>&#62; Support list comprehensions<p>Yes, as a syntax extension. <a href=\"http://batteries.forge.ocamlcore.org/doc.preview:batteries-beta1/html/extensions.html#Comprehension\" rel=\"nofollow\">http://batteries.forge.ocamlcore.org/doc.preview:batteries-b...</a><p>&#62; Provide map,list and set types similar to those of Python<p>The syntax is not as nice but apart from that:<p><a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/libref/Map.Make.html\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/libref/Map.Make.h...</a><p><a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/libref/Hashtbl.html\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/libref/Hashtbl.ht...</a><p><a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/libref/List.html\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/libref/List.html</a><p><a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/libref/Set.S.html\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/libref/Set.S.html</a><p>&#62;  Support dynamic typing<p>Nope. You can circumvent the type system using Obj but its generally not advisable.<p>&#62; Support optional static typing, and contracts<p>Static typing - yes. Contracts - see eg<p><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5372&#38;rep=rep1&#38;type=pdf\" rel=\"nofollow\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157...</a><p><a href=\"http://perso.eleves.bretagne.ens-cachan.fr/~dagand/opis/opis_presentation.pdf\" rel=\"nofollow\">http://perso.eleves.bretagne.ens-cachan.fr/~dagand/opis/opis...</a><p>&#62; Provide standard libraries with breadth of functionality comparable to those of Java but simpler API's (more like Python)<p>No. Ocaml Batteries is a start but nowhere near as broad as Python or Java.<p>&#62; Provide a mechanism for efficient compile-time parametrization of algorithms, like C++ templates<p>Not just compile time specialization but multi-stage compilation via MetaOcaml. See eg <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.2541&#38;rep=rep1&#38;type=pdf\" rel=\"nofollow\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73....</a><p>&#62; Support free-form (ie. whitespace independent) syntax<p>Yep, although there are some issues with the syntax eg dangling-else-like problems with nested matches.<p>&#62; Provide a high quality cross-platform GUI toolkit with support for OpenGL<p>Well tested bingdings to Tk, Gtk and OpenGL.<p>&#62; Provide an interactive graphical environment for experimentation and data analysis<p>None that I know of. I tend to use matplotlib and opengl interactively from the repl but its not up to the standards of mathematica etc.<p>&#62; Provide a dataset abstraction similar to R data frames<p>I dont think so. I haven't used R much so I don't know exactly what features are missing.<p>&#62; Be supported by a high-quality IDE and debugger<p>There are a couple of IDEs but none of them seem to be very well polished. Ocaml-mode and emacs is generally the way to go.<p>The time-travelling ocaml debugger is pretty amazing. You can also compile with support for gdb for low level debugging.",
      "num_comments": null,
      "story_id": 1950973,
      "story_title": "Mozilla Is Designing a New Programming Language Language Called Rust",
      "story_url": "http://www.readwriteweb.com/hack/2010/11/mozilla-designing-programming-language-rust.php",
      "parent_id": 1951398,
      "created_at_i": 1291100684,
      "_tags": [
        "comment",
        "author_jamii",
        "story_1950973"
      ],
      "objectID": "1953398",
      "_highlightResult": {
        "author": {
          "value": "jamii",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Ocaml hits most of the points on your list, if you can bring yourself to use a statically typed language.<p>> Support OO, imperative and functional paradigms<p>Yep. Objects aren't used all that often but they are fully supported and can do some things that are difficult in Java or C++ eg <a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/manual007.html#toc39\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/manual007.html#to...</a><p>> Compile to fully optimized machine code with efficiency comparable to that of C<p>Not quite, but ocamlopt generates pretty damn fast code and, more importantly, has very predictable performance. Ocaml makes a pretty good systems language as demonstrated by the recent Mirage paper: <a href=\"http://anil.recoil.org/papers/2010-hotcloud-lamp.pdf\" rel=\"nofollow\">http://anil.recoil.org/papers/2010-hotcloud-lamp.pdf</a><p>> Provide language support for numerical multidimensional arrays and linear algebra with a syntax comparable to Matlab<p>No, but this would make a good Jane Street summer project. Ocaml has extensible syntax via camlp4 and bindings to R, GSL and Matlab (no octave bindings for some reason).<p>> Support list comprehensions<p>Yes, as a syntax extension. <a href=\"http://batteries.forge.ocamlcore.org/doc.preview:batteries-beta1/html/extensions.html#Comprehension\" rel=\"nofollow\">http://batteries.forge.ocamlcore.org/doc.preview:batteries-b...</a><p>> Provide map,list and set types similar to those of Python<p>The syntax is not as nice but apart from that:<p><a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/libref/Map.Make.html\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/libref/Map.Make.h...</a><p><a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/libref/Hashtbl.html\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/libref/Hashtbl.ht...</a><p><a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/libref/List.html\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/libref/List.html</a><p><a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/libref/Set.S.html\" rel=\"nofollow\">http://caml.inria.fr/pub/docs/manual-ocaml/libref/Set.S.html</a><p>>  Support dynamic typing<p>Nope. You can circumvent the type system using Obj but its generally not advisable.<p>> Support optional <em>static</em> typing, and contracts<p><em>Static</em> typing - yes. Contracts - see eg<p><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5372&rep=rep1&type=pdf\" rel=\"nofollow\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157...</a><p><a href=\"http://perso.eleves.bretagne.ens-cachan.fr/~dagand/opis/opis_presentation.pdf\" rel=\"nofollow\">http://perso.eleves.bretagne.ens-cachan.fr/~dagand/opis/opis...</a><p>> Provide standard libraries with breadth of functionality comparable to those of Java but simpler API's (more like Python)<p>No. Ocaml Batteries is a start but nowhere near as broad as Python or Java.<p>> Provide a mechanism for efficient compile-time parametrization of algorithms, like C++ templates<p>Not just compile time specialization but multi-stage compilation via MetaOcaml. See eg <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.2541&rep=rep1&type=pdf\" rel=\"nofollow\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73....</a><p>> Support free-form (ie. whitespace independent) syntax<p>Yep, although there are some issues with the syntax eg dangling-else-like problems with nested matches.<p>> Provide a high quality cross-platform GUI <em>toolk</em>it with support for OpenGL<p>Well tested bingdings to Tk, Gtk and OpenGL.<p>> Provide an interactive graphical environment for experimentation and data <em>analysis</em><p>None that I know of. I tend to use matplotlib and opengl interactively from the repl but its not up to the standards of mathematica etc.<p>> Provide a dataset abstraction similar to R data frames<p>I dont think so. I haven't used R much so I don't know exactly what features are missing.<p>> Be supported by a high-quality IDE and debugger<p>There are a couple of IDEs but none of them seem to be very well polished. Ocaml-mode and emacs is generally the way to go.<p>The time-travelling ocaml debugger is pretty amazing. You can also compile with support for gdb for low level debugging.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mozilla Is Designing a New Programming Language Language Called Rust",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.readwriteweb.com/hack/2010/11/mozilla-designing-programming-language-rust.php",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2010-11-29T19:11:48.000Z",
      "title": null,
      "url": null,
      "author": "tgflynn",
      "points": null,
      "story_text": null,
      "comment_text": "I'd like to see a better programming language.  All of the existing languages involve accepting certain trade-offs.  Of course maybe no \"perfect\" language can exist but until someone proves that there's always hope.<p>For me the ideal language would :\n - Support OO, imperative and functional paradigms\n - Compile to fully optimized machine code with efficiency comparable to that of C\n - Provide language support for numerical multidimensional arrays and linear algebra with a syntax comparable to Matlab\n - Support list comprehensions\n - Provide map,list and set types similar to those of Python\n - Support dynamic typing\n - Support optional static typing, and contracts\n - Provide standard libraries with breadth of functionality comparable to those of Java but simpler API's (more like Python)\n - Provide a mechanism for efficient compile-time parametrization of algorithms, like C++ templates\n - Support free-form (ie. whitespace independent) syntax\n - Provide a high quality cross-platform GUI toolkit with support for OpenGL\n - Provide an interactive graphical environment for experimentation and data analysis\n - Provide a dataset abstraction similar to R data frames\n - Be supported by a high-quality IDE and debugger<p>Of course that's a lot to ask for, but it would be nice to be able to do everything with a single unified syntax and environment.",
      "num_comments": null,
      "story_id": 1950973,
      "story_title": "Mozilla Is Designing a New Programming Language Language Called Rust",
      "story_url": "http://www.readwriteweb.com/hack/2010/11/mozilla-designing-programming-language-rust.php",
      "parent_id": 1951094,
      "created_at_i": 1291057908,
      "_tags": [
        "comment",
        "author_tgflynn",
        "story_1950973"
      ],
      "objectID": "1951398",
      "_highlightResult": {
        "author": {
          "value": "tgflynn",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'd like to see a better programming language.  All of the existing languages involve accepting certain trade-offs.  Of course maybe no \"perfect\" language can exist but until someone proves that there's always hope.<p>For me the ideal language would :\n - Support OO, imperative and functional paradigms\n - Compile to fully optimized machine code with efficiency comparable to that of C\n - Provide language support for numerical multidimensional arrays and linear algebra with a syntax comparable to Matlab\n - Support list comprehensions\n - Provide map,list and set types similar to those of Python\n - Support dynamic typing\n - Support optional <em>static</em> typing, and contracts\n - Provide standard libraries with breadth of functionality comparable to those of Java but simpler API's (more like Python)\n - Provide a mechanism for efficient compile-time parametrization of algorithms, like C++ templates\n - Support free-form (ie. whitespace independent) syntax\n - Provide a high quality cross-platform GUI <em>toolk</em>it with support for OpenGL\n - Provide an interactive graphical environment for experimentation and data <em>analysis</em>\n - Provide a dataset abstraction similar to R data frames\n - Be supported by a high-quality IDE and debugger<p>Of course that's a lot to ask for, but it would be nice to be able to do everything with a single unified syntax and environment.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Mozilla Is Designing a New Programming Language Language Called Rust",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.readwriteweb.com/hack/2010/11/mozilla-designing-programming-language-rust.php",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2014-11-28T16:46:37.000Z",
      "title": null,
      "url": null,
      "author": "viach",
      "points": null,
      "story_text": null,
      "comment_text": "&quot;brand new language to avoid JavaScript’s bad side while embracing its good side.&quot;<p>Why don&#x27;t just use the good side? Well, with all the tools available for JavaScript - static code analysers, type checkers and code coverage tools, is it really _that_ hard to just write this damn code without introducing a new language?",
      "num_comments": null,
      "story_id": 8671054,
      "story_title": "Introducing Spider 0.1",
      "story_url": "http://blog.spiderlang.org/post/103752682650/introducing-spider-0-1",
      "parent_id": 8671054,
      "created_at_i": 1417193197,
      "_tags": [
        "comment",
        "author_viach",
        "story_8671054"
      ],
      "objectID": "8671414",
      "_highlightResult": {
        "author": {
          "value": "viach",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "&quot;brand new language to avoid JavaScript’s bad side while embracing its good side.&quot;<p>Why don't just use the good side? Well, with all the <em>tools</em> available for JavaScript - <em>static</em> code <em>analysers</em>, type checkers and code coverage <em>tools</em>, is it really _that_ hard to just write this damn code without introducing a new language?",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Introducing Spider 0.1",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.spiderlang.org/post/103752682650/introducing-spider-0-1",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2011-11-22T14:42:48.000Z",
      "title": "",
      "url": "",
      "author": "nickik",
      "points": 3,
      "story_text": null,
      "comment_text": "It is possible to build all kinds of crazy type stuff into any lisp. Look at Qi or Typed Racket they build all kinds of type-stuff into the language (Im not an expert in stuff like this so I don't know how far you could go). There are allready people working on this in Clojure.<p>A Typesystem in this still combind with some tools to check this befor you run the programm should provide almost everything you get from Haskell or Scala.<p>This kind of approach does yield the additional benefits:<p>1. Much easier to change<p>2. You can add another static analysing system ontop of it<p>3. Less restrictive",
      "num_comments": null,
      "story_id": 3264849,
      "story_title": "Scala Feels like EJB 2 ",
      "story_url": "http://blog.joda.org/2011/11/scala-feels-like-ejb-2-and-other.html",
      "parent_id": 3265209,
      "created_at_i": 1321972968,
      "_tags": [
        "comment",
        "author_nickik",
        "story_3264849"
      ],
      "objectID": "3265652",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "nickik",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "It is possible to build all kinds of crazy type stuff into any lisp. Look at Qi or Typed Racket they build all kinds of type-stuff into the language (Im not an expert in stuff like this so I don't know how far you could go). There are allready people working on this in Clojure.<p>A Typesystem in this still combind with some <em>tools</em> to check this befor you run the programm should provide almost everything you get from Haskell or Scala.<p>This kind of approach does yield the additional benefits:<p>1. Much easier to change<p>2. You can add another <em>static</em> <em>analysing</em> system ontop of it<p>3. Less restrictive",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Scala Feels like EJB 2 ",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://blog.joda.org/2011/11/scala-feels-like-ejb-2-and-other.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-04-02T01:01:47.000Z",
      "title": null,
      "url": null,
      "author": "dabent",
      "points": 1,
      "story_text": null,
      "comment_text": "Santa Monica, CA (Los Angeles area) also possibly SF Bay area or other cities, but most jobs are in Santa Monica.<p>TRUECar - Put simply, TrueCar shows consumers how much people actually paid for a particular new car in their area, then guide them to dealers we've certified.  We bring transparency to auto pricing and so far we are getting a solid piece of a huge market.<p>* Java - We are looking for talented Java architects to design and build the technology used to power our production websites, APIs, widgets, and internal tools.  This is a chance for you to join a growing company and build something that's going to need to scale to support millions of users/visitors and provide them with all kinds of data.<p>* Data Analyst - Will work on data management and ensure robust pipelines implemented for a diverse range of analytical products.  You will be utilizing the latest technologies to solve challenging problems and create innovative applications from the ground up.<p>* Data Warehouse Developer - We are looking for a super smart and detail-oriented SQL Database Developer who will support the ETL and Data Modeling processes which feed our data warehouse and MicroStrategy environment.<p>* Senior Designer - Works closely with the Creative Director, VP Product, and Chief Product Officer to provide high-level front-end design in the development of key TrueCar products. This position rapidly visualizes information presentation for the web (and portable devices) and turns that vision into static/functional prototypes. The Designer serves as a member of core product team supporting front-end developers and product owners.<p>* Senior Linux Systems Engineer - Will be involved from the design stage through production troubleshooting, from DNS to networking to application behavior and ultimately responsible for making sure our production systems are reliable and perform well.<p>* Statistician/Data Mining Specialist - Masters or Ph.D. in Statistics, Econometrics, Operations Research, Data Mining, or Biostatistics who will work on a wide range of projects from transaction price modeling, forecasting, to multivariate testing and marketing analytics, utilize the latest technologies to solve challenging problems, create innovative applications from the ground up and understand exactly what it takes to create a reliable Web experience for our customers.<p>* Software QA Engineer - We need a well-rounded QA Engineer.  This person will design and execute tests for web services and applications and then help us automate those cases.<p>We've also got non-technical positions for a Director of Customer Relations (in Austin, TX), Area Sales Managers in multiple cities, and a Senior Accountant.<p>As I mentioned, we just hired an excellent front-end developer from the \"Who's Hiring\" thread a couple months back.  He's loving it here as much as I am.<p>Many of the tech team is an open workspace that has a view of the ocean (<a href=\"http://picplz.com/user/dabent/pic/tpc4v/\" rel=\"nofollow\">http://picplz.com/user/dabent/pic/tpc4v/</a>), and all the Santa Monica offices are blocks from the beach.  They have great benefits, amazing team solving hard problems and a company that's well-funded and earning revenue.<p>If you're interested, send me your resume.  My email is in my profile.",
      "num_comments": null,
      "story_id": 3783657,
      "story_title": "Ask HN: Who is Hiring? (April 2012)",
      "story_url": "",
      "parent_id": 3783657,
      "created_at_i": 1333328507,
      "_tags": [
        "comment",
        "author_dabent",
        "story_3783657"
      ],
      "objectID": "3785688",
      "_highlightResult": {
        "author": {
          "value": "dabent",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "Santa Monica, CA (Los Angeles area) also possibly SF Bay area or other cities, but most jobs are in Santa Monica.<p>TRUECar - Put simply, TrueCar shows consumers how much people actually paid for a particular new car in their area, then guide them to dealers we've certified.  We bring transparency to auto pricing and so far we are getting a solid piece of a huge market.<p>* Java - We are looking for talented Java architects to design and build the technology used to power our production websites, APIs, widgets, and internal <em>tools</em>.  This is a chance for you to join a growing company and build something that's going to need to scale to support millions of users/visitors and provide them with all kinds of data.<p>* Data <em>Analyst</em> - Will work on data management and ensure robust pipelines implemented for a diverse range of analytical products.  You will be utilizing the latest technologies to solve challenging problems and create innovative applications from the ground up.<p>* Data Warehouse Developer - We are looking for a super smart and detail-oriented SQL Database Developer who will support the ETL and Data Modeling processes which feed our data warehouse and MicroStrategy environment.<p>* Senior Designer - Works closely with the Creative Director, VP Product, and Chief Product Officer to provide high-level front-end design in the development of key TrueCar products. This position rapidly visualizes information presentation for the web (and portable devices) and turns that vision into <em>static</em>/functional prototypes. The Designer serves as a member of core product team supporting front-end developers and product owners.<p>* Senior Linux Systems Engineer - Will be involved from the design stage through production troubleshooting, from DNS to networking to application behavior and ultimately responsible for making sure our production systems are reliable and perform well.<p>* Statistician/Data Mining Specialist - Masters or Ph.D. in Statistics, Econometrics, Operations Research, Data Mining, or Biostatistics who will work on a wide range of projects from transaction price modeling, forecasting, to multivariate testing and marketing analytics, utilize the latest technologies to solve challenging problems, create innovative applications from the ground up and understand exactly what it takes to create a reliable Web experience for our customers.<p>* Software QA Engineer - We need a well-rounded QA Engineer.  This person will design and execute tests for web services and applications and then help us automate those cases.<p>We've also got non-technical positions for a Director of Customer Relations (in Austin, TX), Area Sales Managers in multiple cities, and a Senior Accountant.<p>As I mentioned, we just hired an excellent front-end developer from the \"Who's Hiring\" thread a couple months back.  He's loving it here as much as I am.<p>Many of the tech team is an open workspace that has a view of the ocean (<a href=\"http://picplz.com/user/dabent/pic/tpc4v/\" rel=\"nofollow\">http://picplz.com/user/dabent/pic/tpc4v/</a>), and all the Santa Monica offices are blocks from the beach.  They have great benefits, amazing team solving hard problems and a company that's well-funded and earning revenue.<p>If you're interested, send me your resume.  My email is in my profile.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Ask HN: Who is Hiring? (April 2012)",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2013-07-11T18:22:02.000Z",
      "title": "",
      "url": "",
      "author": "bsaul",
      "points": 24,
      "story_text": null,
      "comment_text": "i&#x27;ve been coding in python professionally for 4 years now, and i&#x27;m currently working on the biggest project i&#x27;ve ever worked on.\nto me, being scared of changing the signature of a function because the static analyser will not be able to spot all the places i&#x27;ve used this function is a real problem ( along with incomplete autocomplete ). i do unit test everything, but i&#x27;d like to keep unit tests for things a computer can not theorically do.<p>since i&#x27;m still in the early phase of the project, i know that python expressiveness is an edge, but i&#x27;m looking right now at what&#x27;s going to be the &quot;definitive&quot; language i&#x27;m going to rebuild my product for the next 3 to 4 years.<p>Python badly needs optional typing. really. i&#x27;m pretty sure that would solve both the speed and tooling issues. right now, for me, it starts to become unsuitable as soon as you reach 5-10k lines of code and a team of 2.",
      "num_comments": null,
      "story_id": 6026442,
      "story_title": "Navigating the Postmodern Python World",
      "story_url": "http://www.stephendiehl.com/posts/postmodern.html",
      "parent_id": 6026442,
      "created_at_i": 1373566922,
      "_tags": [
        "comment",
        "author_bsaul",
        "story_6026442"
      ],
      "objectID": "6028007",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "bsaul",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "i've been coding in python professionally for 4 years now, and i'm currently working on the biggest project i've ever worked on.\nto me, being scared of changing the signature of a function because the <em>static</em> <em>analyser</em> will not be able to spot all the places i've used this function is a real problem ( along with incomplete autocomplete ). i do unit test everything, but i'd like to keep unit tests for things a computer can not theorically do.<p>since i'm still in the early phase of the project, i know that python expressiveness is an edge, but i'm looking right now at what's going to be the &quot;definitive&quot; language i'm going to rebuild my product for the next 3 to 4 years.<p>Python badly needs optional typing. really. i'm pretty sure that would solve both the speed and <em>tooli</em>ng issues. right now, for me, it starts to become unsuitable as soon as you reach 5-10k lines of code and a team of 2.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Navigating the Postmodern Python World",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.stephendiehl.com/posts/postmodern.html",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-03-19T17:51:00.000Z",
      "title": "",
      "url": "",
      "author": "gillianseed",
      "points": 10,
      "story_text": null,
      "comment_text": "I'd say that in 9 out of 10 GCC creates faster code than LLVM/Clang (I see typically 5-10% difference in performance oriented code), add to this that LLVM/Clang lacks strong special optimization strategies like PGO (profile guided optimization) then it's a clear win for GCC. GCC also supports more languages and architectures than Clang which simply mirrors the needs of Apple (ObjC, C, C++). If you are on OSX then yes, there's likely little reason for you to use GCC since OSX ships with a (5 year?) old GCC version and also obviously because Clang/LLVM integrates much better with Apple's proprietary XCode.<p>That said I use both, and at work we test our code against both toolchains (and some other compilers aswell). The static analyser in Clang is a welcome addition and the error diagnostics/reporting is top notch so it certainly has strong features even though it falls behind GCC in code optimization.",
      "num_comments": null,
      "story_id": 3724421,
      "story_title": "Talk Of GCC 5.0 To Be Modular, More Like LLVM",
      "story_url": "http://www.phoronix.com/scan.php?page=news_item&px=MTA3MzE",
      "parent_id": 3725002,
      "created_at_i": 1332179460,
      "_tags": [
        "comment",
        "author_gillianseed",
        "story_3724421"
      ],
      "objectID": "3725168",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "gillianseed",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "I'd say that in 9 out of 10 GCC creates faster code than LLVM/Clang (I see typically 5-10% difference in performance oriented code), add to this that LLVM/Clang lacks strong special optimization strategies like PGO (profile guided optimization) then it's a clear win for GCC. GCC also supports more languages and architectures than Clang which simply mirrors the needs of Apple (ObjC, C, C++). If you are on OSX then yes, there's likely little reason for you to use GCC since OSX ships with a (5 year?) old GCC version and also obviously because Clang/LLVM integrates much better with Apple's proprietary XCode.<p>That said I use both, and at work we test our code against both <em>toolc</em>hains (and some other compilers aswell). The <em>static</em> <em>analyser</em> in Clang is a welcome addition and the error diagnostics/reporting is top notch so it certainly has strong features even though it falls behind GCC in code optimization.",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "Talk Of GCC 5.0 To Be Modular, More Like LLVM",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://www.phoronix.com/scan.php?page=news_item&px=MTA3MzE",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    },
    {
      "created_at": "2012-02-01T19:10:43.000Z",
      "title": "",
      "url": "",
      "author": "noblethrasher",
      "points": 3,
      "story_text": null,
      "comment_text": "&#62; For instance, I once saw a Silverlight app that took 20 minutes to initialize because it traversed a tree of relationships using REST. It started out O.K. but as the app grew more complicated it took tens of thousands of requests and an incredible amount of latency.<p>Not that I agree with that particular architecture, but my first question is: why did the Silverlight app discard the knowledge that it had worked hard to discover? If a technician spent 20 minutes figuring out how a thing worked, would he just willfully forget it?<p>&#62; People who are building toy applications can blubber about \"the decoupling of the client from the server\" but the #1 delusion in distributed systems is that you can compose distributed operations the same way you compose function calls in a normal program.<p>The whole idea behind object oriented programming is that you don't compose functions, you let objects pass and respond to messages and record their observations (state).<p>&#62; All of the great distributed algorithms such as Jacobsen's heuristic for TCP and Bittorrent have <i>holistic properties</i> possesed by the system as a whole that are responsible for their success.<p>Meaning that the \"objects\" observe and record information about the world and respond appropriately based on their (recorded) observations. Interetingly enough, Alan Kay said that TCP was one of the few things that was designed well from the start. (Or maybe it was IP, I'm trying to find a source.)<p>&#62;Security is another problem with REST. Security rules are usually about state transitions, not about states. To ensure that security (and integrity) constraints are met, REST applications need to contain error prone code that compares the before and after states to check if the transition is legal. This is in contrast to POX/RPC applications in which it is straightforward to analyse the security impacts of individual RPC calls.<p>That's a good point about  security rules and state transitions but I don't understand the problem, objects are supposed to be responsible for some kind of state and we should let them  worry about their state transitions. Can you provide and example of error prone code that needs to compare the before and after state?<p>------------------------------------------------------------------------------------------------------------------------<p>REST isn't a scam but the tooling (programming languages and frameworks) just aren't there. Our languages, even the so-called object-oriented ones are still based around the idea of calling procedures. REST works when you're dealing with objects that respond to messages, not imperatives.<p>Alan Kay made the case for something like REST in his 1997 OOPSLA keynote[1] (preceding Fielding's dissertation by 3 years). The idea is that in really big systems (distributed over space and time), the individual components need to be smart enough to learn how to interact with the other components because the system is simply too big to accomodate static knowledge (and I say this as a fan of statically typed languages).<p>[1]<a href=\"http://video.google.com/videoplay?docid=-2950949730059754521\" rel=\"nofollow\">http://video.google.com/videoplay?docid=-2950949730059754521</a> at 43:00",
      "num_comments": null,
      "story_id": 3538585,
      "story_title": "What exactly is RESTful programming?",
      "story_url": "http://stackoverflow.com/questions/671118/what-exactly-is-restful-programming",
      "parent_id": 3539011,
      "created_at_i": 1328123443,
      "_tags": [
        "comment",
        "author_noblethrasher",
        "story_3538585"
      ],
      "objectID": "3539412",
      "_highlightResult": {
        "title": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "url": {
          "value": "",
          "matchLevel": "none",
          "matchedWords": []
        },
        "author": {
          "value": "noblethrasher",
          "matchLevel": "none",
          "matchedWords": []
        },
        "comment_text": {
          "value": "> For instance, I once saw a Silverlight app that took 20 minutes to initialize because it traversed a tree of relationships using REST. It started out O.K. but as the app grew more complicated it took tens of thousands of requests and an incredible amount of latency.<p>Not that I agree with that particular architecture, but my first question is: why did the Silverlight app discard the knowledge that it had worked hard to discover? If a technician spent 20 minutes figuring out how a thing worked, would he just willfully forget it?<p>> People who are building toy applications can blubber about \"the decoupling of the client from the server\" but the #1 delusion in distributed systems is that you can compose distributed operations the same way you compose function calls in a normal program.<p>The whole idea behind object oriented programming is that you don't compose functions, you let objects pass and respond to messages and record their observations (state).<p>> All of the great distributed algorithms such as Jacobsen's heuristic for TCP and Bittorrent have <i>holistic properties</i> possesed by the system as a whole that are responsible for their success.<p>Meaning that the \"objects\" observe and record information about the world and respond appropriately based on their (recorded) observations. Interetingly enough, Alan Kay said that TCP was one of the few things that was designed well from the start. (Or maybe it was IP, I'm trying to find a source.)<p>>Security is another problem with REST. Security rules are usually about state transitions, not about states. To ensure that security (and integrity) constraints are met, REST applications need to contain error prone code that compares the before and after states to check if the transition is legal. This is in contrast to POX/RPC applications in which it is straightforward to <em>analyse</em> the security impacts of individual RPC calls.<p>That's a good point about  security rules and state transitions but I don't understand the problem, objects are supposed to be responsible for some kind of state and we should let them  worry about their state transitions. Can you provide and example of error prone code that needs to compare the before and after state?<p>------------------------------------------------------------------------------------------------------------------------<p>REST isn't a scam but the <em>tooli</em>ng (programming languages and frameworks) just aren't there. Our languages, even the so-called object-oriented ones are still based around the idea of calling procedures. REST works when you're dealing with objects that respond to messages, not imperatives.<p>Alan Kay made the case for something like REST in his 1997 OOPSLA keynote[1] (preceding Fielding's dissertation by 3 years). The idea is that in really big systems (distributed over space and time), the individual components need to be smart enough to learn how to interact with the other components because the system is simply too big to accomodate <em>static</em> knowledge (and I say this as a fan of statically typed languages).<p>[1]<a href=\"http://video.google.com/videoplay?docid=-2950949730059754521\" rel=\"nofollow\">http://video.google.com/videoplay?docid=-2950949730059754521</a> at 43:00",
          "matchLevel": "full",
          "matchedWords": [
            "static",
            "analysis",
            "tools"
          ]
        },
        "story_title": {
          "value": "What exactly is RESTful programming?",
          "matchLevel": "none",
          "matchedWords": []
        },
        "story_url": {
          "value": "http://stackoverflow.com/questions/671118/what-exactly-is-restful-programming",
          "matchLevel": "none",
          "matchedWords": []
        }
      }
    }
  ],
  "nbHits": 601,
  "page": 0,
  "nbPages": 1,
  "hitsPerPage": 1000,
  "processingTimeMS": 117,
  "query": "static analysis tools",
  "params": "advancedSyntax=true&analytics=false&hitsPerPage=2000&query=static+analysis+tools&tags=comment"
}